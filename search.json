[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "HEMP Using R",
    "section": "",
    "text": "머리말\n이 책은 Handbook of Educational Measurement and Psychometrics Using R의 번역서입니다."
  },
  {
    "objectID": "chap01.html#개요",
    "href": "chap01.html#개요",
    "title": "1  R 소개",
    "section": "1.1 개요",
    "text": "1.1 개요\n이 장에서는 이 책 전반에 걸쳐 사용하게 될 R 프로그래밍 언어에 대해 간략하게 소개합니다. 먼저 R을 소개하고 독자들에게 R과 RStudio를 모두 다운로드하고 설치하는 방법을 보여줍니다. 이 장의 나머지 부분에서는 RStudio에서 R 코드를 실행하는 방법을 살펴보고 이 책과 함께 제작된 hemp 패키지를 소개합니다. hemp 패키지는 이 책에서 사용되는 데이터 세트와 많은 기능이 포함되어 있습니다. 이 패키지는 또한 이 책에서 사용된 코드를 실행하는 데 필요한 일부 R 패키지를 자동으로 설치합니다. 독자들은 이 장의 “R 패키지” 섹션에서 이 책에서 사용된 R 패키지의 전체 목록을 찾을 수 있습니다."
  },
  {
    "objectID": "chap01.html#r이란",
    "href": "chap01.html#r이란",
    "title": "1  R 소개",
    "section": "1.2 R이란?",
    "text": "1.2 R이란?\n통계계산을 위한 R 프로젝트(https://www.r-project.org)는 통계 계산 및 그래픽을 위한 무료 오픈 소스 언어 및 환경인 R을 지원하고 개발합니다. R은 크로스 플랫폼이며 Windows, Mac OS X 및 다양한 UNIX 타입 플랫폼(예: Linux, FreeBSD, OpenBSD)에서 사용할 수 있습니다. 이 책에서 사용하게 될 최고의 통계 언어 및 통계 환경입니다.\n독자들이 R을 공부하는 데 관심을 갖는 데에는 여러 가지 이유가 있습니다.\n\nR은 무료이며 오픈 소스입니다. R은 무료이기 때문에 누구나 컴퓨터와 인터넷이 연결되어 있으면 R에 접근할 수 있습니다. R은 오픈 소스이기 때문에 통계학자나 컴퓨터 과학자들은 오류(예: 버그나 보안상 결함)를 제거하고 계산 능력을 향상시키기 위해 코드베이스를 완전히 심사할 수 있습니다.\nR은 통계를 위한 계산 환경입니다. 통계, 데이터 마이닝, 기계 학습, 심리측정 논문에서 새로운 방법에 대해 읽을 때 누군가가 R에서 알고리즘 또는 방법을 구현하는 패키지 또는 코드를 이미 작성했을 확률이 높습니다. 저자가 통계 저널에 새로운 방법을 제출하면서 R 패키지를 함께 제공하는 것이 드문 일은 아닙니다. 특별한 소프트웨어를 배울 필요없이 R만 잘 배우면 대부분의 분석을 수행할 수 있습니다.\nR은 놀라운 시각화 기능이 있습니다. 이 책에서는 R 기본 그래픽과 lattice, ggplot2패키지가 포함됩니다.\nR 커뮤니티. R 세계에는 엄청난 수의 패키지가 있고, 이러한 많은 패키지를 개발한 재능 있는 프로그래머가 있습니다. 또한 많은 프로그래머와 사용자 중 다수는 R 메일링 리스트 또는 Stack Overflow(https://stackoverflow.com/)에서 R 코드에 대한 추가적인 도움이나 명확한 설명을 찾는 사용자를 위해 시간을 할애하고 있습니다.\nR에는 훌륭한 통합 개발 환경인 RStudio가 있습니다. R을 지원하는 것 외에도 RStudio는 Python, C/C++, LATEX, Markdown, JavaScript 등도 지원합니다. RStudio는 R을 더 쉽게 배울 수 있도록 해주고 사용자가 좋은 프로그래밍 및 코딩 습관을 가질 수 있도록 도와줍니다.\n\nR을 처음 접할 때, 특히 R을 정기적으로 사용하지 않거나 프로그래밍 경험이 없는 독자들에게는 어렵고 좌절할 수 있습니다. 그러나 R을 열심히 공부하면 데이터를 보다 효율적으로 구성하고 관리하며, 다양한 통계 모델을 실행하고, 고품질의 아름다운 그래프를 생성하고, GUI 통계 프로그램에서 하는 것보다 더 빠르게 보고서를 작성할 수 있습니다. 추가적으로 R의 구문이 측정 및 심리측정 분야에서 사용되는 수학적 표기법을 따르는 경우가 많기 때문에 이 분야의 개념과 방법을 강화하는 데 많은 도움이 됩니다.\n\n1.2.1 R에 대한 접근 방식\n일반적으로 이 책에서는 R 교육에 대해 보수적인 접근 방식을 취합니다. 즉 이 책에서는 일반적으로 R 기본 패키지에 의존합니다. 이렇게 접근하는 이유는 R 코어 팀에서 제공하는 기능이 가장 철저하게 검증된 기능이고, R 코어 팀이 개발에 보수적인 경향이 있기 때문입니다. 하지만, 불행하게도 여기에 제시된 모든 모델에 대해 항상 코어 패키지만 의존할 수는 없습니다. 이러한 상황에서는 우리 분야에서 일반적으로 사용되며 기능이 풍부하고 현재 유지 관리 및 개발중인 패키지를 소개합니다.\nR 교육에 대한 이러한 접근 방식의 단점은 R을 더 쉽게 사용하고, 배우고, 읽을 수 있게 만드는 많은 기능을 가진 패키지(예: tidyverse1, magrittr 등)를 다루지 않는 것입니다. 그러나 독자들이 이 책에서 배우는 내용은 코어 함수를 사용했는지, 데이터 관리에 있어 더 전문화된 패키지를 이용했는지, 또는 자체 함수를 만들어 사용했는지에 관계없이 큰 가치가 있을 것입니다. R 학습에 대해 대안적인 접근 방식에 관심이 있는 독자는 Wickham and Grolemund(2017)를 추천합니다."
  },
  {
    "objectID": "chap01.html#r-다운로드-및-설치",
    "href": "chap01.html#r-다운로드-및-설치",
    "title": "1  R 소개",
    "section": "1.3 R 다운로드 및 설치",
    "text": "1.3 R 다운로드 및 설치\nR을 다운로드 받기 위해서는 아래 CRAN 사이트에 방문하거나 검색 창에 CRAN을 검색해서 찾아가야 합니다.\nhttps://cran.r-project.org/\nCRAN 사이트는 기본 R 시스템의 사전 컴파일된 바이너리와 Windows, Mac, Linux용 패키지를 제공합니다. CRAN 사이트는 사용자가 R을 다운로드할 수 있는 미러(서버)를 자동으로 선택합니다. 사용자가 지리적으로 더 가까운 미러를 직접 선택하려는 경우 CRAN2 목록에서 하나를 지정할 수 있습니다. 예를 들어 보스턴에 거주하는 경우 Pittsburgh 또는 Ohio 미러가 현명한 선택일 수 있습니다. 지리적으로 더 가까운 미러를 선택하면 다운로드 속도가 빨라질 수 있습니다. HTTP 링크보다는 HTTPS 링크를 선택하는 것을 권합니다3.\n미러가 선택되면 R을 다운로드할 수 있는 새 페이지가 열립니다. 플랫폼 별로 R을 다운로드하고 설치하기 위한 지침은 다음과 같습니다.\n\n1.3.1 Windows\nWindows용 R을 다운로드하려면 “Windows용 R 다운로드”를 클릭해야 합니다. 그러면 “Base” 링크가 제공되는 윈도우용 R 페이지가 나오고, R 버전별 웹사이트가 로드되며 여기서 최신 버전의 R을 클릭해 다운로드 받습니다. R 설치 버전이 다운로드 되면 더블 클릭해 설치하고, R이 올바르게 설치된 경우 시작 메뉴에서 R 바로가기를 클릭하면 R 콘솔이 열립니다.\n\n\n1.3.2 Mac\nMac용 R을 다운로드하려면 “Mac OS X용 R 다운로드”를 클릭해야 합니다. 그러면 Mac용 R 페이지가 나오고, “FIles:” 헤더 아래에서 첫 번째 파일에 대한 링크를 클릭해야 합니다. 이 파일이 최신 R 릴리스입니다. 만일 R 4.2.2가 최신 버전인 경우 이 링크는 “R 4.2.2.pkg”라고 합니다. 이 링크를 클릭하면 설치 프로그램이 다운로드 되고, 다운로드가 완료되면 설치 프로그램을 더블 클릭해 R을 설치해야 합니다. R이 설치되면 응용 프로그램에서 R을 찾아 실행할 수 있고, 올바르게 설치된 경우 R 콘솔이 열립니다.\n\n\n1.3.3 Linux\n리눅스용 R을 다운로드하려면 “Linux용 R 다운로드”를 클릭해야 합니다. 그런 다음, Debian, Redhat, SUSE, Ubuntu에 대한 설치 지침 링크가 있는 페이지로 리디렉션됩니다. 다른 리눅스 배포판의 경우, CRAN에 목록이 없기 때문에 배포 이름과 R을 검색하는 것이 좋습니다. 리눅스 및 기타 UNIX 유사 운영체제에서의 R 설치는 Windows 및 Mac 버전과 달리 편집기가 없으며 콘솔 기반 R 프로그램으로만 구성됩니다. R은 터미널에 R을 입력하여 터미널에서 실행할 수 있습니다.\n\n\n1.3.4 RStudio 설치\nRStudio는 R을 위한 통합 개발 환경이며 초보자이든 숙련자이든 모두 R 프로젝트에서 제공하는 R 프로그램으로 작업하는 것보다 RStudio에서 작업할 것을 적극 추천합니다. R 프로그램에서 작업하는 것보다 RStudio에서 작업하는 것이 많은 이점이 있지만 가장 중요한 장점은 모든 운영체제에서 동일한 인터페이스와 경험을 제공한다는 것입니다.\nRStudio는 무료이며 오픈 소스이지만, 유료 상용 버전도 있습니다. 이 책 전반에 걸쳐 무료 오픈 소스 버전을 사용하였습니다. RStudio를 설치하려면 다음 링크를 열어야 합니다.\nhttps://posit.co/download/rstudio-desktop/\n그럼 다음, “All Installers and Tarballs”가 보일 때까지 페이지 하단으로 스크롤 다운해 운영체제에 따라 적절한 설치 프로그램을 선택해 설치합니다. 새로운 R 스크립트는 왼쪽 상단의 파일 메뉴(파일->새 파일->R 스크립트)에서 생성합니다.\n RStudio는 기본적으로 4개의 창으로 나뉩니다. 왼쪽 위 창은 스크립트 편집기가 포함된 소스 창입니다. 이 창에서 R 코드를 입력한 후, “Run” 버튼을 클릭하거나 키보드 단축키(Ctrl+Enter)를 누르면 아래 쪽 콘솔 창으로 명령어가 전송되어 실행됩니다. 왼쪽 아래 창에는 터미널(Terminal)에 쉽게 접근할 수 있는 탭이 있습니다.\n일반적으로 콘솔에 직접 코드를 작성하는 경우는 다시 실행할 필요가 없는 것 위주로 하고, 나중에 다시 실행하려는 코드는 소스 창에 작성한 후 저장하는 것이 좋습니다. 이렇게 하면 RStudio가 열리고 스크립트가 다시 실행될 때마다 모든 코드를 다시 입력하지 않아도 결과가 빠르고 쉽게 생성됩니다.\n오른쪽 위에 있는 환경 창은 R 개체에 대한 정보와 콘솔에서 실행한 코드의 기록을 찾을 수 있습니다. 마지막으로 오른쪽 아래 창에는 현재 작업 디렉토리의 파일 나열되고, 그래프가 표시되며, 코드를 실행할 필요 없이 패키지를 설치하고 로드할 수 있습니다. 또한 도움말 페이지와 JavaScript 기반 시각화와 상호작용할 수 있습니다. 이러한 창의 구성은 사용자가 직접 재구성할 수도 있습니다(예: Tools->Global Options->Pane Layout).\nRStudio에 대한 자세한 내용은 도움말 메뉴(Help->RStudio)를 통해 제공되는 RStudio 문서와 RStudio 웹사이트(https://posit.co/)에서 이용가능한 웨비나, 치트시트, 학습자료 등을 참고하시기 바랍니다."
  },
  {
    "objectID": "chap01.html#r-사용하기",
    "href": "chap01.html#r-사용하기",
    "title": "1  R 소개",
    "section": "1.4 R 사용하기",
    "text": "1.4 R 사용하기\n이 장에서 우리는 R을 사용하는 방법을 자습서와 같이 자세히 다루지는 않습니다. 그러나 이 책을 읽는 독자들이 이전에 R을 사용한 적이 없다고 가정하고 R을 사용할 수 있는 몇 가지 일반적인 방법을 소개하고자 합니다. 다음 장에서는 R을 사용한 다양한 응용 프로그램을 계속해서 소개하고 논의합니다.\nR 프로그래밍 언어는 매우 유연하기 때문에 R에서 주어진 작업을 완료하는 방법은 다양합니다. 즉, 매우 많은 함수(내장 함수 또는 사용자 정의 함수)와 이러한 함수에 필요한 인수(arguments)가 있습니다. 이 책에서 제공하는 모든 코드를 실행해 보는 것을 권하지만 함수의 모든 기능을 기억하고 코드가 실행되는 데 필요한 모든 것을 즉시 이해할 필요는 없습니다.\n외국어나 악기를 배우는 것처럼 R 언어를 배우는 것도 시간이 걸립니다. 따라서 이 책 전반에 걸쳐 제시된 예제를 살펴볼 때 세부 사항에 집착하지 않고 전체 그림에 초점을 맞춰 살펴보시기 바랍니다. R을 배우는 동안 인내심을 갖고 공부한다면 적절한 보상을 받을 것입니다.\n명시적으로 언급하지 않는 한, 모든 R 코드는 소스창에서 작성되고 실행 버튼, 코드 메뉴 또는 단축키를 통해 실행되며 콘솔에 직접 입력되지 않는다고 가정합니다. 이를 통해 필요할 때마다 자신의 프로젝트를 위해 재사용하고, 수정할 수 있는 R 코드 스크립트를 작성할 수 있습니다.\n\n1.4.1 기본 R 사용법\n이 책에 있는 R 코드는 코드 청크(chunks)로 작성됩니다. 소스 창에 입력하기 원하는 입력 청크는 다음과 같습니다.\n\n2+2\n\n출력 청크는 다음과 같습니다.\n\n\n[1] 4\n\n\n입력 청크는 음영이 있는 반면 출력 청크는 없습니다. 따라서 여러분들은 입력 청크에 있는 내용을 입력하시고, 출력 청크를 입력하시면 안 됩니다.\nR에서 코드가 수행하는 작업, R 스크립트 또는 함수의 목적에 대한 설명은 해시태크(#)로 지정하시면 됩니다. 여러 줄의 코드를 실행할 때 #으로 시작하는 모든 줄은 R에서 주석으로 간주되며 실행되지 않습니다. 이것은 코드의 앞이나 뒤에 주석을 추가할 수 있기 때문에 유용한 기능입니다. 나중에 코드를 다시 사용할 때 코드의 목적을 기억하는 데 도움이 됩니다.\n다음 예제에서 R은 주석이기 때문에 첫 번째 줄은 무시하지만 두 번째 줄을 실행합니다.\n\n# 다음 R 코드는 2와 2의 합을 계산합니다.\n2+2\n\n[1] 4\n\n\n소스 창에 위의 청크를 입력하거나 복사하여 붙여넣고 두 줄을 클릭 앤 드래그해서 블럭을 씌운 다음 “실행”을 클릭하면 콘솔에 다음 결과 표시됩니다.\n\n# 다음 R 코드는 2와 2의 합을 계산합니다.\n2+2 \n\n[1] 4\n\n\n콘솔은 소스 분할창에서 전송된 입력을 되풀이해 줍니다. 일반적으로 콘솔의 입력은 명령 프롬프트인 “>”가 앞에 옵니다. 하지만 이 책에서는 출력을 더 쉽게 읽을 수 있도록 출력 청크와 입력 명령에서 “>”를 제거했습니다. 마지막으로 주목해야 할 점은 위의 예제와 같이 출력 앞에 [1]이 오는 경우가 있습니다.\nR은 계산기처럼 더하기, 빼기, 곱하기, 나누기를 할 수 있습니다. 예를 들면,\n\n6+20\n89-53\n424*68\n1110/37\n\n또한 R은 로그 연산과 같은 수많은 수학 함수를 내장하고 있습니다. 다음 코드는 10의 자연로그를 계산합니다.\n\nlog(10)\n\nR에서 함수의 출력을 변수에 저장하려면 할당연산자 ’<-“를 사용합니다. 변수 x에 1을 할당하려면, 다음과 같이 입력해야 합니다.\n\nx <- 1\n\nx를 프린트하려면 x를 입력하고 실행시키면 R은 1을 반환합니다.\n\nx <- 1\nx\n\n[1] 1\n\n\nR에서 변수는 일반적으로 객체라고 부릅니다. 객체는 단일값, 벡터(값 모음), 데이터 프레임(전체 데이터 세트), 통계 모델의 결과값, 그래프 등을 포함할 수 있습니다. R의 거의 모든 것은 할당 연산자를 사용해 저장할 수 있으며 R의 모든 것이 객체입니다. 이 책에서 가금 모델의 결과값을 객체에 저장하는 것을 언급합니다. 이것은 위 청크에서 객체 x로 1을 저장했다고 말하는 것과 같습니다.\n여러분이 반드시 알아야 할 R의 중요한 특징은 R이 대소문자를 구분한다는 것입니다. 따라서 소문자로 작성된 R 코드는 대문자로 작성된 동일한 코드를 참조하지 않습니다. x를 1로 정의한 이전 예제에서 X가 x와 동일한 결과를 반환하는지 확인합니다. X를 입력하고 코드를 실행하면 다음과 같습니다.\n\nX\n\nR은 에러 메시지로 이 객체가 존재하지 않음을 나타냅니다. 그러나 x를 입력하고 코드를 실행하면 아래와 같이 예상대로 1을 출력합니다.\n\nx\n\n[1] 1\n\n\nx을 여러 값을 포함하는 벡터로 바꾸려면 결합(combine)을 의미하는 c 함수를 사용합니다.\n\nx <- c(1,5,3,6,9)\n\n이렇게 하면 1, 5, 3, 6, 9가 x 객체에 저장됩니다. 또한 이 작업은 숫자 1만 포함하였던 이전에 정의된 x를 대체하게 됩니다. 이것은 R에서 기존 객체를 덮어쓸 수 있는 방법입니다. 이렇게 기존 객체를 덮어쓰는 방법은 때때로 객체에 할당된 것이 무엇인지 잊어버릴 수 있기 때문에 코드 오류가 발생할 수 있습니다. 따라서 기존 객체를 덮어쓰지 않는 것이 좋습니다. 덮어쓰는 대신 각 객체에 대해 고유한 이름을 부여하는 것이 좋습니다. R에서 객체 이름을 지정하는 일반적인 규칙은 다음과 같습니다.\n\n모든 문자를 소문자로(예: mydata)\n모든 문자를 대문자로(예: MYDATA)\ncamelCase 사용하기(예: myData)\n문자와 숫자의 조합(예: mydata10)4\n단어와 숫자를 구분하기 위한 마침표 사용(예: mydata.10)5\n단어와 숫자를 구분하기 위한 밑줄 사용(예: my_data)6\n\n객체 명명으로 인한 오류를 최소화하기 위해서는 특정 명명 규칙을 선택하고 R 스크립트 전반에서 일관되게 사용하는 게 좋습니다.\n위의 예에서, x<-c(1,5,3,6,9)는 숫자형 벡터로 정의되었습니다. 문자열을 포함하는 벡터를 객체로 저장할 수 있는데 예를 들면, 참자가의 성별에 대한 정보를 포함하는 성별(gender)이란 변수를 만들고 싶다면 다음과 같이 하면 됩니다.\n\ngender <- c(\"male\",\"male\",\"male\",\"female\",\"female\")\n\n기본적으로 R은 이 정보를 문자형 벡터로 저장합니다. 가끔 R에서 수행하는 심리측정 모델 및 분석을 위해 이러한 숫자 및 문자 벡터를 요인(factor)으로 저장해야 합니다.\n\nx_f <- as.factor(x)\ngender_f <- as.factor(gender)\n\n여러 객체를 함께 결합하는 것도 가능합니다. 예를 들어, 두 객체(예: y 그리고 z)는 다음과 같이 새로운 객체(예: yz)로 결합될 수 있습니다.\n\ny <- c(9,3,4)\nz <- c(2,6,3)\nyz <- c(y,z)\n\nR에서 작업을 수행하는 객체를 함수라고 부릅니다. 함수는 인수(argument)를 받아 하나 이상의 값을 반환합니다. R 함수를 사용하기 위한 일반적인 구문은 다음과 같습니다.\n\n함수(인수1, 인수2, ....)\n\n여기서 함수는 c, as.factor, log 등일 수 있습니다. 인수1과 인수2는 첫 번째, 두 번째 인수를 나타내고, …은 추가 인수를 나타냅니다. 통계 및 심리측정 분석에 자주 사용되는 R 함수는 <표 1.1>과 같습니다.\n\nR 함수\n\n\n\n\n\n\n함수\n의미\n\n\n\n\nabs(x)\nx의 절댓값\n\n\nexp(x)\nx의 지수\n\n\nlog10(x)\n밑이 10인 로그 x\n\n\nsqrt(x)\nx의 제곱근\n\n\nx^y\nx의 y제곱\n\n\ncor(x,y)\nx와 y의 상관\n\n\ncor(x)\nx의 상관행렬\n\n\nvar(x)\nx의 분산행렬\n\n\nsd(x)\nx의 표준편차\n\n\nmean(x)\nx의 평균\n\n\nmedian(x)\nx의 중앙값\n\n\nsum(x)\nx의 합\n\n\nmax(x)\nx의 최댓값\n\n\nmin(x)\nx의 최솟값\n\n\nsort(x)\nx를 오름차순으로 정렬\n\n\napply(x,1,function)\nx에서 각 행에 대해 함수 실행\n\n\napply(x,2,function)\nx에서 각 열에 대해 함수 실행\n\n\nifelse(x==y,yes,no)\nx와 y가 같다면, yes를 실행하고 그렇지 않으면 no를 실행\n\n\n\n지금까지 사용한 함수에서는 단일 인수만을 전달했습니다. 그러나 많은 함수들은 하나 이상의 인수를 사용합니다. 예를 들어, log 함수를 사용하면 밑이 10이란 것을 두 번째 인수로 전달하면 밑이 10인 로그를 계산할 수 있습니다.\n\nlog(10, base=10)\n\n대부분의 함수들에서, 저자는 해당 함수가 어떻게 사용되는지 설명하기 위해 예제를 포함하고 있습니다. 이러한 예제는 example 함수를 사용해 다음과 같이 볼 수 있습니다.\n\nexample(log)\n\n\n\n1.4.2 R 패키지\n관련된 R 함수끼리는 종종 R 패키지나 라이브러리로 결합합니다. R을 설치하면 다양한 통계 모델을 실행하고, 시각화를 만들고, 데이터를 관리할 수 있는 패키지와 함수들이 제공됩니다. 그러나, 특별한 분석(예: 확인적 요인분석, 문항반응이론)을 수행하거나, 더 발전된 시각화 프레임워크를 이용하거나, 데이터를 더 효율적으로 관리하거나 정리하기 위해 추가적으로 패키지를 설치할 필요가 있습니다. 이러한 패키지 중 다수는 전 세계의 다양한 통계 및 계산 전문가가 작성했으며 R에 대한 경험을 크게 향상시키고 계산 속도를 향상시킵니다.\nR 패키지의 저자가 호스팅할 수 있는 공통의 저장고는 CRAN, GitHub, Bioconductor7가 있습니다. 대부분의 패키지가 CRAN에 있고, 패키지를 설치하기 위해서는 install.packages 함수를 사용합니다. 예를 들면, 제5장부터 제7장까지에서 사용되는 문항반응이론과 관련된 패키지인 mirt 패키지를 설치하려면 다음과 같은 명령을 실행합니다.\n\ninstall.packages(\"mirt\")\n\n패키지를 설치하고 나면 패키지를 제거하거나 새로운 R 버전을 설치하지 않는 한 install.packages 함수를 다시 실행할 필요가 없습니다. 가끔 R 패키지의 저자가 새로운 함수를 추가하거나 기존 함수의 버그를 고치기 위해 업데이트를 하기도 합니다. 패키지가 CRAN에 업데이트 되면 update.packages 함수를 이용해 최신의 업데이트를 얻을 수 있습니다. 여러분의 컴퓨터에 기존 패키지가 설치되어 있다고 가정하고 mirt를 업데이트하려면 다음과 같이 명령어를 작성하면 됩니다.\n\nupdate.packages(\"mirt\")\n\n패키지가 설치되면 패키지에 있는 함수가 현재 R 세션에서 사용될 수 있도록 패키지를 활성화해야 합니다. mirt 패키지를 활성화하는 방법은 다음과 같습니다.\n\nlibrary(\"mirt\")\n\nmirt 패키지에 대한 자세한 정보를 찾으려면 오른쪽 아래 창의 검색 표시줄에 mirt를 입력하거나 R 콘솔에서 다음과 같이 입력할 수 있습니다.\n\nlibrary(help=mirt)\n\nmirt 패키지에 있는 모든 함수 목록을 보기 원하면 다음과 같이 입력하시면 됩니다.\n\nls(\"package:mirt\")\n\n그리고, mirt 패키지에 있는 데이터 세트를 보려면\n\ndata(package=\"mirt\")\n\nGitHub(https://github.com)는 소프트웨어 개발 플랫폼입니다. 많은 R 개발자들이 GitHub를 사용하여 패키지를 개발하고 나중에 CRAN에 제출합니다. 또한 일부 개발자는 CRAN에 올리지 않고, GitHub에 영구적으로 호스팅합니다. 이는 CRAN이 R 패키지를 만들고 유지하는 데 엄격한 정책을 가지고 있기 때문입니다. 일반적으로 CRAN에 있는 패키지는 안정적인 버전으로 간주할 수 있는 반면, GitHub에 있는 패키지는 개발중인 패키지이거나 베타 버전일 수 있습니다.\nGitHub에 있는 패키지를 설치하기 위해서는 우선 devtools 패키지를 설치하고 활성화시켜야 합니다(Wickham & Chang, 2017).8\n이 책 전반에 걸쳐 사용되는 패키지는 현재 GitHub에 저장되어 있는 hemp 패키지입니다. hemp 패키지는 이 책의 동반 패키지이며, 이 책에서 사용된 모든 데이터 세트와 분석 수행, 그래프 생성에 필요한 함수를 포함하고 있습니다. 또한 hemp 패키지는 이 책에서 사용되는 다른 패키지 중 일부를 설치하고 로딩하는 메타 패키지의 역할을 합니다.\nhemp 패키지를 설치하고 활성화하는 방법은 다음과 같습니다.\n\ninstall_github(\"cddesja/hemp\")\nlibrary(\"hemp\")\n\nhemp 패키지 외에 이 책에서 사용되는 패키지 목록은 <표 1.2>와 같습니다. <표 1.2>는 패키지명, 목적, 버전 번호가 제시되어 있습니다. hemp 패키지를 제외한 모든 패키지는 CRAN에서 이용가능합니다.\n\n이 책에서 사용된 패키지 목록\n\n\n패키지명\n목적\n버전\n\n\n\n\nboot\n부트스트래핑\n1.3-20\n\n\ndifR\n차별기능문항\n4.7\n\n\nequate\n동등화\n2.0.6\n\n\nfaoutlier\n영향점 감지 및 시각화\n0.7.3\n\n\nGPArotation\n요인분석의 회전\n2014.11-1\n\n\nlattice\n격자 그래프\n0.20-38\n\n\nlavaan\n잠재변인모델링\n0.5-23.1097\n\n\nlme4\n일반 및 일반화 혼합효과 모형\n1.1-13\n\n\nmirt\n문항반응이론\n1.25\n\n\npsych\n일반 심리측정\n1.75\n\n\nsemPlot\n경로 다이어그램 시각화\n1.1\n\n\nshiny\nR용 웹 응용프로그램\n1.0.5\n\n\nhemp\n일반 심리측정\n0.1.0\n\n\n\n각 장의 예제 코드를 실행하기 전에 hemp 패키지와 각 장의 시작 부분에서 언급된 패키지를 로드해야 합니다. 그렇지 않으면 예제를 실행할 때 오류 메시지가 발생합니다.\n이 책 전반에 걸쳐 사용된 예제 R 코드는 아래 링크에서 압축 파일로 다운로드 받을 수 있습니다.\nhttp://bit.ly/hemp_code\n\n1.4.2.1 마스킹된 함수\n때때로 R의 두 패키지가 동일한 함수를 포함하고 동일한 R 세션에서 둘다 활성화되면 두 번째로 활성화된 패키지가 첫 번째 패키지의 함수를 덮어쓰거나 마스킹합니다. 예를 들면, lme4와 mirt는 모두 fixef라는 함수가 포함되어 있습니다. 패키지가 활성화될 때 이에 관한 메시지가 콘솔에 뜨는데 놓치기 쉽습니다. 두 패키지가 활성화될 때 다음과 같이 입력합니다.\n\n?fixef\n\n그러면, RStudio 오른쪽 하단 창에서 fixef 함수의 도움말 페이지를 선택하라는 메시지가 표시됩니다. lme4의 fixef 함수를 사용하려 했는데 mirt를 나중에 활성화한 경우 fixef 함수를 실행시키면 오류 메시지를 받게 됩니다.\n\n# Error: Only applicable to MixedClass and SingleGroupClass objects\n\n이것은 lme4에서 fixef 함수를 사용하려 하지만 R은 mirt의 fixef 함수를 사용하고 있음을 의미합니다. 이러한 문제를 예방하기 위해 이중 콜론 기호(::)를 사용하여 다음과 같이 해당 패키지 함수에 직접 접근할 수 있습니다.\n\nlme4::fixef(x)\n\n이를 통해 mirt나 다른 패키지를 나중에 활성화하여도 lme4에서 fixef 함수를 바로 호출할 수 있습니다.\n이 책에 있는 R 패키지 중 일부는 동일한 함수 이름을 가지고 있기 때문에 패키지 로딩 순서로 인해 위와 유사한 오류 메시지가 표시될 수 있습니다. 만일 그런 경우가 생기면 함수가 다른 함수에 의해 가려지고 있는지 확인하는 것이 좋습니다. 이를 확인하려면 lme4의 fixef 함수와 같이 위에서 설명한 대로 “package_name::function_name”으로 입력하면 됩니다.\n\n\n\n1.4.3 데이터 할당 및 읽기\nR 패키지의 저자는 패키지에서 사용할 수 있는 함수를 보여주기 위해 예제 데이터를 포함시키는 경우가 많습니다. 패키지가 설치되면 예제 데이터 세트도 패키지의 함수와 함께 설치됩니다. 이러한 데이터 세트를 사용하려면 패키지를 활성화 해야 합니다. 일반적으로 패키지가 활성화되면 예제 데이터 세트도 자동으로 활성화됩니다.\n데이터 세트가 자동으로 활성화되지 않는 경우, data 함수를 사용합니다. 예를 들어 다음과 같이 hemp 패키지에 있는 interest 데이터 세트(cognitive, personality, and vocational interest inventory)를 활성화할 수 있습니다.\n\nlibrary(hemp)\ndata(interst)\n\n추가적으로 hemp 패키지의 HSQ 데이터 세트를 추가적으로 활성화하려면 다음과 같이 입력하면 됩니다.\n\ndata(HSQ)\n\n현재 활성화 된 데이터 세트와 우리가 만든 객체를 보려면, ls 함수를 사용하면 됩니다.\n\nls()\n\nR 데이터 세트를 Excel(또는 텍스트 에디터)에서 읽을 수 있도록 스프레드 시트로 내보내고 저장하려면 write.csv 함수를 사용합니다. 다음 예에서, interest 데이터 세트를 “interest.csv”라는 스프레드 시트로 저장합니다. interest 데이터 세트에 행이름이 변수로 추가되지 않도록 row.names=FLASE라는 인수를 지정합니다.\n\nwrite.csv(interest, file=\"interest.csv\", row.names=FALSE)\n\n이 절차는 작업 디렉토리에 “interest.csv” 파일을 저장합니다. interest.csv 파일이 저장된 위치(즉, 작업 디렉토리)를 찾으려면 다음과 같이 입력합니다.\n\ngetwd()\n\nRStudio 메뉴(Session -> Set Working Directory -> Choose Directory)를 통해 작업 디렉토리 위치를 변경할 수 있습니다. R에서 코드를 실행하기 전에 작업 디렉토리를 설정하는 것을 좋은 생각입니다. 데이터, 모델 결과, 플롯 등을 저장할 때 파일 위치를 명시적으로 지정하지 않으면 저장 위치를 알 수 없기 때문입니다.\n스프레드시트(예: .csv 파일) 데이터는 read.csv 함수를 이용해 R로 다시 읽을 수 있습니다. interest.csv 파일을 R에서 다시 불러오는데 헤더 행(파일의 첫 번째 행에 변수 이름이 포함되는 경우)이 있음을 지정하고 모든 문자열을 요인(factors)이 아닌 문자 벡터로, 그리고 객체 이름은 interest_new로 저장하기를 원합니다.\n\ninterest_new <- read.csv(\"interest.csv\", header = TRUE, stringsAsFactors = FALSE)\n\ninterest.csv 파일이 윈도우 컴퓨터의 Desktop 폴더(예: “C:\\Users\\User\\Desktop\\interest.csv”)에 있다고 가정합니다9. 파일의 전체 경로를 보려면, 윈도우 운영 체제 사용자는 파일을 마우스 오른쪽 버튼으로 클릭하고 “속성(Properties)”을 선택할 수 있습니다. OS X를 사용하는 독자는 파일을 마우스 오른쪽 버튼을 클릭하고 “정보 입수(Get Info.)를 선택할 수 있습니다. 아래 예에서 파일 경로의 백슬래시(\\)를 슬래시(/)로 바꿉니다. 그렇지 않으면 R이 파일 경로를 제대로 읽을 수 없습니다. 그런 다음 read.csv 함수에서 전체 파일 경로를 다음과 같이 지정합니다.\n\ninterest_new <- read.csv(\"C:/Users/User/Desktop/interest.csv\", header = TRUE, stringsAsFactors = FALSE)\n\n만일 가져오기 과정에 문제가 있는 경우, R 콘솔은 일반적으로 R이 파일을 찾거나 제대로 읽을 수 없다는 오류 메시지를 표시합니다. 스프레드 시트 외에도 foreign 패키지의 read.spss와 read.xport 함수를 이용해 SPSS 및 SAS XPORT 파일을 읽어 올 수도 있습니다. 이 함수에 관한 더 자세한 내용은 다음 명령을 사용하여 찾을 수 있습니다.\n\nlibrary(\"foreign\")\n?read.spss\n?read.xport\n\n이 책에서 사용하는 모든 데이터 세트는 hemp 패키지에 속해 있기 때문에 이 주제에 관해 더 언급하지 않겠습니다. 다만, 외부 데이터를 R로 읽는 방법에 대해 자세히 알고 싶은 독자는 “the Cookbook for R”10과 “the Stat Methods”11 웹사이트의 도움을 받을 수 있습니다.\n\n\n1.4.4 데이터 다루기\nR에서 데이터를 읽거나 활성화한 후에는 데이터의 내용과 구조를 살펴보는 것이 중요합니다. head 함수를 이용하여 데이터의 첫번째 행부터 볼 수 있습니다. 다음 예에서는 hemp 패키지에 있는 rse 데이터 세트의 처음 세 행을 봅니다(hemp 패키지가 이미 활성화되어 있는 것을 가정함).\n\nlibrary(hemp)\n\nLoading required package: psych\n\n\nLoading required package: lattice\n\n\nLoading required package: lavaan\n\n\nThis is lavaan 0.6-16\nlavaan is FREE software! Please report any bugs.\n\n\n\nAttaching package: 'lavaan'\n\n\nThe following object is masked from 'package:psych':\n\n    cor2cov\n\n\nLoading required package: mirt\n\n\nLoading required package: stats4\n\n\nLoading required package: lme4\n\n\nLoading required package: Matrix\n\n\n\nAttaching package: 'lme4'\n\n\nThe following object is masked from 'package:mirt':\n\n    fixef\n\n\nLoading required package: reshape2\n\n\nLoading required package: boot\n\n\n\nAttaching package: 'boot'\n\n\nThe following object is masked from 'package:lattice':\n\n    melanoma\n\n\nThe following object is masked from 'package:psych':\n\n    logit\n\n\nLoading required package: equate\n\nhead(rse,3)\n\n  Q1 Q2 Q3 Q4 Q5 Q6 Q7 Q8 Q9 Q10 gender age source country person\n1  2  2  3  3  2  2  3  3  3   3      1  10      1      IN      1\n2  2  2  0  2  1  1  1  1  0   0      1  16      1      US      2\n3  1  1  0  1  0  0  0  0  0   0      2  17      1      NL      3\n\n\n만일 표시할 행 수가 지정되지 않으면 head 함수는 데이터 세트에서 처음 6개 행을 반환합니다. tail 함수를 사용해 데이터 세트의 마지막 6개 행을 볼 수도 있습니다.\n\ny\nytail(rse)\n\nrse 데이터 세트는 데이터 프레임으로 알려진 형식입니다. 데이터 프레임에서 변수 이름 전체 목록을 확인하려면 names 함수를 사용할 수 있습니다.\n\nnames(rse)\n\n [1] \"Q1\"      \"Q2\"      \"Q3\"      \"Q4\"      \"Q5\"      \"Q6\"      \"Q7\"     \n [8] \"Q8\"      \"Q9\"      \"Q10\"     \"gender\"  \"age\"     \"source\"  \"country\"\n[15] \"person\" \n\n\n데이터 프레임의 특정 변수에 접근하려면 “데이터 프레임 이름$변수 이름”을 입력합니다. 예를 들면, country 변수의 모든 응답에 접근하고 출력하려면 다음과 같이 입력하면 됩니다.\n\nrse$country\n\n   [1] IN US NL GB AU US US DE HK US CA US US US US US FI US US AU PK CA US US\n  [25] DE US US LT US GB CA US GB GB US US US GB GB A2 US US US US PH GB PT RU\n  [49] GB US US US US AU CA BR US GB US FI US SK US US GB CA FR US HK FI US US\n  [73] US US US US US ZM GB CA US IN GB PH US IT US US PE US US US ID SE PL AU\n  [97] US GB US PH GB US GB NZ GB US US CA US CA SE GB US TR US US AU US GB BE\n [121] US US US CA IN GB GR DE GB AU GB NG US US LT US GB SG US US US RU CA AU\n [145] US US HK SE US US BR CZ NL US US US US US US AU GB NL US CY DO US US GB\n [169] US AU GB US US US US ES CA US ZA GB GB AE BA US US KR SE GB CA US CA TH\n [193] GB IN AU PH SG US US IN US US FI AU EE US CA US US US GB CZ CA GB CA NO\n [217] US US GB US US CH IE US IN US LT AU US PK US GE JO US SG VE GB US US US\n [241] FR DE LT US IT GB FI US GB US US CA JM IN US US GB AU US US US IN US US\n [265] US SE US IN US MX US US US US US ZA ID PT GB US US AU CA GB US US GB GB\n [289] GB AU US US ZA GB CA PH US SE IN US PS US US US MX US FI AU US CA US US\n [313] US GB US PH AU US AU CA US GB GB AU GB US AU AU US GB ZA RS US PH US CA\n [337] US CA ZA AU GB US US CA US US US US US US US NP SE US GB US US US US US\n [361] GB SG RO GB GB DE DE US US AU US PK US US GB US US ZA ET SG JE KR GB US\n [385] US AU US US US NZ MT KE CA US US SE CA GB KR CA AU DE GB PL US US US US\n [409] US FI US UG SG AU GB GB GB CA US GB GB CA US TW CA US US US US US TR US\n [433] GB US US US CA US US US US DE US GB US PH CL US ES US US PK US US US US\n [457] US TR GB CA US US PH US US GB US US US US US US US US US AU GB GB US US\n [481] SG US GB US US CR HK US CA US US GB US GB US GB AU US US US US US US US\n [505] NL US US GB TT US US BH PH FR DE US IE JO HR US GB AU RU NL CH IN US RO\n [529] US US US ES US ES GB AU US GB US US US US CA US NZ TW GB US US US ET GB\n [553] US GB US TR A2 US IE US US US US US ZA SG US US US US US ZA US GB CA US\n [577] GB ZA US US IN GB IN IE CA EG US US GB US US US DK AU US US GB CA BR US\n [601] US FR US US US SA ID US GB US US JP SG GB AU TR US US US US GB US US US\n [625] GB PH US IN IT US US EE US US US AU US US MX US IN US PH US MY US US CA\n [649] GB US US US GB SE US US US IE US US GB FI AU AU KR KR US US US US US AR\n [673] US US IN CA US GB GB US GB AU UA FR ES CA US US GB AU CA US US US GB AU\n [697] US RS MX US PT US US IN US US US US PH US CA GB KE IN HK US US US US SG\n [721] US US GB GB CA AL US IN US GB AU US US GB US US US US CA TT CA GB US US\n [745] US US US ES IR GB US US SG US US US CA US US US US GB US HT US US US US\n [769] CA FI CA US US PH US GB CA US US MX IE NO PK US GB US GB US GB GB US AU\n [793] CA GB US GB BR US US US ZA GB US AU AU AU US US GB NZ US US US GB US GB\n [817] GB RU US GB US GB JM US US US GB US US US GB PH US GB BR PL US HK US US\n [841] US US GB CA US US US US US AE US US US GB IN US GB US US MY AU US TW GB\n [865] IN US GB GB CA US FI EG US US US US US PT AU US US US BE US NL GB ZA PH\n [889] NZ US GB US US US GB US GB NL US US US TH US GB US RS NO FI CA SG PK HK\n [913] GB NZ GB AU AU AU BG US IN AU CA DK US US US US US IT US US HK DE US FR\n [937] GB US CA US SI PH US GB US JM US US US US US GB US US US CA US US SG US\n [961] MY US HK CZ US US IN GB IQ IQ US IN US US US US JP US AU US EE GB US US\n [985] US PH US SG US US US GB PH IN US NO AU US UA US\n76 Levels: A2 AE AL AR AU BA BE BG BH BR CA CH CL CR CY CZ DE DK DO EE ... ZM\n\n\nrse 데이터 세트에서 변수의 구조를 확인하려면 str 함수를 사용하면 됩니다.\n\nstr(rse)\n\n'data.frame':   1000 obs. of  15 variables:\n $ Q1     : int  2 2 1 2 2 3 2 3 0 2 ...\n $ Q2     : int  2 2 1 2 2 3 2 3 3 2 ...\n $ Q3     : int  3 0 0 2 2 3 2 3 3 2 ...\n $ Q4     : int  3 2 1 2 2 3 2 3 3 2 ...\n $ Q5     : int  2 1 0 2 1 2 2 3 3 2 ...\n $ Q6     : int  2 1 0 1 1 2 1 2 3 2 ...\n $ Q7     : int  3 1 0 1 1 2 1 2 3 1 ...\n $ Q8     : int  3 1 0 1 1 3 1 2 3 1 ...\n $ Q9     : int  3 0 0 1 0 3 2 1 3 1 ...\n $ Q10    : int  3 0 0 1 1 3 2 2 3 1 ...\n $ gender : int  1 1 2 1 1 2 2 1 1 2 ...\n $ age    : int  10 16 17 36 15 40 0 30 0 39 ...\n $ source : int  1 1 1 3 3 3 1 1 3 1 ...\n $ country: Factor w/ 76 levels \"A2\",\"AE\",\"AL\",..: 34 73 49 26 5 73 73 17 29 73 ...\n $ person : int  1 2 3 4 5 6 7 8 9 10 ...\n\n\n출력결과는 country 변수를 제외한 모든 변수가 정수( int)인 반면 country 변수는 요인(Factor)임을 보여줍니다. 앞에서 변수를 문자 변수에서 요인 변수로 변환하는 방법에 대해 살펴보았습니다. 요인을 다시 문자 변수로 변환하려면 as.character 함수를 사용합니다. 다음 예에서는 country 변수를 문자 변수로 변환하여 rse 데이터 세트의 원래 country 변수를 이 새 문자 변수로 바꿉니다.\n\nrse$country <- as.character(rse$country)\n\n변환을 수행한 후 str 함수 또는 class 함수를 이용해 변경사항을 확인할 수 있습니다. 예를 들어, rse$country가 이제 문자 벡터임을 확인할 수 있습니다.\n\nstr(rse$country)\nclass(rse$country)\n\n기존 데이터 세트에 새 변수를 추가하려면 다음과 같이 입력합니다.\n\nrse$id <- 1:nrow(rse)\nhead(rse)\n\n이렇게 하면 새 변수 id가 추가되고 1부터(“:”은 시퀀스에서 “through”의 줄임말임) rse 데이터 세트의 행수(nrow)까지 값이 할당됩니다. id 변수는 rse 데이터 세트의 끝에 추가됩니다(마지막 열).\n데이터 세트의 변수를 삭제하려면 변수에 NULL 값을 할당합니다.\n\nrse$id <- NULL\n\n데이터 프레임은 행렬처럼 인덱싱할 수 있습니다. 행렬은 행 번호, 쉼표, 열 번호를 지정하여 인덱싱합니다. 예를 들어, 2행 4열에 해당하는 값을 추출하려면 다음과 같이 입력합니다.\n\nrse[2, 4]\n\n[1] 2\n\n\n마찬가지로 2행에 대해 3열부터 5열까지 출력하려면 다음과 같이 입력합니다.\n\nrse[2, 3:5]\n\n  Q3 Q4 Q5\n2  0  2  1\n\n\n3:5는 3, 4, 5를 줄여쓴 것입니다. 이것은 결합 함수를 를 사용하여 지정할 수도 있습니다.\n\nrse[2, c(3,4,5)]\n\n  Q3 Q4 Q5\n2  0  2  1\n\n\n변수 이름을 지정하여 열을 인덱싱할 수도 있습니다. 4번째 행의 age 변수를 보려면 다음과 같이 입력하면 됩니다.\n\nrse[4, \"age\"]\n\n[1] 36\n\n\n또는\n\nrse$age[4]\n\n[1] 36\n\n\n대만(TW) 수험생의 모든 변수에 대한 응답을 보려면 다음과 같이 입력합니다.\n\nrse[rse$country == \"TW\",]\n\n    Q1 Q2 Q3 Q4 Q5 Q6 Q7 Q8 Q9 Q10 gender age source country person\n424  3  3  3  3  3  3  2  2  3   3      2  55      1      TW    424\n546  3  2  0  2  2  2  2  2  1   1      1  20      1      TW    546\n863  2  2  3  2  2  3  3  2  3   3      1  31      1      TW    863\n\n\n==는 country가 TW인 경우 TRUE로 평가되고 아닌 경우는 FALSE로 평가되는 이항 연산자입니다. 위의 코드는 country==“TW”를 TRUE로 평가하는 모든 행을 선택합니다. 데이터 필터링을 계속하기 위해 “&” 기호(“and”를 나타내는 논리 연산자)를 사용하여 35세 미만인 대만 출신의 수험생만 살펴봅니다.\n\nrse[rse$country == \"TW\" & rse$age < 35,]\n\n    Q1 Q2 Q3 Q4 Q5 Q6 Q7 Q8 Q9 Q10 gender age source country person\n546  3  2  0  2  2  2  2  2  1   1      1  20      1      TW    546\n863  2  2  3  2  2  3  3  2  3   3      1  31      1      TW    863\n\n\n만일 데이터에 오류가 있다면 인덱싱을 활용해 수정할 수 있습니다. 예를 들어, 수험생 424번의 나이가 실제로는 55세가 아닌 35세여야 한다는 것을 알았다면 이 값을 다음과 같이 업데이트할 수 있습니다.\n\nrse[rse$person == 424, \"age\"]\n\n[1] 55\n\nrse[rse$person == 424, \"age\"] <- 35\nrse[rse$person == 424, \"age\"]\n\n[1] 35\n\n\n데이터는 종종 와이드 (tidy)형식으로(예: 각 행은 여러 문항 또는 변수에 대한 단일 대상의 측정 값임) 저장되지만 이 책에 제시된 일부 통계 분석의 경우 데이터를 긴 형식(예: 각 행이 단일 주제에 대한 단일 측정값이므로 대상별로 측정 수에 해당하는 여러 행이 있)으로 변환해야 합니다.\n다음 예에서는 reshape 함수를 사용해 rse 데이터 세트를 긴 형식으로 변환합니다. 대상 방향, rse의 1열에서 10열에 있는 측정값(Q1~Q10)을 포함하는 변수, 각 대상별 여러 측정값을 포함할 새 변수 이름(timevar=“question”), 새 결과 변수 이름(v.names=“response”), 그리고 마지막으로 rse 데이터 세트에서 person인 식별자를 지정합니다. 새로운 데이터의 형식을 보기 위해 head 함수를 사용해 처음 6개 행을 출력합니다.\n\nrse_long <- reshape(data = rse,\n                    direction = \"long\",\n                    varying = 1:10,\n                    timevar = \"question\",\n                    v.names = \"response\",\n                    idvar = \"person\")\nhead(rse_long)\n\n    gender age source country person question response\n1.1      1  10      1      IN      1        1        2\n2.1      1  16      1      US      2        1        2\n3.1      2  17      1      NL      3        1        1\n4.1      1  36      3      GB      4        1        2\n5.1      1  15      3      AU      5        1        2\n6.1      2  40      3      US      6        1        3\n\n\nreshape 함수를 사용해 긴 형식을 다시 와이드 형식으로 바꿀 수도 있습니다.\n\nrse_wide <- reshape(data = rse_long,\n                    direction = \"wide\",\n                    idvar = \"person\",\n                    timevar = \"question\",\n                    v.names = \"response\")\n\n식별자로 긴 형식의 데이터를 정렬한 다음 timevar 인수에 전달한 변수로 데이터를 정렬하는 것이 때때로 유용합니다. 이는 데이터가 종단 형식일 경우 꽤 유용합니다.\n\nrse_long <- rse_long[order(rse_long$person,\n                           rse_long$question),]\nhead(rse_long)\n\n    gender age source country person question response\n1.1      1  10      1      IN      1        1        2\n1.2      1  10      1      IN      1        2        2\n1.3      1  10      1      IN      1        3        3\n1.4      1  10      1      IN      1        4        3\n1.5      1  10      1      IN      1        5        2\n1.6      1  10      1      IN      1        6        2\n\n\n데이터 다루기 및 기본적인 R 구문에 대해 좀더 자세히 살펴보고 싶으면 John Verzani의 vignette를 검토해 보기를 바랍니다.12\n\n\n1.4.5 기술 통계와 추론 통계\nsummary 함수는 데이터에 대한 기술 통계를 얻는 유용한 방법입니다. summary 함수를 데이터 세트에 적용할 수 있습니다.\n\nsummary(rse) \n\n또는 데이터 세트의 특정 변수(예: Q1)에 적용할 수 있습니다.\n\nsummary(rse$Q1)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   2.000   2.000   2.002   3.000   3.000 \n\n\n이 예에서, summary 함수는 Q1에 대한 최솟값, 1사분위값, 중앙값, 평균, 3사분위값, 최댓값을 반환합니다.\n문자 또는 요인 변수인 경우, table 함수가 빈도표와 같이 데이터를 요약하는 데 유용하게 사용될 수 있습니다.\n\ntable(rse$country) \n\n\n A2  AE  AL  AR  AU  BA  BE  BG  BH  BR  CA  CH  CL  CR  CY  CZ  DE  DK  DO  EE \n  2   2   1   1  51   1   2   1   1   5  56   2   1   1   1   3  10   2   1   3 \n EG  ES  ET  FI  FR  GB  GE  GR  HK  HR  HT  ID  IE  IN  IQ  IR  IT  JE  JM  JO \n  2   6   2  11   6 139   1   1   9   1   1   3   6  25   2   1   4   1   3   2 \n JP  KE  KR  LT  MT  MX  MY  NG  NL  NO  NP  NZ  PE  PH  PK  PL  PS  PT  RO  RS \n  2   2   5   4   1   5   3   1   7   4   1   6   1  19   6   3   1   4   2   3 \n RU  SA  SE  SG  SI  SK  TH  TR  TT  TW  UA  UG  US  VE  ZA  ZM \n  4   1   9  14   1   1   2   5   2   3   2   1 489   1  11   1 \n\n\n변수의 평균, 분산, 표준편차는 mean, var, sd 함수를 사용하여 계산할 수 있습니다.\n\nmean(rse$Q1)\n\n[1] 2.002\n\nvar(rse$Q1)\n\n[1] 0.7407367\n\nsd(rse$Q1) \n\n[1] 0.8606606\n\n\ncor 함수는 상관행렬을 만듭니다. 이 함수를 사용하기 위해서는 모든 변수가 숫자형(numeric)이어야 합니다. 아래에서 subset 함수를 사용해 rse 데이터 세트에서 변수 Q1부터 Q10을 선택하고13 상관행렬인 새로운 데이터 세트를 만들어 rse_cor로 저장한 다음, 상관 표를 출력할 때 상관 계수를 소수 둘쨋자리까지 반올림합니다.\n\nrse_sub <- subset(rse, select = Q1:Q10)\nrse_cor <- cor(rse_sub)\nround(rse_cor, 2)\n\n      Q1   Q2   Q3   Q4   Q5   Q6   Q7   Q8   Q9  Q10\nQ1  1.00 0.69 0.49 0.58 0.47 0.61 0.56 0.35 0.39 0.49\nQ2  0.69 1.00 0.45 0.53 0.50 0.57 0.52 0.29 0.39 0.46\nQ3  0.49 0.45 1.00 0.45 0.63 0.59 0.59 0.41 0.56 0.61\nQ4  0.58 0.53 0.45 1.00 0.39 0.48 0.48 0.28 0.37 0.41\nQ5  0.47 0.50 0.63 0.39 1.00 0.55 0.56 0.38 0.52 0.57\nQ6  0.61 0.57 0.59 0.48 0.55 1.00 0.74 0.47 0.52 0.61\nQ7  0.56 0.52 0.59 0.48 0.56 0.74 1.00 0.47 0.52 0.58\nQ8  0.35 0.29 0.41 0.28 0.38 0.47 0.47 1.00 0.51 0.53\nQ9  0.39 0.39 0.56 0.37 0.52 0.52 0.52 0.51 1.00 0.74\nQ10 0.49 0.46 0.61 0.41 0.57 0.61 0.58 0.53 0.74 1.00\n\n\n공분산 행렬도 유사합니다. cor 함수를 cov 함수로 대체하면 됩니다.\n상관 관계의 유의성 검증을 하기 위해서 cor.test 함수를 사용할 수 있습니다. 예를 들어, Q1과 Q2 사이의 관계에 대한 유의성 검증을 하려면 다음과 같이 입력합니다.\n\ncor.test(rse$Q1, rse$Q2)\n\n\n    Pearson's product-moment correlation\n\ndata:  rse$Q1 and rse$Q2\nt = 30.486, df = 998, p-value < 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.6608709 0.7251887\nsample estimates:\n      cor \n0.6944142 \n\n\nt.test 함수를 사용해 t 검증을 할 수 있습니다. rse 데이터 세트에서 남녀 수험생을 하위집합으로 저장해 성별에 따라 연령이 다른지 확인할 수 있습니다. subset 함수에서 “|” 기호는 “또는”에 해당하는 논리 연산자입니다. 이는 성별이 1 또는 2인 수험생을 선택하는 데 도움이 됩니다. 새 데이터 세트를 rse_gender로 저장하고, t.test 함수와 함께 사용합니다. 아래 결과에서 성별에 따라 나이 차가 없음을 알 수 있습니다(p=.6092).\n\nrse_gender <- subset(rse, gender == 1 | gender == 2)\nt.test(age ~ gender, data = rse_gender)\n\n\n    Welch Two Sample t-test\n\ndata:  age by gender\nt = -0.50376, df = 808.53, p-value = 0.6146\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n95 percent confidence interval:\n -10.895349   6.445125\nsample estimates:\nmean in group 1 mean in group 2 \n       29.57825        31.80336 \n\n\nlm 함수를 사용해 단순회귀분석과 중다회귀분석을 수행할 수 있습니다. 아래에서, Q1을 Q2, Q3로 회귀하고 그 결과를 mod1에 저장한 후, mod1 포함된 내용을 표시하고 결과에 대한 요약을 출력합니다.\n\nmod1 <- lm(Q1 ~ Q2 + Q3, data = rse)\nnames(mod1)\n\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"        \n\nsummary(mod1)\n\n\nCall:\nlm(formula = Q1 ~ Q2 + Q3, data = rse)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.88984 -0.24594  0.04116  0.32456  1.82676 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.31494    0.05419   5.812 8.31e-09 ***\nQ2           0.64390    0.02654  24.260  < 2e-16 ***\nQ3           0.21440    0.02256   9.504  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5936 on 997 degrees of freedom\nMultiple R-squared:  0.5252,    Adjusted R-squared:  0.5243 \nF-statistic: 551.5 on 2 and 997 DF,  p-value: < 2.2e-16\n\n\nR의 많은 함수와 같이 회귀분석을 실행할 때 결과 객체는 많은 정보를 포함하고 있으며 names 또는 str 함수를 사용해 볼 수 있습니다. 회귀분석의 경우, 회귀계수, 잔차, 예측값 등이 포함됩니다. 위에서 Q1의 유의한 예측 변수는 Q2, Q3이며 \\(R^2\\)는 0.525이며 잔차의 표준오차 \\(\\hat{\\sigma}\\)는 0.594입니다. 이 모형의 예측값 및 잔차는 다음과 같이 얻을 수 있습니다.\n\npred_values <- predict(mod1)\nresid_values <- resid(mod1)\n\nplot 함수를 사용하여 회귀모델을 평가하기 위한 R의 기본 진단 그래프를 요청할 수 있습니다. 이 작업을 수행하기 전에 mrow 인수를 가진 par 명령어를 사용해 2 X 2 격자로 분할하도록 지시합니다. mar 인수는 그래프 주변의 여백 크기를 설정하는 데 사용합니다. 이 두 인수를 사용하면 4개의 진단 그래프를 동시에 그리고 그 사이의 일부 공백을 제거할 수 있습니다. [그림 1.2]에서 왼쪽 상단 그래프는 잔차 및 일정하지 않은 분산의 패턴을 감지하는 데 유용한 잔차 그래프입니다. 오른쪽 상단 그래프는 정규성 가정을 평가하는 데 유용한 정규 Q-Q 그래프입니다. 왼쪽 하단 그래프는 일정하지 않은 분산을 감지하는 데 유용한 척도위치 그래프입니다. 오른쪽 아래 그래프는 영향력 있는 사례를 감지하는 데 유용한 레버리지(leverage) 그래프입니다.\n\npar(mfrow = c(2, 2), mar=c(2, 4.1, 2, 2))\nplot(mod1)\n\n\n\n\n[그림 1.2]에서 일정하지 않은 분산의 증거와 정규성 위반(두꺼운 꼬리 참고)을 볼 수 있습니다. 만일 이것이 우리가 관심을 가졌던 모형이라면 변수를 변형하거나 다른 추정 방법(예: 가중최소제곱)을 고려해야 합니다.\n\n\n1.4.6 R로 그래프 그리기\n이 책에서는 R에서 기본으로 제공하는 그래프 함수와 lattice(Sarkar, 2008) 패키지의 함수를 사용합니다. 다음 섹션에서 기본 그래프를 만드는 방법과 lattice 패키지를 이용해 격자 그래프를 만드는 방법을 간단하게 소개합니다.\n\n1.4.6.1 R 기본 그래프\nplot 함수를 사용해 산점도를 만들 수 있습니다. interest 데이터 세트의 mathmtcs 변수와 vocab 변수로 그래프를 그리면 다음과 같습니다.\n\nplot(vocab ~ mathmtcs, data = interest)\n\n\n\n\n수험생의 성별에 따라 색상을 추가할 수도 있습니다.\n\nplot(vocab ~ mathmtcs, data = interest, col = gender)\n\n\n\n\n여기에 LOWESS smoother(Cleveland, 1985)를 추가합니다.\n\nplot(vocab ~ mathmtcs, data = interest, col = gender)\nlines(lowess(interest$mathmtcs, interest$vocab))\n\n\n\n\n산점도 행렬은 pairs 함수를 사용해 만들 수 있습니다. interest 데이터 세트에는 33개의 변수가 있기 때문에 매우 큰 산점도 행렬이 생성됩니다. interest 데이터 세트에서 vocab, reading, sentcomp 변수는 지능지수의 언어 측정에 해당합니다. 아래에서 이들 변수를 하위집합으로 저장하고 [그림 1.3]과 같이 새로운 데이터 세트에 대한 산점도 행렬을 만듭니다.\n\nverbal <- subset(interest, select = c(vocab, reading, sentcomp))\npairs(verbal)\n\n\n\n\n히스토그램은 hist 함수를 사용해 만들 수 있습니다.\n\nhist(interest$vocab)\n\n\n\n\n상자그림은 boxplot 함수를 이용해 만들 수 있습니다.\n\nboxplot(interest$vocab)\n\n\n\n\n그룹 변수(예: 성별)로 상자 그림을 만들 수 있습니다.\n\nboxplot(interest$vocab ~ interest$gender)\n\n\n\n\n마지막으로 stem 함수를 사용해 줄기-잎 그림을 만들 수 있습니다.\n\nstem(interest$vocab)\n\n\n  The decimal point is at the |\n\n  -2 | 6\n  -2 | 200\n  -1 | 99888877666655\n  -1 | 4333322222211111000\n  -0 | 9999998888888877777776666666655555555\n  -0 | 444444443333333222222222222222211111111110000000\n   0 | 000001111111122222222233333333344444444\n   0 | 555555556666777777788888999999999\n   1 | 000000001111111111222222333333444\n   1 | 555566667778999\n   2 | 0111123\n   2 | 6\n\n\n\n\n1.4.6.2 Lattice 그래프\n격자 그래프를 만들기 위해서는 주로 lattice 패키지를 사용합니다. lattice로 산점도를 만들려면 xyplot 함수를 사용합니다.\n\nxyplot(vocab ~ reading, data = interest)\n\n\n\n\n격자 그래프를 만들기 위해, “|” 기호를 사용해 세 번째 변수에 대한 조건부 reading에 대한 vocab 그래프를 만들 수 있습니다. 아래에서 성별에 따라 격자 그래프를 만듭니다.\n\nxyplot(vocab ~ reading | gender, data = interest)\n\n\n\n\n[그림 1.4]에서 vocab와 reading의 관계가 성별에 의존하지 않는 것처럼 보인다는 것을 알 수 있습니다. 즉, reading과 vocab는 상호작용이 없습니다. 성별에 따라 점 색깔을 달리하려면 group=gender 인수를 xyplot에 포함하면 됩니다.\n\nxyplot(vocab ~ reading | gender, group=gender, data = interest)"
  },
  {
    "objectID": "chap01.html#이-책에서-사용된-패키지-설치",
    "href": "chap01.html#이-책에서-사용된-패키지-설치",
    "title": "1  R 소개",
    "section": "1.5 이 책에서 사용된 패키지 설치",
    "text": "1.5 이 책에서 사용된 패키지 설치\n이 장을 마치기 전에 이 책에서 사용하는 모든 패키지를 설치하는 것은 중요합니다. 아래에는 이 책의 모든 패키지가 설치되었는지 확인하기 위해 실행해야 하는 명령어가 나와 있습니다.\n\ninstall.packages(\"boot\")\ninstall.packages(\"difR\")\ninstall.packages(\"equate\")\ninstall.packages(\"faoutlier\")\ninstall.packages(\"GPArotation\")\ninstall.packages(\"lattice\")\ninstall.packages(\"lavaan\")\ninstall.packages(\"lme4\")\ninstall.packages(\"mirt\")\ninstall.packages(\"psych\")\ninstall.packages(\"semPlot\")\ninstall.packages(\"shiny\")\ninstall.packages(\"devtools\")\ndevtools::install_github(\"cddesja/hemp\")\n\n독자가 출판물에 R 및 R 패키지를 인용하려는 경우, R의 citation 함수를 사용하여 적절한 인용을 볼 수 있습니다. R의 인용을 보기 위해서는 다음과 같이 합니다.\n\ncitation()\n\nTo cite R in publications use:\n\n  R Core Team (2023). _R: A Language and Environment for Statistical\n  Computing_. R Foundation for Statistical Computing, Vienna, Austria.\n  <https://www.R-project.org/>.\n\nA BibTeX entry for LaTeX users is\n\n  @Manual{,\n    title = {R: A Language and Environment for Statistical Computing},\n    author = {{R Core Team}},\n    organization = {R Foundation for Statistical Computing},\n    address = {Vienna, Austria},\n    year = {2023},\n    url = {https://www.R-project.org/},\n  }\n\nWe have invested a lot of time and effort in creating R, please cite it\nwhen using it for data analysis. See also 'citation(\"pkgname\")' for\nciting R packages.\n\n\n또한 패키지에 대한 인용을 보기 위해서는 다음과 같이 합니다.\n\ncitation(\"package name\")\n\n마지막으로 참고문헌 관리를 위해 BibTeX를 선호하는 독자는 다음 명령을 사용해 R과 R 패키지에 대한 인용을 볼 수 있습니다.\n\ntoBibtex(citation())\ntoBibtex(citation(\"package name\"))\n\n패키지 이름은 사용된 패키지명으로 대체되어야 합니다."
  },
  {
    "objectID": "chap01.html#요약",
    "href": "chap01.html#요약",
    "title": "1  R 소개",
    "section": "1.6 요약",
    "text": "1.6 요약\n이 장에서는 R을 설치하는 방법과 데이터 읽기, 데이터 정리, 기술 및 추론 통계, 그래프 그리기와 같은 R에서 기본적으로 하는 작업을 살펴보았습니다. 또한 이 책 전체에 제시된 예제를 따르기 위해 필요한 패키지를 설치하는 방법도 살펴보았습니다. R에 대한 보다 심도 있는 공부가 필요한 독자는 “Introduction to R by Venables and Smith (2016)”, “the introduction by Verzani (Verzani, 2002)”를 추천하고, R 전체에 대한 참조를 찾는 독자에게는 “The R Book by Crawley (2013)”를 강력 추천합니다."
  },
  {
    "objectID": "chap02.html#개요",
    "href": "chap02.html#개요",
    "title": "2  고전검사이론",
    "section": "2.1 개요",
    "text": "2.1 개요\n이 장에서는 고전검사이론 프레임워크를 이용해 교육측정 및 심리측정을 소개하고자 합니다. 측정, 검사, 척도를 정의하는 것으로 시작한 다음 CTT 맥락에서 신뢰도와 타당도를 살펴봅니다. 간략하게 소개한 후, R에서 CTT 기반 통계치들을 어떻게 구하는지 다양한 예를 제시합니다. 추가적으로 표집분포가 불분명하거나 가정에 위배되었을 경우 CTT 기반 모수에 대한 신뢰구간을 얻기 위한 옵션으로 부트스트래핑을 소개합니다. 문항 분석으로 장을 마무리합니다. 이 장에서 사용하는 R 함수는 hemp와 boot 패키지에서 가져옵니다."
  },
  {
    "objectID": "chap02.html#측정이란-무엇인가",
    "href": "chap02.html#측정이란-무엇인가",
    "title": "2  고전검사이론",
    "section": "2.2 측정이란 무엇인가?",
    "text": "2.2 측정이란 무엇인가?\n일반적으로 측정이란 일련의 규칙이나 원리, 조작에 기반해 구인에 숫자 또는 이름(라벨링)을 부여하는 것입니다. 예를 들어, 고등학교 수학교사인 김선생님은 학생들의 대수학 지식을 측정하려 합니다. 이 작업을 완수하기 위해 김선생님은 학생들의 대수학 지식을 측정하는 수학시험을 설계하고 시행하기로 했습니다. 수학시험을 개발하는 동안, 김선생님은 다음과 같은 몇 가지 측정 문제에 부딪힙니다.\n\n학생들이 알아야 할 대수학 개념은 무엇입니까?\n몇 문제를 사용해야 할까요?\n영역당 포함해야 하는 문제 수와 질문의 형식을 어떻게 해야 할까요?\n문제를 새로 만들어야 할까요? 아니면 기존문제를 사용할 수 있을까요?\n부정행위가 발생할 수 있기 때문에 검사지를 여러 개로 만들어야 할까요? 만일 그렇다면 난이도가 같거나 비슷하다는 것을 어떻게 확신할 수 있을까요?\n문제가 실제 대수학 지식만을 측정한다고 어떻게 확신할 수 있을까요?\n채점은 어떻게 해야 할까요?\n각각의 문제는 같은 방식으로 채점해야 할까요? 예를 들어, 각각의 문제에 동일한 점수를 부여해야 할까요? 또한 학생들은 완전히 정답일 때에만 점수를 받을 수 있을까요? 부분 점수를 받을 수는 없나요?\n\n검사, 척도, 설문조사, 설문지와 같은 측정 도구는 교사, 교육자, 심리학자, 실무자 또는 연구원이 구인, 특성, 또는 관심 영역을 측정하는 데 사용하는 일반적인 수단입니다. 우리는 대수학 지식을 측정하기 위한 수학 시험 개발과 같이 특정 목적을 염두에 두고 측정 도구를 개발합니다. 구인, 특성, 영역은 읽기 능력, 지능, 또는 집행기능과 같은 이론적 실체 또는 개념입니다. 교육학과 심리학에서는 일반적으로 구인이 잠재적(관찰되지 않음)이기 때문에 직접적으로 측정할 수 없으며 발현된 것으로부터 추론을 해야 합니다. 잠재 구인을 측정하기 위해 측정 도구에서 문항(또는 과제)을 개발하고 사용합니다. 이러한 문항은 일반적으로 측정 중인 잠재 구인의 조작적 정의를 제공하는 “발현변수”라고 합니다. 잠재구인은 때때로 지능과 같이 광범위하게 정의되거나 수학의 삼각함수 지식과 같이 좁은 범위로 정의될 수 있습니다. 이 책에서 설명할 측정 프레임워크와 개념이 모든 유형의 측정도구에 일반화될 수 있기 때문에 검사, 검사도구, 설문조사와 같은 용어 간의 구분이 이책에서는 중요하지 않습니다. 따라서 이러한 용어는 이 책 전반에 걸쳐 같은 의미로 사용됩니다."
  },
  {
    "objectID": "chap02.html#측정의-문제",
    "href": "chap02.html#측정의-문제",
    "title": "2  고전검사이론",
    "section": "2.3 측정의 문제",
    "text": "2.3 측정의 문제\n교육 및 심리 측정에 있어 중요한 주제는 타당도, 신뢰도, 불변성(예: 공정성), 척도화 등입니다(De Ayala, 2013). 지금까지 이 주제와 관련된 측정의 문제는 교육 및 심리 측정에 관한 문헌의 주요 초점이었습니다. 타당도는 측정하고자 하는 것을 측정하고 있는 정도를 의미합니다. 타당도의 목표는 명시 변수가 대상이 되는 구인 등의 진정한 발현인지의 여부를 조사하는 것입니다. 타당도는 증거를 수집하고 측정 도구의 사용을 지원하는 사례를 구축하는 것을 포함합니다. 모든 타당도의 증거는 본질적으로 구인 타당도의 범주에 속합니다. 제4장에서 구인타당도를 평가하는 방법으로 간주되는 요인분석을 다룹니다.\n항상 독립적인 개념으로 간주되어 왔지만 사실상 신뢰도는 타당도 증거의 한 형태입니다. 신뢰도는 측정 도구에서 얻은 결과의 일관성을 나타냅니다. 예를 들어, 검사도구를 반복적으로 시행하면 결과가 동일하거나 유사합니까? 아니면 유의하게 다릅니까? 점수가 유의하게 다르면 신뢰도가 낮고 측정오차가 큽니다. 측정 도구의 결과를 기반으로 타당한 추론을 하려면 결과의 신뢰도가 필수적입니다. 즉, 측정 도구는 결과의 신뢰도가 높지 않으면 타당한 추론을 할 수 없습니다. 그러나 높은 신뢰도만으로는 타당한 추론을 하기에 충분하지 않습니다. 예를 들어, 운전 면허를 취득하기 위한 지식 검사는 높은 신뢰도를 가진 검사일 수 있습니다. 그러나 이 검사 개발자가 그 결과를 경주용 자동차 운전자가 될 수 있는 사람을 결정하기 위해 사용했다면 이 측정 과정은 타당하지 않은 추론을 생성할 것입니다.\n일반적으로 검사도구의 결과나 점수가 측정하려는 것을 반영하기를 원합니다. 결과가 피험자의 특성(예: 성별, 민족, 문화적 배경) 및 검사 시행(예: 2016년과 2017년 시험 시행)과 무관한 경우 검사도구가 불변이라 말할 수 있습니다. 불변성의 위반은 결과를 기반으로 한 추론의 타당성을 위태롭게 할 수 있습니다. 이 책에서 고려하는 많은 심리 측정 모델은 불변성을 가정하거나 이 가정을 명시적으로 검사하는 것을 포함합니다. 불변성의 하나의 형태인 측정동일성은 11장에서 자세히 다룹니다.\n마지막으로 측정 도구의 기저에 있는 점수 척도에는 중요한 속성이 있습니다. 척도는 일반적으로 측정 대상을 범주화하거나 정량화하는 데 사용되는 일련의 값 또는 레이블로 구성됩니다. 대수 검사 예에서, 연속 점수 척도는 0에서 100 사이의 총점 또는 0에서 4 사이의 숫자값을 할당하는 데 사용할 수 있습니다. 서열 척도는 A에서 F까지와 같은 문자 등급을 할당하는 데 사용할 수 있습니다. 명목 척도는 합격 또는 불합격, 능숙함 또는 능숙하지 않음과 같은 범주 레이블을 할당하는 데 사용될 수 있습니다. 다음 섹션에서 어떤 유형의 측정 척도를 사용해야 하는지 결정하는 방법에 대해 간략하게 설명하겠습니다.\n\n2.3.1 척도의 종류\n척도의 특성은 선택한 방법과 모델에 영향을 미치기 때문에 측정에서 매우 중요합니다. 이 책 전반에 걸쳐 모델은 척도에 따라 달라지기 때문에 측정 척도에 대한 보다 철저한 논의가 필요합니다. 측정 척도는 일반적으로 명속, 서열, 등간, 비율 척도로 분류됩니다. 명목 척도는 질적이고 서열이 없는 범주로 구성됩니다. 예를 들어, 좋아하는 색깔에 숫자를 할당한 척도는 본질적으로 서열이 없으며 색깔의 순위를 매길 수 없기 때문에 질적입니다. 예를 들어 빨간색에는 “1”, 파란색에는 “2”, 녹색은 “3” 등으로 할당될 수 있습니다. 그러나 할당된 값이 정량적인 것처럼(예: 녹색이 파란색 및 빨간색보다 크다거나 녹색이 빨간색보다 3배 더 크다) 해석하는 것은 부적절합니다. 유사하게, 선호하는 성별 또는 인종에 따라 숫자를 할당하는 척도는 본질적으로 순서가 없기 때문에 명목 척도입니다.\n명목 척도와는 달리 서열척도는 본질적으로 순서가 있습니다. 서열 척도는 정량적(예: 경주에서 1위, 2위, 3위) 또는 정성적(예: 점수 루브릭에서 매우 우수, 우수, 보통, 기초)일 수 있습니다. 그러나 서열 척도를 사용하면 인접한 범주 간의 거리를 알 수 없으며 인접한 범주 간의 거리가 동일하다고 가정할 수 없습니다. 서열 척도의 대표적인 예는 특정 주제에 대해 동의 정도를 묻는 리커트 유형의 문항입니다. 다음 진술문을 고려하십시오: 나는 대수 문제를 푸는 것을 즐깁니다. 이 문항은 매우 동의하지 않는 경우 “1”, 동의하지 않는 경우 “2”, 보통인 경우 “3”, 동의하는 경우 “4”, 매우 동의하는 경우 “5”로 점수를 매길 수 있습니다. 사람들이 대수학의 근본적인 즐거움이 다양하고 그들의 즐거움이 실제로 지속된다고 상상하는 것은 가능합니다. 그러나 검사 도구 덕분에 그들의 즐거움은 세분화되고 사람들은 척도와 일치하는 방식으로 반응해야 합니다. “대수학 문제 해결의 즐거움”의 거리가 동의하지 않는다고 응답하는 사람과 동의도 반대도 아닌 것으로 응답하는 사람, 또는 동의하지 않는다고 응답하는 사람과 강하게 응답하는 사람 사이에 동일하다고 믿을 이유가 없습니다. 동의하지 않는다. 서수 수준에 할당된 수치는 수준 간의 거리가 1점임을 암시할 수 있지만 임의로 선택한 값이므로 정량적으로 비교할 수 없습니다. 예를 들어, 매우 반대하는 경우 “1”, 반대하는 경우 “3”, 중립적인 경우 “4”, 동의하는 경우 “5”, 매우 동의하는 경우 “7”을 할당할 수 있습니다. 이렇게 하면 인접한 범주 사이의 거리가 변경됩니다. 그러나 순서는 동일하게 유지됩니다. 따라서 서수 척도를 다룰 때 우리는 척도의 정렬된 특성을 이용해야 하지만 할당된 숫자는 임의의 레이블에 지나지 않는다는 것을 깨달아야 합니다.\n동일한 간격으로 정렬된 척도가 있다면, 그 척도는 적어도 등간 척도라고 할 수 있습니다. 척도가 절대 0이면 비율 척도이고, 그렇지 않으면 등간 척도입니다. 등간 척도의 대표적인 예는 섭씨 또는 화씨로 기록된 온도입니다. 섭씨에서 0도는 온도나 열이 없음을 의미하지는 않습니다. 그러나 인접한 두 온도 사이의 거리는 섭씨 척도에서 항상 동일합니다. 비율 척도도 등간 척도와 동일한 거리 기능을 가지고 있습니다. 또한 비율 척도는 측정 중인 구인이 없음을 나타내는 실제 영점이 있습니다. 서열 및 등간 척도와 달리 비율 척도는 척도에 있는 값의 비율을 해석할 수 있습니다(예: 10인치는 5인치의 두 배입니다).\n명목 및 서열 척도의 데이터를 범주형 또는 불연속형 데이터라고 하는 반면, 등간 및 비율 척도의 데이터를 연속형 데이터라고 합니다. 연속형 데이터의 경우, 데이터가 일련의 예측 변수, 공변인 또는 독립 변수에 따라 주변 또는 조건부 정규분포를 갖는다고 가정하는 경우가 있습니다. 등간 및 비율 척도를 사용하면 기술 통계(예: 평균 및 표준 편차)를 계산할 수 있지만, 명목 및 서열 척도에서는 이러한 통계가 부적절합니다. 등간 및 비율 척도를 사용하여 산점도, 히스토그램 또는 줄기 및 잎 도표를 조사할 수 있습니다. 명목척도 또는 서열척도를 사용하여 특정 응답을 지지하는 응답자의 수 또는 비율을 표시하는 분할표를 구성하고 막대 그래프, 점도표 또는 모자이크 플롯을 만들 수 있습니다.\n범주형 데이터와 연속형 데이터를 요약하는 방법의 차이점을 간략하게 보여주기 위해 hemp 패키지의 interest 데이터 세트를 사용합니다. interest 데이터는 가상의 인지, 성격 및 직업흥미 설문에서 가져옵니다. 이 데이터 세트에 대한 자세한 내용은 R 콘솔에서 ?interest를 실행할 수 있습니다. hemp 패키지의 함수 및 데이터 세트를 활성화하려면 다음과 같이 library 명령을 사용해야 합니다:\n\nlibrary(hemp)\n\nLoading required package: psych\n\n\nLoading required package: lattice\n\n\nLoading required package: lavaan\n\n\nThis is lavaan 0.6-16\nlavaan is FREE software! Please report any bugs.\n\n\n\nAttaching package: 'lavaan'\n\n\nThe following object is masked from 'package:psych':\n\n    cor2cov\n\n\nLoading required package: mirt\n\n\nLoading required package: stats4\n\n\nLoading required package: lme4\n\n\nLoading required package: Matrix\n\n\n\nAttaching package: 'lme4'\n\n\nThe following object is masked from 'package:mirt':\n\n    fixef\n\n\nLoading required package: reshape2\n\n\nLoading required package: boot\n\n\n\nAttaching package: 'boot'\n\n\nThe following object is masked from 'package:lattice':\n\n    melanoma\n\n\nThe following object is masked from 'package:psych':\n\n    logit\n\n\nLoading required package: equate\n\n\nhemp 패키지가 활성화되면 interest 데이터 세트를 사용할 수 있게 됩니다. interest 데이터 세트의 변수 중 하나는 성별입니다. 성별 변수는 원래 여성 응답자의 경우 1, 남성 응답자의 경우 2로 코딩되었습니다. 이 숫자 변수를 ifelse 함수를 사용하여 실제 성별 레이블이 있는 범주형 변수로 레코딩하는 것으로 시작합니다. ifelse 함수는 “이 문장이 참이면 do … 그렇지 않으면 do ….” 아래 예에서는 ifelse를 사용하여 성별 변수가 1과 같은 관측값(즉, 응답자)을 찾아서 다시 코딩합니다. gender==1 조건이 충족되면 “여성” 레이블을 할당하고, 그렇지 않으면 “남성” 레이블을 할당합니다. 마지막으로 이 새 변수를 gender_nominal로 저장합니다.\n\ngender_nominal <- ifelse(interest$gender==1,\"female\",\"male\")\n\n다음으로, interest 데이터 세트의 연속형 숫자 변수인 나이를 교육적인 목적으로 서열 변수로 변환합니다. 나이를 서열 변수로 변환하면 정보 손실이 발생할 수 있지만, 비율 척도의 연속형 변수를 서열 변수로 변환하는 방법을 보여드리고자 합니다. 나이를 서열 변수로 변환하기 위해 cut 함수를 사용하여 10세부터 70세까지 폭이 10년인 구간차원을 만듭니다. 첫 번째 구간차원에는 10~19세 피험자가 포함되고, 두 번째 구간차원에는 20~29세 피험자가 포함되는 식입니다. 이 새 변수가 명목 변수가 아닌 서열 변수(R에서 기본적으로 가정)임을 R이 알 수 있도록 ordered 함수를 사용하여 age_ordinal로 저장합니다.\n\nage_nominal <- cut(interest$age,breaks = seq(10, 70, by = 10))\nage_ordinal <- ordered(age_nominal)\n\n새 변수를 요약하기 위해 table 함수를 사용합니다.\n\ntable(gender_nominal)\n\ngender_nominal\nfemale   male \n   128    122 \n\n\n\ntable(age_ordinal)\n\nage_ordinal\n(10,20] (20,30] (30,40] (40,50] (50,60] (60,70] \n      9      34      89      88      23       7 \n\n\n위의 결과에서 남성보다 여성이 약간 더 많으며, 피험자의 대부분이 30세에서 50세 사이라는 것을 알 수 있습니다. ftable 함수를 사용하면 여러 개의 명목 및 서열 변수가 포함된 분할표를 만들 수도 있습니다.\n\nftable(age_ordinal, gender_nominal)\n\n            gender_nominal female male\nage_ordinal                           \n(10,20]                         4    5\n(20,30]                        19   15\n(30,40]                        51   38\n(40,50]                        39   49\n(50,60]                        11   12\n(60,70]                         4    3\n\n\nftable 함수에서 반환된 분할표는 남성과 여성 모두 대부분 30세에서 50세 사이라는 것을 보여줍니다. table 함수를 사용하여 빈도표를 만드는 것 외에도 prop.table 함수를 사용하여 비율표를 만들 수도 있습니다. prop.table은 table 함수에서 파생된 빈도표를 기반으로 비율표를 만듭니다. 서열 연령 변수에 대한 비율표를 만들려면 먼저 빈도표를 생성하고 이 표를 prop.table 함수에 인수로 전달합니다.\n\nage_table <- table(age_ordinal)\nprop.table(age_table)\n\nage_ordinal\n(10,20] (20,30] (30,40] (40,50] (50,60] (60,70] \n  0.036   0.136   0.356   0.352   0.092   0.028 \n\n\nprop.table의 결과는 interest 데이터 세트의 피험자 중 약 70%가 30세에서 50세 사이라는 것을 보여줍니다. table 함수와 마찬가지로 prop.table 함수는 분할표에도 적용할 수 있습니다.\n\nprop.table(table(age_ordinal, gender_nominal))\n\n           gender_nominal\nage_ordinal female  male\n    (10,20]  0.016 0.020\n    (20,30]  0.076 0.060\n    (30,40]  0.204 0.152\n    (40,50]  0.156 0.196\n    (50,60]  0.044 0.048\n    (60,70]  0.016 0.012\n\n\n지금까지 살펴본 예제에서는 모든 것을 저장하고 향후 함수에 전달할 수 있다는 R의 중요한 기능을 다시 한 번 확인했습니다. 이를 통해 함수에 함수를 중첩할 필요 없이 더 읽기 쉬운 코드를 만들 수 있습니다.1\n명목변수와 서열 변수를 시각적으로 조사하기 위해 lattice 패키지의 barchart 및 dotplot 함수를 사용하여 막대그래프와 점도표를 만들 수 있습니다(Sarkar, 2008). 예를 들어, 막대그래프를 만들려면 다음 코드를 실행하면 됩니다:\n\nlibrary(\"lattice\")\nbarchart(age_ordinal)\n\n\n\n\n많은 독자들이 점도표에 익숙하지 않을 수 있습니다. 점도표는 범주형 데이터에서 패턴을 발견하는 데 매우 유용한 통찰력을 제공합니다(예시적인 예는 Cleveland (1985) 및 Cleveland (1993) 참조). 명목 변수에서 범주의 빈도가 필요하기 때문에 만들기가 조금 더 어렵습니다. 다행히도 이 정보는 age_table 객체에 이미 포함되어 있으므로 다음과 같이 이 객체를 dotplot 함수에 전달하기만 하면 됩니다:\n\ndotplot(age_table)\n\n\n\n\n또 다른 매우 강력한 플롯은 격자형(trellis) 또는 패싯형(facet) 플롯으로 알려진 플롯 유형입니다. 격자형 플롯은 세 번째 변수를 조건으로 하는 두 변수 간의 관계를 보여줄 수 있습니다(1장에서 간략히 언급했듯이). 예를 들어, 수험생의 연령 분포가 성별에 따라 어떻게 다른지 확인하려면 다음과 같이 할 수 있습니다:\n\nage_gender_table <- table(gender_nominal, age_ordinal)\nage_gender_df <- data.frame(age_gender_table)\ndotplot(age_ordinal ~ Freq | gender_nominal,\nage_gender_df, xlab = \"Frequency\", ylab = \"Age\")\n\n\n\n\n위의 코드는 먼저 2원 테이블(age_gender_table)을 만든 다음 이를 데이터 프레임(age_gender_df)으로 변환합니다. 이는 dotplot 함수를 사용하여 플로팅하기 위해 필요한 중간 단계입니다. 참고로 “|” 기호는 부울 “또는”이 아닌 “조건부”로 해석할 수 있습니다. 위의 예에서 dotplot 함수는 성별 변수에 대한 조건부 연령 변수의 빈도 분포를 플롯합니다.\n그림 2.1은 이 코드를 실행한 결과를 보여줍니다.2 점도표에서 남성의 최빈값은 40~50 사이인 반면 여성의 최빈값은 30~40 사이라는 점을 제외하고는 여성과 남성의 연령 분포가 비슷하다는 것을 알 수 있는데, 이는 우리 샘플에서 여성 피험자가 남성 피험자보다 약간 더 젊다는 것을 의미합니다.\n다음으로, interest 데이터 세트에서 어휘 시험에 해당하는 어휘 변수를 고려합니다. 이 변수는 등간 척도입니다. 이 변수에 대한 요약 데이터는 summary 함수를 사용하여 쉽게 얻을 수 있습니다.\n\nsummary(interest$vocab)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-2.62000 -0.60500  0.04000  0.09016  0.86000  2.63000 \n\n\n어휘력 검사의 최소 점수는 -2.62점, 최대 점수는 2.63점인 것을 알 수 있습니다. 평균은 .09입니다. summary 함수에서는 1사분위수 및 3사분위수와 중앙값도 제공합니다.\n등간 또는 비율 척도를 사용하면 변수가 정규 분포하는 정도를 조사하는 데 관심이 있는 경우가 많습니다. 정규성 가정을 평가하는 데 사용할 수 있는 다양한 통계와 플롯이 있지만, 특히 유용한 옵션은 Q-Q 플롯입니다(Faraway, 2014). 정규성을 평가할 때 히스토그램보다 Q-Q 플롯을 선호하는 이유는 구간차원 폭과 숫자가 임의적이기 때문입니다. 일반적으로 변수의 분포를 보고 편차의 특성을 이해하는 것이 더 유용하므로 왜도 및 첨도 통계는 계산하지 않는 것이 좋습니다.\nQ-Q 플롯을 생성하는 코드는 아래와 같으며, 결과는 그림 2.2에 나와 있습니다. qqnorm 함수를 사용하여 Q-Q 플롯을 만든 다음 qqline을 사용하여 분포가 완벽하게 정규 분포일 경우 점들이 어디에 속할지를 보여주는 선을 오버레이합니다. 이 플롯에서는 꼬리 부분에 약간의 편차가 있지만 정규성을 크게 위반하지 않는 것을 볼 수 있습니다.\n\nqqnorm(interest$vocab, ylab = \"vocab\")\nqqline(interest$vocab)\n\n\n\n\n이 책의 범위를 벗어나지만, 척도 유형은 고려해야 하는 통계 검증 유형에 영향을 미친다는 점에 유의하시기 바랍니다. 등간 또는 비율 척도 데이터에 적합한 검정(예: t 검정, 선형 회귀)은 일반적으로 범주형 데이터에는 적합하지 않습니다. 범주형 데이터 분석에 익숙하지 않은 독자는 Agresti(2002) 및 Faraway(2016)를 참조하시기 바랍니다. 이 책 전체에 걸쳐 제시된 많은 방법은 모든 척도에 적합하지만, 일부는 특정 척도에 한정되어 있습니다. 어떤 방법이 특정 측정 척도를 필요로 하는 경우 이를 명확히 하기 위해 전체적으로 주의를 기울였습니다."
  },
  {
    "objectID": "chap02.html#고전검사이론-프레임워크",
    "href": "chap02.html#고전검사이론-프레임워크",
    "title": "2  고전검사이론",
    "section": "2.4 고전검사이론 프레임워크",
    "text": "2.4 고전검사이론 프레임워크\n진점수 이론이라고도 하는 고전 검사 이론(CTT)은 측정된 결과를 이해하고, 조작하고, 해석할 수 있게 해주는 측정 프레임워크입니다. CTT의 전제는 모든 측정에는 오차가 포함되며 모든 관찰은 불완전하다는 것입니다. CTT 모델은 측정 도구에서 관찰 점수를 진점수와 오차 점수 구성 요소로 분해합니다. 수학적으로 CTT는 다음과 같이 표현됩니다:\n\\[\nX=T+E.\n\\]\nCTT 모델에서 X는 관찰 가능한 측정/검사 점수, T는 실제(잠재) 측정/총 검사 점수, E는 무선 오차입니다. 관찰할 수 없는 총점보다는 개별 문항에 초점을 맞추고자 할 때는 CTT 모델보다는 공통 요인 모델(4장에서 제시)이나 문항 반응 이론(5장에서 소개)이 더 적합합니다. CTT 모델을 사용하려면 방정식 2.1에 제시된 일반적인 형태 외에 네 가지 추가 가정이 필요합니다:\n\n\\(E(X)=T\\), 관찰점수의 기댓값이 진점수임\n\\(Cov(T,E)=0\\), 진점수와 오차점수는 독립적임\n\\(Cov(E_1,E_2)=0\\), 검사 간의 오차점수는 독립적임\n\\(Cov(E_1,T_2)=0\\), 한 검사의 오차점수와 다른 검사의 진점수는 독립적\n\n이러한 가정으로 인해 CTT 모델은 아래와 같이 직교(즉, 상관관계가 없는) 분산 성분의 단순 합으로 다시 표현할 수 있습니다:\n\\[\n\\sigma^2_X=\\sigma^2_T+\\sigma^2_E\n\\]\n방정식 2.2에 따르면 관찰 점수 분산은 진점수 분산과 오차점수 분산의 합입니다. 이 모델에서 진점수 분산은 일정하다고 가정하고(예: 검사도구의 형태, 평가 날짜 등에 관계없이 절대 변하지 않음), 오차점수 분산은 변동한다고 가정합니다(예: 일부 검사는 다른 검사보다 더 많은 오차점수를 포함할 수 있음). 측정 오차는 무선(예측 불가능하고 일관되지 않은) 오차와 체계적(일정하고 예측 가능한) 오차로 나눌 수 있습니다.\n\n2.4.1 신뢰도\n신뢰도는 진점수 분산에 기인할 수 있는 관찰 점수 분산의 비율입니다. 방정식 2.2에서 검사 신뢰도 지수는 다음과 같이 도출할 수 있습니다:\n\\[\nreliability = {\\sigma^2_T \\over \\sigma^2_X}\n\\]\n신뢰도에는 일반적으로 검사-재검사(안정성 계수), 동형검사(parallel forms)(동등성 계수), 대안검사(alternate forms)(대안 검사 신뢰도), 내적 일관성의 네 가지 유형이 있습니다. 여기서는 내적 일관성에 초점을 맞추고 있는데, 피험자가 여러 양식을 응시하거나 여러 번의 시험에서 동일한 양식을 응시하는 경우가 실제 드물기 때문입니다. 대부분의 경우, 다른 형태의 신뢰도는 범위 제한이 있는 경우 감소에 대한 일부 보정과 함께 피어슨 또는 사분산 상관관계를 사용하여 추정할 수 있습니다.\n다음 예에서는 SAPA 데이터 세트를 사용하여 R에서 다양한 내적 일관성 추정치를 계산하는 방법을 보여줍니다. 원래 psych 패키지(Revelle, 2017)에 포함된 SAPA 데이터 집합은 독자의 편의를 위해 hemp 패키지에서 재패키징 및 채점되었습니다. 이 도구는 웹 기반 성격 평가 프로젝트인 합성 식별 인성 평가(SAPA)에서 가져온 16개 문항의 선다형 능력 검사에 대한 1525개의 응답으로 구성되어 있습니다.3 첫 번째 4개 문항은 기본 추론, 두 번째 4개 문항은 영숫자 계열, 세 번째 4개 문항은 행렬 추론, 마지막 4개 문항은 공간 회전을 측정합니다.\n분석은 hemp의 num_miss 함수를 사용하여 각 문항에 대한 결측 관측값의 수를 계산하는 것으로 시작합니다. 결과에는 letter.58에만 결측치가 없고 다른 문항에는 하나 또는 두 개의 결측치가 포함되어 있음을 보여줍니다.\n\nnum_miss(SAPA)\n\n          num_miss perc_miss\nreason.4         2      0.13\nreason.16        1      0.07\nreason.17        2      0.13\nreason.19        2      0.13\nletter.7         1      0.07\nletter.33        2      0.13\nletter.34        2      0.13\nletter.58        0      0.00\nmatrix.45        2      0.13\nmatrix.46        1      0.07\nmatrix.47        2      0.13\nmatrix.55        1      0.07\nrotate.3         2      0.13\nrotate.4         2      0.13\nrotate.6         2      0.13\nrotate.8         1      0.07\n\n\n내적 일관성을 측정하는 간단한 방법은 반분 신뢰도입니다. 반분 신뢰도 추정치는 검사를 동등한 두 개의 검사로 나누고, 두 검사의 총 점수를 계산한 다음, 이들의 상관을 살펴봄으로써 얻을 수 있습니다. 두 검사로 생성하는 방법은 무수히 많습니다(예: 다른 모든 문항을 무작위로 선택하는 등). 아래에서는 split_half 함수를 사용하여 다른 모든 문항을 선택하고 type = “alternate”를 지정하여 반분 신뢰도를 계산합니다.\n\nsplit_half(SAPA, type = \"alternate\")\n\n[1] 0.758\n\n\nSAPA 데이터 세트의 경우, 반분 신뢰도는 0.758로 추정되었습니다. type = “random”를 지정하여 검사를 무작위로 분할하여 반분 신뢰도를 계산할 수도 있습니다.\n\nset.seed(1)\nsplit_half(SAPA, type = \"random\")\n\n[1] 0.723\n\n\n무선 분할로 한 반분 신뢰도는 0.717의 신뢰도 추정치를 얻었습니다. set.seed(1)을 지정하여 독자의 결과가 위에 제시된 결과와 동일하도록 난수 생성기를 설정했습니다.4 이는 나중에 동일한 결과를 재현할 때 유용합니다. 다른 무선 분할에 기반한 새로운 추정치를 얻으려면 set.seed(1) 명령을 제거하거나 시드를 다른 값(예: set.seed(555))으로 변경하면 됩니다.\n반분 신뢰도 추정치는 하향 편향이 있는 것으로 알려져 있습니다(R. J. Cohen, Swerdlik, & Sturman, 2013). 스피어만-브라운 보정을 적용하여 이를 조정할 수 있습니다. 이렇게 하려면 split_half 함수에 sb = TRUE 인수를 전달하면 됩니다.\n\nsplit_half(SAPA, type = \"alternate\", sb = TRUE)\n\n[1] 0.8623436\n\n\n스피어만-브라운 보정을 적용한 후, 이제 반분 신뢰도는 0.862로 추정되며, 이는 상당히 높은 수치입니다. 현재 신뢰도 추정치를 고려할 때 원하는 신뢰도를 얻기 위해 검사의 길이를 결정할 수도 있습니다. 이 작업은 hemp의 test_length 함수를 사용하여 수행할 수 있습니다. 0.95의 신뢰도를 원한다고 가정하면 검사의 길이를 결정할 수 있습니다. test_length를 호출할 때, 스피어만-브라운 보정을 적용한 반분 신뢰도를 사용하여 현재 신뢰도를 계산할 수 있도록 r_type = “split”을 지정합니다. 위에서 한 것처럼 다른 곳에서 신뢰도를 계산한 경우 r_type에 숫자를 지정할 수도 있습니다.\n\ntest_length(SAPA, r = .95, r_type = \"split\")\n\n[1] 49\n\n\n\ntest_length(SAPA, r = .95, r_type = .862)\n\n[1] 49\n\n\n현재 검사의 신뢰도가 16개 문항 기준 0.862라는 점을 감안할 때 원하는 신뢰도가 0.95인 검사를 원한다면 최소 49개 문항으로 구성된 검사가 필요합니다.\n내적 일관성을 측정하는 가장 일반적인 방법은 계수 알파(Cronbach, 1951)입니다. 계수 알파는 가능한 모든 반분 상관관계의 평균을 나타냅니다. 계수 알파는 hemp의 coef_alpha 함수를 사용하여 계산할 수 있습니다.\n\ncoef_alpha(SAPA)\n\n[1] 0.841\n\n\ncoef_alpha 함수에서 반환된 출력은 SAPA 데이터 세트에 대한 계수 알파의 추정치가 0.841임을 보여줍니다. 신뢰도를 점으로 추정하는 것도 유용할 수 있지만, 일반적으로 추정치에 대한 변이를 파악하는 것이 도움이 됩니다. 신뢰 구간은 신뢰 수준(일반적으로 95%)이 주어졌을 때 알 수 없는 모수에 대한 그럴듯한 값의 범위를 정량화하는 수단을 제공합니다. 표본 크기가 작거나, 모델링 가정이 충족되지 않거나, 모수의 표본 분포를 알 수 없는 경우 부트스트랩을 사용하여 경험적 표본 분포를 구성한 다음 신뢰 구간을 만드는 데 사용할 수 있습니다(Efron & Tibshirani, 1986).5\n부트스트래핑을 도입하게 된 동기는 추정되는 모수에 관계없이 신뢰 구간과 불확실성을 생성할 수 있기 때문입니다. 따라서 계수 알파에 부트스트랩을 사용하는 방법을 설명했지만, 위의 반분 신뢰도, 이 장의 뒷부분에 제시된 타당도 또는 문항 분석 통계, 그리고 이 책 전체에 제시된 다른 많은 맥락에서 쉽게 적용할 수 있습니다.\n부트스트랩을 수행하기 위해 boot 패키지를 사용합니다(Canty & Ripley, 2017). 부트 패키지는 boot 함수를 통해 모수적 부트스트랩과 비모수적 부트스트랩 모두에 대한 수많은 옵션을 제공합니다. 이러한 방법에 대한 기술적 세부 사항은 A. C. Davison과 Hinkley(1997)에 설명되어 있으며 이 책의 범위를 벗어납니다. 분석을 시작하려면 먼저 boot 패키지를 활성화합니다.\n\nlibrary(\"boot\")\n\n다음으로 boot 함수를 사용하여 부트스트랩 절차를 구현합니다. boot 함수에는 최소한 데이터 세트, 부트스트랩할 함수, 추출할 샘플 수가 필요합니다. 먼저, boot 함수에 전달할 함수를 만들어야 하는데, 이 함수를 alpha_fun이라고 부릅니다. 이 함수는 data라고 하는 데이터 세트와 row이라고 하는 인덱스 행렬이라는 두 개의 인수를 받습니다. 그런 다음 이 인수는 coef_alpha 함수에 전달됩니다. 이렇게 하면 부트 함수가 SAPA에서 대체된 피험자를 샘플링하여 계수 알파에 대한 경험적 분포를 생성할 수 있습니다(자세한 내용은 Canty(2002) 참조).\n\nalpha_fun <- function(data, row){\ncoef_alpha(data[row, ])}\n\n아래에서는 10,000회 수행으로 부트스트랩을 사용하여 경험적 분포를 생성하고 결과를 alpha_boot로 저장한 다음 결과를 출력합니다.\n\nalpha_boot <- boot(SAPA, alpha_fun, R = 1e4)\nalpha_boot\n\n\nORDINARY NONPARAMETRIC BOOTSTRAP\n\n\nCall:\nboot(data = SAPA, statistic = alpha_fun, R = 10000)\n\n\nBootstrap Statistics :\n    original     bias    std. error\nt1*    0.841 -0.0002698 0.005548143\n\n\n결과에서 t1*은 계수 알파를 나타내고 original은 모든 데이터를 사용한 원본 추정치, bias는 이 원본 추정치를 뺀 경험적 분포의 평균, std. error는 추정자의 표준 오차입니다.\n그림 2.3은 10,000개의 샘플을 기준으로 한 계수 알파의 경험적 분포의 히스토그램과 Q-Q 플롯을 보여줍니다. 이 분포는 꼬리 부분의 약간의 편차를 제외하고는 거의 정규 분포입니다. 이는 신뢰 구간을 구성할 때 점근 정규 분포를 가정하는 부트스트랩 정규 구간을 사용하는 것이 적절할 수 있음을 의미합니다.\n\nplot(alpha_boot)\n\n\n\n\n또한 boot.ci 함수를 사용하여 부트스트랩 정규, 기본 부트스트랩, 부트스트랩 백분위수 및 조정된 부트스트랩 백분위수(BCa) 구간을 사용하여 95% 신뢰 구간을 계산합니다. 간단히 말해, 기본, 백분위수 및 BCa 구간은 부트스트랩 정규 구간보다 더 적은 가정(즉, 점근 정규성 가정 없음)을 하며, BCa 구간은 기본 및 백분위수 구간보다 점근적으로 더 잘 작동합니다. 경험적 분포가 정규성에서 벗어나는 경우 기본, 백분위수 및 BCa 구간이 더 나은 선택입니다. 이러한 구간 간의 차이에 대한 자세한 설명은 A. C. Davison과 Hinkley(1997)에서 자세히 확인할 수 있으며, 이 예에서 중요한 점은 구간이 백분위수와 일치하고 부트스트랩 정규 구간이 약간 더 정밀하다는 것입니다.\n\nboot.ci(alpha_boot, type = c(\"norm\", \"basic\", \"perc\", \"bca\"))\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 10000 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = alpha_boot, type = c(\"norm\", \"basic\", \"perc\", \n    \"bca\"))\n\nIntervals : \nLevel      Normal              Basic         \n95%   ( 0.8304,  0.8521 )   ( 0.8310,  0.8530 )  \n\nLevel     Percentile            BCa          \n95%   ( 0.829,  0.851 )   ( 0.829,  0.851 )  \nCalculations and Intervals on Original Scale\n\n\n대부분의 목적에 있어서는 검사의 길이를 늘려 피험자에게 추가적인 부담을 줄 필요가 없을 정도로 신뢰도가 높은 것으로 보이며, 이 신뢰도 추정치로 대부분의 의사 결정을 내리는 데 무리가 없을 것으로 판단됩니다(극도로 중요한 결정이 아닌 경우).\n\n\n2.4.2 타당도\n타당도 증거는 다양한 형태를 취하며, R을 사용하면 타당도 증거를 정량화하는 것이 매우 간단합니다. 타당도 증거의 일반적인 형태는 전문가 의견입니다. 전문가의 의견은 문항 내용의 적절성, 측정 도구가 구성 요소 내의 모든 개념을 적절하게 샘플링하고 있는지 여부, 문항이 목표 구성 요소를 측정하는 데 필수적인지 여부에 대한 의견을 제시할 수 있습니다. 후자를 정량화하는 한 가지 방법은 내용 타당도 비율인 CVR을 사용하는 것입니다(Lawshe, 1975). CVR은 다음과 같이 정의됩니다:\n\\[\nCVR={n_e-(N/2) \\over N/2}\n\\]\n여기서 n은 해당 문항을 필수 문항으로 간주하는 전문가 수이고, 총 전문가 수는 N입니다. 예를 들어, 부모에게 자녀의 공격성에 대해 질문하는 도구를 만들 수 있습니다. 한 문항은 “귀하의 자녀가 다른 아이를 무는가?”라고 질문할 수 있습니다. 20명의 전문가에게 이 문항이 아동의 공격성을 측정하는 데 필수적이라고 생각하는지 물어보고 17명이 동의하면, hemp에서 cvr 함수를 사용하여 CVR을 계산할 수 있습니다.\n\ncvr(N = 20, n_e = 17)\n\n[1] 0.7\n\n\n이 특정 문항에 대한 CVR이 0.70이라는 것을 알았지만 0.70이 해당 문항을 검사도구에 포함시킬 만큼 충분히 큰 값인지는 알 수 없습니다. Lawshe(1975)의 표 1은 전문가 수가 정해져 있을 때 CVR의 임계값을 제공합니다. 전문가가 20명일 경우, CVR의 최소값은 0.42이며, 전문가들이 이 문항이 우연이 아닌 필수적인 문항이라고 생각하며 이 문항을 측정문항에 포함시킬 가능성이 높다고 결론 내릴 수 있습니다.\n다른 형태의 타당도 증거는 검사 점수가 어떤 외부 기준과 어느 정도 관련되어 있는지를 측정합니다(준거 관련 타당도 증거). 이러한 타당도 증거에 대한 통계적 지원에는 단순 상관관계 계산 또는 회귀 분석이 포함될 수 있습니다. interest 데이터 세트로 돌아가서, 어휘력 테스트(vocab)는 독해력(reading) 및 문장 완성도(sentcomp)를 측정하는 평가와 상관관계가 있을 것으로 예상할 수 있습니다. 따라서 cor 함수를 사용하여 이러한 변수 간의 피어슨 상관관계를 계산할 수 있습니다.\n\ncor(interest[, c(\"vocab\", \"reading\", \"sentcomp\")])\n\n             vocab   reading  sentcomp\nvocab    1.0000000 0.8030912 0.8132765\nreading  0.8030912 1.0000000 0.7252155\nsentcomp 0.8132765 0.7252155 1.0000000\n\n\n어휘와 읽기 간의 피어슨 상관계수는 0.803이고, 어휘와 문장 완성도 간의 상관계수는 0.813입니다. 이는 어휘 시험이 읽기 및 문장 완성도 시험과 동시에 시행되었다면 공인 타당도 증거가 될 수 있습니다. 어휘 시험이 읽기 및 문장 완성 시험보다 먼저 시행된 경우, 피어슨 상관관계는 예언 타당도를 뒷받침하는 증거를 나타냅니다.\n사회적 우세성(socdom)이라는 성격 측정치를 사용하여 교사(교사)가 되고자 하는 사람의 흥미를 측정하고 있는데, 성격 측정치만으로 독해력 평가를 시행할 때 추가적인 예측 능력이 있는지 알고 싶다고 가정해 보겠습니다. 우리는 독해력이 부가적 타당도를 갖는지 평가하려고 하며, 이는 단계적 회귀를 사용하는 회귀 프레임워크 내에서 평가할 수 있습니다.\n이를 위해 두 가지 선형 회귀 모델을 적용합니다. 첫 번째 모델(mod_old)은 교사의 사회적 우세성을 회귀 분석하고, 두 번째 모델(mod_new)은 교사의 사회적 우세성과 읽기 능력을 모두 회귀 분석합니다. 선형 회귀 모델은 R의 lm 함수를 사용하여 추정할 수 있습니다. 이 함수를 사용하려면 하나 이상의 독립 변수(socdom 및 reading)로 예측되는 종속 변수(교사)와 이러한 변수가 포함된 데이터 세트의 이름(interest)이 포함된 회귀 공식을 지정해야 합니다.\n\nmod_old <- lm(teacher ~ socdom, interest)\nmod_new <- lm(teacher ~ socdom + reading, interest)\n\nmod_new에는 mod_old에 사용된 것과 동일한 종속변수와 독립변수가 포함되어 있고 읽기 변수도 포함되어 있기 때문에 결과 모델은 내재됩니다. 교사를 예측하는 데 있어 socdom을 넘어선 읽기의 기여도를 조사하기 위해 두 모델 간의 R-제곱(\\(R^2\\)) 값의 변화를 추출할 수 있습니다. 또한 R의 anova 함수를 사용하여 두 모델을 통계적으로 비교할 수 있습니다. 이 테스트는 두 모델 간의 \\(R^2\\) 변화가 통계적으로 유의미한지(즉, \\(R^2\\) > 0)를 검사합니다. \\(R^2\\) 변화가 통계적으로 유의미한 경우, 읽기가 종속 변수인 교사의 사회적 우세성을 넘어서는 상당한 양의 변이를 설명한다고 결론을 내릴 수 있습니다.\n\nsummary(mod_new)$r.squared - summary(mod_old)$r.squared\n\n[1] 0.09125979\n\nanova(mod_old, mod_new)\n\nAnalysis of Variance Table\n\nModel 1: teacher ~ socdom\nModel 2: teacher ~ socdom + reading\n  Res.Df    RSS Df Sum of Sq      F    Pr(>F)    \n1    248 244.98                                  \n2    247 221.03  1    23.951 26.765 4.754e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n위의 결과에서 독해력 평가는 사회적 지배력 측정치만으로는 설명할 수 없는 부가적 타당도를 가지고 있으며(p < .001), 교직에 대한 흥미의 변산도를 약 9% 더 설명한다는 것을 알 수 있습니다.\n\n\n2.4.3 문항 분석\n문항 분석은 측정 도구를 개발하고 수정하는 데 중요한 역할을 합니다. 문항 분석은 R과 함께 제공되는 기본 함수를 사용하여 수행할 수 있습니다. SAPA 데이터 세트로 돌아가 이분법적으로 채점된 문항에 대해 문항 분석을 수행하는 방법을 보여 드리겠습니다.\n문항 분석을 수행할 때 계산하는 일반적인 통계는 각 문항에 정답을 맞힌 피험자의 비율입니다. 이를 문항 난이도, p 또는 p 값이라고 합니다. 이는 문항 반응 이론의 문항 난이도(제5장 참조)나 통계적 가설 검증의 p값과 혼동해서는 안 됩니다. 문항 난이도가 가장 높은 문항이 아이러니하게도 피험자에게 가장 쉬운 문항이기 때문에 문항 난이도를 문항 용이성이라고 부르기도 합니다.\ncolMeans 함수를 사용하여 문항 난이도를 계산할 수 있습니다. 일부 문항에서 결측치가 있는 피험자가 있으므로 계산에서 결측치를 무시하려면 na.rm = TRUE 인수를 전달해야 합니다. 그렇지 않으면 colMeans 함수는 하나 이상의 결측치가 있는 문항에 대해 “NA”를 반환합니다. 문항의 난이도를 더 쉽게 읽을 수 있도록 반올림 함수를 사용하여 소수점 이하 세 자리로 반올림합니다.\n\nitem_diff <- colMeans(SAPA, na.rm = TRUE)\nround(item_diff, 3)\n\n reason.4 reason.16 reason.17 reason.19  letter.7 letter.33 letter.34 letter.58 \n    0.640     0.698     0.697     0.615     0.600     0.571     0.613     0.444 \nmatrix.45 matrix.46 matrix.47 matrix.55  rotate.3  rotate.4  rotate.6  rotate.8 \n    0.526     0.550     0.614     0.374     0.194     0.213     0.299     0.185 \n\n\n출력 결과, reason.16과 reason.17의 문항 난이도가 가장 높았고, rotate.8의 문항 난이도가 가장 낮은 것으로 나타났습니다. 학생의 약 70%가 reason.16과 reason.17을 정답으로 맞힌 반면, 19%만이 rotate.8을 정답으로 맞혔습니다.\n문항 분석에서 널리 사용되는 또 다른 통계는 문항 변별도로, 문항이 높은 능력을 가진 피험자와 낮은 능력을 가진 피험자를 구분하는 변별력을 말합니다. 문항 변별도를 계산하는 방법에는 여러 가지가 있지만, 가장 일반적인 형태는 문항에 대한 피험자의 응답과 시험 총점 간의 점-이연 상관관계입니다. 양수 값이 크면 문항에 정답을 맞추는 것과 시험에서 높은 점수를 받는 것 사이에 강한 관계가 있음을 나타내고, 0에 가까운 값은 관계가 없음을 나타내며, 음수 값은 문항에 정답을 맞추는 것이 전체 시험 점수를 낮추는 것과 관련이 있음을 나타냅니다. 0에 가깝거나 음수에 가까운 값은 해당 문항이 제대로 작동하지 않을 수 있음을 나타냅니다. 문항 변별도가 낮거나 음수인 이유로는 해당 문항에 잘못된 정답 키를 사용했거나, 정답이 여러 개이거나, 정답이 전혀 없는 경우 등이 있을 수 있습니다. 원인에 관계없이 점수 간 상관관계가 낮거나 음수인 문항은 시험/검사 도구가 수정 상태인 경우 수정하거나 시험 및 채점에서 제거해야 합니다.\nSAPA의 문항 변별도를 계산하려면 먼저 na.rm = TRUE 옵션과 함께 rowSums 함수를 사용하여 총 시험 점수를 계산하고 이를 total_score로 저장합니다. 그런 다음 cor 함수를 사용하여 SAPA의 문항과 총점의 상관 관계를 파악합니다. 응답이 누락되었으므로 cor 함수에서 use = “pairwise.complete.obs” 인수를 지정합니다. 마지막으로 상관 관계 행렬을 item_discr로 저장하고 출력합니다.\n\ntotal_score <- rowSums(SAPA, na.rm = TRUE)\nitem_discr <- cor(SAPA, total_score,\nuse = \"pairwise.complete.obs\")\nitem_discr\n\n               [,1]\nreason.4  0.5875787\nreason.16 0.5326660\nreason.17 0.5859068\nreason.19 0.5582773\nletter.7  0.5835910\nletter.33 0.5569431\nletter.34 0.5946924\nletter.58 0.5750172\nmatrix.45 0.5095047\nmatrix.46 0.5138256\nmatrix.47 0.5478686\nmatrix.55 0.4468619\nrotate.3  0.5100778\nrotate.4  0.5559848\nrotate.6  0.5542336\nrotate.8  0.4807175\n\n\n결과에 따르면 SAPA의 모든 문항이 총점과 적당히 양의 상관 관계가 있는 것으로 나타났습니다. 이는 모든 문항이 제대로 작동하고 있음을 나타내며, 제거하거나 수정해야 할 문항에 대한 두드러진 정보를 제공하지 않습니다.\n문항 변별도를 계산하는 또 다른 방법은 총점을 기준으로 피험자를 두 그룹(예: 1 = 고득점자, 0 = 저득점자)으로 나누고 이 그룹화 변수를 문항 응답과 연관시키는 것입니다. 이를 문항 변별도 지수라고 합니다. 고성취 그룹과 저성취 그룹을 만드는 한 가지 방법은 총점을 기준으로 피험자 중 상위 27%와 하위 27%를 선택하는 것입니다. 여기서 27%를 사용하기로 한 결정은 다소 임의적이라는 점에 유의해야 합니다. 다른 값(예: 10% 또는 20%)을 사용하여 성취도가 높은 그룹과 낮은 그룹을 쉽게 정의할 수 있습니다. 그룹의 커트라인을 정의한 후에는 고성취 그룹과 저성취 그룹에서 해당 문항에 정답을 맞힌 피험자의 비율을 계산합니다.\n다음 예에서는 hemp 패키지의 idi 함수를 사용하여 SAPA 데이터 세트의 reason.4에 대한 문항 변별도 지수를 계산합니다. 성취도가 높은 그룹과 낮은 그룹을 지정하기 위해 idi 함수에서 perc_cut = .27을 사용합니다.\n\nidi(SAPA, SAPA$reason.4, perc_cut = .27)\n\nUpper 27% Lower 27% \n 0.805136  0.194864 \n\n\n성취도가 높은 그룹의 피험자 중 81%가 해당 문항을 맞힌 반면, 성취도가 낮은 그룹의 피험자 중 19%만이 해당 문항을 맞힌 것으로 나타났습니다. 이는 해당 문항이 고득점자에게는 쉬웠고 저득점자에게는 어려웠다는 것을 시사합니다. 따라서 이 특정 문항은 두 그룹을 구분하는 데는 유용하지만 각 그룹 내에서 반드시 유용하지는 않다고 말할 수 있습니다.\n문항 난이도 및 문항 변별도 지수 외에도 문항 분석에 유용한 또 다른 통계는 문항 신뢰도 지수입니다. 문항 신뢰도 지수(IRI)는 다음과 같이 정의됩니다:\n\\[\nIRI=S_i*r_{i,tt}\n\\]\n여기서 \\(S_i\\)는 문항 \\(i\\)의 표준 편차이고, \\(r_{i,tt}\\)는 문항 \\(i\\)와 총점 간의 상관관계입니다. IRI는 이론적으로 -0.5에서 0.5 사이의 범위이며, 값이 크고 양수이면 신뢰도가 높음을 나타냅니다. 아래에서는 SAPA 데이터 세트의 모든 문항에 대한 IRI를 계산합니다. 이 작업은 hemp에서 IRI 함수를 사용하여 수행할 수 있습니다.\n\niri(SAPA)\n\n               [,1]\nreason.4  0.2820989\nreason.16 0.2451971\nreason.17 0.2692675\nreason.19 0.2717135\nletter.7  0.2865325\nletter.33 0.2757209\nletter.34 0.2897118\nletter.58 0.2863221\nmatrix.45 0.2544930\nmatrix.46 0.2562540\nmatrix.47 0.2668171\nmatrix.55 0.2161230\nrotate.3  0.2016459\nrotate.4  0.2276081\nrotate.6  0.2539219\nrotate.8  0.1867207\n\n\niri 함수에서 반환된 결과에 따르면 SAPA 데이터 세트의 IRI 범위는 약 0.19에서 0.29 사이입니다. 이 값은 모두 IRI에 적합한 값입니다(즉, 음수이거나 0에 가까운 값은 없습니다).\n총점 대신 외부 기준을 사용하는 경우, 이 지수를 문항 타당도 지수(IVI)라고 합니다. IVI는 - 0.5에서 0.5 사이일 수 있으며, 절대값이 클수록 타당도가 높음을 나타냅니다. 음수 값이 크면 문항이 기준과 음의 상관관계가 있을 것으로 예상되는 경우 타당도가 높음을 나타냅니다.\n다음 예에서는 hemp의 ivi 함수를 외부 기준으로 reason.17, 흥미 문항으로 reason.4로 설정하여 IVI가 0.19로 나타났습니다.\n\nivi(item = SAPA$reason.4, crit = SAPA$reason.17)\n\n[1] 0.1903219\n\n\n분석해야 하는 문항의 또 다른 중요한 측면은 선택지입니다. 선다형 시험의 맥락에서 대체 가능한(즉, 틀린) 선택지를 방해 요소라고 합니다. 방해 요소는 선다형 문항에서 중요한 역할을 합니다. 고품질의 선다형 문항을 만들려면 부분적인 지식을 가진 피험자의 관심을 끌 가능성이 높은, 잘 작동하고 그럴듯한 방해 요소를 포함시키는 것이 중요합니다. 그럴듯하지 않은 방해 요소는 다시 작성하거나 더 나은 방해 요소로 교체해야 할 수 있습니다. 방해 요소의 품질은 일반적으로 방해 요소 분석을 사용하여 평가합니다(Gierl, Bulut, Guo, & Zhang, 2017). 방해 요인 분석은 피험자가 특정 방해 요인을 선택하는 비율을 살펴보는 방식으로 수행되는 경우가 많습니다(방해 요인 분석에 대한 종합적인 검토는 Gierl 외(2017) 참조).\n방해 요인 분석을 시연하기 위해 multiplechoice 데이터 세트의 문항을 hemp에서 사용합니다. 이는 496명의 수험생에게 27개의 선다형 문항으로 구성된 가상의 선다형 시험입니다. 네 가지 선택지는 데이터 세트에서 1, 2, 3, 4로 코딩되었습니다. 각 문항의 정답은 R에서 ?multiplechoice 명령을 실행하여 확인할 수 있으며, hemp의 distract 함수를 사용하여 각 방해 요소를 선택한 피험자의 비율을 계산합니다. 방해 요인 분석 결과를 distractors로 저장한 다음 head 함수를 사용하여 처음 6개 문항에 대한 결과를 출력합니다.\n\ndistractors <- distract(multiplechoice)\nhead(distractors)\n\n          1     2     3     4\nitem1 0.044 0.058 0.052 0.845\nitem2 0.109 0.069 0.792 0.030\nitem3 0.188 0.562 0.058 0.192\nitem4 0.034 0.125 0.742 0.099\nitem5 0.351 0.254 0.042 0.353\nitem6 0.081 0.198 0.558 0.163\n\n\n위의 표를 보면 모든 문항에서 약 5% 이하의 비율로 선택된 방해 요소가 있음을 알 수 있습니다. 이러한 방해 요소는 대부분의 수험생이 실행 가능하고 그럴듯한 선택지라고 생각하지 않을 정도로 낮은 수준의 지지를 받았기 때문에 수정이 필요한 후보일 수 있습니다. 문항 1의 경우, 방해 요인들은 모두 거의 동일한 기능을 하고 있었으며(즉, 각각 약 5%의 지지를 받음), 이는 모든 방해 요인들이 서로에 대해 잘 기능하고 있지만 문항이 너무 쉽다는 것을 시사합니다(정답은 4번 선택지로, 수험생의 84.5%가 선택함). 이와는 대조적으로 5번 문항은 더 어려운 문항으로, 정답은 역시 4번 선택지였습니다. 선택지 1과 2는 오답 가능성이 매우 높았고, 선택지 3은 지지율이 낮아(4.2%에 불과) 이 문항에서 수정되거나 삭제될 가능성이 있습니다. 선택지 1의 지지율(35.1%)이 매우 높다는 점을 고려할 때, 이 선택지도 정답일 가능성이 매우 높습니다. 이 문항을 더 자세히 분석하려면 이 문항에 대한 문항 변별도 지수를 계산하면 전반적인 문항 기능에 대한 추가적인 통찰력을 얻을 수 있으므로 매우 유용할 것입니다."
  },
  {
    "objectID": "chap02.html#요약",
    "href": "chap02.html#요약",
    "title": "2  고전검사이론",
    "section": "2.5 요약",
    "text": "2.5 요약\n이 장에서는 몇 가지 기초적인 측정 주제를 소개했습니다. 이 장에서는 측정 척도, 타당도, 신뢰도, CTT 프레임워크 및 문항 분석에 중점을 두었습니다. 또한 표본 분포가 불분명할 때 모수에 대한 신뢰 구간을 구하기 위한 옵션으로 부트스트랩을 소개했습니다. 이 장의 개괄적인 성격 때문에 독자는 제시된 통계 및 방법에 대한 자세한 정보를 얻으려면 보다 전통적인 측정 입문 교재를 참조하는 것이 좋습니다. 교육에 초점을 맞춘 측정에 대한 좋은 일반 입문서로는 Thorndike와 Thorndike-Christ(2010)를, 심리학에서 검사에 대한 보다 일반적인 접근 방식에 대해서는 R. J. Cohen 외(2013)를 추천합니다.\n이 장에서 소개한 통계를 확장하는 훌륭한 R용 패키지가 많이 있습니다. 예를 들어, psych 패키지(Revelle, 2017)는 범용 심리 측정 패키지이며 제4장에서 더 자세히 다룰 것입니다. 다음 장에서는 CTT 프레임워크의 몇 가지 단점을 해결하고 신뢰도 계산을 위한 보다 강력하고 유연한 모델을 제공합니다."
  },
  {
    "objectID": "chap03.html#개요",
    "href": "chap03.html#개요",
    "title": "3  일반화가능도 이론",
    "section": "3.1 개요",
    "text": "3.1 개요\n이 장에서는 일반화가능도 이론을 소개하는데, 문헌에서는 G 이론이라고도 합니다. 이 장에서는 G 이론에 대한 간략한 검토로 시작하여 G 이론의 핵심 개념, 특히 일반화 가능도 연구(G 연구)와 결정 연구(D 연구)의 구분, 국면(facets)과 측정 단위, 연구 설계, 고정 국면 무선 국면에 대해 정의합니다. 다양한 설계에 대해 R을 사용하여 G 및 D 연구를 실행하는 방법을 hemp 및 lme4(Bates, Mächler, Bolker, &Walker, 2015) 패키지를 사용하는 몇 가지 예제를 통해 보여드립니다."
  },
  {
    "objectID": "chap03.html#소개",
    "href": "chap03.html#소개",
    "title": "3  일반화가능도 이론",
    "section": "3.2 소개",
    "text": "3.2 소개\n측정에서 우리의 주요 관심사는 구인 또는 잠재 변수에 대한 개인의 기저에 있는 진점수를 추정하는 데 있습니다. 예를 들어, 피험자의 대수 지식, 지능 지수, 집행 기능 기술 또는 삶의 질을 추정하는 데 관심이 있을 수 있습니다. 안타깝게도 이러한 모든 추정치는 최선의 노력에도 불구하고 불완전하고 일정 수준의 측정 오차를 포함할 수밖에 없습니다.\n측정 과정에서 피할 수 없는 이러한 오차를 조정하기 위해 다양한 모델이 제안되었습니다. 제2장에서는 가장 간단하고 실제로 가장 일반적으로 적용되는 모델인 고전적 검사 이론(CTT) 모델을 소개했습니다. CTT 모델에서는 하나의 구인에 대한 개인의 관찰 점수가 해당 구인에 대한 진점수와 오차의 합이고(방정식 3.1의 첫 번째 줄), 따라서 검사 점수의 관찰 분산은 진점수 분산과 잔차(즉, 오차) 분산(방정식 3.1의 두 번째 줄, 자세한 내용은 2장 참조)의 합이라고 가정한다는 점을 기억하시기 바랍니다. 수학적으로 CTT 모델을 다음과 같이 정의할 수 있습니다.\n\\[\nX=T+E\n\\], and\n\\[\n\\sigma_X^2 = \\sigma_T^2 + \\sigma_E^2\n\\]\nCTT 모델에서는 진점수 분산에 기인할 수 없는 관찰된 모든 분산 원인이 단일 잔차 항으로 포착됩니다. 따라서 다양한 오차 원인을 구분하고 정량화하려는 시도는 하지 않습니다. 오차 분산에 포함된 모든 오차 원인은 가변성 여부, 즉 검사 개발자/관리자의 통제 범위 내에 있는지 여부와 가변성이 없는지에 관계없이 동일한 방식으로 처리됩니다.\n일반화 가능도 이론(G 이론)에서 우리의 주요 초점은 오차 분산을 통제 가능한 변산의 원인으로 분리하는 것입니다(Shavelson & Webb, 1991). 우리는 이 분산을 실무자와 연구자가 조작할 수 있는 측정 조건(국면(facets)이라고 함) 및 측정 단위(일반적으로 학생 또는 연구 참여자)와 관련된 변산원으로 분리할 수 있기를 원합니다. 오차를 다양한 원인으로 세분화하면 국면의 수준을 변경하는 것이 시험 점수의 신뢰도에 어떤 영향을 미치는지 정량화할 수 있으며, 그에 따라 검도구를 조정할 수 있습니다.\n구체적인 예로 대학원 준비도를 측정하는 도구를 만든다고 상상해 봅니다. 대학원 프로그램은 학생들이 연구 논문, 원고, 기술 보고서 등을 통해 자신의 아이디어를 발표할 수 있는 연구자가 될 수 있도록 교육합니다. 따라서 지원자는 대학원 지원 및 입학 시 논리적이고 명료한 에세이를 작성할 수 있는 탄탄한 글쓰기 능력을 갖춰야 합니다. 대학원에서 필수적인 작문 능력을 측정하기 위해 지원자가 응답해야 하는 일련의 작문 프롬프트로 구성된 검사도구를 구성합니다. 검사도구에 선택한 쓰기 프롬프트는 우리가 관심을 갖는 모든 쓰기 프롬프트를 나타낼 수 있으며(즉, 고정된 수의 쓰기 프롬프트가 있습니다), 쓰기 프롬프트는 고정국면이라고 할 수 있습니다. 이는 분산분석의 고정 효과와 유사합니다. 쓰기 프롬프트는 우리가 선택할 수 있는 매우 크고 잠재적으로 무한한 쓰기 프롬프트 풀에서 무작위로 추출한 샘플일 가능성이 높습니다. 분산분석의 맥락에서 쓰기 프롬프트는 무선효과로 취급되며 쓰기 프롬프트는 무선 국면라고 할 수 있습니다.\n검사도구를 구성한 후에는 피험자(즉, 예비 대학원생)을 대상으로 평가를 실시합니다. 예비 대학원생에게는 한 시간 동안 글쓰기 프롬프트에 대한 응답을 작성할 시간이 주어집니다. 그런 다음 채점자가 답변을 채점합니다. 작문 프롬프트와 마찬가지로, 우리는 일반적으로 특정 채점자가 아니라 모든 채점자에게 관심이 있으므로 채점자를 무작위적인 측면으로 간주합니다. 채점자가 모든 쓰기 프롬프트에 점수를 매길 수 있다면 쓰기 프롬프트와 채점자는 교차된 것으로 간주되지만, 채점자가 쓰기 프롬프트의 특정 하위 집합에만 점수를 매길 수 있다면 채점자는 쓰기 프롬프트 내에 내재된 것으로 간주됩니다. 이 예에서는 모든 채점자가 모든 쓰기 프롬프트에 점수를 매길 수 있으므로 채점자와 쓰기 프롬프트가 교차한다고 가정합니다.\n우리가 달성하고자 하는 것은 모든 쓰기 프롬프트와 모든 채점자에 걸쳐 학생의 실제 쓰기 능력을 추정하는 것입니다. 즉, G 이론에서 우리의 목표는 모든 잠재적 변인들에 대해 일반화 가능하고 신뢰할 수 있는 작문 능력의 추정치를 얻는 것입니다(Brennan, 1992). 이 가상의 예에서 학생, 쓰기 프롬프트 및 평가자는 모두 변산원을 나타내며, 쓰기 프롬프트와 평가자는 국면을 나타내고 학생은 측정 단위를 나타냅니다. 학생과 관련된 변산은 진점수 분산 또는 G 이론 용어로 전집 점수 분산이 될 것입니다.\n단일 채점자(r)에 의해, 단일 쓰기 프롬프트(w)에서 학생(들)에 대해 관찰된 점수 \\(X_{swr}\\) 는 다음과 같이 분해할 수 있습니다:\n\\[\nX_{swr}=\\mu+\\nu_s+\\nu_w+\\nu_r+\\nu_{sw}+\\nu_{sr}+\\nu_{wr}+\\nu_{swr},e.\n\\]\n방정식 3.2에서 학생의 점수는 총평균(\\(mu\\)), 학생 효과(\\(\\nu_s\\)), 쓰기 프롬프트 효과(\\(\\nu_w\\)), 채점자 효과(\\(\\nu_r\\)), 학생별 쓰기 프롬프트 효과(\\(\\nu_{sw}\\)), 채점자별 학생 효과(\\(\\nu_{sr}\\)), 채점자별 쓰기 프롬프트 효과(\\(\\nu_{wr}\\)), 마지막으로 잔차 항(\\(\\nu_{swr,e}\\))과 완전히 섞여있는 채점자별 쓰기프롬프트별 학생 효과라는 8개의 구성 요소를 포함하고 있습니다. 이러한 각 효과는 무선 효과(확률 변수)라고 가정하기 때문에 일반적으로 평균이 0이고 분산은 알 수 없는 정규 분포(상수인 총평균 제외)로 가정하는 분포를 갖습니다. 또한 이 설계에서 전집(즉, 가능한 모든 문항과 채점자) 및 모집단(즉, 모든 학생)에 걸쳐 작문 프롬프트에서 관찰된 점수의 총 분산은 다음과 같이 표현할 수 있습니다:\n\\[\nX^2_{swr}=\\sigma^2_s+\\sigma^2_w+\\sigma^2_r+\\sigma^2_{sw}+\\sigma^2_{sr}+\\sigma^2_{wr}+\\sigma^2_{swr},e.\n\\]\n방정식 3.3에서 관찰된 점수의 분산은 7개의 독립 분산으로 쓸 수 있음을 알 수 있습니다: 학생의 쓰기 능력의 분산은 G 이론에서 전집 점수 분산으로 알려져 있으며, 이는 CTT의 진점수 분산(\\(\\sigma^2_s\\))과 유사합니다; 쓰기 프롬프트의 분산(예: \\(\\sigma^2_w\\), 일부 프롬프트가 다른 프롬프트보다 응답하기가 더 쉬울 수 있는 정도); 채점자의 분산(\\(\\sigma^2_r\\), 일부 채점자가 다른 채점자보다 더 높거나 낮은 점수를 주는 정도); 학생별 쓰기 프롬프트의 분산(\\(\\sigma^2_{sw}\\), 일부 쓰기 프롬프트가 다른 학생보다 더 쉽게 답할 수 있는 정도); 학생별 채점자 분산(\\(\\sigma^2_{sr}\\), 채점자가 특정 학생에게 다른 학생보다 높은 점수를 부여하는 정도); 채점자별 쓰기 프롬프트 분산(\\(\\sigma^2_{wr}\\), 채점자가 일부 프롬프트에 다른 채점자보다 높은 점수를 주는 정도), 마지막으로 학생별 쓰기 프롬프트별 채점자 분산(\\(\\sigma^2_{swr},e\\), 특정 평가자가 특정 프롬프트에서 학생이 더 높은 점수를 받는 정도)은 잔차 분산과 완전히 섞입니다. CTT에서는 분산인 \\(\\sigma^2_w...\\sigma^2_{swr,e}\\)가 모두 단일 잔차 분산인 \\(\\sigma^2_E\\)로 포착됩니다.\n그림 3.1은 위에서 설명한 가상의 설계에 대한 벤 다이어그램을 보여줍니다. 그림 3.1에는 학생, 쓰기 프롬프트, 채점자 및 이들의 상호 작용과 관련된 변산원이 나와 있습니다. 원 사이의 겹치는 부분(변산원)은 상호작용의 크기를 나타냅니다.\n이 시점에서 CTT에 비해 G 이론의 장점이 더욱 분명해집니다. 총 변동을 조작 가능한 국면으로 분해하면 각 측정 조건과 관련된 변산의 양을 정량화할 수 있으며, 특정 수준의 신뢰도를 얻기 위해 각 조건과 관련된 레벨의 수를 변경할 수 있습니다.\nG 이론에서는 일반적으로 일반화 가능도(G) 연구와 결정(D) 연구라는 두 가지 유형의 연구가 수행됩니다(Shavelson & Webb, 1991). G 연구에서는 모든 잠재적인 변산원을 파악하고 이를 연구 설계에 통합하여 허용 가능한 관찰 전집을 정의합니다. 쓰기 프롬프트 예시에서는 모든 채점자가 모든 쓰기 프롬프트를 채점할 수 있으므로, 허용 가능한 관찰 전집은 프롬프트와 채점자의 모든 조합이 허용 가능하다는 것입니다. G 연구에서는 방정식 3.3과 그림 3.1에 표시된 분산을 추정합니다.\n\n\n\n2국면 교차설계. s는 학생(측정 단위), w는 쓰기 프롬프트, r은 채점자, e는 오차임\n\n\nD 연구에서는 일반화 가능하고 신뢰할 수 있는 점수를 얻기 위해 가상의 시나리오를 조사합니다. 쓰기 프롬프트 예시에서는 프롬프트 수, 채점자 수 또는 둘 다를 변경할 수 있다고 가정할 수 있습니다. G 및 D 연구를 주로 안내하는 것은 검사 점수를 어떻게 사용할 계획인지입니다. 예비 대학원생의 상대적 순위 결정과 같은 상대적인 결정을 내리는 데 검사 점수를 사용하려는 경우, CTT의 신뢰도에 해당하는 G 이론인 일반화 가능도 계수를 사용하여 점수를 요약합니다. 검사 점수를 사용하여 학생이 대학원 수준에서 글을 쓸 준비가 되었는지 여부와 같은 절대적인 결정을 내리려면 의존도 계수를 사용하여 점수를 요약합니다. 일반화 가능도 계수를 구하려면 상대 오차 분산인 \\(\\sigma^2_{rel}\\)을 계산해야 하고, 의존도 계수를 구하려면 절대 오차 분산인 \\(\\sigma^2_{abs}\\)를 계산해야 합니다. 그러면 일반화 가능도 계수와 의존도 계수는 다음과 같이 계산됩니다:\n\\[\n일반화가능도 계수=\\rho^2={\\sigma^2_s \\over \\sigma^2_S + \\sigma^2_{rel}}\n\\]\n\\[\n의존도 계수 = \\phi= {\\sigma^2_s \\over \\sigma^2_S + \\sigma^2_{abs}}\n\\]\n여기서 \\(\\sigma^2_s\\) 분산은 학생의 검사 점수 변산(전집 점수 분산)입니다. \\(\\sigma^2_{rel}\\)과 \\(\\sigma^2_{abs}\\)에 들어가는 것은 연구 설계에 따라 다릅니다. 이러한 분산 구성 요소에 대해 더 자세히 알고 싶은 독자, 그리고 더 일반적으로 G 및 D 연구에 대해 더 알고 싶은 독자에게는 일반화 가능도 이론: 입문서를 강력히 추천합니다(Shavelson and Webb, 1991). 이 입문서는 따라 하기 쉽고, 다양한 G 연구 설계를 안내하며, 관심 있는 독자가 적절한 연구 설계를 결정하는 데 도움을 줄 수 있습니다.\n다음 섹션에서는 다양한 연구 설계에 대해 설명하고, hemp 패키지의 gstudy 및 dstudy 함수를 사용하여 이러한 설계의 일반화 가능도 및 의존도 계수를 계산하는 방법을 보여줍니다."
  },
  {
    "objectID": "chap03.html#예제",
    "href": "chap03.html#예제",
    "title": "3  일반화가능도 이론",
    "section": "3.3 예제",
    "text": "3.3 예제\n\n3.3.1 단일국면 설계\n첫 번째 예시 데이터는 30명의 연구 참여자 그룹을 대상으로 실시한 가상의 집행 기능(EF) 검사도구에서 가져온 것입니다. 이 검사도구는 참가자의 집행기능 능력을 측정하는 이분법적으로 채점된 10개의 문항으로 구성되어 있습니다. efData 데이터 세트는 hemp 패키지에서 사용할 수 있습니다. 이 예에서는 단일국면인 문항(문항)과 측정 단위인 참가자(참가자)가 있습니다. 따라서 이것은 단일 국면(p x i) 설계의 예입니다.\nefData 내의 변수 Score에는 참가자가 제공한 문항에 대한 응답이 포함됩니다. 우리는 시행된 문항에 특별히 관심이 있는 것이 아니라 모든 잠재적 문항에 관심이 있기 때문에 이 국면을 무선으로 간주합니다. 일반적으로 국면을 고정된 것으로 취급해야 하는 특별한 이유가 없는 한 국면을 무선으로 취급하는 것이 좋습니다. 그림 3.2는 이 설계에서 변산원을 보여 주며, 집행 기능에서 관찰된 총 점수의 변산은 다음과 같이 작성할 수 있습니다:\n\\[\n\\sigma^2(X_{pi})=\\sigma^2_p+\\sigma^2_i+\\sigma^2_{pi,e.}\n\\]\n그림 3.2와 방정식 3.6을 보면 연구에는 참가자 관련 변산(p), 문항 관련 변산(i), 문항과 참가자 간의 상호작용 관련 변산(pi,e)의 세 가지 변산원이 있음을 알 수 있습니다. 단일국면 설계에서는 이러한 상호 작용이 무선오차와 완전히 섞여있습니다(Shavelson & Webb, 1991).\n\n\n\n단일국면설계(p*i). p는 참가자(측정 단위), i는 문항, e는 오차임\n\n\n\n3.3.1.1 G 연구\nG 연구에서는 방정식 3.6에 정의된 분산 성분을 추정합니다. 이러한 분산 성분을 추정하기 위해 먼저 라이브러리 명령을 사용하여 hemp 패키지를 로드합니다.\n\nlibrary(hemp)\n\nLoading required package: psych\n\n\nLoading required package: lattice\n\n\nLoading required package: lavaan\n\n\nThis is lavaan 0.6-16\nlavaan is FREE software! Please report any bugs.\n\n\n\nAttaching package: 'lavaan'\n\n\nThe following object is masked from 'package:psych':\n\n    cor2cov\n\n\nLoading required package: mirt\n\n\nLoading required package: stats4\n\n\nLoading required package: lme4\n\n\nLoading required package: Matrix\n\n\n\nAttaching package: 'lme4'\n\n\nThe following object is masked from 'package:mirt':\n\n    fixef\n\n\nLoading required package: reshape2\n\n\nLoading required package: boot\n\n\n\nAttaching package: 'boot'\n\n\nThe following object is masked from 'package:lattice':\n\n    melanoma\n\n\nThe following object is masked from 'package:psych':\n\n    logit\n\n\nLoading required package: equate\n\n\nhemp 패키지는 lme4 패키지의 lmer 함수를 사용하여 분산 성분을 추정합니다. 참가자 및 문항 분산을 추정하려면 무선 효과를 지정하기 위해 lme4의 구문을 사용해야 합니다. 이러한 효과에 대한 lme4 구문은 각각 (1 | Participants) 및 (1 | Items)입니다. 동일한 구문 내에서 Score는 분해하려는 종속 변수 역할을 합니다. lme4에 모델을 맞추고 결과를 onefacet_mod로 저장한 후, 모델에서 gstudy 함수를 호출합니다(즉, onefacet_mod). G 연구를 onefacet으로 저장한 다음 마지막에 결과를 출력합니다.\n\nonefacet_mod <- lmer(Score ~ (1 | Participants) + (1 | Items),\ndata = efData)\nonefacet <- gstudy(onefacet_mod)\nonefacet\n\n        Source Est.Variance Percent.Variance\n1 Participants       0.0258             9.9%\n2        Items       0.0959            36.8%\n3     Residual       0.1387            53.3%\n\n\nG 연구에서 추정된 분산은 단일 EF 문항에 대한 참가자의 점수를 전집 점수로 일반화할 때 발생하는 오차의 크기를 반영합니다. 이는 현재 검사 길이인 10개 문항을 기준으로 일반화할 때 발생하는 분산이 아닙니다. 이를 알고 싶다면, 의심할 여지 없이, D 연구를 수행할 때 10개의 문항으로 구성된 검사를 고려해야 합니다.\nG 연구에서 추정된 분산을 해석하는 데 유용한 휴리스틱(어림짐작)은 각 분산 구성 요소가 전체 분산에서 차지하는 비율을 계산하는 것입니다.1 이 비율은 위의 결과 데이터 프레임의 마지막 열에 나와 있습니다. 단일 문항 검사의 경우, 참가자의 분산 성분(즉, 전집 점수 분산)이 전체 분산에서 차지하는 비중이 10%에 불과하다는 것을 알 수 있습니다. 이는 다소 낮은 수치로, 당연히 단일 문항 검사의 신뢰도가 높지 않음을 시사합니다.\n전집 점수 구성 요소의 해석을 돕기 위해 히스토그램을 만들 수 있습니다. 아래에 제시된 R 코드는 lattice 패키지를 로드하고 aggregate 함수를 사용하여 각 참가자가 정답을 맞힌 문항의 비율을 계산한 다음 히스토그램을 생성합니다(그림 3.3 참조).\n\n\n\nEF 검사도구에서 정답을 맞힌 문항의 비율\n\n\n\nlibrary(\"lattice\")\nscores <- aggregate(efData$Score, by = list(efData$Participants), mean)\nhistogram(~ x, scores, type = \"count\", xlab = \"Proportion of Items Correct\")\n\n\n\n\n히스토그램을 보면 모든 문항을 정답 또는 오답으로 맞힌 참가자는 한 명도 없으며, 압도적으로 많은 참가자가 시험에서 50% 또는 60%의 문항(즉, 정답이 5개 또는 6개)을 정답으로 맞힌 것을 알 수 있습니다. 이렇게 촘촘한 클러스터링으로 인해 전집 점수 분산이 낮았습니다.\n문항의 분산 성분(0.0959 또는 전체 분산의 36.8%)은 전집 점수 분산에 비해 크지만 잔차 분산에 비해서는 작습니다. Shavelson과 Webb(1991)은 이 분산의 제곱근을 구하여 표준 편차를 구한 다음 4개의 표준 편차(정규 분포를 가정할 경우 점수의 약 95%)에 대한 범위를 계산할 것을 제안합니다. 표준 편차는 약 0.31이며 여기에 4를 곱하면 약 1.2가 됩니다. 문항 평균의 범위가 0에서 1까지만 가능하다는 점을 감안할 때 표준편차가 0.31이라는 것은 문항의 평균에 변산이 많다는 것을 의미합니다.\n다음으로 aggregate 함수를 사용하여 각 문항의 평균을 다시 계산하고 문항 평균을 item_means로 저장합니다. 결과를 출력하기 전에 colnames 함수를 사용하여 이 새 데이터 집합의 열 이름을 “Item” 및 “Mean”으로 바꿉니다.\n\nitem_means <- aggregate(efData$Score, by = list(efData$Items), mean)\ncolnames(item_means) <- c(\"Item\", \"Mean\")\nitem_means\n\n   Item       Mean\n1     1 0.94285714\n2     2 0.68571429\n3     3 0.68571429\n4     4 0.08571429\n5     5 0.74285714\n6     6 0.77142857\n7     7 0.08571429\n8     8 0.60000000\n9     9 0.45714286\n10   10 0.11428571\n\n\n문항 평균의 범위는 0.09에서 94로 상당히 큰 변산을 보이며, 문항이 설명하는 높은 변산 비율을 입증합니다.\n잔차 분산이 크다는 것은 참가자와 문항의 상호 작용과 무선 오차(우리가 풀 수 없는)를 모두 포착한 것입니다. 일부 참가자가 일부 문항에 더 쉽게 답했거나, (평가가 실시된 물리적 환경 또는 실내 온도와 같은) 시스템적 변산이 있었을 수도 있고, (일부 참가자가 평가를 완료할 때 배가 고프거나 피곤한 상태였다는 등) 무작위적인 변산이 있었을 수도 있습니다. 어느 쪽이든, 우리는 이 분산 구성 요소에서 이러한 소스를 서로 분리할 수 없습니다.\nG 연구에서 EF에 대한 단일 문항 검사는 신뢰성이 높지 않다는 결론을 내릴 수 있으며, 이는 놀라운 결과가 아닙니다. 다음에는 오차를 줄이고 점수의 신뢰도를 높이기 위해 검사의 길이를 다양하게 하는 것을 고려할 수 있습니다. 이는 D 연구에서 검토할 수 있습니다.\n\n\n3.3.1.2 D 연구\nEF 평가에는 국면(문항)이 하나만 있습니다. 따라서 일반화 가능도 또는 의존도 계수에 영향을 미치기 위해 EF 평가에 표시되는 문항의 수만 변경할 수 있습니다. D 연구는 hemp 패키지의 dstudy 함수를 사용하여 수행할 수 있습니다. 단일 문항 EF 검사의 신뢰도를 계산하려는 경우 다음과 같이 수행합니다:\n\ndstudy(onefacet, unit = \"Participants\", n = c(\"Items\" = 1))\n\n        Source Est.Variance   N Ratio of Var:N\n1 Participants       0.0258 350         0.0258\n2        Items       0.0959   1         0.0959\n3     Residual       0.1387   1         0.1387\n\nThe generalizability coefficient is: 0.1568389.\nThe dependability coefficient is: 0.09907834.\n\n\nhemp 패키지에서 dstudy 함수를 호출하면 기본적으로 세 가지 정보가 출력됩니다:\n\n분산 소스, 추정된 분산, 참여자 및 국면의 수준 수, 이 분산을 국면의 수준 수로 나눈 값이 포함된 데이터 프레임,\n일반화 가능도 계수, 그리고\n의존도 계수.\n\nD 연구에 따르면 하나의 문항으로만 구성된 검사의 일반화 가능도 계수는 약 .16, 의존도 계수는 .10입니다. 현재 검사 길이가 10이므로 10개 문항으로 구성된 검사 길이에 대한 신뢰도를 알고 싶습니다. dstudy 함수에서 “n” 인수를 n = c(“Items” = 10)로 변경합니다. 결과를 onefacet_dstudy로 저장합니다.\n\nonefacet_dstudy <- dstudy(onefacet, unit = \"Participants\", n = c(\"Items\" = 10))\nonefacet_dstudy\n\n        Source Est.Variance   N Ratio of Var:N\n1 Participants       0.0258 350        0.02580\n2        Items       0.0959  10        0.00959\n3     Residual       0.1387  10        0.01387\n\nThe generalizability coefficient is: 0.6503655.\nThe dependability coefficient is: 0.5237515.\n\n\n현재 검사 길이로 일반화 가능도 계수는 .65, 의존도 계수는 .52입니다. 이러한 신뢰도는 여전히 매우 낮으므로 점수의 신뢰도를 개선하려면 검사 길이를 더 늘려야 합니다.\ndstudy 함수의 출력을 onefacet_dstudy로 저장했음을 기억하십시오. onefacet_dstudy에 저장된 결과를 사용하여 상대 오차 분산(relvar)과 절대 오차 분산(absvar)을 추출할 수 있습니다.\n\nonefacet_dstudy$relvar\n\n[1] 0.01387\n\n\n\nonefacet_dstudy$absvar\n\n[1] 0.02346\n\n\n검사 길이 증가가 신뢰도에 미치는 영향을 시각화하는 효과적인 방법은 검사 길이에 대한 계수를 그래프로 그리는 것입니다. 이 작업은 신뢰도를 계산할 검사 길이의 값 범위를 지정하여 dstudy_plot을 사용하여 수행할 수 있습니다. 아래 호출에서는 다양한 검사 길이(예: 10개 항목에서 60개 항목)에 대해 의존도 계수(g_coef = FALSE 인수를 통해 지정됨)를 플롯합니다.\n\ndstudy_plot(onefacet, unit = \"Participants\", facets = list(Items = c(10, 20, 30, 40, 50, 60)), g_coef = FALSE)\n\n\n\n\n그림 3.4에서는 현재 검사의 문항 수를 10개에서 20개로 두 배로 늘릴 때 신뢰도가 가장 크게 향상되는 것을 볼 수 있습니다. 검사 점수의 용도에 따라(예: 고부담인지 저부담의 절대 결정인지) 40개 문항의 검사 길이에 대해 .80 미만의 신뢰도로 만족할 수도 있고, 더 높은 신뢰도가 필요한 경우(예: .90의 신뢰도) 현재 검사보다 6배 더 긴 검사(즉, 60개 문항)가 필요할 수 있습니다. 신뢰도 계수에 대한 다양한 D 연구 그래프의 유용성은 국면의 수준 수를 늘리는 것이 신뢰도에 미치는 영향을 신속하게 평가할 수 있다는 것입니다.\n\n\n\n단일국면 무선 설계에 대한 EF 항목 수에 대한 의존도 계수\n\n\n\n\n\n3.3.2 2국면 교차 설계\n2국면 교차 설계를 시연하기 위해 hemp 패키지의 writing 데이터 세트를 사용합니다. 이 가상의 데이터 세트에는 두 명의 채점자(r)가 채점한 5개의 쓰기 프롬프트(w)에서 측정된 10명의 학생(들)에 대한 데이터가 포함되어 있습니다. 데이터는 각 행이 단일 관찰(즉, 단일 쓰기 프롬프트에 대한 점수)에 해당하는 긴 형식이며, 학생, 프롬프트, 채점자 및 점수 변수에는 학생 식별자, 쓰기 프롬프트 식별자, 평가자 식별자 및 단일 관찰에 대한 점수가 포함되어 있습니다.\n\n3.3.2.1 G 연구\n방정식 3.3과 그림 3.1은 2국면 교차(p x w x r ) 설계에서 추정되는 분산을 나타냅니다. 학생, 쓰기 프롬프트, 채점자 및 이들의 상호작용에 대한 분산이 추정됩니다. 위의 단일국면 설계와 달리 모든 이원 상호작용을 추정할 수 있으므로 lme4에 대한 호출에서 상호작용을 지정해야 합니다. 그러나 위에서 설명한 대로 학생-작성 프롬프트-채점자 간 상호작용은 잔차 분산 내에서 섞여있으므로 지정하지 않습니다. 상호작용을 나타내기 위해 lme4는 구문 (1 | variable1:variable2)을 사용합니다. 이 구문은 lm 호출에서 상호 작용을 지정하는 방식과 유사합니다. 아래의 lmer 함수 호출에서는 6개의 분산(즉, 학생, 프롬프트, 채점자, 프롬프트별 학생, 채점자별 학생, 프롬프트별 채점자)을 지정합니다.\n\ntwofacet_mod <- lmer(scores ~ (1 | students) + (1 | prompts) + (1 | raters) + (1 | students:prompts) + (1 | students:raters) + (1 | prompts:raters), data = writing)\n\n그런 다음 twofacet_mod 개체를 gstudy 함수에 전달하여 G 연구에 대한 분산을 추정할 수 있도록 합니다.\n\ntwofacet <- gstudy(twofacet_mod)\ntwofacet\n\n            Source Est.Variance Percent.Variance\n1 students:prompts      12.8891             3.6%\n2  students:raters      62.4069            17.4%\n3   prompts:raters       4.8775             1.4%\n4         students     180.1812            50.2%\n5          prompts       8.1506             2.3%\n6           raters      19.8003             5.5%\n7         Residual      70.3423            19.6%\n\n\n위의 출력에서는 상호작용이 먼저 나온 다음 학생, 쓰기 프롬프트, 채점자의 분산, 그리고 마지막으로 잔차 분산이 나옵니다. 가장 큰 분산 구성 요소인 학생의 분산(180.176)은 점수 총 분산의 약 50%를 차지합니다. 이는 전집 점수에 대한 분산 성분으로, 학생들이 작문 평가에서 체계적으로 점수에 차이가 있음을 나타냅니다. 채점자의 분산 성분은 학생에 비해 작지만 쓰기 프롬프트 분산보다는 큽니다. 이 분산의 제곱근(\\(\\sqrt{19.8028}\\) = 4.45)을 구하면 채점자 평균의 예상 범위는 약 18 또는 27입니다(정규 분포 및 표준 편차 2 또는 3 가정). 이 범위는 쓰기 프롬프트의 점수 범위(0~100점)에 비해 상당히 작습니다. 마찬가지로 쓰기 프롬프트의 분산은 더 작았으며 쓰기 프롬프트에서 예상되는 점수 범위는 12 또는 18로 매우 작았습니다. 학생별 쓰기 프롬프트와 채점자별 쓰기 프롬프트의 분산은 매우 작았는데, 이는 쓰기 프롬프트에 따라 학생의 순위가 크게 달라지지 않았으며 채점자가 문항을 합리적으로 일관되게 채점했음을 나타냅니다. 채점자별 학생 분산(62.4073)은 다른 분산 구성 요소에 비해 상당히 큽니다. 이 결과는 일부 채점자가 일부 학생에게 다른 학생보다 높은 점수를 부여했음을 시사합니다. 마지막으로, 잔차 분산(70.3428 또는 전체 분산의 약 20%)은 분산의 상당 부분이 학생, 채점자, 쓰기 프롬프트 간의 3원 상호작용 또는 연구에서 설명되지 않은 기타 무선 또는 체계적인 변산의 원인으로 인해 발생했음을 보여줍니다.\n\n\n3.3.2.2 D 연구\n채점자 2명과 쓰기 프롬프트 5개가 있는 2국면 교차 설계의 일반화 가능도 및 의존도 계수는 dstudy 함수를 사용하여 계산할 수 있습니다.\n\ndstudy(twofacet, n = c(\"raters\" = 2, \"prompts\" = 5), unit = \"students\")\n\n            Source Est.Variance   N Ratio of Var:N\n1 students:prompts      12.8891   5        2.57782\n2  students:raters      62.4069   2       31.20345\n3   prompts:raters       4.8775  10        0.48775\n4         students     180.1812 100      180.18120\n5          prompts       8.1506   5        1.63012\n6           raters      19.8003   2        9.90015\n7         Residual      70.3423  10        7.03423\n\nThe generalizability coefficient is: 0.8153117.\nThe dependability coefficient is: 0.773261.\n\n\n일반화 가능도 계수는 0.82, 의존도 계수는 0.77입니다. 저부담 검사의 경우, 이 계수는 허용 가능한 수준입니다. 그러나 고부담 검사에서는 0.90 이상의 신뢰도가 바람직합니다.\n작문 평가가 고부담 검사의 의사 결정에 사용된다고 가정하면, 어떤 종류의 설계가 0.90 이상의 일반화 가능도 계수를 제공할지 결정하기 위해 dstudy_plot 함수를 사용할 수 있습니다. 아래에서는 쓰기 프롬프트의 수(3~8개 범위)에 대한 일반화 가능도 계수를 채점자 수(1~5개 범위)로 플롯했습니다.\n\ndstudy_plot(twofacet, unit = \"students\", facets = list(prompts = 3:8,\nraters = 1:5))\n\n\n\n\n그림 3.5는 쓰기 프롬프트와 채점자에 의해 예상되는 일반화 가능도 계수를 보여줍니다. 신뢰도 0.90을 얻으려면 적어도 4명의 채점자가 필요합니다. 채점자가 4명인 경우 약 7개의 쓰기 프롬프트가 필요하고, 채점자가 5명인 경우 약 4개의 쓰기 프롬프트가 필요합니다. 어떤 설계를 사용할지 여부는 채점자의 가용성 또는 응시자가 응답하게 할 프롬프트의 수에 따라 달라질 수 있습니다. 또한 세 개 이상의 쓰기 프롬프트와 두 명의 채점자를 두어 신뢰도를 추가로 높일 가치가 있는지 여부를 결정할 수도 있습니다.\n\n\n\n채점자 수에 따른 쓰기 프롬프트 수에 대한 일반화 가능도 계수\n\n\n\n\n\n3.3.3 2국면 부분 내재 설계\n부분적으로 내재된 2국면 설계를 보여주기 위해 hemp 패키지의 writing2 데이터 세트를 사용합니다. 이 가상 데이터 세트에는 두 명의 채점자(r)가 채점한 5개의 쓰기 프롬프트(w)에서 측정된 10명의 학생(s)에 대한 데이터가 포함되어 있습니다. 채점자가 모든 학생의 모든 쓰기 프롬프트에 점수를 매긴 writing 데이터 집합과 달리, writing2 데이터 집합에서는 각 채점자가 한 학생에게만 점수를 매겼습니다(즉, 채점자가 학생 내에 중첩되어 있음). 모든 학생에 대해 두 명의 채점자가 5개의 쓰기 프롬프트 모두에서 한 학생에게 점수를 매겼습니다. 그러나 각 채점자는 한 명 이하의 학생에게만 점수를 부여했습니다. 이 설계는 r:s X w 와 같이 표현할 수 있으며, 이는 채점자가 학생 내에 내재되어 있고 쓰기 프롬프트와 교차되어 있음을 나타냅니다.\n\n\n\n2국면 부분 내재 설계의 벤 다이어그램, (r :s) x w. 여기서 s는 학생(측정 단위), w는 쓰기 프롬프트, r은 채점자, e는 오차임\n\n\n\n3.3.3.1 G 연구\nwriting 데이터 집합과 마찬가지로 writing2 데이터도 각 행이 단일 관찰(즉, 단일 쓰기 프롬프트의 점수)에 해당하는 긴 형식입니다. 학생, 쓰기 프롬프트, 채점자 및 점수 변수에는 학생 식별자, 쓰기 프롬프트 식별자, 채점자 식별자 및 단일 관찰에 대한 점수가 포함됩니다.\n그림 3.6은 이 설계의 변산원에 대한 벤 다이어그램을 보여줍니다. 부분 내재 설계에서는 채점자와 관련된 변산이 피험자 내에 완전히 내재되어 있으며 채점자 변산(r)은 피험자별 변산(sr)과 완전히 섞여 있습니다. 그림 3.6은 또한 채점자별 쓰기 프롬프트 변산(wr)이 학생별, 채점자별 쓰기 프롬프트 변산(swr) 및 잔차 분산(e)과 완전히 혼재되어 있음을 보여줍니다. 쓰기 프롬프트 변산(w)과 학생별 쓰기 프롬프트 변산(wr)을 추정할 수 있습니다.\nlmer를 사용하여 내재 설계를 맞추는 것은 교차 설계와 비슷하지만, 채점자가 학생에 내재되도록 지정해야 합니다. 채점자가 학생에 내재되도록 지정하는 구문은 (1 | students/raters)입니다. 이렇게 하면 섞여있는 학생 변산과 채점자 및 채점자별 학생 변산과 관련된 변산을 추정할 수 있습니다. lmer 함수를 호출할 때 쓰기 프롬프트 변산(1 | prompts)과 학생별 쓰기 프롬프트 변산(1 | students:prompts)도 지정해야 합니다. 이 내재 모델의 결과를 nested_model로 저장한 다음 gstudy 함수에서 사용합니다.\n\nnested_model <- lmer(scores ~ (1 | students/raters) + (1 | prompts) +\n(1 | students:prompts), data = writing2)\nnested <- gstudy(nested_model)\nnested\n\n            Source Est.Variance Percent.Variance\n1 students:prompts      10.4498               3%\n2  raters:students      82.2099            23.6%\n3         students     170.2747            48.8%\n4          prompts      10.5903               3%\n5         Residual      75.2199            21.6%\n\n\nG 연구 결과에는 학생별 쓰기 프롬프트 분산(학생:프롬프트), 학생별 채점자 분산(평가자:학생), 학생(즉, 전집 점수) 분산(학생), 쓰기 프롬프트 분산(프롬프트), 마지막으로 학생별 쓰기 프롬프트별 채점자 분산과 쓰기 프롬프트별 채점자 분산이 포함된 잔차(잔차)가 출력됩니다.\n가장 큰 변산원은 학생으로 전체 변산의 거의 50%를 차지하며, 그 다음으로는 채점자별 학생 변산(24%), 마지막으로 잔차 변산 및 기타 혼재된 변산원이 그 뒤를 잇습니다.\n\n\n3.3.3.2 D 연구\n내재 설계는 dstudy 함수를 사용하여 교차 설계와 정확히 동일한 방식으로 지정됩니다. 채점자 2명과 프롬프트 5개가 있는 D 연구는 아래와 같이 지정됩니다.\n\ndstudy(nested, n = c(\"raters\" = 2, \"prompts\" = 5), unit = \"students\")\n\n            Source Est.Variance   N Ratio of Var:N\n1 students:prompts      10.4498   5        2.08996\n2  raters:students      82.2099   2       41.10495\n3         students     170.2747 100      170.27470\n4          prompts      10.5903   5        2.11806\n5         Residual      75.2199  10        7.52199\n\nThe generalizability coefficient is: 0.770503.\nThe dependability coefficient is: 0.7631884.\n\n\n이 설계를 사용하면 상대적 의사 결정(0.77)과 절대적 의사 결정(0.76)에 대한 신뢰도가 상당히 높습니다. 여러 설계를 비교하려면 다시 dstudy_plot 함수를 사용할 수 있습니다.\n\n\n\n3.3.4 고정 국면을 가진 2국면 교차 설계\n마지막 예로, 다시 writing 데이터 세트를 고려해 보겠습니다. 하지만 이번에는 쓰기 프롬프트를 고정된 국면으로 취급하겠습니다. 즉, 쓰기 프롬프트에 대한 일반화에 관심이 있는 것이 아니라 동일한 쓰기 프롬프트에 대해 서로 다른 채점자가 어떻게 점수를 매기는지 알고자 하는 것입니다. 이는 일반화 범위의 제한을 나타내며 추정되는 분산과 그에 따른 신뢰도 추정치에 영향을 미칩니다. 채점자를 무선으로 처리하고 쓰기 프롬프트를 고정된 것으로 간주하므로 결과 모델은 분산 분석 프레임워크에서 혼합 모형이 됩니다.\n\n3.3.4.1 G 연구\n이전 예제에서는 writing 데이터 세트에 두 개의 국면이 교차하는 설계를 적용하고 이를 twofacet_mod로 저장했습니다. 이번에는 쓰기 프롬프트를 고정 국면으로 처리하고 싶다는 것을 gstudy 함수에 알려야 합니다. 이를 위해 gstudy 함수에 fixed = “prompts”를 포함시키고 결과를 twofacet_fixed로 저장합니다.\n\ntwofacet_fixed <- gstudy(twofacet_mod, fixed = \"prompts\")\ntwofacet_fixed\n\n    Source Est.Variance Percent.Variance\n1   raters      20.7758             7.4%\n2 students     182.7590            65.3%\n3 Residual      76.4754            27.3%\n\n\n쓰기 프롬프트와 관련된 변산원이 이러한 변산원 내에 포함되기 때문에 출력에는 완전히 교차된 2국면 설계의 변산보다 적은 수의 변산원이 포함됩니다. 쓰기 프롬프트가 고정된 국면인 경우에는 표시되지 않지만, 학생별 쓰기 프롬프트 변산이 학생 변산(전집 점수 변산)에 기여하므로 이 변산 성분이 2국면이 무선인 2국면 설계의 변산 성분보다 더 큰 이유입니다. 이 때문에 이 특정 설계에서는 신뢰도가 더 높습니다.\n\n\n3.3.4.2 D 연구\n고정 국면을 가진 설계가 더 높은 신뢰도를 갖는 경향이 있음을 보여주기 위해 앞서 사용한 것과 동일한 D 연구에 2명의 채점자와 5개의 쓰기 프롬프트를 적용했습니다.\n\ndstudy(twofacet_fixed, n = c(\"raters\" = 2, \"prompts\" = 5), unit = \"students\")\n\n    Source Est.Variance   N Ratio of Var:N\n1   raters      20.7758   2       10.38790\n2 students     182.7590 100      182.75900\n3 Residual      76.4754  10        7.64754\n\nThe generalizability coefficient is: 0.9598357.\nThe dependability coefficient is: 0.9101796.\n\n\n쓰기 프롬프트가 고정된 경우 일반화 가능도 계수는 0.96으로 무선으로 처리된 경우의 0.82에 비해 높았습니다. 이는 국면이 무작위인지 고정인지 고려하는 것의 중요성과 이러한 결정이 신뢰도에 미치는 결과를 강조합니다."
  },
  {
    "objectID": "chap03.html#요약",
    "href": "chap03.html#요약",
    "title": "3  일반화가능도 이론",
    "section": "3.4 요약",
    "text": "3.4 요약\n이 장에서는 G 이론을 소개했습니다. 다양한 설계과 이러한 특정 설계에 대한 G 및 D 연구를 실행하는 방법을 제시했습니다. G 이론에서 더 복잡한 설계를 사용하고자 하는 독자에게는 gtheory 패키지를 추천합니다(Moore, 2016). gtheory 패키지는 단변량 및 다변량 모델 모두에 적합할 수 있는 반면, hemp의 G 이론 함수는 단변량 모델에만 적합할 수 있습니다. 다음 장에서는 요인 분석에 대해 알아보겠습니다. 요인 분석은 이 교재에서 중요한 전환을 의미합니다. 지금까지 제시된 모델은 (관찰된) 검사 점수에 초점을 맞춘 반면, 요인 분석은 개별 문항에 초점을 맞춥니다. 요인 분석은 또한 제5장에서 소개할 문항 반응 이론의 기초를 형성합니다."
  },
  {
    "objectID": "chap04.html#개요",
    "href": "chap04.html#개요",
    "title": "4  측정에서 요인분석적 접근",
    "section": "4.1 개요",
    "text": "4.1 개요\n제4장에서는 측정에서 요인분석적 접근법을 소개합니다. 요인분석은 제3장에서 제시된 고전검사이론과 제5장부터 제8장까지 제시된 문항반응이론 사이의 연결고리입니다. 이 장에서는 공통요이모델에 대한 간략한 검토로 시작합니다. 그런 다음 탐색적 요인분석은 psych 패키지의 factanal 함수와 fa 함수를 사용해 예제와 함께 제시됩니다. 탐색적 요인분석에서는 회전, 차원성 및 요인점수 추출에 대해 설명합니다. 그런 다음 확인적 요인분석과 lavaan 패키지를 사용한 예제로 마무리합니다. 탐색적 요인분석과 확인적 요인분석 모두에 대해 비율, 등간 척도 변수와 서열 척도를 사용하는 예제가 제시됩니다."
  },
  {
    "objectID": "chap04.html#소개",
    "href": "chap04.html#소개",
    "title": "4  측정에서 요인분석적 접근",
    "section": "4.2 소개",
    "text": "4.2 소개\n요인분석은 요인 또는 차원으로 알려진 축소된 변수 집합을 사용하여 명시변수 또는 측정변수 집합 간의 공통 변산성을 설명하는 것을 목표로 하는 통계 모델링 기법입니다. p를 측정변수의 수, q를 요인의 수라고 하면 공통요인모델은 다음과 같이 표현할 수 있습니다.\n\\[\nx=\\mu+\\Lambda f+\\epsilon\n\\]\n여기서 \\(x는\\) 연속 관찰 변수의 \\(p\\) 차원의 벡터이고, \\(\\mu\\)는 스칼라(즉, 절편)의 \\(p\\) 차원의 벡터, \\(\\Lambda\\)는 요인적재치의 \\(pXq\\) 행렬, \\(f\\)는 잠재변수/요인의 \\(q\\) 차원의 벡터로 \\(E(f)=0\\), \\(Var(f)=\\phi\\), \\(\\epsilon\\)은 \\(p\\)차원의 무선 오차, 즉 고유 또는 특정 요인이며, 여기서 \\(Var(\\epsilon)=\\psi\\) 라고 가정합니다. 만일 모집단에서 \\(x\\)의 실제 공분산 행렬을 \\(\\Sigma\\)라고 가정하면, 요인 분석의 목표는 \\(\\Sigma\\)를 가능한 가장 가깝게 설명하는 모수 모델인 \\(\\Sigma(\\theta)\\)를 찾는 것입니다.\n\\[\nVar(x)=\\Lambda\\phi\\Lambda^T +\\psi=\\Sigma(\\theta)\n\\]\n여기서 \\(\\theta=(\\Lambda, \\phi, \\psi)\\) 입니다. \\(\\Sigma(\\theta)\\)를 관찰할 수 없기 때문에 \\(\\Sigma(\\hat{\\theta})\\) 으로 \\(\\Sigma(\\theta)\\)를 추정해야 하며 \\(\\Sigma(\\hat{\\theta})\\)은 표본 공분산 행렬에 최대한 가까워야 한다는 제약 조건이 적용됩니다. 제약 조건의 유형에 따라 방정식 4.2의 모델에서 모든 요인에 측정변수가 적재되고 측정변수 잔차가 상관 관계가 없는 탐색적 요인분석(EFA)을 수행할지, 아니면 가설화된 요인에만 측정변수가 적재되고 측정변수의 잔차가 상관 관계가 있을 가능성이 있는 확인적 요인분석(CFA)을 수행할지 결정합니다. EFA 프레임워크 내에서 직각(\\(\\phi\\)는 대각행렬, 요인은 상관 관계가 없음) 또는 사각 회전(\\(\\phi\\) 는 대각행렬이 아님, 요인은 상관 관계가 있음)을 사용할지 여부도 지정해야 합니다.\n요인분석의 핵심은 데이터의 차원을 \\(p\\) 개의 측정변수에서 \\(q\\) 개의 요인으로, 즉 \\(q<p\\) 로 줄이려는 것입니다.이러한 의미에서 요인분석은 주성분 분석(PCA)과 유사하지만, 요인분석은 통게적 모델인 반면 PCA는 엄밀히 말해 차원 축소 기법이라는 점에서 차이가 있습니다. 요인분석은 잠재변수(즉, 요인) 간의 이론적 관계의 타당성을 평가하는 데 관심이 있는 경우에도 일반적으로 사용됩니다. 공통 요인 모형의 기초가 되는 이론적, 통계적 프레임워크에 대한 보다 심층적인 이해에 관심이 있는 독자는 Gorsuch(1983), Bollen(1989), Mulaik(2009), Kline(2015)을 강력히 추천합니다."
  },
  {
    "objectID": "chap04.html#탐색적-요인분석efa",
    "href": "chap04.html#탐색적-요인분석efa",
    "title": "4  측정에서 요인분석적 접근",
    "section": "4.3 탐색적 요인분석(EFA)",
    "text": "4.3 탐색적 요인분석(EFA)\n측정도구를 개발하는 동안 또는 기존 측정 도구의 차원이나 구조에 대한 사전 지식이 없는 경우, 측정도구의 요인 구조를 조사하기 위해 EFA를 고려해야 합니다. EFA를 수행할 때 방정식 4.1과 4.2에 제시된 공통 요인 모델에는 아무런 제한이 없습니다. EFA에서 주요 고려 사항은 추출한 요인의 수, 둘 이상의 요인을 추출해야 하는지 여부, 직각 또는 사각회전을 수행할지 여부, 데이터의 특성(예를 들어, 범주형 변수 vs 연속형 변수, 정규 데이터 vs 비정규 데이터)에 따라 어떤 유형의 통계적 추정 기법을 사용해야 하는지 여부입니다.\nstats 패키지(R Core Team, 2017)는 빈약하긴 하지만 수용가능한 요인분석 함수인 factanal을 제공합니다. factanal 함수는 최대우도로 요인분석을 수행할 수 있다는 점에서 한계가 있습니다. 많은 경우에, 최대우도 기반 요인분석으로도 충분합니다. 그러나 최대우도는 측정변수가 다변량 정규분포 가정을 전제로 합니다. 다변량 정규성 검정은 R에 있는 MVN 패키지(Korkmaz, Goksuluk, & Zararsiz, 2014)로 검정이 가능합니다. 그러나 요인분석을 수행하기 전에 데이터를 시각적으로 검사하는 것이 좋습니다. 요인 분석에서 다변량 정규성을 조사하는 일반적인 방법은 측정변수의 주변 정규성을 평가하고 필요에 따라 변수를 변환하는 것입니다. 그러나 이 방법은 단변량 정규성이 다변량 정규성을 의미하지 않고 그 반대의 경우도 마찬가지이므로 다변량 정규성을 보장하지는 않습니다.\n최대우도에 기반한 EFA를 제시한 후 psych 패키지를 사용하여 최소 잔차해를 구하기 위해 최소자능(OLS) 추정을 사용하는 대안적 통계불일치 함수를 제시합니다. 최소 잔차해는 최대우도가 수렴하지 않는 상황(예, 특이행렬)에서 선호됩니다. 그러나 이 방법도 고유한 단점이 있습니다(예, 가끔 공통성(commonalities)이 1보다 큰 경우가 있음).\n\n4.3.1 인지검사의 FEA\nR에서 EFA를 수행하는 방법을 보여드리기 위해 hemp 패키지의 interest 데이터 세트를 이용하겠습니다. interest 데이터 세트는 250명의 참가자가 실시한 가상의 검사도구에대한 결과입니다. 이 검사도구의 문항은 인지, 성격, 직업흥미를 측정합니다. interest 데이터 세트에서 처음 세 변수는 성별, 교육연한, 나이에 해당합니다. 다음 6개의 변수는 인지를 측정하는 것으로 가정하며, 이후 나오는 예제에서는 이 변수에 초점을 맞출 것입니다(interest 데이터 세트에 대한 자세한 내용은 R에서 ?interest를 실행하면 볼 수 있습니다).\n먼저, library 명령을 사용해 hemp 패키지를 로드합니다. 다음으로 인지 문항만 포함하는 interest 데이터 세트의 하위 데이터 세트를 가져와서 이 새 데이터 세트를 cognition이라고 저장합니다. cognition 데이터 세트는 어휘(vocab), 독해력(reading), 문장 완성도(sentcomp), 수학(mathmtcs), 기하학(geometry), 분석적 추론(analyrea)의 측정값이 포함됩니다.\n\nlibrary(hemp)\n\nLoading required package: psych\n\n\nLoading required package: lattice\n\n\nLoading required package: lavaan\n\n\nThis is lavaan 0.6-16\nlavaan is FREE software! Please report any bugs.\n\n\n\nAttaching package: 'lavaan'\n\n\nThe following object is masked from 'package:psych':\n\n    cor2cov\n\n\nLoading required package: mirt\n\n\nLoading required package: stats4\n\n\nLoading required package: lme4\n\n\nLoading required package: Matrix\n\n\n\nAttaching package: 'lme4'\n\n\nThe following object is masked from 'package:mirt':\n\n    fixef\n\n\nLoading required package: reshape2\n\n\nLoading required package: boot\n\n\n\nAttaching package: 'boot'\n\n\nThe following object is masked from 'package:lattice':\n\n    melanoma\n\n\nThe following object is masked from 'package:psych':\n\n    logit\n\n\nLoading required package: equate\n\ncognition <- subset(interest, select=vocab:analyrea)\n\n다른 통계 분석과 마찬가지로 요인분석 모델을 적합하기 전에 데이터를 탐색해야 합니다. 이러한 사전 분석을 수행하는 이유는 여러 가지가 있습니다. 데이터가 R로 올바르게 읽혀졌는지 확인하기 위해, 결측치 데이터의 범위를 파악하기 위해, 측정변수의 주변분포, 측정변수 간의 관계를 파악하기 위해, 그리고, 특정 관측치는 분석에 영향을 미칠 수 있는 이상치일 가능성이 높습니다. 이러한 사전 분석에는 일반적으로 기술통계를 검토하고 단변량 및 이변량 그래프를 만드는 작업이 포함됩니다.\n제1장에서 언급했듯이 summary 함수를 사용해 데이터 프레임에서 기술통계를 추출할 수 있습니다. apply 함수를 사용하여 측정변수의 분산을 계산함으로써 summary 함수에서 반환된 기술통계를 보완합니다. apply 함수에서는 사용 중인 데이터 집합(cognition), 원하는 함수를 적용하는 방법(모든 행: 1, 모든 열: 2), 적용하고자 하는 함수의 이름(분산은 var)을 지정합니다.\n\nsummary(cognition)\n\n     vocab             reading           sentcomp           mathmtcs      \n Min.   :-2.62000   Min.   :-2.4700   Min.   :-2.47000   Min.   :-3.7100  \n 1st Qu.:-0.60500   1st Qu.:-0.5175   1st Qu.:-0.55000   1st Qu.:-0.4925  \n Median : 0.04000   Median : 0.1850   Median : 0.10500   Median : 0.1000  \n Mean   : 0.09016   Mean   : 0.1350   Mean   : 0.07356   Mean   : 0.1055  \n 3rd Qu.: 0.86000   3rd Qu.: 0.7975   3rd Qu.: 0.77500   3rd Qu.: 0.9200  \n Max.   : 2.63000   Max.   : 2.7000   Max.   : 2.73000   Max.   : 3.0600  \n    geometry          analyrea      \n Min.   :-3.3200   Min.   :-2.8300  \n 1st Qu.:-0.5600   1st Qu.:-0.4825  \n Median : 0.0900   Median : 0.2000  \n Mean   : 0.1125   Mean   : 0.1750  \n 3rd Qu.: 0.7675   3rd Qu.: 0.8375  \n Max.   : 3.8600   Max.   : 3.5000  \n\n\n\napply(cognition,2,var)\n\n    vocab   reading  sentcomp  mathmtcs  geometry  analyrea \n0.9966514 0.9811568 0.9834142 1.1117325 1.0686631 1.1170926 \n\n\n기술통계를 보면 변수가 표준화되었을 수 있습니다(평균이 약 0, 분산이 약 1로 표시됨). 이 데이터 세트는 시뮬레이션 데이터 세트이기 때문에 표준정규분포에서 변수가 무선으로 생성되었을 가능성이 더 큽니다. 평균과 중앙값 모두 서로 가깝기 때문에 분포가 상당히 대칭적일 수 있음을 시사합니다. mathmtcs와 geometry 변수의 범위가 가장 크고, summary(cognition)에서 출력된 NA가 없기 때문에 결측 데이터가 없음을 알 수 있습니다. 변수를 그래프로 그러면 이러한 측정변수의 분포에 대해 훨씬 더 많은 정보를 얻을 수 있습니다.\n우선, lattice 패키지를 사용하여 cognition의 주변 분포의 히스토그램을 살펴봅니다(Sarkar, 2008). 먼저 lattice 패키지를 로드합니다. 그런 다음 reshape 함수를 사용하여 주변 분포를 더 쉽게 그래프로 그리기 위해 데이터를 와이드 포맷에서 롱 포맷으로 변환합니다. 와이드 포맷에서 각 행은 한 사람을 나타내고 각 열은 해당 사람과 관련된 다른 변수(예: 나이, 성별, 검사 점수)를 나타냅니다. 와이드 포맷과 달리 롱 포맷에서는 각 사람이 여러 개의 행을 가지며, 각 행은 cognition 데이터 세트의 특정 변수에 대한 점수에 해당합니다.\n다음 예에서, 와이드 포맷 cognition 데이터 세트를 롱 포맷 데이터 세트로 변환해 cognition_l로 저장합니다. head 함수를 사용해 참가자 식별자 “id”를 기준으로 데이터를 정렬한 후 롱 포맷 데이터 집합의 처음 여섯 행을 출력합니다.\n\nlibrary(lattice)\ncognition_l <- reshape(data = cognition, \n                       varying = 1:6, \n                       v.names = \"score\", \n                       timevar = \"indicator\", \n                       times = names(cognition), \n                       direction = \"long\")\nhead(cognition_l[order(cognition_l$id),])\n\n           indicator score id\n1.vocab        vocab  1.67  1\n1.reading    reading  1.67  1\n1.sentcomp  sentcomp  1.46  1\n1.mathmtcs  mathmtcs  0.90  1\n1.geometry  geometry  0.49  1\n1.analyrea  analyrea  1.65  1\n\n\n다음으로, 각 측정변수의 점수(즉, 점수)를 포함하는 변수를 지정하는 histogram 함수를 사용합니다. histogram 함수에서 | 을 사용하여 측정변수별로 격자( 또는 국면) 그래프를 만듭니다. 이렇게 하면 각 측정변수에 대한 히스토그램이 생성되고 그리드에 정렬됩니다(이 그래프에 대한 자세한 내용은 제1, 2장 참조)\n\nhistogram(~score|indicator,data=cognition_l)\n\n\n\n\n그림 4.1에서 변수가 단봉이고 대칭이며 대략 정규분포에 가깝다는 것을 알 수 있습니다. 이 그래프에서 (특히 수학 변수의 경우) 몇 가지 극단적인 관측치가 존재함을 알 수 있습니다. 다음으로, 산점도 행렬을 사용하여 측정변수간 이변량 관계를 살펴봅니다. 산점도 행렬에서는 일반적으로 4가지를 살펴봅니다.\n\n변수 간의 관계의 크기\n변수 간의 관계의 방향\n극단적이거나 잠재적으로 영향력이 있는 지점이 있는지의 여부\n비선형 관계의 존재 여부\n\ncognition 데이터 세트에 대한 산점도 행렬을 만들기 위해 pairs 함수를 다음과 같이 사용합니다.\n\npairs(cognition)\n\n\n\n\n그림 4.2에 표시된 산점도 행렬을 보면 모든 변수가 서로 양의 상관관계가 있음을 알 수 있습니다(증가 추세, 정적 경향에 근거해). 언어 측정치(vocab, reading, sentcomp)와 수학 측정치(mathmtcs, geometry, analyrea)가 서로 더 강한 상관관계를 보이는 것으로 나타났습니다. 이는 두 가지 요인이 있을 수 있음을 시사하지만, 변수들은 모두 적어도 중간 정도의 관계가 있으므로 하나의 일반적 요인으로도 충분할 수 있음을 시사합니다. 그림 4.2의 대부분에서, 극단값 또는 이상치가 존재하지만 변수 간의 비선형 관계에 대한 증거는 보이지 않습니다.\n마지막으로 Bollen(1989)에서 설명한 다변량 영향력 있는 사례를 찾기 위한 그래프를 살펴봅니다. 이 그래프는 특정 관측값이 데이터의 중심으로부터 얼마나 멀리 떨어져 있는지 대략적으로 알려줍니다(데이터 시각화에 대한 자세한 내용은 제9장에서 확인할 수 있습니다). 이 그래프는 hemp 패키지의 bollen_plot 함수를 사용해서 그릴 수 있습니다. bollen_plot 함수는 데이터 프레임(필수)과 특정 임계값 이상의 값에 해당하는 행 번호에 레이블을 지정하는 선택 인자인 crit.value라는 두 개의 인수를 받습니다.\n\nbollen_plot(cognition,crit.value = .06)\n\n\n\n\n그림 4.3에서 검은색 가로선은 예상 크기, 0.024(측정 변수의 수를 관측값의 수로 나눈 값)를 나타내는데, 예상 크기에 비해 큰 값은 영향력이 있는 것으로 간주할 수 있습니다(자세한 내용은 Bollen(1989) 참조). 다른 관측치와 상당히 거리가 먼 관측치가 몇 개 있음을 알 수 있습니다. 또한 0.06보다 큰 값(지정한 crit.value 인수를 기준으로)에는 행 번호가 지정되어 있습니다. 행 번호 202, 53, 111은 결과에 상당한 영향을 미칠 수 있는 관측치입니다. 아래에서, 이러한 관측값이 잘못 입력된 데이터 또는 과소 추출되었을 수 있는 모집단의 일부 값을 나타낼 수 있으므로 이를 살펴봅니다.\n\ncognition[c(202,53,11),]\n\n    vocab reading sentcomp mathmtcs geometry analyrea\n202  2.63    2.23     2.55     1.38     3.86     3.50\n53  -0.38    0.99    -0.50     1.79    -0.19     2.13\n11  -0.96    0.54    -0.04    -0.25     0.97     0.30\n\n\n위 코드는 cognition 데이터 세트에서 행번호(즉, 참가자) 202, 53, 111을 출력합니다. 그런 다음 아래에는 각 측정변수의 최솟값과 최댓값을 출력합니다.\n\napply(cognition,2,min)\n\n   vocab  reading sentcomp mathmtcs geometry analyrea \n   -2.62    -2.47    -2.47    -3.71    -3.32    -2.83 \n\n\n\napply(cognition,2,max)\n\n   vocab  reading sentcomp mathmtcs geometry analyrea \n    2.63     2.70     2.73     3.06     3.86     3.50 \n\n\n관측값 202는 vocab, geometry, analyrea에서 최대 관측값을 보이지만 다른 점수를 고려할 때 예상되는 것보다 mathmtcs 점수가 약간 낮다는 것을 알 수 있습니다. 마찬가지로 관측값 53은 analyrea 점수는 높지만 geometry 점수는 낮습니다. 마지막으로 111은 일반적으로 수행이 좋지 않습니다. 시뮬레이션 데이터인 것을 감안할 때, 데이터가 잘못 입력되었을 가능성은 없으며, 개인이 geometry와 analyrea에서 최대 점수를 얻을 가능성은 낮지만 불가능하지는 않습니다.\n이러한 통계 또는 유사한 그래프를 살펴본 후, 측정변수 간 Pearson의 상관관계를 살펴보는 것이 좋습니다. 먼저 그래프를 보면 Pearson 상관관계의 적절성을 평가할 수 있습니다. 아래에서는 cor 함수를 사용하여 Pearson의 상관관계를 계산하고, 결과를 correlations로 저장한 다음, 마지막으로 round 함수를 사용하여 소수 셋째 자리로 반올림합니다.\n\ncorrelations <- cor(cognition)\nround(correlations, 3)\n\n         vocab reading sentcomp mathmtcs geometry analyrea\nvocab    1.000   0.803    0.813    0.708    0.633    0.673\nreading  0.803   1.000    0.725    0.660    0.526    0.636\nsentcomp 0.813   0.725    1.000    0.618    0.575    0.618\nmathmtcs 0.708   0.660    0.618    1.000    0.774    0.817\ngeometry 0.633   0.526    0.575    0.774    1.000    0.715\nanalyrea 0.673   0.636    0.618    0.817    0.715    1.000\n\n\n상관관계는 그림 4.2에서 살펴본 내용을 뒷받침합니다. cognition 데이터 세트의 변수들은 모두 서로 중간 정도에서 강한 상관관계가 있으며, 이는 1요인 또는 2요인 구조로 충분할 수 있음을 시사합니다. 측정변수의 범주(예, 언어, 수학) 내에서가 범주 간보다 서로 더 높은 상관관계를 보이는 것을 알 수 있습니다.\n민감도 분석으로, 모든 관측값을 사용한 상관 행렬과 관측값 202, 53, 111만 삭제한 상관 행렬의 차이를 계산하는 것도 권장합니다.\n\ncorrelations <- cor(cognition)\nround(correlations, 3)\n\n         vocab reading sentcomp mathmtcs geometry analyrea\nvocab    1.000   0.803    0.813    0.708    0.633    0.673\nreading  0.803   1.000    0.725    0.660    0.526    0.636\nsentcomp 0.813   0.725    1.000    0.618    0.575    0.618\nmathmtcs 0.708   0.660    0.618    1.000    0.774    0.817\ngeometry 0.633   0.526    0.575    0.774    1.000    0.715\nanalyrea 0.673   0.636    0.618    0.817    0.715    1.000\n\n\n상관 행렬의 차이는 매우 작으며, geometry와 mathmtcs의 차이(-.012)가 가장 크다는 것을 알 수 있습니다. 이는 영향력 있는 관측값이 상관 관계에 미치는 영향이 미미하다는 것을 나타냅니다.\n이러한 모든 사전 분석이 끝나면 이제 cogntion 데이터 세트에 EFA 모델을 맞출 준비가 되었습니다. 요인분석에서 얼마나 많은 요인을 추출할지 결정할 때 고려해야 몇 가지 기준이 있습니다. 가장 간단한 접근 방식은 변수의 상관 행렬의 고유 분해에서 고유값을 조사하는 것입니다. 상관 관계에 대해 고유 분해(eigen_value)를 실행하여 eigen_decomp로 저장한 다음, 고유값을 소수 셋째짜리로 반올림하여 출력합니다.\n\neigen_decomp <- eigen(correlations)\nround(eigen_decomp$values,3)\n\n[1] 4.436 0.676 0.322 0.245 0.168 0.152\n\n\n결과에서 큰 고유값이 하나 있음을 알 수 있으며, 요인 수를 1보다 큰 고유값 수와 같도록 추출하는 Kaiser 규칙(Kaiser, 1960)을 사용하면 하나의 요인만 고려할 수 있습니다. 이 데이터 세트에 PCA를 적합하면 첫 번째 구성 요소만으로 관찰된 변산성의 약 74%를 설명할 수 있음을 알 수 있습니다.\n또 다른 일반적인 방법은 스크리 도표를 구성하고 도표에서 엘보의 위치를 찾은 다음 엘보 바로 앞에서 발생하는 고유값과 동일한 요인의 수를 추출하는 것입니다. 다음 예는 hemp 패키지의 lattice_scree 함수를 사용해 스크리 도표를 만드는 방법을 보여줍니다.\n\nlattice_scree(cognition)\n\n\n\n\n다시 한 번, 고유값이 두 요인 이후에 평준화되기 시작하면서 하나의 주요 요인과 잠재적으로 두 번째 요인의 증거를 볼 수 있습니다. 이 그림은 축소된 상관행렬의 고유값을 사용한 스크리 도표이며 고유값이 0보다 크면 추출을 고려할 수 있는 요인의 수를 나타냅니다. 보다 정교한 접근 방식은 병렬 분석(parallel analysis)을 사용하는 것입니다(Horn, 1965). 병렬 분석은 아래 그림과 같이 psych 패키지의 fa.parallel 함수를 사용해 수행할 수 있습니다. 관심변수(cognition)와 함께 데이터 세트의 이름과 추정 방법(최대 우도인 경우 fm=“ml”)을 지정해야 합니다.\n\ncorrelations <- cor(cognition)\nround(correlations, 3)\n\n         vocab reading sentcomp mathmtcs geometry analyrea\nvocab    1.000   0.803    0.813    0.708    0.633    0.673\nreading  0.803   1.000    0.725    0.660    0.526    0.636\nsentcomp 0.813   0.725    1.000    0.618    0.575    0.618\nmathmtcs 0.708   0.660    0.618    1.000    0.774    0.817\ngeometry 0.633   0.526    0.575    0.774    1.000    0.715\nanalyrea 0.673   0.636    0.618    0.817    0.715    1.000\n\n\n여기서는 fa.parallel의 결과를 검토하지 않겠습니다. 그 대신, hemp 패키지의 lattice_pa라는 추가 함수를 사용하여 병렬 분석을 수행하고 그래프를 그리겠습니다. lattice_pa 함수는 fa.parallel 함수의 수정된 버전이며 불일치 함수로 최대우도와 데이터가 비율 또는 등간척도를 사용하고자 할 때 적합합니다. 변수가 비율 또는 등간척도가 아니거나 다른 불일치 함수(예: 최소잔차, 추축분석, 가중된 최소 제곱)가 필요하거나 병렬 분석에 대한 보다 세밀한 제어가 필요한 경우 fa.parallel 함수를 사용하는 것이 좋습니다.\n\nlattice_pa(cognition)\n\n\n\n\n실선은 축소된 상관행렬의 고유값에 해당하며(즉, 상관 행렬의 대각선에 있는 것을 추정된 공통분에 대체하여), 점선은 시뮬레이션된 무선 데이터를 기반으로 축소된 상관 행렬의 고유값에 해당합니다. 병렬 분석을 사용하면, 점선 위에 있는 요인수를 추출합니다. 병렬 분석에 근거해 두 개의 요인을 추출합니다. 아래에서는 단일요인과 2요인 모두를 고려할 것입니다.\n먼저 cognition 데이터 세트에 단일요인 솔루션을 적합하는 것으로 시작합니다. factanal 함수를 사용하려면 데이터 세트의 이름(공분산행렬)과 추출할 요인 수(즉, factors=1)를 지정해야 합니다. 결과를 one_factor로 저장한 다음, 결과를 출력합니다.\n\none_factor <- factanal(cognition, factors = 1)\none_factor\n\n\nCall:\nfactanal(x = cognition, factors = 1)\n\nUniquenesses:\n   vocab  reading sentcomp mathmtcs geometry analyrea \n   0.213    0.324    0.331    0.270    0.412    0.318 \n\nLoadings:\n         Factor1\nvocab    0.887  \nreading  0.822  \nsentcomp 0.818  \nmathmtcs 0.854  \ngeometry 0.767  \nanalyrea 0.826  \n\n               Factor1\nSS loadings      4.132\nProportion Var   0.689\n\nTest of the hypothesis that 1 factor is sufficient.\nThe chi square statistic is 171.91 on 9 degrees of freedom.\nThe p-value is 2.46e-32 \n\n\n먼저, 호출(factanal이 실행되도록 지시한 내용)이 출력되고, 추출된 요인으로 설명되지 않는 변산성의 비율인 고유요인, 지표와 요인의 상관관계를 나타내는 요인부하량, 제곱하면 요인에 의해 설명되는 지표의 변산성 비율(즉, 공통분)이 표시됩니다. 요인부하량의 제곱합(SS 부하량), 요인에 의해 설명되는 변산성의 비율(SS 부하량을 지표 수로 나눈 값과 같음), 마지막으로 단일 요인 솔루션으로 충분하다는 영가설이 있는 경우 \\(\\chi^2\\) 통계치가 출력됩니다.\n결과에서, 모든 지표가 추출된 요인에 높은 부하가 걸렸으며 이 단일 요인이 cognition 데이터의 변산성을 약 69% 설명할 수 있음을 알 수 있습니다. \\(\\chi^2\\) 통계치는 영가설을 기각하고, 단일 요인으로는 충분하지 않다는 것을 시사합니다. factors=2로 2요인을 지정하여 코드를 업데이트합니다. 결과는 two_factor로 저장됩니다.\n\ntwo_factor <- factanal(cognition, factors = 2)\ntwo_factor\n\n\nCall:\nfactanal(x = cognition, factors = 2)\n\nUniquenesses:\n   vocab  reading sentcomp mathmtcs geometry analyrea \n   0.104    0.281    0.261    0.109    0.327    0.246 \n\nLoadings:\n         Factor1 Factor2\nvocab    0.853   0.410  \nreading  0.750   0.395  \nsentcomp 0.785   0.350  \nmathmtcs 0.424   0.843  \ngeometry 0.384   0.725  \nanalyrea 0.437   0.751  \n\n               Factor1 Factor2\nSS loadings      2.426   2.246\nProportion Var   0.404   0.374\nCumulative Var   0.404   0.779\n\nTest of the hypothesis that 2 factors are sufficient.\nThe chi square statistic is 11.22 on 4 degrees of freedom.\nThe p-value is 0.0242 \n\n\n2요인 솔루션에서는 vocab, reading, sentcomp가 첫 번째 요인에 높은 부하를, mathmtcs,geometry, analyrea가 두 번째 요인에 높은 부하를 주는 것을 알 수 있습니다. 첫 번째와 두 번째 요인의 잠재적 이름은 각각 언어적 추론과 수학적 추론이 될 수 있습니다. 2요인 구조는 cognition 데이터 세트의 변산성의 78%를 설명합니다. 2요인 구조에서도 여전히 영가설을 기각하고 카이제곱 검정에 근거해 2요인 구조가 충분하지 않다고 결론을 내립니다. 그러나 이 검정은 종종 기각되며 제안된 요인 구조의 적절성에 대한 강건한 결과는 아닙니다. 지표가 다른 요인보다 한 요인에 더 많은 부하가 걸리지만 교차 부하가 적절히 걸리므로 구조가 단순하지 않다는 것을 알 수 있습니다. factanal의 기본 회전은 varimax이며, 이는 요인들이 서로 상관관계가 없도록 하는 직교 회전입니다. 즉 각 지표가 단일 요인으로만 상관되는 단순한 구조입니다. 사각회전을 고려하는 것이 유리할 수도 있습니다.\nR에서 사각회전을 수행하려면 오래된 버그 때문에 기본 회전과 함께 factanal을 사용한 다음 솔루션을 회전하는 것이 좋습니다.1 다양한 직교 및 사각 회전은 GPArotation 패키지에서 사용할 수 있습니다(Bernaards & Jennrich, 2005). 회전을 수행하려면, 사용할 회전 이름을 지정하고 회전되지 않은 솔루션의 요인부하량을 전달합니다. 아래 예제에서는 GPArotation 패키지를 설치 및 로드한 다음 앞서 생성한 two_factor 객체에서 로딩을 전달하여 사각회전을 수행합니다.\n\n# install.packages(\"GPArotation\")\nlibrary(\"GPArotation\")\n\n\nAttaching package: 'GPArotation'\n\n\nThe following objects are masked from 'package:psych':\n\n    equamax, varimin\n\noblimin(loadings(two_factor))\n\nOblique rotation method Oblimin Quartimin converged.\nLoadings:\n          Factor1  Factor2\nvocab     0.94412  0.00325\nreading   0.80339  0.05482\nsentcomp  0.88899 -0.03725\nmathmtcs -0.03159  0.96884\ngeometry  0.00144  0.81923\nanalyrea  0.05990  0.81970\n\n               Factor1 Factor2\nSS loadings      2.359   2.313\nProportion Var   0.393   0.386\nCumulative Var   0.393   0.779\n\nPhi:\n        Factor1 Factor2\nFactor1   1.000   0.803\nFactor2   0.803   1.000\n\n\n사각회전을 통해 간단한 구조를 얻을 수 있었고(즉, 모든 지표가 한 요인에 높게 적재되고 다른 요인에는 0에 가깝게 적재됨), 두 요인 간의 상관관계가 .803임을 알 수 있습니다(Phi는 요인 간 상관행렬). 이 경우 단순히 요인 간의 상관 관계를 허용하면 교차 부하가 제거되는 것을 알 수 있습니다.\n요인 점수는 scores 인수를 지정하여 추출할 수 있습니다. Thompson의 점수는 scroes=“regression”을 사용해 추출할 수 있으며 Bartlett의 가중 최소 제곱 점수는 scores=“Bartlett”을 사용하여 추출할 수 있습니다(이러한 요인 점수 추출 방법에 대한 검토는 Bartholomew, Deary, and Lawn (2009)을 참조). 요인 점수는 불확실성 때문에 항상 주의해서 사용해야 합니다(Mulaik, 2009).\n\n\n4.3.2 psych 패키지를 사용한 EFA\n데이터가 다변량 정규성을 위반하는 경우, EFA에 다른 통계적 불일치 함수를 사용해야 할 수도 있습니다. psych 패키지는 최소잔차해(기본 통계적 불일치 함수)를 찾기 위해 OLS를 사용하는 등 여러 가지 옵션을 제공합니다. 다음 예제에서는 psycho 패키지의 FA 함수를 사용해 동일한 cognition 데이터 세트에 EFA 모델을 적합합니다. 요인 수를 2로 지정하고(nfactors=2) 회전 방법을 사각회전으로 지정합니다(rotate=“oblimin”).\n\nlibrary(\"psych\")\nfa(r = cognition, nfactors = 2, rotate = \"oblimin\")\n\nFactor Analysis using method =  minres\nCall: fa(r = cognition, nfactors = 2, rotate = \"oblimin\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n           MR1   MR2   h2   u2 com\nvocab     0.95  0.00 0.90 0.10   1\nreading   0.83  0.02 0.72 0.28   1\nsentcomp  0.87 -0.02 0.74 0.26   1\nmathmtcs -0.03  0.96 0.89 0.11   1\ngeometry -0.02  0.84 0.68 0.32   1\nanalyrea  0.07  0.81 0.76 0.24   1\n\n                       MR1  MR2\nSS loadings           2.36 2.31\nProportion Var        0.39 0.38\nCumulative Var        0.39 0.78\nProportion Explained  0.51 0.49\nCumulative Proportion 0.51 1.00\n\n With factor correlations of \n    MR1 MR2\nMR1 1.0 0.8\nMR2 0.8 1.0\n\nMean item complexity =  1\nTest of the hypothesis that 2 factors are sufficient.\n\ndf null model =  15  with the objective function =  5.11 with Chi Square =  1257.24\ndf of  the model are 4  and the objective function was  0.05 \n\nThe root mean square of the residuals (RMSR) is  0.01 \nThe df corrected root mean square of the residuals is  0.03 \n\nThe harmonic n.obs is  250 with the empirical chi square  1.42  with prob <  0.84 \nThe total n.obs was  250  with Likelihood Chi Square =  11.64  with prob <  0.02 \n\nTucker Lewis Index of factoring reliability =  0.977\nRMSEA index =  0.087  and the 90 % confidence intervals are  0.031 0.148\nBIC =  -10.44\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   MR1  MR2\nCorrelation of (regression) scores with factors   0.97 0.97\nMultiple R square of scores with factors          0.94 0.94\nMinimum correlation of possible factor scores     0.88 0.87\n\n\nfa 함수 결과는 적합도 지수에 대한 정보를 포함하므로 factanal 결과보다 더 깁니다. 첫 번째 표에는 요인 적재량(1, 2열), 공통분, 고유요인 및 두 열의 합계가 포함되어 있습니다. 두 번째 표에는 각 요인에 대한 SS 적재치, 각 요인에 대해 설명된 변산성의 비율, 각 요인에 대해 설명된 누적 분산, 총 설명된 변산성에서 각 요인이 차지하는 비율, 각 요인에 의해 설명된 변산성의 누적 비율(합계가 1이 되어야 함)이 출력됩니다. 그런 다음 요인 상관관계 표와 두 가지 카이제곱 검정, 즉 경험적 카이제곱 통계와 최대 확률 카이제곱 통계가 출력됩니다. 마지막으로 RMSR(평균제곱잔차제곱근), Tucker Lewis Index(TLI), RMSEA(근사 평균제곱근 오차)를 포함한 적합도 측정치를 볼 수 있습니다. 전반적으로 적합도 측정치는 2요인 모델이 cognition 데이터 세트에 잘 맞는다는 것을 시사합니다(Hu와 Bentler(1999)와 같이 일반적으로 사용되는 기준에 근거함). 이 분석을 바탕으로 cognition 데이터 세트의 지표에 대한 2요인 구조를 뒷받침하는 증거를 발견했습니다.\n\n\n4.3.3 범주형 데이터를 사용한 EFA\n지금까지의 예제에서는 등간 또는 비율척도의 연속형 변수에 중점을 두었습니다. 이 섹션에서는 psych 패키지로 범주형 데이터를 사용하여 EFA를 수행하는 방법을 보여 드리겠습니다. 여기서는 제2장에서 설명한 SAPA 데이터 세트로부터 추출한 문항 데이터 세트를 사용합니다. 이 데이터 세트를 SAPA_subset으로 저장합니다.\n\nSAPA_subset <- subset(SAPA, select = c(letter.7:letter.58, rotate.3:rotate.8))\n\nSAPA_subset 데이터 세트의 변수는 이분형으로 채점되었습니다(즉, 변수 값으로 0, 1이 사용됨). 따라서 병렬 분석 또는 요인 분석을 실행할 때 이산 분석으로 인해 Pearson의 상관관계가 약화되므로 Pearson의 상관관계 대신 다항(polychoric) 상관관계(fa.parallel 및 fa 함수에 대한 기본 옵션)를 지정해야 합니다. 병렬 분석은 다음을 실행하여 수행할 수 있습니다:\n\nfa.parallel(SAPA_subset, cor = \"poly\")\n\n\n\n\nParallel analysis suggests that the number of factors =  2  and the number of components =  2 \n\n\n병렬 분석 결과는 데이터에서 2개의 요인 또는 2개의 성분을 추출할 수 있음을 제안합니다. 또한 cor=“poly” 인수를 지정하여 psych의 fa 함수를 사용해 동일한 데이터 세트에 대한 EFA를 수행합니다.\n\nEFA_SAPA <- fa(SAPA_subset, 2, rotate = \"oblimin\", cor = \"poly\")\nEFA_SAPA\n\nFactor Analysis using method =  minres\nCall: fa(r = SAPA_subset, nfactors = 2, rotate = \"oblimin\", cor = \"poly\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n            MR1   MR2   h2   u2 com\nletter.7  -0.02  0.79 0.60 0.40 1.0\nletter.33  0.01  0.70 0.50 0.50 1.0\nletter.34 -0.02  0.80 0.63 0.37 1.0\nletter.58  0.21  0.54 0.46 0.54 1.3\nrotate.3   0.86 -0.02 0.72 0.28 1.0\nrotate.4   0.82  0.10 0.77 0.23 1.0\nrotate.6   0.77  0.05 0.64 0.36 1.0\nrotate.8   0.86 -0.09 0.65 0.35 1.0\n\n                       MR1  MR2\nSS loadings           2.84 2.13\nProportion Var        0.36 0.27\nCumulative Var        0.36 0.62\nProportion Explained  0.57 0.43\nCumulative Proportion 0.57 1.00\n\n With factor correlations of \n     MR1  MR2\nMR1 1.00 0.56\nMR2 0.56 1.00\n\nMean item complexity =  1\nTest of the hypothesis that 2 factors are sufficient.\n\ndf null model =  28  with the objective function =  4.26 with Chi Square =  6477.4\ndf of  the model are 13  and the objective function was  0.06 \n\nThe root mean square of the residuals (RMSR) is  0.02 \nThe df corrected root mean square of the residuals is  0.02 \n\nThe harmonic n.obs is  1523 with the empirical chi square  22.69  with prob <  0.046 \nThe total n.obs was  1525  with Likelihood Chi Square =  97.39  with prob <  5.3e-15 \n\nTucker Lewis Index of factoring reliability =  0.972\nRMSEA index =  0.065  and the 90 % confidence intervals are  0.053 0.078\nBIC =  2.1\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   MR1  MR2\nCorrelation of (regression) scores with factors   0.95 0.92\nMultiple R square of scores with factors          0.91 0.84\nMinimum correlation of possible factor scores     0.81 0.68\n\n\nfa 함수의 결과에서 일부만 인쇄했다는 점에 유의하세요. 출력 결과에서 2요인 구조의 상당히 강력한 증거와 함께 사각 회전을 사용하여 간단한 구조를 달성했음을 알 수 있습니다(두 요인이 변산성의 약 62%를 차지하며, RMSR은 .02, TLI는 .972, RMSEA는 .065임). SAPA_subset 데이터 대신 다항 상관행렬을 전달하여 factanal 함수를 직접 사용할 수도 있습니다. 이를 위해 먼저 polychoric 함수를 사용해 polychoric 상관 관계를 계산한 다음 이를 factanal 함수로 전달합니다(covmat=SAPA_cor$rho).\n\nSAPA_cor <- polychoric(SAPA_subset)\nfactanal(covmat = SAPA_cor$rho, factors = 2, n.obs = nrow(SAPA))\n\n\nCall:\nfactanal(factors = 2, covmat = SAPA_cor$rho, n.obs = nrow(SAPA))\n\nUniquenesses:\n letter.7 letter.33 letter.34 letter.58  rotate.3  rotate.4  rotate.6  rotate.8 \n    0.397     0.498     0.382     0.542     0.260     0.223     0.368     0.361 \n\nLoadings:\n          Factor1 Factor2\nletter.7  0.205   0.749  \nletter.33 0.211   0.676  \nletter.34 0.212   0.757  \nletter.58 0.345   0.582  \nrotate.3  0.826   0.239  \nrotate.4  0.815   0.336  \nrotate.6  0.744   0.280  \nrotate.8  0.780   0.174  \n\n               Factor1 Factor2\nSS loadings      2.761   2.208\nProportion Var   0.345   0.276\nCumulative Var   0.345   0.621\n\nTest of the hypothesis that 2 factors are sufficient.\nThe chi square statistic is 94.48 on 13 degrees of freedom.\nThe p-value is 1.93e-14"
  },
  {
    "objectID": "chap04.html#확인적-요인분석cfa",
    "href": "chap04.html#확인적-요인분석cfa",
    "title": "4  측정에서 요인분석적 접근",
    "section": "4.4 확인적 요인분석(CFA)",
    "text": "4.4 확인적 요인분석(CFA)\n검사도구가 개발되고 검증되면 검사도구의 차원과 어떤 지표를 어떤 요인에 적재해야 하는지 파악할 수 있습니다. 이러한 환경에서는 요인 구조를 검토할 때 EFA가 아닌 CFA를 고려하는 것이 적절합니다. EFA와 달리 CFA에서는 방정식 4.1과 4.2의 모델 예측 행렬에 특정 제한을 둡니다. CFA에서는 각 요인에 대해 단일 요인 부하를 설정하거나 요인의 분산을 1로 설정하여 척도를 고정하기 때문에 회전 및 불확실성에 대해 고려하지 않습니다.\n\n4.4.1 WISC-R 데이터의 CFA\nWISC‑R은 1975년에 발표된 WISC(아동용 Weschler‑Belleview 검사의 하향 확장)의 개정판입니다. 이 데이터는 175명의 아동을 대상으로 WISC‑R을 시행한 결과입니다. 데이터에 대한 자세한 내용은 Tabachnick, Fidell 및 Osterlind(2001)에서 확인할 수 있습니다. 이 데이터 세트는 hemp 패키지에 wiscsem으로 포함되어 있습니다. wiscsem의 변수에는 클라이언트(id 변수), agemat(범주 연령 변수), 10개의 핵심 하위 검사 점수 및 하나의 선택적 하위 검사 점수가 포함됩니다.\n간결함을 위해 이전에 EFA를 수행하는 동안 수행한 모든 초기 탐색적 설명 및 그래픽 분석은 생략하겠습니다. 그러나 이것은 CFA뿐만 아니라 모든 유형의 심리측정 분석과 함께 수행되어야 합니다. 경로분석 및 구조방정식 모델링(SEM)과 마찬가지로 R에서 실제 CFA를 수행하기 위해 잠재변수분석(latent variable analysis)을 대표하는 lavaan 패키지 Rosseel(2012)을 사용합니다. 아래에서 lavaan 패키지를 설치하고 활성화합니다.\n\ninstall.packages(\"lavaan\")\n\nWarning: package 'lavaan' is in use and will not be installed\n\nlibrary(\"lavaan\")\n\nlavaan 패키지는 회귀분석, CFA, SEM, 성장곡선모델링, 매개, 조절효과 등을 수행할 수 있습니다. lavaan을 사용하려면 다음 세 단계를 거쳐야 합니다.\n\nlavaan의 특수 구문(Mplus와 유사)을 사용하여 모델 정의\n모델 적합\n적합된 모델에서 정보 추출\n\nlavaan 패키지는 고유한 모델 구문을 사용합니다. CFA를 수행하기 위해 일반적으로 다음 구문이 사용됩니다.\n\n=~: 잠재 변수와 관련 지표를 정의하는 방법\n~~: 공분산 또는 분산을 정의하는 방법\n~: 경로 분석, 회귀분석 또는 SEM에 대한 경로를 정의하는 방법\n+: 변수를 함께 묶는 방법(lm으로 중다 회귀를 적합하는 방법과 동일)\n\nlavaan의 저자는 잘 문서화된 튜토리얼이 있는 훌륭한 웹사이트를 가지고 있으며 관심 있는 독자는 이 웹사이트를 참조하여 lavaan에 대한 자세한 내용을 확인하시기 바랍니다.2\n어떤 하위 검사가 지능의 어떤 구성 요소(즉, 언어(verbal) 또는 수행(perf) IQ)를 측정해야 하는지 알고 있기 때문에 이 구조를 반영하도록 모델을 정의합니다. 가장 먼저 해야 할 일은 lavaan의 구문을 사용하여 모델을 정의하는 것입니다.\n\niq_mod <- '\nverb =~ info + comp + arith + simil + digit + vocab\nperf =~ pictcomp + parang + block + object + coding\n'\n\n기본적으로 lavaan은 각 잠재 변수(이 경우 info 및 pictcomp)의 첫 번째 지표를 “1”로 고정하여 요인의 척도를 설정합니다. 표준화된 해를 얻기 위해 verb 및 perf의 척도를 1로 설정할 수 있습니다. 그러나 summary 함수(아래 참조)에서 표준화된 해를 요청하는 것이 더 쉽습니다. 따라서 이 간단한 경우에는 기본 옵션을 그대로 사용하는 것이 좋습니다. 다음으로 lavaan의 cfa 함수를 사용하여 모델(iq_mod)을 맞춥니다. 모델 적합 절차를 세밀하게 제어하려면 lavaan 함수를 사용할 수 있습니다(시뮬레이션을 실행하고 더 복잡한 구조 방정식 모델을 적합하는 데 매우 유용할 수 있음). 우리는 비교적 간단한 CFA 모델을 적합하고 있기 때문에 cfa 함수를 사용하여 모델을 추정하고 iq_fit이라는 객체로 저장합니다.\n\niq_fit <- cfa(iq_mod, data = wiscsem)\n\n가장 먼재 해야 할 일은 모델을 검사하여 lavaan이 실제로 우리가 의도한 모델을 적합하는지 확인하는 것입니다. 이 단계에서는 inspect 함수와 함께 CFA 결과인 iq_fit을 함께 사용합니다.\n\ninspect(iq_fit)\n\n$lambda\n         verb perf\ninfo        0    0\ncomp        1    0\narith       2    0\nsimil       3    0\ndigit       4    0\nvocab       5    0\npictcomp    0    0\nparang      0    6\nblock       0    7\nobject      0    8\ncoding      0    9\n\n$theta\n         info comp arith simil digit vocab pctcmp parang block object coding\ninfo       10                                                               \ncomp        0   11                                                          \narith       0    0    12                                                    \nsimil       0    0     0    13                                              \ndigit       0    0     0     0    14                                        \nvocab       0    0     0     0     0    15                                  \npictcomp    0    0     0     0     0     0     16                           \nparang      0    0     0     0     0     0      0     17                    \nblock       0    0     0     0     0     0      0      0    18              \nobject      0    0     0     0     0     0      0      0     0     19       \ncoding      0    0     0     0     0     0      0      0     0      0     20\n\n$psi\n     verb perf\nverb   21     \nperf   23   22\n\n\n$lambda 행렬은 지표에 대해 추정되는 요인 적재치입니다. 0이 아닌 값은 해당 요인에 대한 부하가 추정되고 있음을 나타냅니다. info와 pictcomp는 모두 0입니다. 이는 로딩을 1로 고정했기 때문입니다. $theta 행렬은 지표의 잔차 분산을 나타내는 지표의 공분산 행렬입니다(즉, 고유하거나 특정 분산). 모든 지표에는 추정된 잔차가 있고 어떤 지표도 상관관계가 없습니다(즉, 모든 비대각선 요소는 0임). $psi 행렬은 요인의 공분산 행렬입니다. 이 행렬의 모든 요소(즉, 분산 및 공분산)가 추정됩니다. 즉, 우리는 언어 지능과 수행 지능이 서로 연관되어 있다고 가정합니다.\ninspect 함수의 결과를 바탕으로 CFA 모델이 실제로 우리가 추정하고자 했던 것과 일치한다는 것을 알 수 있습니다. 이제 summary 함수를 사용하여 적합된 모델에서 정보를 추출할 수 있습니다.\n\nsummary(iq_fit)\n\nlavaan 0.6.16 ended normally after 51 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        23\n\n  Number of observations                           175\n\nModel Test User Model:\n                                                      \n  Test statistic                                70.640\n  Degrees of freedom                                43\n  P-value (Chi-square)                           0.005\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  verb =~                                             \n    info              1.000                           \n    comp              0.926    0.108    8.609    0.000\n    arith             0.589    0.084    7.013    0.000\n    simil             1.012    0.115    8.764    0.000\n    digit             0.477    0.099    4.805    0.000\n    vocab             1.020    0.107    9.548    0.000\n  perf =~                                             \n    pictcomp          1.000                           \n    parang            0.719    0.156    4.614    0.000\n    block             1.060    0.187    5.675    0.000\n    object            0.921    0.177    5.215    0.000\n    coding            0.119    0.147    0.810    0.418\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  verb ~~                                             \n    perf              2.263    0.515    4.397    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .info              3.566    0.507    7.034    0.000\n   .comp              4.572    0.585    7.815    0.000\n   .arith             3.602    0.420    8.571    0.000\n   .simil             5.096    0.662    7.702    0.000\n   .digit             6.162    0.680    9.056    0.000\n   .vocab             3.487    0.506    6.886    0.000\n   .pictcomp          5.526    0.757    7.296    0.000\n   .parang            5.463    0.658    8.298    0.000\n   .block             3.894    0.640    6.083    0.000\n   .object            5.467    0.719    7.600    0.000\n   .coding            8.159    0.874    9.335    0.000\n    verb              4.867    0.883    5.514    0.000\n    perf              3.035    0.844    3.593    0.000\n\n\n출력은 Mplus와 유사하도록 의도되었습니다(Muthén & Muthén, 2015). 그러나 기본 결과는 좀 더 간결합니다. 최소 함수 검정 통계량은 현재 모델에 대한 카이제곱 통계량이며 모델 예측 공분산 행렬과 관찰된 공분산 행렬 사이의 편차를 측정한 것입니다. 다음은 자유도 수이며, 그 다음은 이 검정의 p값입니다. 자유도는 hemp 패키지의 unique_elements와 free_params 함수를 사용하여 공분산 행렬의 고유 요소 수에서 자유 모수 수를 뺀 값으로 계산할 수 있습니다.\n\nunique_elements(iq_fit) - free_params(iq_fit)\n\n[1] 43\n\n\nsummary(iq_fit) 인수는 세 개의 표를 반환합니다. 첫 번째 표는 표준 오차, z‑값 및 p‑값을 가진 추정된 요인적재치를 나타냅니다. 두 번째 표에는 요인의 공분산이 표시되고, 마지막 표에는 지표와 요인 모두의 분산이 포함됩니다(요인은 마지막에 나열됨). 이들 표에서 가장 주목할만한 발견은 coding이 perf IQ와 관련이 없는 것으로 보인다는 것입니다. cfa 함수는 기본적으로 지표에 대한 절편을 제공하지 않는다는 점에 유의해야 합니다(Mplus와 달리). 그러나 절편은 meanstructure = TRUE 인수를 사용하여 모델에 포함될 수 있습니다. 이러한 절편항은 지표의 원 평균에 해당합니다.\nsummary 함수는 기본적으로 추정된 CFA 모델에 대해 표준화되지 않은 해를 반환하지만, summary 함수에 standardized = TRUE 및 fit.measures = TRUE를 포함하여 표준화된 해와 모델 적합도를 출력할 수 있습니다.\n\nsummary(iq_fit, standardized = TRUE, fit.measures = TRUE)\n\nlavaan 0.6.16 ended normally after 51 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        23\n\n  Number of observations                           175\n\nModel Test User Model:\n                                                      \n  Test statistic                                70.640\n  Degrees of freedom                                43\n  P-value (Chi-square)                           0.005\n\nModel Test Baseline Model:\n\n  Test statistic                               519.204\n  Degrees of freedom                                55\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.940\n  Tucker-Lewis Index (TLI)                       0.924\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -4491.822\n  Loglikelihood unrestricted model (H1)      -4456.502\n                                                      \n  Akaike (AIC)                                9029.643\n  Bayesian (BIC)                              9102.433\n  Sample-size adjusted Bayesian (SABIC)       9029.600\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.061\n  90 Percent confidence interval - lower         0.033\n  90 Percent confidence interval - upper         0.085\n  P-value H_0: RMSEA <= 0.050                    0.233\n  P-value H_0: RMSEA >= 0.080                    0.103\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.059\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  verb =~                                                               \n    info              1.000                               2.206    0.760\n    comp              0.926    0.108    8.609    0.000    2.042    0.691\n    arith             0.589    0.084    7.013    0.000    1.300    0.565\n    simil             1.012    0.115    8.764    0.000    2.232    0.703\n    digit             0.477    0.099    4.805    0.000    1.053    0.390\n    vocab             1.020    0.107    9.548    0.000    2.250    0.770\n  perf =~                                                               \n    pictcomp          1.000                               1.742    0.595\n    parang            0.719    0.156    4.614    0.000    1.253    0.473\n    block             1.060    0.187    5.675    0.000    1.846    0.683\n    object            0.921    0.177    5.215    0.000    1.605    0.566\n    coding            0.119    0.147    0.810    0.418    0.207    0.072\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  verb ~~                                                               \n    perf              2.263    0.515    4.397    0.000    0.589    0.589\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .info              3.566    0.507    7.034    0.000    3.566    0.423\n   .comp              4.572    0.585    7.815    0.000    4.572    0.523\n   .arith             3.602    0.420    8.571    0.000    3.602    0.681\n   .simil             5.096    0.662    7.702    0.000    5.096    0.506\n   .digit             6.162    0.680    9.056    0.000    6.162    0.848\n   .vocab             3.487    0.506    6.886    0.000    3.487    0.408\n   .pictcomp          5.526    0.757    7.296    0.000    5.526    0.646\n   .parang            5.463    0.658    8.298    0.000    5.463    0.777\n   .block             3.894    0.640    6.083    0.000    3.894    0.533\n   .object            5.467    0.719    7.600    0.000    5.467    0.680\n   .coding            8.159    0.874    9.335    0.000    8.159    0.995\n    verb              4.867    0.883    5.514    0.000    1.000    1.000\n    perf              3.035    0.844    3.593    0.000    1.000    1.000\n\n\nstandardized = TRUE 인수는 계수 표에 두 개의 열을 추가합니다. Std.lv 열은 잠재변수만을 표준화한 표준화된 값이고, Std.all 열은 잠재변수와 지표를 표준화한 표준화된 출력입니다. 전자는 지표가 이산적일 때 유용하고 후자는 지표가 연속적일 때 유용합니다.\nfit.measures = TRUE 인수는 다양한 적합도 지수(예: BIC(Bayesian Information Criteria), AIC(Akaike’s information criteria), 비교 적합도 지수(CFI), TLI, RMSEA, SRMR)를 출력합니다. 또한 지표의 분산만 추정하는 가장 간명하고 그럴듯한 모델의 카이제곱 검정도 추가로 제공합니다. 적합 모델에서 다양한 추가 적합도 지수를 추출할 수 있습니다. 사용 가능한 모든 지수를 출력하려면 fitMeasures 함수를 사용할 수 있습니다.\n\nfitmeasures(iq_fit)\n\n                 npar                  fmin                 chisq \n               23.000                 0.202                70.640 \n                   df                pvalue        baseline.chisq \n               43.000                 0.005               519.204 \n          baseline.df       baseline.pvalue                   cfi \n               55.000                 0.000                 0.940 \n                  tli                  nnfi                   rfi \n                0.924                 0.924                 0.826 \n                  nfi                  pnfi                   ifi \n                0.864                 0.675                 0.942 \n                  rni                  logl     unrestricted.logl \n                0.940             -4491.822             -4456.502 \n                  aic                   bic                ntotal \n             9029.643              9102.433               175.000 \n                 bic2                 rmsea        rmsea.ci.lower \n             9029.600                 0.061                 0.033 \n       rmsea.ci.upper        rmsea.ci.level          rmsea.pvalue \n                0.085                 0.900                 0.233 \n       rmsea.close.h0 rmsea.notclose.pvalue     rmsea.notclose.h0 \n                0.050                 0.103                 0.080 \n                  rmr            rmr_nomean                  srmr \n                0.466                 0.466                 0.059 \n         srmr_bentler   srmr_bentler_nomean                  crmr \n                0.059                 0.059                 0.064 \n          crmr_nomean            srmr_mplus     srmr_mplus_nomean \n                0.064                 0.059                 0.059 \n                cn_05                 cn_01                   gfi \n              147.916               168.121                 0.931 \n                 agfi                  pgfi                   mfi \n                0.894                 0.606                 0.924 \n                 ecvi \n                0.667 \n\n\ninspect 함수를 사용하여 \\(R^2\\) (잠재 변수로 설명되는 지표의 변산성 비율)를 별도의 결과로 출력할 수 있습니다.\n\ninspect(iq_fit, \"rsquare\")\n\n    info     comp    arith    simil    digit    vocab pictcomp   parang \n   0.577    0.477    0.319    0.494    0.152    0.592    0.354    0.223 \n   block   object   coding \n   0.467    0.320    0.005 \n\n\n동일한 정보는 기본 요약 결과(예: 1 ‑ 고유 분산)에서도 얻을 수 있습니다. 또한 summary 함수에 추가 인수를 전달하여 \\(R^2\\)를 요청할 수 있습니다.\n\nsummary(iq_fit, rsquare = TRUE)\n\nlavaan 0.6.16 ended normally after 51 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        23\n\n  Number of observations                           175\n\nModel Test User Model:\n                                                      \n  Test statistic                                70.640\n  Degrees of freedom                                43\n  P-value (Chi-square)                           0.005\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  verb =~                                             \n    info              1.000                           \n    comp              0.926    0.108    8.609    0.000\n    arith             0.589    0.084    7.013    0.000\n    simil             1.012    0.115    8.764    0.000\n    digit             0.477    0.099    4.805    0.000\n    vocab             1.020    0.107    9.548    0.000\n  perf =~                                             \n    pictcomp          1.000                           \n    parang            0.719    0.156    4.614    0.000\n    block             1.060    0.187    5.675    0.000\n    object            0.921    0.177    5.215    0.000\n    coding            0.119    0.147    0.810    0.418\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  verb ~~                                             \n    perf              2.263    0.515    4.397    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .info              3.566    0.507    7.034    0.000\n   .comp              4.572    0.585    7.815    0.000\n   .arith             3.602    0.420    8.571    0.000\n   .simil             5.096    0.662    7.702    0.000\n   .digit             6.162    0.680    9.056    0.000\n   .vocab             3.487    0.506    6.886    0.000\n   .pictcomp          5.526    0.757    7.296    0.000\n   .parang            5.463    0.658    8.298    0.000\n   .block             3.894    0.640    6.083    0.000\n   .object            5.467    0.719    7.600    0.000\n   .coding            8.159    0.874    9.335    0.000\n    verb              4.867    0.883    5.514    0.000\n    perf              3.035    0.844    3.593    0.000\n\nR-Square:\n                   Estimate\n    info              0.577\n    comp              0.477\n    arith             0.319\n    simil             0.494\n    digit             0.152\n    vocab             0.592\n    pictcomp          0.354\n    parang            0.223\n    block             0.467\n    object            0.320\n    coding            0.005\n\n\nCFA 모델로 돌아가서 모델에서 “coding” 변수를 삭제하고 모델을 다시 적합합니다. 이 새 모델의 결과를 iq_fit_nocode로 저장합니다.\n\niq_mod_nocode <- '\nverb =~ info + comp + arith + simil + digit + vocab\nperf =~ pictcomp + parang + block + object\n'\niq_fit_nocode <- cfa(iq_mod_nocode, wiscsem)\n\n다음으로 coding(code)이 있는 모델과 없는 모델(nocode)을 비교하고 rbind 함수를 사용하여 적합도 지수를 결합할 수 있습니다.\n\nnocode <- fitmeasures(iq_fit_nocode,\nfit.measures = c(\"rmsea\", \"tli\", \"cfi\"))\ncode <- fitmeasures(iq_fit,\nfit.measures = c(\"rmsea\", \"tli\", \"cfi\"))\nrbind(nocode, code)\n\n            rmsea       tli       cfi\nnocode 0.05983914 0.9384618 0.9535045\ncode   0.06060555 0.9238418 0.9404581\n\n\n이러한 모델은 공분산 행렬이 다르기 때문에 내재되지 않으며 이러한 모델을 카이제곱 차이 검정 또는 정보 기준으로 비교할 수 없습니다. 그러나 절대 적합도 지수를 비교할 수 있습니다. 모델은 같은 공분산 행렬을 갖고 있지만 자유 모수가 더 적은 경우에만 내재됩니다. 그런 상황에서 우리는 단순히 카이 제곱 차이 검정을 사용할 수 있습니다.\n이 결과를 바탕으로 coding 변수를 삭제하는 것이 정당화될 수 있지만 coding을 삭제해도 모델 적합도가 크게 개선되지는 않는 것 같습니다. 모델 적합도를 개선하려면 modindices 함수를 사용하여 계산할 수 있는 수정 지수를 검토하는 것을 고려할 수 있습니다. 현재 모델은 이러한 모든 추가 경로가 자유로운 모델 내에 내재되어 있습니다. 아래에서는 수정 지수를 계산하여 내림차순으로 정렬하고, 카이 제곱 검정을 기반으로 모델 적합도를 크게 향상시키는 것만 출력합니다(즉, \\(\\chi^2\\)의 변화가 df=1일 때 3.84보다 커짐)\n\nmodind_iq <- modindices(iq_fit_nocode, sort. = TRUE)\nmodind_iq[modind_iq$mi > 3.84,]\n\n     lhs op      rhs    mi    epc sepc.lv sepc.all sepc.nox\n29  perf =~     comp 9.853  0.534   0.939    0.318    0.318\n57 arith ~~   object 6.246 -0.936  -0.936   -0.211   -0.211\n34  info ~~     comp 5.247 -0.987  -0.987   -0.245   -0.245\n47  comp ~~ pictcomp 4.629  0.961   0.961    0.192    0.192\n38  info ~~    vocab 4.429  0.915   0.915    0.259    0.259\n28  perf =~     info 4.372 -0.335  -0.589   -0.203   -0.203\n35  info ~~    arith 4.156  0.699   0.699    0.195    0.195\n70 vocab ~~   parang 4.072 -0.791  -0.791   -0.181   -0.181\n\n\n결과에서, 첫 세 열은 자유모수 경로를 나타냅니다. op 열은 left-hand side(lhs) 변수와 right-hand side(rhs) 변수 사이에 lavaan 연산자에 해당합니다. 앞서 우리는 “=~”는 왼쪽 변수가 오른쪽 변수에 의해 명시된다는 것을 의미한다고 보았습니다. 첫 번째 줄은 comp가 수행 IQ 변수인 perf 의 표현식이 될 수 있도록 허용해야 함을 나타냅니다. 두 번째 줄에는 “~~” 연산자가 포함되어 있어 왼쪽의 변수와 오른쪽에 있는 변수가 공변할 수 있도록 허용해야 한다고 제안합니다. 이 경우, arith가 object와 공변하도록 허용해야 합니다.\n나머지 열은 카이제곱 통계량의 예상되는 변화입니다. 기대되는 모수 변화(즉, 해당 자유 경로의 추정된 모수) 그리고 다음과 같은 표준화 버전(잠재 변수만 표준화, 모든 변수 표준화, 모델의 외생 변수를 제외한 모든 변수 표준화)입니다. 수정 지수(즉, mi 열)는 comp가 perf에 적재되도록 허용함으로써 모델 적합도에서 가장 큰 변화를 찾을 수 있음을 보여줍니다. 카이제곱의 변화는 9.823입니다.\n수정 지수를 기반으로 한 제안을 사용하여 perf 요인 하에 comp를 추가하여 CFA 모델을 업데이트하고 새 모델을 iq_fit_mi로 저장합니다.\n\niq_mod_mi <- '\nverb =~ info + comp + arith + simil + digit + vocab\nperf =~ pictcomp + parang + block + object + comp\n'\niq_fit_mi <- cfa(iq_mod_mi, wiscsem)\nfitMeasures(iq_fit_mi, c(\"rmsea\", \"tli\", \"cfi\", \"srmr\"))\n\nrmsea   tli   cfi  srmr \n0.046 0.963 0.973 0.049 \n\n\n이제 업데이트된 모델(즉, iq_fit_mi)에서 적합도가 매우 양호한 것을 알 수 있으며 summary 결과를 살펴보면 카이제곱 검정에 대한 영가설을 기각하지 못하는 것을 볼 수 있습니다. 하지만 우리는 comp가 perf의 명시변수가 되도록 허용하는 이유를 정당화할 준비가 되어 있어야 합니다. 이는 타당도에 대한 질문이며 일반화가능도에도 영향을 미칩니다(즉, 모델을 과적합하고 있는 것은 아닌지?). 이제 모델이 내재되었으므로 anova 함수를 사용하여 카이제곱 차이 검정을 수행할 수 있습니다.\n\nanova(iq_fit_nocode, iq_fit_mi)\n\n\nChi-Squared Difference Test\n\n              Df    AIC    BIC  Chisq Chisq diff   RMSEA Df diff Pr(>Chisq)   \niq_fit_mi     33 8153.4 8223.0 45.276                                         \niq_fit_nocode 34 8161.4 8227.9 55.305     10.029 0.22714       1   0.001541 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n이해력을 수행 IQ에 적재하도록 허용하면 모델 적합도가 통계적으로 유의미하게 향상되는 것을 보실 수 있습니다. 가장 적합한 모델인 iq_fit_mi에서 요인 점수를 추출하기 위해 predict 함수를 사용하고 결과를 factor_scores로 저장한 다음 head 함수를 사용하여 처음 6개 행을 출력합니다.\n\nfactor_scores <- predict(iq_fit_mi)\nhead(factor_scores)\n\n           verb       perf\n[1,] -0.2227813 -1.2256055\n[2,] -1.1473545 -2.0686206\n[3,]  3.8269042  2.4161738\n[4,] -0.9696807 -0.8159658\n[5,] -0.9728589 -2.5860298\n[6,]  0.8370746 -1.7503289\n\n\n마지막으로, cfa 함수로 추정된 CFA 모델에서 모델 예측 공분산과 잔차 공분산 행렬을 추출하려면 fitted 함수와 residual 함수를 사용할 수 있습니다.\n\nfitted(iq_fit_mi)\n\n$cov\n           info   comp  arith  simil  digit  vocab pctcmp parang  block object\ninfo      8.433                                                               \ncomp      4.429  8.743                                                        \narith     2.948  2.564  5.291                                                 \nsimil     4.976  4.329  2.881 10.078                                          \ndigit     2.424  2.108  1.403  2.369  7.271                                   \nvocab     5.129  4.461  2.970  5.013  2.442  8.552                            \npictcomp  2.172  3.035  1.258  2.123  1.034  2.188  8.560                     \nparang    1.426  1.993  0.826  1.394  0.679  1.437  2.144  7.033              \nblock     2.177  3.042  1.260  2.128  1.036  2.193  3.272  2.148  7.301       \nobject    1.961  2.741  1.136  1.917  0.934  1.976  2.949  1.936  2.955  8.042\n\n\n\nresiduals(iq_fit_mi)\n\n$type\n[1] \"raw\"\n\n$cov\n           info   comp  arith  simil  digit  vocab pctcmp parang  block object\ninfo      0.000                                                               \ncomp     -0.417  0.000                                                        \narith     0.355  0.104  0.000                                                 \nsimil    -0.246  0.460 -0.184  0.000                                          \ndigit     0.281 -0.228  0.265 -0.148  0.000                                   \nvocab     0.179  0.133 -0.364 -0.020 -0.121  0.000                            \npictcomp -0.219  0.485 -0.212  1.307 -0.440  0.254  0.000                     \nparang    0.126 -0.530  0.557  1.116  0.381 -0.412 -0.214  0.000              \nblock    -0.379 -0.093  0.431  0.115 -0.506  0.158 -0.252  0.369  0.000       \nobject   -0.439 -0.038 -0.856  0.502 -0.668 -0.439  0.066 -0.031  0.104  0.000\n\n\n출력의 첫 번째 부분은 공분산 행렬이고 두 번째 부분은 측정 변수의 평균입니다. cfa는 기본적으로 평균을 추정하지 않기 때문에 두 함수 모두 평균이 0입니다. 적합 함수에서 반환된 평균의 경우 cfa 함수에서 평균 구조 = TRUE가 사용된 경우 0이 지표 평균으로 대체됩니다. 이 업데이트는 residual 함수에서 반환된 결과에는 영향을 주지 않습니다(즉, 평균은 여전히 0임).\n\n\n4.4.2 범주형 데이터가 포함된 CFA\n마지막 섹션에서, 범주형 데이터로 CFA를 수행하는 방법을 보여줍니다. 범주형인 경우 lavaan에 대한 데이터를 설정하는 방법에는 두 가지가 있습니다.\n\n지표가 명목척도이면 C ‑ 1개의 더미 변수를 생성해야 합니다(여기서 C는 지표의 범주 수). lm 함수와 같은 R의 많은 함수가 자동으로 더미 변수를 생성하지만 이것은 전통적인 회귀 문제에서 처리하는 방법과 유사합니다.\n지표가 서열척도인 경우 cfa를 실행하기 전에 ordered 함수와 함께 지표가 서열척도임을 R에게 알릴 수 있습니다. 또는 cfa 함수를 사용하여 모델을 적합할 때 ordered 인수를 전달할 수 있습니다.\n\n기본적으로 데이터가 범주형일 때 lavaan은 대각 가중 최소 제곱을 사용하는, 가중 최소 제곱 추정량으로 전환합니다. wiscsem 데이터 세트를 서열 변수로 다시 코딩하여 위에서 언급한 두 가지 접근 방식을 설명합니다. 이것은 엄밀히 말해 교육적인 목적으로 수행된 것이며, 독자들이 일반적으로 데이터에 대해 수행해야 하는 작업이 아니라는 점에 유의하시기 바랍니다.\n우리는 wiscsem을 wiscsem_cat으로 저장하고 지표를 사분위수로 분할하는 함수(quart_cut)를 적용하고 lapply 함수를 통해 각 관 측치를 사분위수에 할당합니다. lapply 함수를 사용하면 quart_cut 함수를 개별적으로가 아니라 동시에 모든 지표에 적용할 수 있습니다.\n\nwiscsem_cat <- wiscsem\nwiscsem_cat[ ,] <- lapply(wiscsem_cat[ ,], quart_cut)\n\n\n4.4.2.1 서열 CFA-방법 1\n방법 1은 cfa 함수를 사용하기 전에 지표가 서열척도임을 R에 알리는 것입니다. 현재 지표는 관측치가 어느 사분위수에 속하는지에 해당하는 1, 2, 3, 4의 숫자 값일 뿐입니다. lapply 명령을 사용하여 이러한 숫자 값을 서열척도로 다시 변환할 수 있습니다. 먼저 wiscsem_cat을 wiscsem_ord로 저장합니다. 그런 다음 lapply에게 ordered 함수를 사용하여 wiscsem_ord의 모든 변수를 서열 변수로 변환하고 다시 wiscsem_ord로 저장하도록 지시합니다.\n\nwiscsem_ord <- wiscsem_cat\nwiscsem_ord[,] <- lapply(wiscsem_ord[ ,], ordered)\n\n다음으로 wiscsem 대신 wiscsem_ord 데이터 세트를 사용하여 CFA 모델을 적합합니다. 이 모델의 결과를 iq_fit_ord1로 저장한 다음 summary 함수를 사용하여 결과를 출력합니다.\n\niq_fit_ord1 <- cfa(iq_mod, wiscsem_ord)\nsummary(iq_fit_ord1)\n\nlavaan 0.6.16 ended normally after 21 iterations\n\n  Estimator                                       DWLS\n  Optimization method                           NLMINB\n  Number of model parameters                        41\n\n  Number of observations                           175\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                                42.611      60.299\n  Degrees of freedom                                43          43\n  P-value (Chi-square)                           0.488       0.042\n  Scaling correction factor                                  0.813\n  Shift parameter                                            7.882\n    simple second-order correction                                \n\nParameter Estimates:\n\n  Standard errors                           Robust.sem\n  Information                                 Expected\n  Information saturated (h1) model        Unstructured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  verb =~                                             \n    info              1.000                           \n    comp              1.114    0.128    8.721    0.000\n    arith             0.732    0.129    5.667    0.000\n    simil             1.035    0.141    7.329    0.000\n    digit             0.357    0.148    2.408    0.016\n    vocab             1.185    0.135    8.787    0.000\n  perf =~                                             \n    pictcomp          1.000                           \n    parang            0.753    0.194    3.890    0.000\n    block             1.092    0.175    6.233    0.000\n    object            0.767    0.165    4.648    0.000\n    coding            0.327    0.158    2.062    0.039\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  verb ~~                                             \n    perf              0.288    0.056    5.128    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .info              0.000                           \n   .comp              0.000                           \n   .arith             0.000                           \n   .simil             0.000                           \n   .digit             0.000                           \n   .vocab             0.000                           \n   .pictcomp          0.000                           \n   .parang            0.000                           \n   .block             0.000                           \n   .object            0.000                           \n   .coding            0.000                           \n    verb              0.000                           \n    perf              0.000                           \n\nThresholds:\n                   Estimate  Std.Err  z-value  P(>|z|)\n    info|t1          -0.725    0.105   -6.925    0.000\n    info|t2          -0.343    0.097   -3.536    0.000\n    info|t3           0.670    0.103    6.493    0.000\n    comp|t1          -0.862    0.109   -7.908    0.000\n    comp|t2          -0.436    0.098   -4.432    0.000\n    comp|t3           0.883    0.110    8.044    0.000\n    arith|t1         -1.043    0.116   -8.958    0.000\n    arith|t2         -0.389    0.098   -3.984    0.000\n    arith|t3          0.670    0.103    6.493    0.000\n    simil|t1         -0.688    0.104   -6.638    0.000\n    simil|t2         -0.343    0.097   -3.536    0.000\n    simil|t3          0.688    0.104    6.638    0.000\n    digit|t1         -0.949    0.112   -8.446    0.000\n    digit|t2          0.905    0.111    8.180    0.000\n    vocab|t1         -0.801    0.107   -7.492    0.000\n    vocab|t2          0.688    0.104    6.638    0.000\n    pictcomp|t1      -0.725    0.105   -6.925    0.000\n    pictcomp|t2      -0.209    0.096   -2.184    0.029\n    pictcomp|t3       0.971    0.113    8.577    0.000\n    parang|t1        -0.801    0.107   -7.492    0.000\n    parang|t2         0.821    0.108    7.631    0.000\n    block|t1         -0.763    0.106   -7.210    0.000\n    block|t2          0.905    0.111    8.180    0.000\n    object|t1        -0.801    0.107   -7.492    0.000\n    object|t2        -0.436    0.098   -4.432    0.000\n    object|t3         0.949    0.112    8.446    0.000\n    coding|t1        -1.018    0.115   -8.833    0.000\n    coding|t2        -0.298    0.097   -3.086    0.002\n    coding|t3         0.883    0.110    8.044    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .info              0.555                           \n   .comp              0.447                           \n   .arith             0.761                           \n   .simil             0.523                           \n   .digit             0.943                           \n   .vocab             0.375                           \n   .pictcomp          0.580                           \n   .parang            0.762                           \n   .block             0.499                           \n   .object            0.753                           \n   .coding            0.955                           \n    verb              0.445    0.082    5.412    0.000\n    perf              0.420    0.109    3.843    0.000\n\nScales y*:\n                   Estimate  Std.Err  z-value  P(>|z|)\n    info              1.000                           \n    comp              1.000                           \n    arith             1.000                           \n    simil             1.000                           \n    digit             1.000                           \n    vocab             1.000                           \n    pictcomp          1.000                           \n    parang            1.000                           \n    block             1.000                           \n    object            1.000                           \n    coding            1.000                           \n\n\n이 명령을 실행하면 일부 지표에 대해 이변량 테이블의 행 또는 열에 0개의 셀이 있음을 나타내는 경고 메시지가 나타납니다. 이 경고 메시지가 표시되는 이유는 lavaan이 다변량(polychoric) 상관관계를 계산하기 때문입니다. 여기서 경고 메시지는 무시하고 summary 함수에서 반환된 결과를 검토할 수 있습니다. 결과에 모델 적합의 강력한 추정량 열이 추가되었습니다. 다른 곳에서 광범위하게 논의된 이 샌드위치 추정량(Asparouhov & Muthén, 2010)을 사용하는 것이 좋습니다.3 summary 결과에는 지표 임계값 및 척도에 대한 정보도 포함됩니다(위에서 변수 “info”에 대해서만 표시됨). 그렇지 않으면, 결과는 일반적인 cfa 호출과 유사합니다.\n\n\n4.4.2.2 서열 CFA-방법 2\n이 방법은 지표가 서수임을 cfa 함수에 알려주는 것입니다. 이 추가 조정은 다음과 같이 수행할 수 있습니다 .\n\niq_fit_ord2 <- cfa(iq_mod, wiscsem_cat, \n                   ordered = names(wiscsem_cat))\n\nordered=names(wiscsem_cat)를 지정하여 cfa에 wiscsem_cat의 모든 지표가 서열화 되도록 지시합니다. 이 호출의 summary 결과는 iq_fit_ord1과 동일합니다. 만일 지표 중 두 개가 서열척도인 경우, 해당 두 개의 지표만 지정합니다(예: verb와 info가 서열척도이고 다른 것은 없는 경우)\n\niq_fit_ord2 <- cfa(iq_mod, wiscsem_cat, \n                   ordered = c(\"verb\", \"info\"))\n\nWarning in lavaan::lavaan(model = iq_mod, data = wiscsem_cat, ordered = c(\"verb\", : lavaan WARNING: ordered variable(s): verb\n  could not be found in the data and will be ignored"
  },
  {
    "objectID": "chap04.html#요약",
    "href": "chap04.html#요약",
    "title": "4  측정에서 요인분석적 접근",
    "section": "4.5 요약",
    "text": "4.5 요약\n이 장에서는 탐색적 요인분석과 및 확인적 요인 분석에 대한 간략한 소개와 함께 factanal 및 psych 패키지를 사용하여 EFA를 수행하는 방법과 lavaan 패키지를 사용하여 CFA를 수행하는 방법을 보여드렸습니다. 공통 요인 모델에 대한 간략한 검토로 시작한 다음 EFA 및 CFA를 사용하는 예제로 이동했습니다. 독자들은 이러한 방법론을 더 잘 이해하기 위해 요인 분석 및 SEM에 대한 다른 리소스(예: Kline, 2015)를 검토할 것을 권장합니다. 다음으로 lavaan 외에도 요인 분석 및구조방정식 모델을 추정할 수 있는 수많은 R 패키지가 있다는 점에 주목하고 싶습니다. 예를 들어, sem(Fox, Nie, & Byrnes, 2017), Fac-toMineR(Lê, Josse, & Husson, 2008) 및 OpenMx(Neale et al., 2016) 등이 있습니다. 다음 장에서는 일반적으로 단일 기본 잠재 변수를 가정하는 문항반응이론 모델을 다룹니다. 요인 분석을 통해 찾은 단일차원 해는 제5, 6장에 제시된 모델의 중요한 가정입니다."
  },
  {
    "objectID": "chap05.html#개요",
    "href": "chap05.html#개요",
    "title": "5  이분 문항반응이론",
    "section": "5.1 개요",
    "text": "5.1 개요\n이 장에서는 이분법적으로 채점된 문항에 대한 단일차원 문항 반응 이론(IRT) 모델을 소개합니다. 이 장은 IRT 프레임워크에 대한 간략한 설명으로 시작됩니다. 이 장의 나머지 부분은 다음과 같이 진행됩니다: 수학적 공식과 함께 단일차원 IRT 모델을 간략하게 소개하고, 해석을 용이하게 하기 위해 모수를 설명한 다음, 마지막으로 이분법적 문항에 대한 단일차원 IRT 모델을 추정하고 정보를 추출하는 방법을 보여주는 R 예제를 제시합니다. 이 장에서 다루는 IRT 모델에는 라쉬 모델, 1-모수, 2-모수, 3-모수 및 4-모수 IRT 모델이 포함됩니다. CRAN에는 IRT 모델에 적합한 eRm(Mair & Hatzinger, 2007a), ltm(Rizopoulos, 2006), mirt(Chalmers, 2012), TAM(Kiefer, Robitzsch, & Wu, 2016) 등과 같은 여러 사용자 패키지가 존재합니다. 이 장에서는 다양한 IRT 모델을 추정할 수 있는 가장 포괄적이고 최신의 R 패키지인 mirt 패키지(Chalmers, 2012)를 사용하여 단일차원 IRT 모델을 추정하는 방법을 설명합니다."
  },
  {
    "objectID": "chap05.html#소개",
    "href": "chap05.html#소개",
    "title": "5  이분 문항반응이론",
    "section": "5.2 소개",
    "text": "5.2 소개\n\n5.2.1 고전검사이론과의 비교\n제2장에서는 고전검사이론(CTT) 모델을 소개했습니다. IRT는 CTT 모델의 단점을 극복하기 위해 개발되었습니다. 특히 IRT는 몇 가지 이론적이고 검증 가능한 가정을 한다는 점에서 CTT와 다릅니다(Embretson & Reise, 2000, 제1장 참조). 첫째, IRT는 피험자가 기저에 있는 잠재 특성의 수준에 따라 주어진 문항에 어떻게 반응하는지에 대한 확률적 모델입니다. 문항에 올바르게 응답하거나 더 일반적으로 문항을 지지할 확률은 측정된 잠재 특성(\\(\\theta\\)로 표시)의 단조 증가하는 함수입니다. 이 함수는 문항의 난이도(또는 위치), 변별도(또는 기울기), 추측도(즉, 낮은 점근값) 모수에 따라 달라질 수 있습니다. IRT와 달리 CTT는 문항과 측정된 잠재 특성 간의 관계보다는 관찰 가능한(즉, 원점수) 점수에만 초점을 맞춥니다.\n둘째, IRT 모델에서 얻은 잠재 특성 추정치는 검사 문항 및 피험자 집단의 특성과 독립적인 것으로 가정하는 반면, CTT에서 얻은 검사 점수는 검사에서 선택한 문항에 크게 의존합니다. 문항의 난이도가 검사마다 다르더라도 IRT의 잠재 특성 추정치는 매우 유사할 것으로 예상되는 반면, CTT의 검사 점수는 검사에 따라 크게 다를 수 있습니다. 따라서 CTT 프레임워크에 비해 IRT 프레임워크 내에서 서로 다른 검사 간 피험자의 성적을 비교하는 것이 훨씬 쉽습니다.\n셋째, IRT는 문항 모수가 피험자의 하위 그룹과 여러 검사 시행에 걸쳐 변하지 않는다고 가정합니다. 이러한 가정에 따라 문항은 피험자의 하위 그룹(예: 성별이나 인종이 다른 피험자)에 관계없이 동일한 모수를 가질 것으로 예상됩니다.1 또한 문항 모수를 선형으로 변환할 수 있는 경우 여러 검사 시행에 걸친 문항은 상호 불변성으로 간주됩니다(Hambleton, Swaminathan, & Rogers, 1991; Rupp & Zumbo, 2006; Stocking & Lord, 1983). IRT의 모수 불변성 속성을 통해 검사 동등화 및 컴퓨터 적응 검사에서 발생하는 문제와 같이 CTT에서 다루기 어려웠던 중요한 측정 문제를 해결할 수 있습니다(Hambleton et al., 1991).\n\n\n5.2.2 IRT의 기본 개념\nIRT 프레임워크 내에서 문항은 개별적으로 특성화되며, 문항에서 검사 특성이 도출됩니다. 이러한 특성에는 문항의 정답을 맞히는 데 필요한 잠재 특성 수준인 난이도2, 잠재 특성 수준이 낮은 사람과 높은 사람을 구별하는 문항의 힘인 변별도, 잠재 특성 수준이 매우 낮은 수험자가 문항에 정답을 맞힐 확률인 추측도 등이 있습니다. 문항의 난이도, 변별도, 추측도 수준을 바탕으로 피험자의 잠재 특성(\\(\\theta\\)) 수준에 따라 문항을 정답으로 맞힐 확률을 나타내는 문항 특성 곡선(ICC)을 그릴 수 있습니다.\n그림 5.1은 변별도와 추측도의 수준은 같지만 난이도(즉, 쉬움, 보통, 어려움)가 다른 세 문항의 ICC를 보여줍니다. 문항에 정답할 확률이 0.5가 되기 위해 필요한 잠재 특성 수준인 \\(\\theta\\)는 쉬운 문항의 경우 -1, 보통 문항의 경우 0, 어려운 문항의 경우 1입니다. ICC는 로지스틱 확률 곡선이기 때문에 잠재 특성은 일반적으로 -5에서 +5 범위의 로지스틱 척도에 있습니다. 문항의 난이도를 결정할 때도 동일한 로지스틱 척도가 사용됩니다.\n\n\n\n난이도가 각각 상, 중, 하인 문항의 문항특성곡선\n\n\n그림 5.2는 난이도와 추측도 수준은 같지만 변별도 수준(즉, 낮음, 보통, 높음)이 다른 세 가지 문항의 ICC를 보여줍니다. 문항 변별도는 기본적으로 문항의 위치(난이도)에 따른 ICC의 기울기입니다(즉, 그림 5.2의 경우 \\(\\theta\\) = 0). ICC가 가파를수록 문항이 저능력 피험자와 고능력 피험자 간에 변별도가 높다는 것을 의미합니다. 그림 5.2에서 변별도가 가장 낮은 문항(점선)의 ICC가 가장 평탄한 기울기를 갖습니다. 다른 두 문항의 기울기가 높아질수록 문항의 변별도가 향상되고 해당 문항의 문항 위치에서 변별도가 더 높아집니다.\n\n\n\n변별도가 각각 상, 중, 하인 문항의 문항특성곡선\n\n\n그림 5.3은 난이도와 변별도는 같지만 추측도의 수준(즉, 낮거나 높음)이 다른 두 문항의 ICC를 보여줍니다. 추측도의 수준이 높을수록 ICC의 절편(즉, ICC가 Y축과 교차하는 지점)이 증가합니다. 추측도의 수준이 높을수록 잠재 특성 수준이 낮은 피험자가 문항에 정답할 가능성이 높아집니다. 그림 5.3에서 추측도가 높은 문항(점선)의 ICC는 더 큰 절편으로, 잠재 특성 수준이 낮은 피험자(예: \\(\\theta\\) = -1)가 이 문항에 정답을 맞힐 확률이 약 60%에 달합니다. 추측도가 낮은 다른 문항(즉, 실선)의 경우 동일한 수험자가 해당 문항에 정답할 확률은 약 35%입니다. 추측도의 영향은 잠재 특성 수준이 증가함에 따라 감소합니다.\n\n\n\n추측도가 높고 낮은 문항의 문항 특성 곡선\n\n\nIRT에서 또 다른 중요한 개념은 문항 정보 함수(IIF)입니다. IIF는 잠재 특성의 연속성을 따라 문항에 대한 정보의 양을 나타냅니다. 잠재 특성의 고정된 수준에 대해 IIF가 클수록 해당 잠재 특성의 특정 수준에서 피험자가 이용할 수 있는 정보가 많아집니다. 잠재 특성 수준 \\(\\theta\\)에서 문항 \\(i\\)(\\(i = 1, 2, …, N\\))에 대한 정보 함수를 \\(I_i(\\theta)\\)로 표시합니다. 문항은 지역 독립성 가정이므로(아래 참조), 모든 문항에 대한 IIF를 합산하여 다음과 같이 검사 정보 함수(TIF)를 계산할 수 있습니다.\n\\[\nI(\\theta)=\\sum_{i=1} ^N I_i(\\theta)\n\\]\n\n여기서 \\(I(\\theta)\\)는 잠재 특성 \\(\\theta\\)에 대한 총 검사 정보입니다.\n\nTIF를 사용하면, 주어진 잠재 특성 수준에서 검사의 정밀도에 대한 정보를 제공하는 조건부 측정의 표준오차(cSEM)를 계산할 수 있습니다. cSEM 값은 다음에서 TIF의 역수 값의 제곱근입니다.\n\\[\ncSEM(\\theta)=\\sqrt{1 \\over I(\\theta)^.}\n\\]\n그림 5.4는 TIF(실선)와 cSEM(점선) 간의 상호 관계를 보여줍니다. TIF의 최대 지점은 cSEM의 최저 지점에 해당합니다. 즉, 검사 또는 문항에 대한 정보가 최대치에 있는 경우 이 지점 주변의 피험자에 대한 잠재 특성 수준을 더 정확하게 추정할 수 있습니다. 그림 5.4에서는 \\(\\theta\\)가 0에 가까운 피험자의 잠재 특성을 가장 정확하게 추정하는 검사임을 확인할 수 있습니다.\n\n\n\nTIF(실선)와 cSEM(점선) 간의 상호 관계\n\n\n이로부터 얻을 수 있는 중요한 결론은 검사에 응시하는 피험자는 잠재 특성 수준에 따라 각기 다른 cSEM을 갖게 된다는 것입니다.\n\n\n5.2.3 IRT 모델의 가정\nIRT에는 두 가지 주요 모델링 가정이 있습니다. 하나는 단일 차원성과 지역 독립성입니다. 단일차원성 가정은 검사 문항 세트의 기저에 하나의 잠재 특성이 존재해야 한다는 가정입니다. 이 가정을 충족하려면 검사 수행에 영향을 미치는 지배적인 구성 요소 또는 요인을 찾아야 합니다. 단일 차원성 가정을 확인하는 방법에는 주성분 분석, 탐색적 요인 분석, 확인적 요인 분석, DIMTEST(Strout, 1990), DETECT(Zhang & Stout, 1999) 등이 있습니다. 이러한 방법 중 탐색적 요인 분석과 확인적 요인 분석은 제4장에서 설명했습니다(차원성을 평가하는 가장 일반적인 방법).\n지역 독립성 가정에 따르면 주어진 문항에 성공적으로 응답할 확률은 검사의 다른 문항에 대한 응답과 관계없이 잠재 특성에만 근거해야 합니다. 즉, 잠재 특성 수준에 따라 조건을 설정할 때 지역 독립성은 문항 간에 관계가 남아 있지 않음을 의미합니다(Embretson & Reise, 2000). 단일 차원성 가정이 성립하면 두 개념이 하나의 잠재 특성을 통해서만 서로 관련되기 때문에 지역 독립성 가정도 충족됩니다(Lord, 1980). Yen의 Q3 통계(Yen, 1984)는 지역 독립성 가정을 검증하는 데 가장 일반적으로 사용되는 방법 중 하나입니다.\n검사 문항의 단일 차원성 및 지역 독립성 외에도 문항 모수와 잠재 특성 수준을 추정하기 전에 확인해야 할 몇 가지 가정이 있습니다. 비속도 검사 시행 가정에서는 모든 피험자가 검사 문항에 답할 수 있는 충분한 시간을 가져야 합니다. Rasch, 1모수 및 2모수 IRT 모델에서는 주어진 문항에 대한 정답을 추측하는 것이 해당 문항의 정답 확률에 미치는 영향이 미미하거나 전혀 없다고 가정합니다. 이 가정에 따르면 1모수 및 2모수 모델의 ICC는 0에 낮은 점근값을 갖습니다. 이 가정은 잠재 특성 수준이 낮은 피험자가 해당 문항에 정답할 확률이 매우 낮다는 것을 나타냅니다. 마지막 가정은 문항 변별도가 검사의 모든 문항에서 동일하다는 가정이며, 이는 Rasch 및 1모수 IRT 모델에서만 가정됩니다. 이 가정은 모든 문항에서 문항 변별도가 동일(즉, “1” 또는 다른 추정 값)하도록 제한합니다."
  },
  {
    "objectID": "chap05.html#이분-문항에-대한-단일-차원-irt-모델",
    "href": "chap05.html#이분-문항에-대한-단일-차원-irt-모델",
    "title": "5  이분 문항반응이론",
    "section": "5.3 이분 문항에 대한 단일 차원 IRT 모델",
    "text": "5.3 이분 문항에 대한 단일 차원 IRT 모델\n이분으로 채점된 검사 문항에 대한 4개의 단일 차원 IRT 모델에는 1모수, 2모수, 3모수 및 4모수 IRT 모델이 있습니다.3 이러한 모델은 변별도와 추측도에 대한 가정과 모델링 제약 조건에 따라 다릅니다.\n\n5.3.1 1모수 로지스틱 모델과 Rasch 모델\n\n5.3.1.1 1모수 로지스틱 모델\n가장 간단한 IRT 모델은 1모수 로지스틱 IRT 모델(1PL 모델이라고도 함)입니다. 수학적으로 1PL 모델은 다음과 같이 작성할 수 있습니다.\n\\[\nP(Y_{ij}=1|\\theta_j, a, b_i) = {exp(Da(\\theta_j-b_i)) \\over 1+exp(Da(\\theta_j-b_i))}\n\\]\n\n여기서 \\(\\theta_j\\)는 피험자 \\(j\\)의 잠재 특성 수준(\\(j = 1, …, J\\)),\n\\(a\\)는 문항 변별도 모수,\n\\(b_i\\)는 문항 \\(i\\)의 문항 난이도 모수(\\(i = 1, …, I\\)),\n\\(D\\)는 로지스틱 모델의 모수를 정규 오자이브 모델의 척도에 배치하는 척도 상수입니다(\\(D = 1.7\\)일 때).\n\n이 방정식은 피험자 \\(j\\)가 문항 \\(i\\)에 정답할 확률이 잠재 특성, 문항 변별도 및 문항 난이도의 함수임을 나타냅니다. 방정식 5.3에서 문항 변별도에 대한 첨자가 없고 추측도에 대한 언급이 없는 것을 알 수 있습니다. 이는 1PL 모델에서는 문항 변별도가 동일하고 추측도가 문항에 정답하는 데 미치는 영향이 없다고 가정한다는 것을 나타냅니다.\nR에서 1PL 모델을 추정하는 방법을 보여주기 위해 제2장에서 소개한 hemp 패키지에 포함된 SAPA 데이터 세트를 다시 고려합니다. 문항 모수를 추정하기 위해 mirt 패키지의 mirt 함수를 사용합니다(Chalmers, 2012). mirt 패키지의 함수를 사용하려면 먼저 mirt 패키지를 설치해야 합니다. 그런 다음 라이브러리 명령을 사용하여 mirt와 hemp를 모두 활성화합니다.\n\n#install.packages(\"mirt\")\nlibrary(\"mirt\")\n\nLoading required package: stats4\n\n\nLoading required package: lattice\n\nlibrary(\"hemp\")\n\nLoading required package: psych\n\n\nLoading required package: lavaan\n\n\nThis is lavaan 0.6-16\nlavaan is FREE software! Please report any bugs.\n\n\n\nAttaching package: 'lavaan'\n\n\nThe following object is masked from 'package:psych':\n\n    cor2cov\n\n\nLoading required package: lme4\n\n\nLoading required package: Matrix\n\n\n\nAttaching package: 'lme4'\n\n\nThe following object is masked from 'package:mirt':\n\n    fixef\n\n\nLoading required package: reshape2\n\n\nLoading required package: boot\n\n\n\nAttaching package: 'boot'\n\n\nThe following object is masked from 'package:psych':\n\n    logit\n\n\nThe following object is masked from 'package:lattice':\n\n    melanoma\n\n\nLoading required package: equate\n\n\nSAPA 데이터 세트에 대해 mirt에서 1PL 모델을 정의하려면 mirt의 모델 구문을 사용하여 onepl_mod로 저장합니다.\n\nonepl_mod <- \"F = 1 - 16\nCONSTRAIN = (1 - 16, a1)\"\n\n이 코드의 첫 번째 줄은 SAPA 데이터 세트의 열 1~16에 있는 문항에 의해 단일 잠재 특성 F가 나타난다는 것을 나타냅니다. CONSTRAIN으로 시작하는 두 번째 줄은 열 1부터 16까지의 문항이 동일한 문항 변별도를 갖도록 제한합니다. mirt 패키지는 방정식 5.3에 표시된 것처럼 단일 차원 IRT 모델의 문항 변별도 모수를 a가 아닌 a1으로 레이블을 지정합니다. 1PL을 1 ~ 4열의 문항에만 맞추려면 1 - 16을 1 - 4로 변경하고, 1 ~ 3열, 5열, 9 ~ 16열의 문항을 사용하려면 1 - 3, 5, 9~16으로 정의하면 됩니다.\nmirt 패키지의 구문은 처음에는 조금 번거롭고 어려울 수 있습니다. 하지만 이 패키지는 다양한 IRT 모델(예: 다분 IRT 모델, 다차원 IRT 모델, 설명적 IRT 모델)4을 추정할 수 있으므로 IRT 모델 추정을 위해 이 패키지를 학습하는 것을 적극 권장합니다.\n다음으로, 위에서 정의한 모델을 사용하여 1PL 모델에 적합하고 SE = TRUE를 설정하여 문항 모수에 대한 표준 오차를 추정하도록 mirt 함수에 지시합니다. 적합된 모델을 onepl_fit에 저장합니다.\n\nonepl_fit <- mirt(data = SAPA, model = onepl_mod, SE = TRUE)\n\n\nIteration: 1, Log-Lik: -13494.679, Max-Change: 0.23406\nIteration: 2, Log-Lik: -13335.854, Max-Change: 0.12756\nIteration: 3, Log-Lik: -13292.524, Max-Change: 0.07878\nIteration: 4, Log-Lik: -13277.030, Max-Change: 0.05217\nIteration: 5, Log-Lik: -13270.789, Max-Change: 0.03431\nIteration: 6, Log-Lik: -13268.209, Max-Change: 0.02244\nIteration: 7, Log-Lik: -13266.529, Max-Change: 0.00847\nIteration: 8, Log-Lik: -13266.376, Max-Change: 0.00575\nIteration: 9, Log-Lik: -13266.308, Max-Change: 0.00382\nIteration: 10, Log-Lik: -13266.259, Max-Change: 0.00131\nIteration: 11, Log-Lik: -13266.255, Max-Change: 0.00084\nIteration: 12, Log-Lik: -13266.253, Max-Change: 0.00062\nIteration: 13, Log-Lik: -13266.251, Max-Change: 0.00017\nIteration: 14, Log-Lik: -13266.251, Max-Change: 0.00013\nIteration: 15, Log-Lik: -13266.251, Max-Change: 0.00009\n\nCalculating information matrix...\n\nonepl_params <- coef(onepl_fit, IRTpars = TRUE, simplify = TRUE)\n\nonepl_fit 개체에는 추정된 문항 모수, 잠재 특성의 평균, 잠재 특성의 분산-공분산 행렬 및 추정 프로세스와 관련된 추가 정보가 포함되어 있습니다. 모델 적합 후 추정된 모수와 잠재 특성의 평균 및 공분산 행렬을 coef 함수를 사용하여 추출하고 이를 onepl_params에 저장합니다. 이 단계에서 IRTpars = TRUE를 사용하여 기울기 및 절편 모수(mirt의 기본 모수화)를 기존 IRT 모수로 변환하고, simplify = TRUE를 사용하여 문항 모수를 긴 목록이 아닌 단일 데이터 프레임으로 결합했습니다. 절편 모수를 기존 문항 난이도 모수로 변환하는 방법은 다음 공식을 사용하여 수행할 수 있습니다.\n\\[\nb_i={-d_i \\over a1_i}\n\\]\n\n여기서 \\(d_i\\)는 절편 모수,\n\\(a1_i\\)는 기울기(즉, 변별도) 모수,\n\\(b_i\\)는 기존의 문항 난이도 모수입니다.\n\n\\(d_i\\)와 \\(b_i\\)의 주요 차이점은 \\(b_i\\)는 문항 난이도를 나타내는 반면, \\(d_i\\)는 문항 쉬움을 나타낸다는 점입니다.\n마지막으로, 추정된 문항 모수를 보다 간결하게 출력하기 위해 문항이 포함된 데이터 프레임을 onepl_items에 저장하고 head 함수를 사용하여 처음 6행을 확인합니다.\n\nonepl_items <- onepl_params$items\nhead(onepl_items)\n\n                 a          b g u\nreason.4  1.445587 -0.5557199 0 1\nreason.16 1.445587 -0.8020747 0 1\nreason.17 1.445587 -0.7980649 0 1\nreason.19 1.445587 -0.4546611 0 1\nletter.7  1.445587 -0.3923381 0 1\nletter.33 1.445587 -0.2810892 0 1\n\n\n각 행은 문항 이름으로 시작하며 열은 추정된 문항 모수에 해당합니다. 첫 번째 열(a)은 문항 변별도, 두 번째 열(b)은 문항 난이도, 세 번째 열(g)은 하부 점근값(즉, 추측도), 마지막 열(u)은 상부 점근값입니다. 1PL 모델에는 하한 및 상한 점근 모수가 포함되지 않으므로 마지막 두 열은 항상 각각 0과 1이 되므로 무시합니다. (하한 및 상한 점근 모수에 대한 자세한 내용은 3PL 및 4PL 모델 섹션의 뒷부분에서 설명합니다.) 첫 번째 열에는 1.446으로 추정된 문항 판별도 모수가 표시됩니다. 1PL 모델을 사용했기 때문에 문항 판별도 모수는 모든 문항에서 동일합니다. 두 번째 열에는 추정된 문항 난이도 모수가 표시됩니다. SAPA 데이터 세트에서 두 번째 문항(reason.16)은 가장 쉬운 문항이고 마지막 문항(rotate. 8)은 검사에서 가장 어려운 문항입니다.\n추정된 문항 모수에 대한 표준 오차를 확인하려면 printSE = TRUE 인수를 사용하여 coef 함수를 다시 실행해야 합니다. 아래에서 이 작업을 수행하고 name 함수를 사용하여 출력 내용을 인쇄합니다.\n\nonepl_se <- coef(onepl_fit, printSE = TRUE)\nnames(onepl_se)\n\n [1] \"reason.4\"  \"reason.16\" \"reason.17\" \"reason.19\" \"letter.7\"  \"letter.33\"\n [7] \"letter.34\" \"letter.58\" \"matrix.45\" \"matrix.46\" \"matrix.47\" \"matrix.55\"\n[13] \"rotate.3\"  \"rotate.4\"  \"rotate.6\"  \"rotate.8\"  \"GroupPars\"\n\n\nonepl_se 개체는 각 문항에 대한 정보를 개별적으로 포함하는 목록이라는 것을 알 수 있습니다. 가장 어려운 문항인 rotate.8에 대한 정보를 보려면 아래와 같이 $ 기호를 사용하여 추출할 수 있습니다.\n\nonepl_se$rotate.8\n\n            a1           d logit(g) logit(u)\npar 1.44558726 -2.00517306     -999      999\nSE  0.03612038  0.08517212       NA       NA\n\n\n첫 번째 행은 추정된 모수에 해당하고 두 번째 행은 표준 오차에 해당합니다. 첫 번째 열은 다시 문항 변별도에 해당하지만 두 번째 열은 더 이상 문항 난이도에 해당하지 않습니다(이제 b가 d가 됨). 문항 난이도에 대한 표준 오차가 필요한 독자의 경우 ltm 패키지(Rizopoulos, 2006)에서 이 정보를 제공합니다. -999, 999 및 NA는 모델에 대해 하한 및 상한 점근 모수가 추정되지 않았기 때문입니다.\nmirt 패키지는 다양한 문항 및 검사 특성을 나타내는 그래프에 대한 두 가지 함수, plot과 itemplot을 제공합니다. 이 함수는 사실 lattice 패키지의 xyplot 함수를 위한 래퍼 함수일 뿐입니다. 따라서 그래프를 사용자화하려면 xyplot 함수에 사용할 수 있는 모든 그래픽 인수(예: 색상 또는 선 유형 변경)를 사용할 수 있습니다(자세한 내용은 ?xyplot 참조).\n아래 예는 처음 두 문항에 대한 ICC를 만드는 방법을 보여줍니다. 그림 5.5에서 ICC의 x축은 잠재 특성(\\(\\theta\\))을 나타내며, SAPA 데이터 세트의 경우 지능 또는 적성으로 간주될 수 있고, ICC의 y축은 해당 문항에 정답할 확률인 \\(P(\\theta)\\)를 나타냅니다. 1PL 모델은 변별도 모수가 모든 문항에서 동일하도록 제약하기 때문에 ICC의 기울기는 동일하지만 문항 난이도 모수는 X축을 따라 이동합니다.\n\nplot(onepl_fit, type = \"trace\", which.items = 1:2)\n\n\n\n\n위에 제시된 코드를 실행하면 그래프는 컬러로 표시되지만 여기서는 회색조로 표시된다는 점을 독자들에게 상기시키고자 합니다.\nICC를 만드는 다른 방법은 itemplot 함수를 사용하는 것입니다. 다음 예제에서는 처음 두 문항에 itemplot 함수를 다시 사용합니다.\n\nitemplot(onepl_fit, type = \"trace\", item = 1)\n\n\n\nitemplot(onepl_fit, type = \"trace\", item = 2)\n\n\n\n\n잠재 특성의 함수로 문항 정보의 양을 표시하는 문항 정보 그래프도 plot 함수를 사용하여 쉽게 만들 수 있습니다. 아래에서는 SAPA 데이터 세트의 세 번째 및 다섯 번째 문항에 대한 IIF를 그리는 방법을 보여줍니다(그림 5.6 참조).\n\nplot(onepl_fit, type = \"infotrace\", which.items = c(3, 5))\n\n\n\n\n그림 5.5와 그림 5.6에서는 문항에 대해 ICC와 IIF가 개별적으로 그려져 있습니다. facet_items = FALSE 인수를 사용하여 단일 그래프 내에서 두 문항의 그래프를 결합할 수 있습니다. 다음 예에서는 문항 1과 2의 ICC 그래프를 함께 결합합니다. 또한 auto.key = list(points = FALSE, lines = TRUE, columns = 2) 및 par.settings = simpleTheme(lty = 1:2)를 설정하여 각 ICC의 선 유형을 구분하고 문항을 나타내는 두 열 범례를 그립니다. 그림 5.7은 문항 1(실선)과 문항 2(점선)에 대한 결합된 ICC를 보여줍니다.\n\nplot(onepl_fit, type = \"trace\", which.items = 1:2, \n     facet_items = FALSE, auto.key = list(points = FALSE, lines = TRUE, columns = 2), \n     par.settings = simpleTheme(lty = 1:2))\n\n\n\n\nICC 및 IIF 외에도 TIF 그래프와 cSEM 그래프를 만들 수도 있습니다. 다음 예에서는 능력 범위(-3 ~ 3)를 지정하고 1PL SAPA 모델에 대해 결합된 TIF 및 cSEM 그래프를 만드는 방법을 보여 줍니다.\n\nplot(onepl_fit, type = \"infoSE\", theta_lim = c(-3, 3))\n\n\n\n\n그림 5.8은 SAPA 데이터 세트의 문항이 매우 유익하며 \\(\\theta\\) = -1 에서 \\(\\theta\\) = 1 사이의 측정 오차가 가장 적다는 것을 보여줍니다. 또한 plot 함수의 type = “info” 및 type = “SE” 인수를 사용하여 별도의 TIF 및 cSEM 그래프를 만들 수도 있습니다.\n\nplot(onepl_fit, type = \"info\", theta_lim = c(-3, 3))\n\n\n\nplot(onepl_fit, type = \"SE\", theta_lim = c(-3, 3))\n\n\n\n\n\n\n5.3.1.2 Rasch 모델\nRasch 모델(Rasch, 1960)은 모든 문항에 대해 문항 변별도가 1로 설정된 1PL 모델의 특정 형태입니다. 이러한 조정의 결과로 문항에 정답할 확률은 문항의 난이도와 잠재 특성만 고려한 함수가 됩니다. 수학적으로 Rasch 모델은 다음과 같이 작성할 수 있습니다.\n\\[\nP(Y_{ij}=1|\\theta_j, b_i) = {exp(D(\\theta_j-b_i)) \\over 1+exp(D(\\theta_j-b_i))}\n\\]\n여기서 모든 구성 요소는 공통 문항 변별도 모수를 제외한 모든 구성 요소가 1PL 모델과 동일하며, 모든 문항에 대해 a = 1이므로 생략할 수 있습니다.5\n문항 변별도 모수는 문항의 정답 확률에 영향을 미치지 않으므로 간단한 설명을 통해 문항 난이도와 잠재 특성 간의 관계를 설명할 수 있습니다. 피험자의 잠재 특성 수준이 문항의 난이도와 일치하는 경우, 피험자는 해당 문항을 정답으로 맞힐 확률이 50%입니다(추측도가 포함되지 않았다고 가정할 경우). Rasch 모델에서는 어떤 문항 난이도 위치를 사용했는지에 관계없이 피험자의 예상 응답 순서가 동일하게 정해집니다. 마찬가지로, 문항은 어떤 수준의 잠재 특성을 고려하든 예측된 응답의 측면에서 동일하게 정렬됩니다.\nRasch 모델을 설명하기 위해 다시 SAPA 데이터 세트를 사용합니다. 1PL 모델과 달리 Rasch 모델 구문에는 CONSTRAIN 명령이 필요하지 않습니다. 대신 mirt 함수에 itemtype = “Rasch”를 지정하여 Rasch 모델에 따라 문항 모수를 추정하고 적합 모델을 rasch_fit에 저장합니다.\n\nrasch_mod <- \"F = 1 - 16\"\nrasch_fit <- mirt(data = SAPA, model = rasch_mod, \n                  itemtype = \"Rasch\", SE = TRUE)\n\n\nIteration: 1, Log-Lik: -13381.676, Max-Change: 0.37122\nIteration: 2, Log-Lik: -13304.782, Max-Change: 0.28795\nIteration: 3, Log-Lik: -13277.916, Max-Change: 0.18828\nIteration: 4, Log-Lik: -13269.602, Max-Change: 0.11075\nIteration: 5, Log-Lik: -13267.193, Max-Change: 0.06135\nIteration: 6, Log-Lik: -13266.517, Max-Change: 0.03290\nIteration: 7, Log-Lik: -13266.327, Max-Change: 0.01775\nIteration: 8, Log-Lik: -13266.276, Max-Change: 0.00886\nIteration: 9, Log-Lik: -13266.262, Max-Change: 0.00459\nIteration: 10, Log-Lik: -13266.257, Max-Change: 0.00243\nIteration: 11, Log-Lik: -13266.256, Max-Change: 0.00120\nIteration: 12, Log-Lik: -13266.255, Max-Change: 0.00063\nIteration: 13, Log-Lik: -13266.255, Max-Change: 0.00034\nIteration: 14, Log-Lik: -13266.255, Max-Change: 0.00016\nIteration: 15, Log-Lik: -13266.255, Max-Change: 0.00009\n\nCalculating information matrix...\n\n\n앞서 1PL 모델에 대해 수행한 것처럼 coef 함수를 사용하여 추정된 문항 모수를 추출하고, 이를 저장하고(rasch_params), 문항 모수를 데이터 프레임으로 추출한 다음(rasch_items), 마지막으로 head 함수를 사용하여 처음 6개의 행을 출력할 수 있습니다.\n\nrasch_params <- coef(rasch_fit, IRTpars = TRUE, simplify = TRUE)\nrasch_items <- rasch_params$items\nhead(rasch_items)\n\n          a          b g u\nreason.4  1 -0.8024508 0 1\nreason.16 1 -1.1585583 0 1\nreason.17 1 -1.1527651 0 1\nreason.19 1 -0.6563678 0 1\nletter.7  1 -0.5662859 0 1\nletter.33 1 -0.4054796 0 1\n\n\n결과에서 첫 번째 열(즉, 문항 변별도)은 Rasch 모델의 모든 문항에 대해 1이지만, 1PL 모델의 모든 문항에 대해 문항 변별도는 1.446으로 추정되었습니다. 두 번째 열은 문항 변별도 외에도 Rasch 모델의 문항 난이도 모수가 1PL 모델의 문항 난이도 모수와 다르다는 것을 나타냅니다.\n1PL과 마찬가지로 Rasch 모델에 대한 ICC를 그래프로 그릴 수 있습니다. Rasch 모델의 결과에 따르면, 문항 2(reason.16)가 가장 쉬운 문항이고 문항 16(rotate.8)이 SAPA 데이터 세트에서 가장 어려운 문항입니다. 이는 1PL 모델에서 가장 쉬운 문항과 가장 어려운 문항으로 식별된 것과 동일한 문항입니다. 아래에는 이 두 문항에 대한 ICC가 표시되어 있습니다(그림 5.9 참조).\n\nplot(rasch_fit, type = \"trace\", which.items = c(2, 16))\n\n\n\n\nRasch 모델은 모든 문항에 대해 문항 변별도 모수가 1이라고 가정하기 때문에 그림 5.5에 제시된 것보다 그림 5.9의 ICC가 덜 가파르다는 점에 유의하십시오. 그림 5.9는 잠재 특성에서 낮은 능력을 가진 피험자도 문항 2를 정답으로 맞힐 확률이 높은 반면, 문항 16은 적어도 \\(\\theta = 2\\) 이상의 높은 능력을 가진 피험자만 정답으로 맞힐 확률이 50%라는 것을 보여줍니다. 1PL 모델에 대해 설명한 것처럼 Rasch 모델에 대해서도 유사한 방식으로 IIF와 TIF를 생성할 수 있습니다. 독자들이 연습할 수 있도록 남겨두겠습니다.\n\n\n\n5.3.2 2모수 로지스틱 모델\n2모수 로지스틱(2PL) 모델은 1PL 및 Rasch 모델보다 유연한 형태입니다. 2PL 모델에서는 각 문항이 고유한 문항 변별도 모수를 가질 수 있습니다. 2PL 모델의 수학적 공식은 다음과 같습니다.\n\\[\nP(Y_{ij}=1|\\theta_j, a_i, b_i) = {exp(Da_i(\\theta_j-b_i)) \\over 1+exp(Da_i(\\theta_j-b_i))}\n\\]\n여기서 모수는 위 방정식 5.3에 대해 설명한 것과 동일하지만 \\(a_i\\)가 문항 \\(i\\)에 대한 유일한 변별도 모수라는 점을 제외하면 동일합니다.\n다음 예에서는 2PL 모델을 사용하여 SAPA 데이터 세트의 문항 모수를 추정합니다. 2PL 모델을 추정하는 모델 구문은 Rasch 모델과 동일한 방식입니다. 유일한 차이점은 mirt 함수를 호출할 때입니다. 이번에는 2PL 모델을 추정하기 위해 itemtype = “2PL” 인수를 전달해야 합니다. 이전과 마찬가지로, 적합 모델을 저장하고(twopl_fit), 모델 모수를 추출하고(twopl_params), 모든 문항에 대한 문항 모수를 출력합니다.\n\ntwopl_mod <- \"F = 1 - 16\"\ntwopl_fit <- mirt(data = SAPA, model = twopl_mod, \n                  itemtype = \"2PL\", SE = TRUE)\n\n\nIteration: 1, Log-Lik: -13494.679, Max-Change: 0.53899\nIteration: 2, Log-Lik: -13284.214, Max-Change: 0.25237\nIteration: 3, Log-Lik: -13231.691, Max-Change: 0.16517\nIteration: 4, Log-Lik: -13213.028, Max-Change: 0.10162\nIteration: 5, Log-Lik: -13205.997, Max-Change: 0.07336\nIteration: 6, Log-Lik: -13202.832, Max-Change: 0.04558\nIteration: 7, Log-Lik: -13201.628, Max-Change: 0.02752\nIteration: 8, Log-Lik: -13200.891, Max-Change: 0.02268\nIteration: 9, Log-Lik: -13200.619, Max-Change: 0.01424\nIteration: 10, Log-Lik: -13200.449, Max-Change: 0.00438\nIteration: 11, Log-Lik: -13200.420, Max-Change: 0.00306\nIteration: 12, Log-Lik: -13200.407, Max-Change: 0.00227\nIteration: 13, Log-Lik: -13200.397, Max-Change: 0.00068\nIteration: 14, Log-Lik: -13200.397, Max-Change: 0.00031\nIteration: 15, Log-Lik: -13200.397, Max-Change: 0.00083\nIteration: 16, Log-Lik: -13200.396, Max-Change: 0.00032\nIteration: 17, Log-Lik: -13200.396, Max-Change: 0.00072\nIteration: 18, Log-Lik: -13200.396, Max-Change: 0.00027\nIteration: 19, Log-Lik: -13200.396, Max-Change: 0.00024\nIteration: 20, Log-Lik: -13200.396, Max-Change: 0.00012\nIteration: 21, Log-Lik: -13200.396, Max-Change: 0.00032\nIteration: 22, Log-Lik: -13200.396, Max-Change: 0.00013\nIteration: 23, Log-Lik: -13200.396, Max-Change: 0.00029\nIteration: 24, Log-Lik: -13200.396, Max-Change: 0.00011\nIteration: 25, Log-Lik: -13200.396, Max-Change: 0.00009\n\nCalculating information matrix...\n\ntwopl_params <- coef(twopl_fit, IRTpars = TRUE, simplify = TRUE)\ntwopl_items <- twopl_params$items\ntwopl_items\n\n                  a          b g u\nreason.4  1.6924256 -0.5127258 0 1\nreason.16 1.4616058 -0.7967194 0 1\nreason.17 1.8568189 -0.7052519 0 1\nreason.19 1.4429276 -0.4544282 0 1\nletter.7  1.5739581 -0.3749607 0 1\nletter.33 1.3512472 -0.2906578 0 1\nletter.34 1.6568903 -0.4165187 0 1\nletter.58 1.4637541  0.2090402 0 1\nmatrix.45 1.0649705 -0.1241352 0 1\nmatrix.46 1.1060157 -0.2292152 0 1\nmatrix.47 1.3463316 -0.4666121 0 1\nmatrix.55 0.8786048  0.6793708 0 1\nrotate.3  1.7878172  1.1986461 0 1\nrotate.4  2.0841977  1.0317428 0 1\nrotate.6  1.6388551  0.7524753 0 1\nrotate.8  1.5855260  1.3201267 0 1\n\n\n2PL 모델의 결과에서 문항 변별도(첫 번째 열)와 난이도(두 번째 열) 모수는 각 문항마다 다릅니다. item 14(rotate.4)의 문항 변별도가 가장 높은 반면(2.084), item 12(matrix.55)의 문항 변별도가 가장 낮습니다. 다음으로, plot 함수를 사용하여 ICC 그래프로 이 두 문항의 차이를 시각적으로 살펴봅니다.\n\nplot(twopl_fit, type = \"trace\", which.items = c(12, 14))\n\n\n\n\n그림 5.10은 문항 변별도 모수의 차이로 인해 rotate.4(오른쪽)의 기울기가 matrix.55(왼쪽)의 기울기보다 훨씬 가파르다는 것을 보여줍니다. 이 차이는 2PL 모델을 사용하여 문항 모수를 추정할 때 item 14(rotate.4)가 item 12(matrix.55)보다 잠재 특성이 낮은 피험자와 높은 피험자를 더 잘 구분할 수 있음을 시사합니다.\n또한 난이도 모수는 다르지만 변별도가 비슷한 문항에 대한 ICC를 비교할 수도 있습니다. 예를 들어, SAPA 데이터 세트에서 item 5(letter.7)와 item 16(rotate.8)은 문항 변별도 모수가 비슷하지만 난이도 측면에서 차이가 있습니다. 아래 표시된 코드를 사용하여 생성된 그림 5.11은 추정된 잠재 특성 수준 \\(\\theta = 0\\)에서 letter.7(더 쉬운 문항)을 정답할 확률은 거의 0.7이지만 rotate.8(더 어려운 문항)을 정답할 확률은 0.1에 불과하다는 것을 보여줍니다.\n\nplot(twopl_fit, type = \"trace\", which.items = c(5, 16),\n     facet_items = FALSE, \n     auto.key = list(points = FALSE, \n                     lines = TRUE, columns = 2), \n     par.settings = simpleTheme(lty = 1:2))\n\n\n\n\n\n\n5.3.3 3모수 로지스틱 모델\n3모수 로지스틱(3PL) 모델은 2PL 모델의 확장에 불과합니다. 이 모델에는 2PL 모델과 동일한 문항 모수(예: \\(a_i\\) 및 \\(b_i\\))와 우연 또는 추측만으로 문항을 지지할 가능성을 나타내는 추가 모수(\\(c_i\\))가 포함됩니다. \\(c_i\\) 모수는 하부 점근 또는 의사 추측도 모수라고 합니다. 3PL 모델은 다음과 같이 작성할 수 있습니다.\n\\[\nP(Y_{ij}=1|\\theta_j, a_i, b_i, c_i) = c_i + {1-c_i \\over 1+exp(-Da_i(\\theta_j-b_i))}\n\\]\nRasch, 1PL 및 2PL 모델과 달리 3PL 모델에서의 정답 확률은 잠재 특성이 \\(-\\infty\\)로 이동함에 따라 0에 가까워지지 않습니다. 대신 확률은 양수 값에 가까워집니다(일반적으로 \\(1/k\\), 여기서 \\(k\\)는 선다형 문항의 반응 범주 수). \\(c_i\\) 모수를 포함하는 이유는 잠재 특성이 매우 낮은 일부 피험자는 응답 옵션을 무작위로 선택할 가능성이 높기 때문에 무작위 추측을 하면 \\(c_i\\)와 같은 확률로 정답을 선택할 수 있기 때문입니다.\n다음 예에서는 3PL 모델을 사용하여 SAPA 데이터 세트에 대한 문항 모수를 추정합니다. 모델을 맞출 때 itemtype = “3PL” 인수를 지정하여 3PL 모델을 추정합니다. 아래에서는 적합 모델을 정의, 적합 및 저장하고, 모수를 추출하고, 문항 모수의 처음 몇 행을 출력합니다.\n\nthreepl_mod <- \"F = 1-16\"\nthreepl_fit <- mirt(data = SAPA, model = threepl_mod, \n                    itemtype = \"3PL\", SE = TRUE)\n\n\nIteration: 1, Log-Lik: -13980.085, Max-Change: 3.07860\nIteration: 2, Log-Lik: -13349.993, Max-Change: 1.58321\nIteration: 3, Log-Lik: -13250.082, Max-Change: 0.63745\nIteration: 4, Log-Lik: -13193.936, Max-Change: 0.60611\nIteration: 5, Log-Lik: -13162.424, Max-Change: 0.46102\nIteration: 6, Log-Lik: -13145.533, Max-Change: 0.46319\nIteration: 7, Log-Lik: -13135.526, Max-Change: 0.43833\nIteration: 8, Log-Lik: -13129.722, Max-Change: 0.39049\nIteration: 9, Log-Lik: -13126.097, Max-Change: 0.23341\nIteration: 10, Log-Lik: -13123.127, Max-Change: 0.11726\nIteration: 11, Log-Lik: -13121.920, Max-Change: 0.10081\nIteration: 12, Log-Lik: -13121.459, Max-Change: 1.08910\nIteration: 13, Log-Lik: -13120.941, Max-Change: 0.09246\nIteration: 14, Log-Lik: -13120.755, Max-Change: 0.28264\nIteration: 15, Log-Lik: -13120.632, Max-Change: 0.06058\nIteration: 16, Log-Lik: -13120.609, Max-Change: 0.02914\nIteration: 17, Log-Lik: -13120.555, Max-Change: 0.02525\nIteration: 18, Log-Lik: -13120.515, Max-Change: 0.00717\nIteration: 19, Log-Lik: -13120.508, Max-Change: 0.00664\nIteration: 20, Log-Lik: -13120.464, Max-Change: 0.02348\nIteration: 21, Log-Lik: -13120.442, Max-Change: 0.00521\nIteration: 22, Log-Lik: -13120.440, Max-Change: 0.00508\nIteration: 23, Log-Lik: -13120.428, Max-Change: 0.00501\nIteration: 24, Log-Lik: -13120.413, Max-Change: 0.00326\nIteration: 25, Log-Lik: -13120.405, Max-Change: 0.00246\nIteration: 26, Log-Lik: -13120.400, Max-Change: 0.00239\nIteration: 27, Log-Lik: -13120.395, Max-Change: 0.00315\nIteration: 28, Log-Lik: -13120.385, Max-Change: 0.00138\nIteration: 29, Log-Lik: -13120.382, Max-Change: 0.00119\nIteration: 30, Log-Lik: -13120.381, Max-Change: 0.00105\nIteration: 31, Log-Lik: -13120.378, Max-Change: 0.00225\nIteration: 32, Log-Lik: -13120.377, Max-Change: 0.00108\nIteration: 33, Log-Lik: -13120.376, Max-Change: 0.00133\nIteration: 34, Log-Lik: -13120.375, Max-Change: 0.00064\nIteration: 35, Log-Lik: -13120.374, Max-Change: 0.00069\nIteration: 36, Log-Lik: -13120.374, Max-Change: 0.00061\nIteration: 37, Log-Lik: -13120.374, Max-Change: 0.00135\nIteration: 38, Log-Lik: -13120.374, Max-Change: 0.00035\nIteration: 39, Log-Lik: -13120.374, Max-Change: 0.00084\nIteration: 40, Log-Lik: -13120.373, Max-Change: 0.00047\nIteration: 41, Log-Lik: -13120.373, Max-Change: 0.00122\nIteration: 42, Log-Lik: -13120.373, Max-Change: 0.00033\nIteration: 43, Log-Lik: -13120.373, Max-Change: 0.00029\nIteration: 44, Log-Lik: -13120.373, Max-Change: 0.00071\nIteration: 45, Log-Lik: -13120.373, Max-Change: 0.00116\nIteration: 46, Log-Lik: -13120.373, Max-Change: 0.00077\nIteration: 47, Log-Lik: -13120.373, Max-Change: 0.00024\nIteration: 48, Log-Lik: -13120.373, Max-Change: 0.00064\nIteration: 49, Log-Lik: -13120.373, Max-Change: 0.00029\nIteration: 50, Log-Lik: -13120.373, Max-Change: 0.00072\nIteration: 51, Log-Lik: -13120.373, Max-Change: 0.00022\nIteration: 52, Log-Lik: -13120.373, Max-Change: 0.00099\nIteration: 53, Log-Lik: -13120.373, Max-Change: 0.00028\nIteration: 54, Log-Lik: -13120.373, Max-Change: 0.00069\nIteration: 55, Log-Lik: -13120.373, Max-Change: 0.00037\nIteration: 56, Log-Lik: -13120.373, Max-Change: 0.00096\nIteration: 57, Log-Lik: -13120.373, Max-Change: 0.00027\nIteration: 58, Log-Lik: -13120.373, Max-Change: 0.00024\nIteration: 59, Log-Lik: -13120.373, Max-Change: 0.00060\nIteration: 60, Log-Lik: -13120.373, Max-Change: 0.00091\nIteration: 61, Log-Lik: -13120.373, Max-Change: 0.00059\nIteration: 62, Log-Lik: -13120.373, Max-Change: 0.00088\nIteration: 63, Log-Lik: -13120.373, Max-Change: 0.00025\nIteration: 64, Log-Lik: -13120.373, Max-Change: 0.00022\nIteration: 65, Log-Lik: -13120.373, Max-Change: 0.00056\nIteration: 66, Log-Lik: -13120.372, Max-Change: 0.00084\nIteration: 67, Log-Lik: -13120.372, Max-Change: 0.00056\nIteration: 68, Log-Lik: -13120.372, Max-Change: 0.00082\nIteration: 69, Log-Lik: -13120.372, Max-Change: 0.00024\nIteration: 70, Log-Lik: -13120.372, Max-Change: 0.00021\nIteration: 71, Log-Lik: -13120.372, Max-Change: 0.00053\nIteration: 72, Log-Lik: -13120.372, Max-Change: 0.00079\nIteration: 73, Log-Lik: -13120.372, Max-Change: 0.00054\nIteration: 74, Log-Lik: -13120.372, Max-Change: 0.00079\nIteration: 75, Log-Lik: -13120.372, Max-Change: 0.00023\nIteration: 76, Log-Lik: -13120.372, Max-Change: 0.00020\nIteration: 77, Log-Lik: -13120.372, Max-Change: 0.00051\nIteration: 78, Log-Lik: -13120.372, Max-Change: 0.00075\nIteration: 79, Log-Lik: -13120.372, Max-Change: 0.00052\nIteration: 80, Log-Lik: -13120.372, Max-Change: 0.00077\nIteration: 81, Log-Lik: -13120.372, Max-Change: 0.00022\nIteration: 82, Log-Lik: -13120.372, Max-Change: 0.00020\nIteration: 83, Log-Lik: -13120.372, Max-Change: 0.00050\nIteration: 84, Log-Lik: -13120.372, Max-Change: 0.00073\nIteration: 85, Log-Lik: -13120.372, Max-Change: 0.00051\nIteration: 86, Log-Lik: -13120.372, Max-Change: 0.00075\nIteration: 87, Log-Lik: -13120.372, Max-Change: 0.00022\nIteration: 88, Log-Lik: -13120.372, Max-Change: 0.00019\nIteration: 89, Log-Lik: -13120.372, Max-Change: 0.00049\nIteration: 90, Log-Lik: -13120.372, Max-Change: 0.00072\nIteration: 91, Log-Lik: -13120.372, Max-Change: 0.00050\nIteration: 92, Log-Lik: -13120.372, Max-Change: 0.00074\nIteration: 93, Log-Lik: -13120.372, Max-Change: 0.00021\nIteration: 94, Log-Lik: -13120.372, Max-Change: 0.00019\nIteration: 95, Log-Lik: -13120.372, Max-Change: 0.00048\nIteration: 96, Log-Lik: -13120.372, Max-Change: 0.00070\nIteration: 97, Log-Lik: -13120.372, Max-Change: 0.00050\nIteration: 98, Log-Lik: -13120.372, Max-Change: 0.00072\nIteration: 99, Log-Lik: -13120.372, Max-Change: 0.00021\nIteration: 100, Log-Lik: -13120.372, Max-Change: 0.00019\nIteration: 101, Log-Lik: -13120.372, Max-Change: 0.00047\nIteration: 102, Log-Lik: -13120.372, Max-Change: 0.00069\nIteration: 103, Log-Lik: -13120.372, Max-Change: 0.00049\nIteration: 104, Log-Lik: -13120.372, Max-Change: 0.00071\nIteration: 105, Log-Lik: -13120.372, Max-Change: 0.00021\nIteration: 106, Log-Lik: -13120.372, Max-Change: 0.00018\nIteration: 107, Log-Lik: -13120.372, Max-Change: 0.00047\nIteration: 108, Log-Lik: -13120.372, Max-Change: 0.00068\nIteration: 109, Log-Lik: -13120.372, Max-Change: 0.00048\nIteration: 110, Log-Lik: -13120.372, Max-Change: 0.00070\nIteration: 111, Log-Lik: -13120.372, Max-Change: 0.00020\nIteration: 112, Log-Lik: -13120.372, Max-Change: 0.00018\nIteration: 113, Log-Lik: -13120.372, Max-Change: 0.00046\nIteration: 114, Log-Lik: -13120.372, Max-Change: 0.00067\nIteration: 115, Log-Lik: -13120.372, Max-Change: 0.00047\nIteration: 116, Log-Lik: -13120.372, Max-Change: 0.00069\nIteration: 117, Log-Lik: -13120.372, Max-Change: 0.00020\nIteration: 118, Log-Lik: -13120.372, Max-Change: 0.00018\nIteration: 119, Log-Lik: -13120.372, Max-Change: 0.00045\nIteration: 120, Log-Lik: -13120.372, Max-Change: 0.00066\nIteration: 121, Log-Lik: -13120.372, Max-Change: 0.00047\nIteration: 122, Log-Lik: -13120.372, Max-Change: 0.00068\nIteration: 123, Log-Lik: -13120.371, Max-Change: 0.00020\nIteration: 124, Log-Lik: -13120.371, Max-Change: 0.00018\nIteration: 125, Log-Lik: -13120.371, Max-Change: 0.00045\nIteration: 126, Log-Lik: -13120.371, Max-Change: 0.00065\nIteration: 127, Log-Lik: -13120.371, Max-Change: 0.00046\nIteration: 128, Log-Lik: -13120.371, Max-Change: 0.00068\nIteration: 129, Log-Lik: -13120.371, Max-Change: 0.00020\nIteration: 130, Log-Lik: -13120.371, Max-Change: 0.00017\nIteration: 131, Log-Lik: -13120.371, Max-Change: 0.00044\nIteration: 132, Log-Lik: -13120.371, Max-Change: 0.00064\nIteration: 133, Log-Lik: -13120.371, Max-Change: 0.00046\nIteration: 134, Log-Lik: -13120.371, Max-Change: 0.00067\nIteration: 135, Log-Lik: -13120.371, Max-Change: 0.00019\nIteration: 136, Log-Lik: -13120.371, Max-Change: 0.00017\nIteration: 137, Log-Lik: -13120.371, Max-Change: 0.00044\nIteration: 138, Log-Lik: -13120.371, Max-Change: 0.00064\nIteration: 139, Log-Lik: -13120.371, Max-Change: 0.00045\nIteration: 140, Log-Lik: -13120.371, Max-Change: 0.00066\nIteration: 141, Log-Lik: -13120.371, Max-Change: 0.00019\nIteration: 142, Log-Lik: -13120.371, Max-Change: 0.00017\nIteration: 143, Log-Lik: -13120.371, Max-Change: 0.00043\nIteration: 144, Log-Lik: -13120.371, Max-Change: 0.00063\nIteration: 145, Log-Lik: -13120.371, Max-Change: 0.00045\nIteration: 146, Log-Lik: -13120.371, Max-Change: 0.00065\nIteration: 147, Log-Lik: -13120.371, Max-Change: 0.00019\nIteration: 148, Log-Lik: -13120.371, Max-Change: 0.00017\nIteration: 149, Log-Lik: -13120.371, Max-Change: 0.00043\nIteration: 150, Log-Lik: -13120.371, Max-Change: 0.00062\nIteration: 151, Log-Lik: -13120.371, Max-Change: 0.00044\nIteration: 152, Log-Lik: -13120.371, Max-Change: 0.00065\nIteration: 153, Log-Lik: -13120.371, Max-Change: 0.00019\nIteration: 154, Log-Lik: -13120.371, Max-Change: 0.00017\nIteration: 155, Log-Lik: -13120.371, Max-Change: 0.00042\nIteration: 156, Log-Lik: -13120.371, Max-Change: 0.00062\nIteration: 157, Log-Lik: -13120.371, Max-Change: 0.00044\nIteration: 158, Log-Lik: -13120.371, Max-Change: 0.00064\nIteration: 159, Log-Lik: -13120.371, Max-Change: 0.00019\nIteration: 160, Log-Lik: -13120.371, Max-Change: 0.00017\nIteration: 161, Log-Lik: -13120.371, Max-Change: 0.00042\nIteration: 162, Log-Lik: -13120.371, Max-Change: 0.00061\nIteration: 163, Log-Lik: -13120.371, Max-Change: 0.00044\nIteration: 164, Log-Lik: -13120.371, Max-Change: 0.00064\nIteration: 165, Log-Lik: -13120.371, Max-Change: 0.00018\nIteration: 166, Log-Lik: -13120.371, Max-Change: 0.00016\nIteration: 167, Log-Lik: -13120.371, Max-Change: 0.00042\nIteration: 168, Log-Lik: -13120.371, Max-Change: 0.00061\nIteration: 169, Log-Lik: -13120.371, Max-Change: 0.00043\nIteration: 170, Log-Lik: -13120.371, Max-Change: 0.00063\nIteration: 171, Log-Lik: -13120.371, Max-Change: 0.00018\nIteration: 172, Log-Lik: -13120.371, Max-Change: 0.00016\nIteration: 173, Log-Lik: -13120.371, Max-Change: 0.00041\nIteration: 174, Log-Lik: -13120.371, Max-Change: 0.00060\nIteration: 175, Log-Lik: -13120.371, Max-Change: 0.00043\nIteration: 176, Log-Lik: -13120.371, Max-Change: 0.00063\nIteration: 177, Log-Lik: -13120.371, Max-Change: 0.00018\nIteration: 178, Log-Lik: -13120.371, Max-Change: 0.00016\nIteration: 179, Log-Lik: -13120.371, Max-Change: 0.00041\nIteration: 180, Log-Lik: -13120.371, Max-Change: 0.00060\nIteration: 181, Log-Lik: -13120.371, Max-Change: 0.00043\nIteration: 182, Log-Lik: -13120.371, Max-Change: 0.00062\nIteration: 183, Log-Lik: -13120.371, Max-Change: 0.00018\nIteration: 184, Log-Lik: -13120.371, Max-Change: 0.00016\nIteration: 185, Log-Lik: -13120.371, Max-Change: 0.00041\nIteration: 186, Log-Lik: -13120.371, Max-Change: 0.00059\nIteration: 187, Log-Lik: -13120.371, Max-Change: 0.00042\nIteration: 188, Log-Lik: -13120.371, Max-Change: 0.00062\nIteration: 189, Log-Lik: -13120.371, Max-Change: 0.00018\nIteration: 190, Log-Lik: -13120.371, Max-Change: 0.00016\nIteration: 191, Log-Lik: -13120.371, Max-Change: 0.00040\nIteration: 192, Log-Lik: -13120.371, Max-Change: 0.00059\nIteration: 193, Log-Lik: -13120.371, Max-Change: 0.00042\nIteration: 194, Log-Lik: -13120.371, Max-Change: 0.00061\nIteration: 195, Log-Lik: -13120.371, Max-Change: 0.00018\nIteration: 196, Log-Lik: -13120.371, Max-Change: 0.00016\nIteration: 197, Log-Lik: -13120.370, Max-Change: 0.00040\nIteration: 198, Log-Lik: -13120.370, Max-Change: 0.00058\nIteration: 199, Log-Lik: -13120.370, Max-Change: 0.00042\nIteration: 200, Log-Lik: -13120.370, Max-Change: 0.00061\nIteration: 201, Log-Lik: -13120.370, Max-Change: 0.00018\nIteration: 202, Log-Lik: -13120.370, Max-Change: 0.00016\nIteration: 203, Log-Lik: -13120.370, Max-Change: 0.00040\nIteration: 204, Log-Lik: -13120.370, Max-Change: 0.00058\nIteration: 205, Log-Lik: -13120.370, Max-Change: 0.00042\nIteration: 206, Log-Lik: -13120.370, Max-Change: 0.00060\nIteration: 207, Log-Lik: -13120.370, Max-Change: 0.00018\nIteration: 208, Log-Lik: -13120.370, Max-Change: 0.00016\nIteration: 209, Log-Lik: -13120.370, Max-Change: 0.00040\nIteration: 210, Log-Lik: -13120.370, Max-Change: 0.00058\nIteration: 211, Log-Lik: -13120.370, Max-Change: 0.00041\nIteration: 212, Log-Lik: -13120.370, Max-Change: 0.00060\nIteration: 213, Log-Lik: -13120.370, Max-Change: 0.00017\nIteration: 214, Log-Lik: -13120.370, Max-Change: 0.00015\nIteration: 215, Log-Lik: -13120.370, Max-Change: 0.00039\nIteration: 216, Log-Lik: -13120.370, Max-Change: 0.00057\nIteration: 217, Log-Lik: -13120.370, Max-Change: 0.00041\nIteration: 218, Log-Lik: -13120.370, Max-Change: 0.00060\nIteration: 219, Log-Lik: -13120.370, Max-Change: 0.00017\nIteration: 220, Log-Lik: -13120.370, Max-Change: 0.00015\nIteration: 221, Log-Lik: -13120.370, Max-Change: 0.00039\nIteration: 222, Log-Lik: -13120.370, Max-Change: 0.00057\nIteration: 223, Log-Lik: -13120.370, Max-Change: 0.00041\nIteration: 224, Log-Lik: -13120.370, Max-Change: 0.00060\nIteration: 225, Log-Lik: -13120.370, Max-Change: 0.00017\nIteration: 226, Log-Lik: -13120.370, Max-Change: 0.00015\nIteration: 227, Log-Lik: -13120.370, Max-Change: 0.00039\nIteration: 228, Log-Lik: -13120.370, Max-Change: 0.00057\nIteration: 229, Log-Lik: -13120.370, Max-Change: 0.00041\nIteration: 230, Log-Lik: -13120.370, Max-Change: 0.00059\nIteration: 231, Log-Lik: -13120.370, Max-Change: 0.00017\nIteration: 232, Log-Lik: -13120.370, Max-Change: 0.00015\nIteration: 233, Log-Lik: -13120.370, Max-Change: 0.00039\nIteration: 234, Log-Lik: -13120.370, Max-Change: 0.00057\nIteration: 235, Log-Lik: -13120.370, Max-Change: 0.00041\nIteration: 236, Log-Lik: -13120.370, Max-Change: 0.00059\nIteration: 237, Log-Lik: -13120.370, Max-Change: 0.00017\nIteration: 238, Log-Lik: -13120.370, Max-Change: 0.00015\nIteration: 239, Log-Lik: -13120.370, Max-Change: 0.00039\nIteration: 240, Log-Lik: -13120.370, Max-Change: 0.00056\nIteration: 241, Log-Lik: -13120.370, Max-Change: 0.00040\nIteration: 242, Log-Lik: -13120.370, Max-Change: 0.00059\nIteration: 243, Log-Lik: -13120.370, Max-Change: 0.00017\nIteration: 244, Log-Lik: -13120.370, Max-Change: 0.00015\nIteration: 245, Log-Lik: -13120.370, Max-Change: 0.00038\nIteration: 246, Log-Lik: -13120.370, Max-Change: 0.00056\nIteration: 247, Log-Lik: -13120.370, Max-Change: 0.00040\nIteration: 248, Log-Lik: -13120.370, Max-Change: 0.00058\nIteration: 249, Log-Lik: -13120.370, Max-Change: 0.00017\nIteration: 250, Log-Lik: -13120.370, Max-Change: 0.00015\nIteration: 251, Log-Lik: -13120.370, Max-Change: 0.00038\nIteration: 252, Log-Lik: -13120.370, Max-Change: 0.00056\nIteration: 253, Log-Lik: -13120.370, Max-Change: 0.00040\nIteration: 254, Log-Lik: -13120.370, Max-Change: 0.00058\nIteration: 255, Log-Lik: -13120.370, Max-Change: 0.00017\nIteration: 256, Log-Lik: -13120.370, Max-Change: 0.00015\nIteration: 257, Log-Lik: -13120.370, Max-Change: 0.00038\nIteration: 258, Log-Lik: -13120.370, Max-Change: 0.00056\nIteration: 259, Log-Lik: -13120.370, Max-Change: 0.00040\nIteration: 260, Log-Lik: -13120.370, Max-Change: 0.00058\nIteration: 261, Log-Lik: -13120.370, Max-Change: 0.00017\nIteration: 262, Log-Lik: -13120.370, Max-Change: 0.00015\nIteration: 263, Log-Lik: -13120.370, Max-Change: 0.00038\nIteration: 264, Log-Lik: -13120.370, Max-Change: 0.00055\nIteration: 265, Log-Lik: -13120.370, Max-Change: 0.00040\nIteration: 266, Log-Lik: -13120.370, Max-Change: 0.00058\nIteration: 267, Log-Lik: -13120.370, Max-Change: 0.00017\nIteration: 268, Log-Lik: -13120.370, Max-Change: 0.00015\nIteration: 269, Log-Lik: -13120.370, Max-Change: 0.00038\nIteration: 270, Log-Lik: -13120.370, Max-Change: 0.00055\nIteration: 271, Log-Lik: -13120.370, Max-Change: 0.00040\nIteration: 272, Log-Lik: -13120.370, Max-Change: 0.00058\nIteration: 273, Log-Lik: -13120.370, Max-Change: 0.00017\nIteration: 274, Log-Lik: -13120.370, Max-Change: 0.00015\nIteration: 275, Log-Lik: -13120.370, Max-Change: 0.00038\nIteration: 276, Log-Lik: -13120.370, Max-Change: 0.00055\nIteration: 277, Log-Lik: -13120.370, Max-Change: 0.00039\nIteration: 278, Log-Lik: -13120.370, Max-Change: 0.00057\nIteration: 279, Log-Lik: -13120.370, Max-Change: 0.00017\nIteration: 280, Log-Lik: -13120.370, Max-Change: 0.00015\nIteration: 281, Log-Lik: -13120.370, Max-Change: 0.00038\nIteration: 282, Log-Lik: -13120.370, Max-Change: 0.00055\nIteration: 283, Log-Lik: -13120.370, Max-Change: 0.00039\nIteration: 284, Log-Lik: -13120.369, Max-Change: 0.00057\nIteration: 285, Log-Lik: -13120.369, Max-Change: 0.00017\nIteration: 286, Log-Lik: -13120.369, Max-Change: 0.00015\nIteration: 287, Log-Lik: -13120.369, Max-Change: 0.00038\nIteration: 288, Log-Lik: -13120.369, Max-Change: 0.00055\nIteration: 289, Log-Lik: -13120.369, Max-Change: 0.00039\nIteration: 290, Log-Lik: -13120.369, Max-Change: 0.00057\nIteration: 291, Log-Lik: -13120.369, Max-Change: 0.00017\nIteration: 292, Log-Lik: -13120.369, Max-Change: 0.00015\nIteration: 293, Log-Lik: -13120.369, Max-Change: 0.00037\nIteration: 294, Log-Lik: -13120.369, Max-Change: 0.00054\nIteration: 295, Log-Lik: -13120.369, Max-Change: 0.00039\nIteration: 296, Log-Lik: -13120.369, Max-Change: 0.00057\nIteration: 297, Log-Lik: -13120.369, Max-Change: 0.00016\nIteration: 298, Log-Lik: -13120.369, Max-Change: 0.00015\nIteration: 299, Log-Lik: -13120.369, Max-Change: 0.00037\nIteration: 300, Log-Lik: -13120.369, Max-Change: 0.00054\nIteration: 301, Log-Lik: -13120.369, Max-Change: 0.00039\nIteration: 302, Log-Lik: -13120.369, Max-Change: 0.00057\nIteration: 303, Log-Lik: -13120.369, Max-Change: 0.00016\nIteration: 304, Log-Lik: -13120.369, Max-Change: 0.00015\nIteration: 305, Log-Lik: -13120.369, Max-Change: 0.00037\nIteration: 306, Log-Lik: -13120.369, Max-Change: 0.00054\nIteration: 307, Log-Lik: -13120.369, Max-Change: 0.00039\nIteration: 308, Log-Lik: -13120.369, Max-Change: 0.00056\nIteration: 309, Log-Lik: -13120.369, Max-Change: 0.00016\nIteration: 310, Log-Lik: -13120.369, Max-Change: 0.00015\nIteration: 311, Log-Lik: -13120.369, Max-Change: 0.00037\nIteration: 312, Log-Lik: -13120.369, Max-Change: 0.00054\nIteration: 313, Log-Lik: -13120.369, Max-Change: 0.00039\nIteration: 314, Log-Lik: -13120.369, Max-Change: 0.00056\nIteration: 315, Log-Lik: -13120.369, Max-Change: 0.00016\nIteration: 316, Log-Lik: -13120.369, Max-Change: 0.00015\nIteration: 317, Log-Lik: -13120.369, Max-Change: 0.00037\nIteration: 318, Log-Lik: -13120.369, Max-Change: 0.00054\nIteration: 319, Log-Lik: -13120.369, Max-Change: 0.00039\nIteration: 320, Log-Lik: -13120.369, Max-Change: 0.00056\nIteration: 321, Log-Lik: -13120.369, Max-Change: 0.00016\nIteration: 322, Log-Lik: -13120.369, Max-Change: 0.00014\nIteration: 323, Log-Lik: -13120.369, Max-Change: 0.00037\nIteration: 324, Log-Lik: -13120.369, Max-Change: 0.00054\nIteration: 325, Log-Lik: -13120.369, Max-Change: 0.00039\nIteration: 326, Log-Lik: -13120.369, Max-Change: 0.00056\nIteration: 327, Log-Lik: -13120.369, Max-Change: 0.00016\nIteration: 328, Log-Lik: -13120.369, Max-Change: 0.00014\nIteration: 329, Log-Lik: -13120.369, Max-Change: 0.00037\nIteration: 330, Log-Lik: -13120.369, Max-Change: 0.00054\nIteration: 331, Log-Lik: -13120.369, Max-Change: 0.00038\nIteration: 332, Log-Lik: -13120.369, Max-Change: 0.00056\nIteration: 333, Log-Lik: -13120.369, Max-Change: 0.00016\nIteration: 334, Log-Lik: -13120.369, Max-Change: 0.00014\nIteration: 335, Log-Lik: -13120.369, Max-Change: 0.00037\nIteration: 336, Log-Lik: -13120.369, Max-Change: 0.00053\nIteration: 337, Log-Lik: -13120.369, Max-Change: 0.00038\nIteration: 338, Log-Lik: -13120.369, Max-Change: 0.00056\nIteration: 339, Log-Lik: -13120.369, Max-Change: 0.00016\nIteration: 340, Log-Lik: -13120.369, Max-Change: 0.00014\nIteration: 341, Log-Lik: -13120.369, Max-Change: 0.00037\nIteration: 342, Log-Lik: -13120.369, Max-Change: 0.00053\nIteration: 343, Log-Lik: -13120.369, Max-Change: 0.00038\nIteration: 344, Log-Lik: -13120.369, Max-Change: 0.00056\nIteration: 345, Log-Lik: -13120.369, Max-Change: 0.00016\nIteration: 346, Log-Lik: -13120.369, Max-Change: 0.00014\nIteration: 347, Log-Lik: -13120.369, Max-Change: 0.00037\nIteration: 348, Log-Lik: -13120.369, Max-Change: 0.00053\nIteration: 349, Log-Lik: -13120.369, Max-Change: 0.00038\nIteration: 350, Log-Lik: -13120.369, Max-Change: 0.00056\nIteration: 351, Log-Lik: -13120.369, Max-Change: 0.00016\nIteration: 352, Log-Lik: -13120.369, Max-Change: 0.00014\nIteration: 353, Log-Lik: -13120.369, Max-Change: 0.00036\nIteration: 354, Log-Lik: -13120.369, Max-Change: 0.00053\nIteration: 355, Log-Lik: -13120.369, Max-Change: 0.00038\nIteration: 356, Log-Lik: -13120.369, Max-Change: 0.00055\nIteration: 357, Log-Lik: -13120.369, Max-Change: 0.00016\nIteration: 358, Log-Lik: -13120.369, Max-Change: 0.00014\nIteration: 359, Log-Lik: -13120.369, Max-Change: 0.00036\nIteration: 360, Log-Lik: -13120.369, Max-Change: 0.00053\nIteration: 361, Log-Lik: -13120.369, Max-Change: 0.00038\nIteration: 362, Log-Lik: -13120.369, Max-Change: 0.00055\nIteration: 363, Log-Lik: -13120.369, Max-Change: 0.00016\nIteration: 364, Log-Lik: -13120.369, Max-Change: 0.00014\nIteration: 365, Log-Lik: -13120.369, Max-Change: 0.00036\nIteration: 366, Log-Lik: -13120.369, Max-Change: 0.00053\nIteration: 367, Log-Lik: -13120.369, Max-Change: 0.00038\nIteration: 368, Log-Lik: -13120.369, Max-Change: 0.00055\nIteration: 369, Log-Lik: -13120.369, Max-Change: 0.00016\nIteration: 370, Log-Lik: -13120.369, Max-Change: 0.00014\nIteration: 371, Log-Lik: -13120.369, Max-Change: 0.00036\nIteration: 372, Log-Lik: -13120.369, Max-Change: 0.00053\nIteration: 373, Log-Lik: -13120.369, Max-Change: 0.00038\nIteration: 374, Log-Lik: -13120.369, Max-Change: 0.00055\nIteration: 375, Log-Lik: -13120.369, Max-Change: 0.00016\nIteration: 376, Log-Lik: -13120.369, Max-Change: 0.00014\nIteration: 377, Log-Lik: -13120.369, Max-Change: 0.00036\nIteration: 378, Log-Lik: -13120.369, Max-Change: 0.00053\nIteration: 379, Log-Lik: -13120.369, Max-Change: 0.00038\nIteration: 380, Log-Lik: -13120.368, Max-Change: 0.00055\nIteration: 381, Log-Lik: -13120.368, Max-Change: 0.00016\nIteration: 382, Log-Lik: -13120.368, Max-Change: 0.00014\nIteration: 383, Log-Lik: -13120.368, Max-Change: 0.00036\nIteration: 384, Log-Lik: -13120.368, Max-Change: 0.00053\nIteration: 385, Log-Lik: -13120.368, Max-Change: 0.00038\nIteration: 386, Log-Lik: -13120.368, Max-Change: 0.00055\nIteration: 387, Log-Lik: -13120.368, Max-Change: 0.00016\nIteration: 388, Log-Lik: -13120.368, Max-Change: 0.00014\nIteration: 389, Log-Lik: -13120.368, Max-Change: 0.00036\nIteration: 390, Log-Lik: -13120.368, Max-Change: 0.00052\nIteration: 391, Log-Lik: -13120.368, Max-Change: 0.00038\nIteration: 392, Log-Lik: -13120.368, Max-Change: 0.00055\nIteration: 393, Log-Lik: -13120.368, Max-Change: 0.00016\nIteration: 394, Log-Lik: -13120.368, Max-Change: 0.00014\nIteration: 395, Log-Lik: -13120.368, Max-Change: 0.00036\nIteration: 396, Log-Lik: -13120.368, Max-Change: 0.00052\nIteration: 397, Log-Lik: -13120.368, Max-Change: 0.00038\nIteration: 398, Log-Lik: -13120.368, Max-Change: 0.00055\nIteration: 399, Log-Lik: -13120.368, Max-Change: 0.00016\nIteration: 400, Log-Lik: -13120.368, Max-Change: 0.00014\nIteration: 401, Log-Lik: -13120.368, Max-Change: 0.00036\nIteration: 402, Log-Lik: -13120.368, Max-Change: 0.00052\nIteration: 403, Log-Lik: -13120.368, Max-Change: 0.00038\nIteration: 404, Log-Lik: -13120.368, Max-Change: 0.00055\nIteration: 405, Log-Lik: -13120.368, Max-Change: 0.00016\nIteration: 406, Log-Lik: -13120.368, Max-Change: 0.00014\nIteration: 407, Log-Lik: -13120.368, Max-Change: 0.00036\nIteration: 408, Log-Lik: -13120.368, Max-Change: 0.00052\nIteration: 409, Log-Lik: -13120.368, Max-Change: 0.00038\nIteration: 410, Log-Lik: -13120.368, Max-Change: 0.00055\nIteration: 411, Log-Lik: -13120.368, Max-Change: 0.00016\nIteration: 412, Log-Lik: -13120.368, Max-Change: 0.00014\nIteration: 413, Log-Lik: -13120.368, Max-Change: 0.00036\nIteration: 414, Log-Lik: -13120.368, Max-Change: 0.00052\nIteration: 415, Log-Lik: -13120.368, Max-Change: 0.00038\nIteration: 416, Log-Lik: -13120.368, Max-Change: 0.00055\nIteration: 417, Log-Lik: -13120.368, Max-Change: 0.00016\nIteration: 418, Log-Lik: -13120.368, Max-Change: 0.00014\nIteration: 419, Log-Lik: -13120.368, Max-Change: 0.00036\nIteration: 420, Log-Lik: -13120.368, Max-Change: 0.00052\nIteration: 421, Log-Lik: -13120.368, Max-Change: 0.00038\nIteration: 422, Log-Lik: -13120.368, Max-Change: 0.00054\nIteration: 423, Log-Lik: -13120.368, Max-Change: 0.00016\nIteration: 424, Log-Lik: -13120.368, Max-Change: 0.00014\nIteration: 425, Log-Lik: -13120.368, Max-Change: 0.00036\nIteration: 426, Log-Lik: -13120.368, Max-Change: 0.00052\nIteration: 427, Log-Lik: -13120.368, Max-Change: 0.00037\nIteration: 428, Log-Lik: -13120.368, Max-Change: 0.00054\nIteration: 429, Log-Lik: -13120.368, Max-Change: 0.00016\nIteration: 430, Log-Lik: -13120.368, Max-Change: 0.00014\nIteration: 431, Log-Lik: -13120.368, Max-Change: 0.00036\nIteration: 432, Log-Lik: -13120.368, Max-Change: 0.00052\nIteration: 433, Log-Lik: -13120.368, Max-Change: 0.00037\nIteration: 434, Log-Lik: -13120.368, Max-Change: 0.00054\nIteration: 435, Log-Lik: -13120.368, Max-Change: 0.00016\nIteration: 436, Log-Lik: -13120.368, Max-Change: 0.00014\nIteration: 437, Log-Lik: -13120.368, Max-Change: 0.00036\nIteration: 438, Log-Lik: -13120.368, Max-Change: 0.00052\nIteration: 439, Log-Lik: -13120.368, Max-Change: 0.00037\nIteration: 440, Log-Lik: -13120.368, Max-Change: 0.00054\nIteration: 441, Log-Lik: -13120.368, Max-Change: 0.00016\nIteration: 442, Log-Lik: -13120.368, Max-Change: 0.00014\nIteration: 443, Log-Lik: -13120.368, Max-Change: 0.00036\nIteration: 444, Log-Lik: -13120.368, Max-Change: 0.00052\nIteration: 445, Log-Lik: -13120.368, Max-Change: 0.00037\nIteration: 446, Log-Lik: -13120.368, Max-Change: 0.00054\nIteration: 447, Log-Lik: -13120.368, Max-Change: 0.00016\nIteration: 448, Log-Lik: -13120.368, Max-Change: 0.00014\nIteration: 449, Log-Lik: -13120.368, Max-Change: 0.00036\nIteration: 450, Log-Lik: -13120.368, Max-Change: 0.00052\nIteration: 451, Log-Lik: -13120.368, Max-Change: 0.00037\nIteration: 452, Log-Lik: -13120.368, Max-Change: 0.00054\nIteration: 453, Log-Lik: -13120.368, Max-Change: 0.00016\nIteration: 454, Log-Lik: -13120.368, Max-Change: 0.00014\nIteration: 455, Log-Lik: -13120.368, Max-Change: 0.00036\nIteration: 456, Log-Lik: -13120.368, Max-Change: 0.00052\nIteration: 457, Log-Lik: -13120.368, Max-Change: 0.00037\nIteration: 458, Log-Lik: -13120.368, Max-Change: 0.00054\nIteration: 459, Log-Lik: -13120.368, Max-Change: 0.00016\nIteration: 460, Log-Lik: -13120.368, Max-Change: 0.00014\nIteration: 461, Log-Lik: -13120.368, Max-Change: 0.00036\nIteration: 462, Log-Lik: -13120.368, Max-Change: 0.00052\nIteration: 463, Log-Lik: -13120.368, Max-Change: 0.00037\nIteration: 464, Log-Lik: -13120.368, Max-Change: 0.00054\nIteration: 465, Log-Lik: -13120.368, Max-Change: 0.00016\nIteration: 466, Log-Lik: -13120.368, Max-Change: 0.00014\nIteration: 467, Log-Lik: -13120.368, Max-Change: 0.00036\nIteration: 468, Log-Lik: -13120.368, Max-Change: 0.00052\nIteration: 469, Log-Lik: -13120.368, Max-Change: 0.00037\nIteration: 470, Log-Lik: -13120.368, Max-Change: 0.00054\nIteration: 471, Log-Lik: -13120.368, Max-Change: 0.00016\nIteration: 472, Log-Lik: -13120.368, Max-Change: 0.00014\nIteration: 473, Log-Lik: -13120.368, Max-Change: 0.00035\nIteration: 474, Log-Lik: -13120.368, Max-Change: 0.00052\nIteration: 475, Log-Lik: -13120.368, Max-Change: 0.00037\nIteration: 476, Log-Lik: -13120.368, Max-Change: 0.00054\nIteration: 477, Log-Lik: -13120.368, Max-Change: 0.00016\nIteration: 478, Log-Lik: -13120.368, Max-Change: 0.00014\nIteration: 479, Log-Lik: -13120.368, Max-Change: 0.00035\nIteration: 480, Log-Lik: -13120.368, Max-Change: 0.00051\nIteration: 481, Log-Lik: -13120.368, Max-Change: 0.00037\nIteration: 482, Log-Lik: -13120.367, Max-Change: 0.00054\nIteration: 483, Log-Lik: -13120.367, Max-Change: 0.00016\nIteration: 484, Log-Lik: -13120.367, Max-Change: 0.00014\nIteration: 485, Log-Lik: -13120.367, Max-Change: 0.00035\nIteration: 486, Log-Lik: -13120.367, Max-Change: 0.00051\nIteration: 487, Log-Lik: -13120.367, Max-Change: 0.00037\nIteration: 488, Log-Lik: -13120.367, Max-Change: 0.00054\nIteration: 489, Log-Lik: -13120.367, Max-Change: 0.00016\nIteration: 490, Log-Lik: -13120.367, Max-Change: 0.00014\nIteration: 491, Log-Lik: -13120.367, Max-Change: 0.00035\nIteration: 492, Log-Lik: -13120.367, Max-Change: 0.00051\nIteration: 493, Log-Lik: -13120.367, Max-Change: 0.00037\nIteration: 494, Log-Lik: -13120.367, Max-Change: 0.00054\nIteration: 495, Log-Lik: -13120.367, Max-Change: 0.00016\nIteration: 496, Log-Lik: -13120.367, Max-Change: 0.00014\nIteration: 497, Log-Lik: -13120.367, Max-Change: 0.00035\nIteration: 498, Log-Lik: -13120.367, Max-Change: 0.00051\nIteration: 499, Log-Lik: -13120.367, Max-Change: 0.00037\nIteration: 500, Log-Lik: -13120.367, Max-Change: 0.00054\n\n\nEM cycles terminated after 500 iterations.\n\n\n\n\nCalculating information matrix...\n\nthreepl_params <- coef(threepl_fit, IRTpars = TRUE, \n                       simplify = TRUE)\nthreepl_items <- threepl_params$items\nhead(threepl_items)\n\n                 a          b            g u\nreason.4  1.965832 -0.2869613 0.1220243277 1\nreason.16 1.419231 -0.7995733 0.0022155571 1\nreason.17 1.780427 -0.7076754 0.0020240288 1\nreason.19 1.379131 -0.4514928 0.0005308146 1\nletter.7  1.535846 -0.3622950 0.0007297169 1\nletter.33 1.336533 -0.2751526 0.0010139285 1\n\n\n결과의 처음 두 열은 SAPA 데이터 세트의 각 문항에 대한 문항 변별도 및 난이도 모수를 보여줍니다. 1PL 및 2PL 모델과 달리 3PL 모델의 세 번째 열(즉, g)은 0이 아닙니다. 이 열은 낮은 점근 모수를 보여줍니다. item 1(reason.4)은 일반적으로 추측도가 최소화되는 다른 출력된 문항에 비해 추측도 모수가 큽니다.\n추측도가 문항에 미치는 영향을 확인하기 위해 item 1(reason.4)과 4(reason.19)에 대한 ICC 그래프를 그립니다. 그림 5.12는 잠재 특성이 작아질수록(예: \\(\\theta < -2\\)) 문항 1의 정답 확률이 0.12에 가까워지는 반면, item 4의 확률은 거의 0에 가까워지는 것을 보여줍니다.\n\nplot(threepl_fit, type = \"trace\", which.items = c(1, 4), \n     facet_items = FALSE, auto.key = list(points = FALSE,\n                                          lines = TRUE, columns = 2),\n     par.settings = simpleTheme(lty = 1:2))\n\n\n\n\n\n\n5.3.4 4모수 로지스틱 모델\nBarton과 Lord(1981)가 도입한 4모수 로지스틱(4PL) 모델은 3PL 모델의 특수한 경우입니다. 4PL 모델에서는 문항이 하한 및 상한 점근 모수를 모두 가질 수 있습니다. 상한 점근 모수는 피험자의 잠재 특성 수준에 관계없이 정답을 맞힐 확률이 1(즉, 100%)에 가까워지는 것을 방지하는 상한 모수로 설명할 수 있습니다. 4PL은 다음과 같이 작성됩니다.\n\\[\nP(Y_{ij}=1|\\theta_j, a_i, b_i, c_i, u_i) = c_i + {u_i-c_i \\over 1+exp(-Da_i(\\theta_j-b_i))}\n\\]\n\n여기서 \\(u_i\\) 모수는 상부 점근을 나타냅니다.\n\n이 추가 모수는 \\(c_i\\) 모수가 0이 아니고 \\(u_i\\) 모수가 1이 아닐 때 방정식의 분자를 1보다 작게 만듭니다(4PL 모델에 대한 자세한 설명은 Magis(2013) 참조).\n성취도 및 적성과 같은 잠재 특성을 모델링하는 데는 3PL 모델이 더 일반적이지만, 신경증, 개방성, 공격성 및 동기 부여와 같은 비인지적 성격 특성에는 이러한 특성의 최고 수준에 도달할 확률이 1에 가까워지지 않을 수 있으므로 4PL 모델이 더 적합할 수 있습니다. IRT 모델에 상위 점근 모수를 포함할 경우의 이점은 여러 연구에서 입증되었습니다(Loken & Rulison, 2010; Osgood, McMorris, & Potenza, 2002; Reise & Waller, 2009; Tavares, Andrade, & Pereira, 2004).\n다음 예에서는 SAPA 데이터 세트에 대한 4PL 모델을 추정합니다. itemtype = “4PL”을 설정하여 4PL 모델을 추정합니다. 이전과 마찬가지로, 적합 모델을 fourpl_fit으로 저장한 다음 추정된 문항 모수를 추출하고 문항 모수의 처음 몇 행을 출력합니다.\n\nfourpl_mod <- \"F = 1 - 16\"\nfourpl_fit <- mirt(data = SAPA, model = fourpl_mod,\n                   itemtype = \"4PL\", SE = TRUE)\n\n\nIteration: 1, Log-Lik: -14241.720, Max-Change: 2.22037\nIteration: 2, Log-Lik: -13336.802, Max-Change: 0.95506\nIteration: 3, Log-Lik: -13171.878, Max-Change: 0.91670\nIteration: 4, Log-Lik: -13121.825, Max-Change: 0.75554\nIteration: 5, Log-Lik: -13099.489, Max-Change: 0.59099\nIteration: 6, Log-Lik: -13088.709, Max-Change: 0.51223\nIteration: 7, Log-Lik: -13082.537, Max-Change: 0.50146\nIteration: 8, Log-Lik: -13078.456, Max-Change: 0.45543\nIteration: 9, Log-Lik: -13075.870, Max-Change: 0.49227\nIteration: 10, Log-Lik: -13074.620, Max-Change: 0.27210\nIteration: 11, Log-Lik: -13069.813, Max-Change: 0.42392\nIteration: 12, Log-Lik: -13069.109, Max-Change: 0.67288\nIteration: 13, Log-Lik: -13068.027, Max-Change: 0.10701\nIteration: 14, Log-Lik: -13067.772, Max-Change: 0.83409\nIteration: 15, Log-Lik: -13067.484, Max-Change: 0.43269\nIteration: 16, Log-Lik: -13067.314, Max-Change: 0.49296\nIteration: 17, Log-Lik: -13067.157, Max-Change: 0.67363\nIteration: 18, Log-Lik: -13066.999, Max-Change: 0.64192\nIteration: 19, Log-Lik: -13066.536, Max-Change: 0.12335\nIteration: 20, Log-Lik: -13066.375, Max-Change: 0.11240\nIteration: 21, Log-Lik: -13066.331, Max-Change: 0.06089\nIteration: 22, Log-Lik: -13066.302, Max-Change: 0.01846\nIteration: 23, Log-Lik: -13066.286, Max-Change: 0.01666\nIteration: 24, Log-Lik: -13066.274, Max-Change: 0.01310\nIteration: 25, Log-Lik: -13066.250, Max-Change: 0.01981\nIteration: 26, Log-Lik: -13066.239, Max-Change: 0.29737\nIteration: 27, Log-Lik: -13066.197, Max-Change: 0.00984\nIteration: 28, Log-Lik: -13066.197, Max-Change: 0.00985\nIteration: 29, Log-Lik: -13066.192, Max-Change: 0.00923\nIteration: 30, Log-Lik: -13066.188, Max-Change: 0.28666\nIteration: 31, Log-Lik: -13066.149, Max-Change: 0.00845\nIteration: 32, Log-Lik: -13066.145, Max-Change: 0.00813\nIteration: 33, Log-Lik: -13066.141, Max-Change: 0.56865\nIteration: 34, Log-Lik: -13066.089, Max-Change: 0.00684\nIteration: 35, Log-Lik: -13066.085, Max-Change: 0.00658\nIteration: 36, Log-Lik: -13066.083, Max-Change: 0.00497\nIteration: 37, Log-Lik: -13066.080, Max-Change: 0.00577\nIteration: 38, Log-Lik: -13066.077, Max-Change: 0.00483\nIteration: 39, Log-Lik: -13066.076, Max-Change: 0.00481\nIteration: 40, Log-Lik: -13066.071, Max-Change: 0.00219\nIteration: 41, Log-Lik: -13066.070, Max-Change: 0.00172\nIteration: 42, Log-Lik: -13066.070, Max-Change: 0.00041\nIteration: 43, Log-Lik: -13066.069, Max-Change: 0.00189\nIteration: 44, Log-Lik: -13066.069, Max-Change: 0.00047\nIteration: 45, Log-Lik: -13066.069, Max-Change: 0.00131\nIteration: 46, Log-Lik: -13066.069, Max-Change: 0.01761\nIteration: 47, Log-Lik: -13066.067, Max-Change: 0.00170\nIteration: 48, Log-Lik: -13066.066, Max-Change: 0.00090\nIteration: 49, Log-Lik: -13066.066, Max-Change: 0.00239\nIteration: 50, Log-Lik: -13066.066, Max-Change: 0.00150\nIteration: 51, Log-Lik: -13066.066, Max-Change: 0.00129\nIteration: 52, Log-Lik: -13066.066, Max-Change: 0.00206\nIteration: 53, Log-Lik: -13066.066, Max-Change: 0.00172\nIteration: 54, Log-Lik: -13066.066, Max-Change: 0.00042\nIteration: 55, Log-Lik: -13066.066, Max-Change: 0.00038\nIteration: 56, Log-Lik: -13066.066, Max-Change: 0.00107\nIteration: 57, Log-Lik: -13066.065, Max-Change: 0.00127\nIteration: 58, Log-Lik: -13066.065, Max-Change: 0.00042\nIteration: 59, Log-Lik: -13066.065, Max-Change: 0.00049\nIteration: 60, Log-Lik: -13066.065, Max-Change: 0.00062\nIteration: 61, Log-Lik: -13066.065, Max-Change: 0.00040\nIteration: 62, Log-Lik: -13066.065, Max-Change: 0.00050\nIteration: 63, Log-Lik: -13066.065, Max-Change: 0.00059\nIteration: 64, Log-Lik: -13066.065, Max-Change: 0.00041\nIteration: 65, Log-Lik: -13066.065, Max-Change: 0.00048\nIteration: 66, Log-Lik: -13066.065, Max-Change: 0.00060\nIteration: 67, Log-Lik: -13066.065, Max-Change: 0.00040\nIteration: 68, Log-Lik: -13066.065, Max-Change: 0.00050\nIteration: 69, Log-Lik: -13066.065, Max-Change: 0.00058\nIteration: 70, Log-Lik: -13066.065, Max-Change: 0.00041\nIteration: 71, Log-Lik: -13066.065, Max-Change: 0.00048\nIteration: 72, Log-Lik: -13066.065, Max-Change: 0.00059\nIteration: 73, Log-Lik: -13066.065, Max-Change: 0.00039\nIteration: 74, Log-Lik: -13066.065, Max-Change: 0.00049\nIteration: 75, Log-Lik: -13066.065, Max-Change: 0.00058\nIteration: 76, Log-Lik: -13066.065, Max-Change: 0.00040\nIteration: 77, Log-Lik: -13066.064, Max-Change: 0.00047\nIteration: 78, Log-Lik: -13066.064, Max-Change: 0.00059\nIteration: 79, Log-Lik: -13066.064, Max-Change: 0.00039\nIteration: 80, Log-Lik: -13066.064, Max-Change: 0.00048\nIteration: 81, Log-Lik: -13066.064, Max-Change: 0.00057\nIteration: 82, Log-Lik: -13066.064, Max-Change: 0.00040\nIteration: 83, Log-Lik: -13066.064, Max-Change: 0.00047\nIteration: 84, Log-Lik: -13066.064, Max-Change: 0.00058\nIteration: 85, Log-Lik: -13066.064, Max-Change: 0.00038\nIteration: 86, Log-Lik: -13066.064, Max-Change: 0.00048\nIteration: 87, Log-Lik: -13066.064, Max-Change: 0.00056\nIteration: 88, Log-Lik: -13066.064, Max-Change: 0.00039\nIteration: 89, Log-Lik: -13066.064, Max-Change: 0.00046\nIteration: 90, Log-Lik: -13066.064, Max-Change: 0.00057\nIteration: 91, Log-Lik: -13066.064, Max-Change: 0.00038\nIteration: 92, Log-Lik: -13066.064, Max-Change: 0.00047\nIteration: 93, Log-Lik: -13066.064, Max-Change: 0.00056\nIteration: 94, Log-Lik: -13066.064, Max-Change: 0.00039\nIteration: 95, Log-Lik: -13066.064, Max-Change: 0.00046\nIteration: 96, Log-Lik: -13066.064, Max-Change: 0.00057\nIteration: 97, Log-Lik: -13066.064, Max-Change: 0.00037\nIteration: 98, Log-Lik: -13066.064, Max-Change: 0.00047\nIteration: 99, Log-Lik: -13066.064, Max-Change: 0.00055\nIteration: 100, Log-Lik: -13066.063, Max-Change: 0.00039\nIteration: 101, Log-Lik: -13066.063, Max-Change: 0.00045\nIteration: 102, Log-Lik: -13066.063, Max-Change: 0.00056\nIteration: 103, Log-Lik: -13066.063, Max-Change: 0.00037\nIteration: 104, Log-Lik: -13066.063, Max-Change: 0.00046\nIteration: 105, Log-Lik: -13066.063, Max-Change: 0.00055\nIteration: 106, Log-Lik: -13066.063, Max-Change: 0.00038\nIteration: 107, Log-Lik: -13066.063, Max-Change: 0.00045\nIteration: 108, Log-Lik: -13066.063, Max-Change: 0.00056\nIteration: 109, Log-Lik: -13066.063, Max-Change: 0.00037\nIteration: 110, Log-Lik: -13066.063, Max-Change: 0.00046\nIteration: 111, Log-Lik: -13066.063, Max-Change: 0.00054\nIteration: 112, Log-Lik: -13066.063, Max-Change: 0.00038\nIteration: 113, Log-Lik: -13066.063, Max-Change: 0.00045\nIteration: 114, Log-Lik: -13066.063, Max-Change: 0.00055\nIteration: 115, Log-Lik: -13066.063, Max-Change: 0.00037\nIteration: 116, Log-Lik: -13066.063, Max-Change: 0.00046\nIteration: 117, Log-Lik: -13066.063, Max-Change: 0.00054\nIteration: 118, Log-Lik: -13066.063, Max-Change: 0.00038\nIteration: 119, Log-Lik: -13066.063, Max-Change: 0.00044\nIteration: 120, Log-Lik: -13066.063, Max-Change: 0.00055\nIteration: 121, Log-Lik: -13066.063, Max-Change: 0.00036\nIteration: 122, Log-Lik: -13066.063, Max-Change: 0.00045\nIteration: 123, Log-Lik: -13066.063, Max-Change: 0.00053\nIteration: 124, Log-Lik: -13066.062, Max-Change: 0.00037\nIteration: 125, Log-Lik: -13066.062, Max-Change: 0.00044\nIteration: 126, Log-Lik: -13066.062, Max-Change: 0.00054\nIteration: 127, Log-Lik: -13066.062, Max-Change: 0.00036\nIteration: 128, Log-Lik: -13066.062, Max-Change: 0.00045\nIteration: 129, Log-Lik: -13066.062, Max-Change: 0.00053\nIteration: 130, Log-Lik: -13066.062, Max-Change: 0.00037\nIteration: 131, Log-Lik: -13066.062, Max-Change: 0.00044\nIteration: 132, Log-Lik: -13066.062, Max-Change: 0.00054\nIteration: 133, Log-Lik: -13066.062, Max-Change: 0.00036\nIteration: 134, Log-Lik: -13066.062, Max-Change: 0.00045\nIteration: 135, Log-Lik: -13066.062, Max-Change: 0.00053\nIteration: 136, Log-Lik: -13066.062, Max-Change: 0.00037\nIteration: 137, Log-Lik: -13066.062, Max-Change: 0.00044\nIteration: 138, Log-Lik: -13066.062, Max-Change: 0.00054\nIteration: 139, Log-Lik: -13066.062, Max-Change: 0.00036\nIteration: 140, Log-Lik: -13066.062, Max-Change: 0.00044\nIteration: 141, Log-Lik: -13066.062, Max-Change: 0.00053\nIteration: 142, Log-Lik: -13066.062, Max-Change: 0.00037\nIteration: 143, Log-Lik: -13066.062, Max-Change: 0.00043\nIteration: 144, Log-Lik: -13066.062, Max-Change: 0.00054\nIteration: 145, Log-Lik: -13066.062, Max-Change: 0.00036\nIteration: 146, Log-Lik: -13066.062, Max-Change: 0.00044\nIteration: 147, Log-Lik: -13066.062, Max-Change: 0.00052\nIteration: 148, Log-Lik: -13066.062, Max-Change: 0.00037\nIteration: 149, Log-Lik: -13066.062, Max-Change: 0.00043\nIteration: 150, Log-Lik: -13066.061, Max-Change: 0.00053\nIteration: 151, Log-Lik: -13066.061, Max-Change: 0.00035\nIteration: 152, Log-Lik: -13066.061, Max-Change: 0.00044\nIteration: 153, Log-Lik: -13066.061, Max-Change: 0.00052\nIteration: 154, Log-Lik: -13066.061, Max-Change: 0.00036\nIteration: 155, Log-Lik: -13066.061, Max-Change: 0.00043\nIteration: 156, Log-Lik: -13066.061, Max-Change: 0.00053\nIteration: 157, Log-Lik: -13066.061, Max-Change: 0.00035\nIteration: 158, Log-Lik: -13066.061, Max-Change: 0.00044\nIteration: 159, Log-Lik: -13066.061, Max-Change: 0.00052\nIteration: 160, Log-Lik: -13066.061, Max-Change: 0.00036\nIteration: 161, Log-Lik: -13066.061, Max-Change: 0.00043\nIteration: 162, Log-Lik: -13066.061, Max-Change: 0.00053\nIteration: 163, Log-Lik: -13066.061, Max-Change: 0.00035\nIteration: 164, Log-Lik: -13066.061, Max-Change: 0.00044\nIteration: 165, Log-Lik: -13066.061, Max-Change: 0.00052\nIteration: 166, Log-Lik: -13066.061, Max-Change: 0.00036\nIteration: 167, Log-Lik: -13066.061, Max-Change: 0.00043\nIteration: 168, Log-Lik: -13066.061, Max-Change: 0.00053\nIteration: 169, Log-Lik: -13066.061, Max-Change: 0.00035\nIteration: 170, Log-Lik: -13066.061, Max-Change: 0.00043\nIteration: 171, Log-Lik: -13066.061, Max-Change: 0.00052\nIteration: 172, Log-Lik: -13066.061, Max-Change: 0.00036\nIteration: 173, Log-Lik: -13066.061, Max-Change: 0.00042\nIteration: 174, Log-Lik: -13066.061, Max-Change: 0.00052\nIteration: 175, Log-Lik: -13066.061, Max-Change: 0.00035\nIteration: 176, Log-Lik: -13066.061, Max-Change: 0.00043\nIteration: 177, Log-Lik: -13066.060, Max-Change: 0.00051\nIteration: 178, Log-Lik: -13066.060, Max-Change: 0.00036\nIteration: 179, Log-Lik: -13066.060, Max-Change: 0.00042\nIteration: 180, Log-Lik: -13066.060, Max-Change: 0.00052\nIteration: 181, Log-Lik: -13066.060, Max-Change: 0.00035\nIteration: 182, Log-Lik: -13066.060, Max-Change: 0.00043\nIteration: 183, Log-Lik: -13066.060, Max-Change: 0.00051\nIteration: 184, Log-Lik: -13066.060, Max-Change: 0.00036\nIteration: 185, Log-Lik: -13066.060, Max-Change: 0.00042\nIteration: 186, Log-Lik: -13066.060, Max-Change: 0.00052\nIteration: 187, Log-Lik: -13066.060, Max-Change: 0.00035\nIteration: 188, Log-Lik: -13066.060, Max-Change: 0.00043\nIteration: 189, Log-Lik: -13066.060, Max-Change: 0.00051\nIteration: 190, Log-Lik: -13066.060, Max-Change: 0.00036\nIteration: 191, Log-Lik: -13066.060, Max-Change: 0.00042\nIteration: 192, Log-Lik: -13066.060, Max-Change: 0.00052\nIteration: 193, Log-Lik: -13066.060, Max-Change: 0.00035\nIteration: 194, Log-Lik: -13066.060, Max-Change: 0.00043\nIteration: 195, Log-Lik: -13066.060, Max-Change: 0.00051\nIteration: 196, Log-Lik: -13066.060, Max-Change: 0.00036\nIteration: 197, Log-Lik: -13066.060, Max-Change: 0.00042\nIteration: 198, Log-Lik: -13066.060, Max-Change: 0.00052\nIteration: 199, Log-Lik: -13066.060, Max-Change: 0.00035\nIteration: 200, Log-Lik: -13066.060, Max-Change: 0.00043\nIteration: 201, Log-Lik: -13066.060, Max-Change: 0.00051\nIteration: 202, Log-Lik: -13066.060, Max-Change: 0.00035\nIteration: 203, Log-Lik: -13066.060, Max-Change: 0.00042\nIteration: 204, Log-Lik: -13066.059, Max-Change: 0.00052\nIteration: 205, Log-Lik: -13066.059, Max-Change: 0.00035\nIteration: 206, Log-Lik: -13066.059, Max-Change: 0.00043\nIteration: 207, Log-Lik: -13066.059, Max-Change: 0.00051\nIteration: 208, Log-Lik: -13066.059, Max-Change: 0.00035\nIteration: 209, Log-Lik: -13066.059, Max-Change: 0.00042\nIteration: 210, Log-Lik: -13066.059, Max-Change: 0.00052\nIteration: 211, Log-Lik: -13066.059, Max-Change: 0.00034\nIteration: 212, Log-Lik: -13066.059, Max-Change: 0.00043\nIteration: 213, Log-Lik: -13066.059, Max-Change: 0.00051\nIteration: 214, Log-Lik: -13066.059, Max-Change: 0.00035\nIteration: 215, Log-Lik: -13066.059, Max-Change: 0.00042\nIteration: 216, Log-Lik: -13066.059, Max-Change: 0.00051\nIteration: 217, Log-Lik: -13066.059, Max-Change: 0.00034\nIteration: 218, Log-Lik: -13066.059, Max-Change: 0.00043\nIteration: 219, Log-Lik: -13066.059, Max-Change: 0.00051\nIteration: 220, Log-Lik: -13066.059, Max-Change: 0.00035\nIteration: 221, Log-Lik: -13066.059, Max-Change: 0.00042\nIteration: 222, Log-Lik: -13066.059, Max-Change: 0.00051\nIteration: 223, Log-Lik: -13066.059, Max-Change: 0.00034\nIteration: 224, Log-Lik: -13066.059, Max-Change: 0.00042\nIteration: 225, Log-Lik: -13066.059, Max-Change: 0.00050\nIteration: 226, Log-Lik: -13066.059, Max-Change: 0.00035\nIteration: 227, Log-Lik: -13066.059, Max-Change: 0.00042\nIteration: 228, Log-Lik: -13066.059, Max-Change: 0.00051\nIteration: 229, Log-Lik: -13066.059, Max-Change: 0.00034\nIteration: 230, Log-Lik: -13066.059, Max-Change: 0.00042\nIteration: 231, Log-Lik: -13066.059, Max-Change: 0.00050\nIteration: 232, Log-Lik: -13066.058, Max-Change: 0.00035\nIteration: 233, Log-Lik: -13066.058, Max-Change: 0.00042\nIteration: 234, Log-Lik: -13066.058, Max-Change: 0.00051\nIteration: 235, Log-Lik: -13066.058, Max-Change: 0.00034\nIteration: 236, Log-Lik: -13066.058, Max-Change: 0.00042\nIteration: 237, Log-Lik: -13066.058, Max-Change: 0.00050\nIteration: 238, Log-Lik: -13066.058, Max-Change: 0.00035\nIteration: 239, Log-Lik: -13066.058, Max-Change: 0.00041\nIteration: 240, Log-Lik: -13066.058, Max-Change: 0.00051\nIteration: 241, Log-Lik: -13066.058, Max-Change: 0.00034\nIteration: 242, Log-Lik: -13066.058, Max-Change: 0.00042\nIteration: 243, Log-Lik: -13066.058, Max-Change: 0.00050\nIteration: 244, Log-Lik: -13066.058, Max-Change: 0.00035\nIteration: 245, Log-Lik: -13066.058, Max-Change: 0.00041\nIteration: 246, Log-Lik: -13066.058, Max-Change: 0.00051\nIteration: 247, Log-Lik: -13066.058, Max-Change: 0.00034\nIteration: 248, Log-Lik: -13066.058, Max-Change: 0.00042\nIteration: 249, Log-Lik: -13066.058, Max-Change: 0.00050\nIteration: 250, Log-Lik: -13066.058, Max-Change: 0.00035\nIteration: 251, Log-Lik: -13066.058, Max-Change: 0.00041\nIteration: 252, Log-Lik: -13066.058, Max-Change: 0.00051\nIteration: 253, Log-Lik: -13066.058, Max-Change: 0.00034\nIteration: 254, Log-Lik: -13066.058, Max-Change: 0.00042\nIteration: 255, Log-Lik: -13066.058, Max-Change: 0.00050\nIteration: 256, Log-Lik: -13066.058, Max-Change: 0.00035\nIteration: 257, Log-Lik: -13066.058, Max-Change: 0.00041\nIteration: 258, Log-Lik: -13066.058, Max-Change: 0.00051\nIteration: 259, Log-Lik: -13066.058, Max-Change: 0.00034\nIteration: 260, Log-Lik: -13066.057, Max-Change: 0.00042\nIteration: 261, Log-Lik: -13066.057, Max-Change: 0.00050\nIteration: 262, Log-Lik: -13066.057, Max-Change: 0.00035\nIteration: 263, Log-Lik: -13066.057, Max-Change: 0.00041\nIteration: 264, Log-Lik: -13066.057, Max-Change: 0.00051\nIteration: 265, Log-Lik: -13066.057, Max-Change: 0.00034\nIteration: 266, Log-Lik: -13066.057, Max-Change: 0.00042\nIteration: 267, Log-Lik: -13066.057, Max-Change: 0.00050\nIteration: 268, Log-Lik: -13066.057, Max-Change: 0.00035\nIteration: 269, Log-Lik: -13066.057, Max-Change: 0.00041\nIteration: 270, Log-Lik: -13066.057, Max-Change: 0.00051\nIteration: 271, Log-Lik: -13066.057, Max-Change: 0.00034\nIteration: 272, Log-Lik: -13066.057, Max-Change: 0.00042\nIteration: 273, Log-Lik: -13066.057, Max-Change: 0.00050\nIteration: 274, Log-Lik: -13066.057, Max-Change: 0.00035\nIteration: 275, Log-Lik: -13066.057, Max-Change: 0.00041\nIteration: 276, Log-Lik: -13066.057, Max-Change: 0.00051\nIteration: 277, Log-Lik: -13066.057, Max-Change: 0.00034\nIteration: 278, Log-Lik: -13066.057, Max-Change: 0.00042\nIteration: 279, Log-Lik: -13066.057, Max-Change: 0.00050\nIteration: 280, Log-Lik: -13066.057, Max-Change: 0.00035\nIteration: 281, Log-Lik: -13066.057, Max-Change: 0.00041\nIteration: 282, Log-Lik: -13066.057, Max-Change: 0.00050\nIteration: 283, Log-Lik: -13066.057, Max-Change: 0.00034\nIteration: 284, Log-Lik: -13066.057, Max-Change: 0.00042\nIteration: 285, Log-Lik: -13066.057, Max-Change: 0.00050\nIteration: 286, Log-Lik: -13066.057, Max-Change: 0.00035\nIteration: 287, Log-Lik: -13066.057, Max-Change: 0.00041\nIteration: 288, Log-Lik: -13066.057, Max-Change: 0.00050\nIteration: 289, Log-Lik: -13066.056, Max-Change: 0.00034\nIteration: 290, Log-Lik: -13066.056, Max-Change: 0.00042\nIteration: 291, Log-Lik: -13066.056, Max-Change: 0.00050\nIteration: 292, Log-Lik: -13066.056, Max-Change: 0.00034\nIteration: 293, Log-Lik: -13066.056, Max-Change: 0.00041\nIteration: 294, Log-Lik: -13066.056, Max-Change: 0.00050\nIteration: 295, Log-Lik: -13066.056, Max-Change: 0.00034\nIteration: 296, Log-Lik: -13066.056, Max-Change: 0.00042\nIteration: 297, Log-Lik: -13066.056, Max-Change: 0.00050\nIteration: 298, Log-Lik: -13066.056, Max-Change: 0.00034\nIteration: 299, Log-Lik: -13066.056, Max-Change: 0.00041\nIteration: 300, Log-Lik: -13066.056, Max-Change: 0.00050\nIteration: 301, Log-Lik: -13066.056, Max-Change: 0.00034\nIteration: 302, Log-Lik: -13066.056, Max-Change: 0.00042\nIteration: 303, Log-Lik: -13066.056, Max-Change: 0.00050\nIteration: 304, Log-Lik: -13066.056, Max-Change: 0.00034\nIteration: 305, Log-Lik: -13066.056, Max-Change: 0.00041\nIteration: 306, Log-Lik: -13066.056, Max-Change: 0.00050\nIteration: 307, Log-Lik: -13066.056, Max-Change: 0.00034\nIteration: 308, Log-Lik: -13066.056, Max-Change: 0.00042\nIteration: 309, Log-Lik: -13066.056, Max-Change: 0.00050\nIteration: 310, Log-Lik: -13066.056, Max-Change: 0.00034\nIteration: 311, Log-Lik: -13066.056, Max-Change: 0.00041\nIteration: 312, Log-Lik: -13066.056, Max-Change: 0.00050\nIteration: 313, Log-Lik: -13066.056, Max-Change: 0.00034\nIteration: 314, Log-Lik: -13066.056, Max-Change: 0.00041\nIteration: 315, Log-Lik: -13066.056, Max-Change: 0.00050\nIteration: 316, Log-Lik: -13066.056, Max-Change: 0.00034\nIteration: 317, Log-Lik: -13066.056, Max-Change: 0.00041\nIteration: 318, Log-Lik: -13066.056, Max-Change: 0.00050\nIteration: 319, Log-Lik: -13066.055, Max-Change: 0.00034\nIteration: 320, Log-Lik: -13066.055, Max-Change: 0.00041\nIteration: 321, Log-Lik: -13066.055, Max-Change: 0.00049\nIteration: 322, Log-Lik: -13066.055, Max-Change: 0.00034\nIteration: 323, Log-Lik: -13066.055, Max-Change: 0.00041\nIteration: 324, Log-Lik: -13066.055, Max-Change: 0.00050\nIteration: 325, Log-Lik: -13066.055, Max-Change: 0.00034\nIteration: 326, Log-Lik: -13066.055, Max-Change: 0.00041\nIteration: 327, Log-Lik: -13066.055, Max-Change: 0.00049\nIteration: 328, Log-Lik: -13066.055, Max-Change: 0.00034\nIteration: 329, Log-Lik: -13066.055, Max-Change: 0.00041\nIteration: 330, Log-Lik: -13066.055, Max-Change: 0.00050\nIteration: 331, Log-Lik: -13066.055, Max-Change: 0.00034\nIteration: 332, Log-Lik: -13066.055, Max-Change: 0.00041\nIteration: 333, Log-Lik: -13066.055, Max-Change: 0.00049\nIteration: 334, Log-Lik: -13066.055, Max-Change: 0.00034\nIteration: 335, Log-Lik: -13066.055, Max-Change: 0.00041\nIteration: 336, Log-Lik: -13066.055, Max-Change: 0.00050\nIteration: 337, Log-Lik: -13066.055, Max-Change: 0.00034\nIteration: 338, Log-Lik: -13066.055, Max-Change: 0.00041\nIteration: 339, Log-Lik: -13066.055, Max-Change: 0.00049\nIteration: 340, Log-Lik: -13066.055, Max-Change: 0.00034\nIteration: 341, Log-Lik: -13066.055, Max-Change: 0.00041\nIteration: 342, Log-Lik: -13066.055, Max-Change: 0.00050\nIteration: 343, Log-Lik: -13066.055, Max-Change: 0.00034\nIteration: 344, Log-Lik: -13066.055, Max-Change: 0.00041\nIteration: 345, Log-Lik: -13066.055, Max-Change: 0.00049\nIteration: 346, Log-Lik: -13066.055, Max-Change: 0.00034\nIteration: 347, Log-Lik: -13066.055, Max-Change: 0.00041\nIteration: 348, Log-Lik: -13066.054, Max-Change: 0.00050\nIteration: 349, Log-Lik: -13066.054, Max-Change: 0.00034\nIteration: 350, Log-Lik: -13066.054, Max-Change: 0.00041\nIteration: 351, Log-Lik: -13066.054, Max-Change: 0.00049\nIteration: 352, Log-Lik: -13066.054, Max-Change: 0.00034\nIteration: 353, Log-Lik: -13066.054, Max-Change: 0.00041\nIteration: 354, Log-Lik: -13066.054, Max-Change: 0.00050\nIteration: 355, Log-Lik: -13066.054, Max-Change: 0.00033\nIteration: 356, Log-Lik: -13066.054, Max-Change: 0.00041\nIteration: 357, Log-Lik: -13066.054, Max-Change: 0.00049\nIteration: 358, Log-Lik: -13066.054, Max-Change: 0.00034\nIteration: 359, Log-Lik: -13066.054, Max-Change: 0.00041\nIteration: 360, Log-Lik: -13066.054, Max-Change: 0.00050\nIteration: 361, Log-Lik: -13066.054, Max-Change: 0.00033\nIteration: 362, Log-Lik: -13066.054, Max-Change: 0.00041\nIteration: 363, Log-Lik: -13066.054, Max-Change: 0.00049\nIteration: 364, Log-Lik: -13066.054, Max-Change: 0.00034\nIteration: 365, Log-Lik: -13066.054, Max-Change: 0.00041\nIteration: 366, Log-Lik: -13066.054, Max-Change: 0.00050\nIteration: 367, Log-Lik: -13066.054, Max-Change: 0.00033\nIteration: 368, Log-Lik: -13066.054, Max-Change: 0.00041\nIteration: 369, Log-Lik: -13066.054, Max-Change: 0.00049\nIteration: 370, Log-Lik: -13066.054, Max-Change: 0.00034\nIteration: 371, Log-Lik: -13066.054, Max-Change: 0.00040\nIteration: 372, Log-Lik: -13066.054, Max-Change: 0.00050\nIteration: 373, Log-Lik: -13066.054, Max-Change: 0.00033\nIteration: 374, Log-Lik: -13066.054, Max-Change: 0.00041\nIteration: 375, Log-Lik: -13066.054, Max-Change: 0.00049\nIteration: 376, Log-Lik: -13066.054, Max-Change: 0.00034\nIteration: 377, Log-Lik: -13066.054, Max-Change: 0.00040\nIteration: 378, Log-Lik: -13066.053, Max-Change: 0.00050\nIteration: 379, Log-Lik: -13066.053, Max-Change: 0.00033\nIteration: 380, Log-Lik: -13066.053, Max-Change: 0.00041\nIteration: 381, Log-Lik: -13066.053, Max-Change: 0.00049\nIteration: 382, Log-Lik: -13066.053, Max-Change: 0.00034\nIteration: 383, Log-Lik: -13066.053, Max-Change: 0.00040\nIteration: 384, Log-Lik: -13066.053, Max-Change: 0.00050\nIteration: 385, Log-Lik: -13066.053, Max-Change: 0.00033\nIteration: 386, Log-Lik: -13066.053, Max-Change: 0.00041\nIteration: 387, Log-Lik: -13066.053, Max-Change: 0.00049\nIteration: 388, Log-Lik: -13066.053, Max-Change: 0.00034\nIteration: 389, Log-Lik: -13066.053, Max-Change: 0.00040\nIteration: 390, Log-Lik: -13066.053, Max-Change: 0.00049\nIteration: 391, Log-Lik: -13066.053, Max-Change: 0.00033\nIteration: 392, Log-Lik: -13066.053, Max-Change: 0.00041\nIteration: 393, Log-Lik: -13066.053, Max-Change: 0.00049\nIteration: 394, Log-Lik: -13066.053, Max-Change: 0.00034\nIteration: 395, Log-Lik: -13066.053, Max-Change: 0.00040\nIteration: 396, Log-Lik: -13066.053, Max-Change: 0.00049\nIteration: 397, Log-Lik: -13066.053, Max-Change: 0.00033\nIteration: 398, Log-Lik: -13066.053, Max-Change: 0.00041\nIteration: 399, Log-Lik: -13066.053, Max-Change: 0.00049\nIteration: 400, Log-Lik: -13066.053, Max-Change: 0.00034\nIteration: 401, Log-Lik: -13066.053, Max-Change: 0.00040\nIteration: 402, Log-Lik: -13066.053, Max-Change: 0.00049\nIteration: 403, Log-Lik: -13066.053, Max-Change: 0.00033\nIteration: 404, Log-Lik: -13066.053, Max-Change: 0.00041\nIteration: 405, Log-Lik: -13066.053, Max-Change: 0.00049\nIteration: 406, Log-Lik: -13066.053, Max-Change: 0.00034\nIteration: 407, Log-Lik: -13066.053, Max-Change: 0.00040\nIteration: 408, Log-Lik: -13066.052, Max-Change: 0.00049\nIteration: 409, Log-Lik: -13066.052, Max-Change: 0.00033\nIteration: 410, Log-Lik: -13066.052, Max-Change: 0.00041\nIteration: 411, Log-Lik: -13066.052, Max-Change: 0.00049\nIteration: 412, Log-Lik: -13066.052, Max-Change: 0.00034\nIteration: 413, Log-Lik: -13066.052, Max-Change: 0.00040\nIteration: 414, Log-Lik: -13066.052, Max-Change: 0.00049\nIteration: 415, Log-Lik: -13066.052, Max-Change: 0.00033\nIteration: 416, Log-Lik: -13066.052, Max-Change: 0.00041\nIteration: 417, Log-Lik: -13066.052, Max-Change: 0.00049\nIteration: 418, Log-Lik: -13066.052, Max-Change: 0.00034\nIteration: 419, Log-Lik: -13066.052, Max-Change: 0.00040\nIteration: 420, Log-Lik: -13066.052, Max-Change: 0.00049\nIteration: 421, Log-Lik: -13066.052, Max-Change: 0.00033\nIteration: 422, Log-Lik: -13066.052, Max-Change: 0.00041\nIteration: 423, Log-Lik: -13066.052, Max-Change: 0.00049\nIteration: 424, Log-Lik: -13066.052, Max-Change: 0.00034\nIteration: 425, Log-Lik: -13066.052, Max-Change: 0.00040\nIteration: 426, Log-Lik: -13066.052, Max-Change: 0.00049\nIteration: 427, Log-Lik: -13066.052, Max-Change: 0.00033\nIteration: 428, Log-Lik: -13066.052, Max-Change: 0.00041\nIteration: 429, Log-Lik: -13066.052, Max-Change: 0.00049\nIteration: 430, Log-Lik: -13066.052, Max-Change: 0.00034\nIteration: 431, Log-Lik: -13066.052, Max-Change: 0.00040\nIteration: 432, Log-Lik: -13066.052, Max-Change: 0.00049\nIteration: 433, Log-Lik: -13066.052, Max-Change: 0.00033\nIteration: 434, Log-Lik: -13066.052, Max-Change: 0.00041\nIteration: 435, Log-Lik: -13066.052, Max-Change: 0.00049\nIteration: 436, Log-Lik: -13066.052, Max-Change: 0.00034\nIteration: 437, Log-Lik: -13066.052, Max-Change: 0.00040\nIteration: 438, Log-Lik: -13066.052, Max-Change: 0.00049\nIteration: 439, Log-Lik: -13066.051, Max-Change: 0.00033\nIteration: 440, Log-Lik: -13066.051, Max-Change: 0.00041\nIteration: 441, Log-Lik: -13066.051, Max-Change: 0.00049\nIteration: 442, Log-Lik: -13066.051, Max-Change: 0.00034\nIteration: 443, Log-Lik: -13066.051, Max-Change: 0.00040\nIteration: 444, Log-Lik: -13066.051, Max-Change: 0.00049\nIteration: 445, Log-Lik: -13066.051, Max-Change: 0.00033\nIteration: 446, Log-Lik: -13066.051, Max-Change: 0.00041\nIteration: 447, Log-Lik: -13066.051, Max-Change: 0.00049\nIteration: 448, Log-Lik: -13066.051, Max-Change: 0.00034\nIteration: 449, Log-Lik: -13066.051, Max-Change: 0.00040\nIteration: 450, Log-Lik: -13066.051, Max-Change: 0.00049\nIteration: 451, Log-Lik: -13066.051, Max-Change: 0.00033\nIteration: 452, Log-Lik: -13066.051, Max-Change: 0.00041\nIteration: 453, Log-Lik: -13066.051, Max-Change: 0.00049\nIteration: 454, Log-Lik: -13066.051, Max-Change: 0.00034\nIteration: 455, Log-Lik: -13066.051, Max-Change: 0.00040\nIteration: 456, Log-Lik: -13066.051, Max-Change: 0.00049\nIteration: 457, Log-Lik: -13066.051, Max-Change: 0.00033\nIteration: 458, Log-Lik: -13066.051, Max-Change: 0.00041\nIteration: 459, Log-Lik: -13066.051, Max-Change: 0.00049\nIteration: 460, Log-Lik: -13066.051, Max-Change: 0.00033\nIteration: 461, Log-Lik: -13066.051, Max-Change: 0.00040\nIteration: 462, Log-Lik: -13066.051, Max-Change: 0.00049\nIteration: 463, Log-Lik: -13066.051, Max-Change: 0.00033\nIteration: 464, Log-Lik: -13066.051, Max-Change: 0.00040\nIteration: 465, Log-Lik: -13066.051, Max-Change: 0.00049\nIteration: 466, Log-Lik: -13066.051, Max-Change: 0.00033\nIteration: 467, Log-Lik: -13066.051, Max-Change: 0.00040\nIteration: 468, Log-Lik: -13066.051, Max-Change: 0.00049\nIteration: 469, Log-Lik: -13066.051, Max-Change: 0.00033\nIteration: 470, Log-Lik: -13066.050, Max-Change: 0.00040\nIteration: 471, Log-Lik: -13066.050, Max-Change: 0.00049\nIteration: 472, Log-Lik: -13066.050, Max-Change: 0.00033\nIteration: 473, Log-Lik: -13066.050, Max-Change: 0.00040\nIteration: 474, Log-Lik: -13066.050, Max-Change: 0.00049\nIteration: 475, Log-Lik: -13066.050, Max-Change: 0.00033\nIteration: 476, Log-Lik: -13066.050, Max-Change: 0.00040\nIteration: 477, Log-Lik: -13066.050, Max-Change: 0.00048\nIteration: 478, Log-Lik: -13066.050, Max-Change: 0.00033\nIteration: 479, Log-Lik: -13066.050, Max-Change: 0.00040\nIteration: 480, Log-Lik: -13066.050, Max-Change: 0.00049\nIteration: 481, Log-Lik: -13066.050, Max-Change: 0.00033\nIteration: 482, Log-Lik: -13066.050, Max-Change: 0.00040\nIteration: 483, Log-Lik: -13066.050, Max-Change: 0.00048\nIteration: 484, Log-Lik: -13066.050, Max-Change: 0.00033\nIteration: 485, Log-Lik: -13066.050, Max-Change: 0.00040\nIteration: 486, Log-Lik: -13066.050, Max-Change: 0.00049\nIteration: 487, Log-Lik: -13066.050, Max-Change: 0.00033\nIteration: 488, Log-Lik: -13066.050, Max-Change: 0.00040\nIteration: 489, Log-Lik: -13066.050, Max-Change: 0.00048\nIteration: 490, Log-Lik: -13066.050, Max-Change: 0.00033\nIteration: 491, Log-Lik: -13066.050, Max-Change: 0.00040\nIteration: 492, Log-Lik: -13066.050, Max-Change: 0.00049\nIteration: 493, Log-Lik: -13066.050, Max-Change: 0.00033\nIteration: 494, Log-Lik: -13066.050, Max-Change: 0.00040\nIteration: 495, Log-Lik: -13066.050, Max-Change: 0.00048\nIteration: 496, Log-Lik: -13066.050, Max-Change: 0.00033\nIteration: 497, Log-Lik: -13066.050, Max-Change: 0.00040\nIteration: 498, Log-Lik: -13066.050, Max-Change: 0.00049\nIteration: 499, Log-Lik: -13066.050, Max-Change: 0.00033\nIteration: 500, Log-Lik: -13066.050, Max-Change: 0.00040\n\n\nEM cycles terminated after 500 iterations.\n\n\n\n\nCalculating information matrix...\n\nfourpl_params <- coef(fourpl_fit, IRTpars = TRUE,\n                      simplify = TRUE)\nfourpl_items <- fourpl_params$items\nhead(fourpl_items)\n\n                 a          b            g         u\nreason.4  1.975112 -0.3394009 0.1103560321 0.9912975\nreason.16 1.603067 -0.8560177 0.0004110258 0.9673521\nreason.17 2.064785 -0.7469931 0.0007629951 0.9718849\nreason.19 1.911800 -0.6231126 0.0005020762 0.9058245\nletter.7  3.599069 -0.3507855 0.1257652136 0.8856107\nletter.33 3.398542 -0.3096880 0.1338100363 0.8530054\n\n\n결과에서 마지막 열(즉, 상한 점근)이 이번에는 0이 아닌 것을 볼 수 있는데, 이는 추정에 4PL 모델을 사용했기 때문입니다. 대부분의 문항에서 상한 점근 모수가 1에 가깝지만 상한 점근이 더 낮은 문항이 몇 개 있습니다(예: letter.7, letter.33). 이러한 문항에 올바르게 응답할 수 있는 최대 확률은 잠재 특성이 높은 피험자의 경우에도 1에 근접하지 않습니다. 이전 모델에서 했던 것처럼 4PL 모델의 문항 모수가 ICC에 미치는 영향을 시각적으로 살펴볼 수도 있습니다. 다음 코드는 item 13 및 16에 대한 ICC 그래프를 생성하는 명령을 보여줍니다.\n\nplot(fourpl_fit, type = \"trace\", which.items = c(13, 16))"
  },
  {
    "objectID": "chap05.html#irt-모델에서-능력-추정",
    "href": "chap05.html#irt-모델에서-능력-추정",
    "title": "5  이분 문항반응이론",
    "section": "5.4 IRT 모델에서 능력 추정",
    "text": "5.4 IRT 모델에서 능력 추정\n특정 IRT 모델을 사용하여 문항 모수를 추정하고 나면 다음 단계는 \\(N\\)개의 문항에 응답한 각 피험자의 잠재 특성 추정치를 구하는 것입니다. 잠재 특성 수준이 \\(\\theta_j\\)인 사람의 \\(N\\)개 문항에 대한 응답 벡터가 주어지면 IRT 모델의 모수(이 경우 3PL)가 주어진 각 문항에 대해 정답 확률인 \\(P(\\theta_j, a_i, b_i, c_i)\\)와 오답 확률인 \\(Q(\\theta_j, a_i, b_i, c_i) = 1 - P(\\theta_j, a_i, b_i, c_i)\\)를 계산할 수 있습니다. 응답 패턴에 있는 문항의 확률을 곱하면 다음과 같이 \\(N\\)개 문항에 대한 결합 우도 함수를 구할 수 있습니다.\n\\[\nL(\\theta_j)=\\prod_{i=1}^N P_i(\\theta_j, a_i, b_i, c_i)^{x_i}Q_i(\\theta_j, a_i, b_i, c_i)^{1-x_i}\n\\]\n\n여기서 \\(x_i\\)는 문항 \\(i\\)에 대한 피험자 \\(j\\)의 점수입니다(0 또는 1 중 하나).\n\n각각의 고유한 응답 패턴에 대해 단일 우도 함수가 있습니다. 아래에서는 결합 우도 함수를 통해 잠재 특성을 추정하는 데 널리 사용되는 세 가지 방법을 설명합니다.\n\n최대 우도 추정(MLE): 이 방법은 관찰된 피험자의 응답 패턴과 문항 모수가 주어졌을 때 가장 가능성이 높은 잠재 특성을 찾는 것을 목표로 합니다. 즉, MLE는 우도 함수를 최대화하는 추정치 \\(\\theta_j\\)를 찾습니다.\n최대 사후 추정(MAP): MLE 접근 방식의 일반적인 변형은 베이지안 모달 추정 절차로, 최대 사후 추정 또는 MAP라고도 하며, 여기서 결합 우도 함수에 가정된 모집단 분포를 나타내는 추가 곡선을 곱합니다. MAP는 이 사후 분포의 최빈값을 잠재 특성의 최종 추정치로 계산합니다.\n사후 기대치(EAP): MAP 접근 방식의 변형은 사후 분포의 최빈값 대신 평균을 사용하는 사후 기대치 또는 EAP입니다.\n\n베이지안 방법의 주요 장점은 피험자가 정답 또는 오답만 있는 경우에도 잠재 특성을 추정할 수 있는 반면, MLE 접근법은 응답 벡터에 변동성이 0인 경우 잠재 특성 추정치를 제공할 수 없다는 것입니다. 베이지안 방법을 사용하면 가정된 모집단 분포를 통해 추정된 모수에 편향이 도입됩니다. mirt 패키지는 fscores 함수를 통해 MLE, MAP 및 EAP 접근법을 사용하여 잠재 특성을 추정할 수 있습니다. 또한 fscores 함수는 합계 점수(Thissen, Pommerich, Billeaud, & Williams, 1995) 및 가중된 우도 추정(Warm, 1989)을 위해 EAP를 사용할 수 있습니다. MLE, MAP 및 EAP는 연구자 및 실무자가 일반적으로 사용하므로 아래에서는 이러한 방법에만 초점을 맞춥니다.\n다음 예에서는 SAPA 데이터 세트와 이 장의 앞부분에 적합했던 2PL 모델의 문항 모수를 사용하여 MLE, MAP 및 EAP 접근법을 사용하여 잠재 특성을 추정합니다.\n\nlatent_mle <- fscores(twopl_fit, method = \"ML\",\n                      full.scores = TRUE, full.scores.SE = TRUE)\n\nWarning: The following factor score estimates failed to converge successfully:\n    368,614,996\n\nlatent_map <- fscores(twopl_fit, method = \"MAP\",\n                      full.scores = TRUE, full.scores.SE = TRUE)\nlatent_eap <- fscores(twopl_fit, method = \"EAP\",\n                      full.scores = TRUE, full.scores.SE = TRUE)\n\n처음 6명의 피험자에 대한 MLE 잠재 특성 추정치를 보려면 latent_mle과 함께 head 함수를 사용하면 됩니다.\n\nhead(latent_mle)\n\n              F      SE_F\n[1,] -1.7233250 0.5971554\n[2,] -0.7311886 0.4026671\n[3,] -0.6771320 0.3986155\n[4,] -1.3901749 0.5032752\n[5,] -0.7127487 0.4012232\n[6,]  1.8175250 0.5662481\n\n\n결과에서 첫 번째 열(F1)은 추정된 잠재 특성을 나타내고 두 번째 열(즉, SE_F1)은 표준 오차를 나타냅니다. 세 가지 추정 방법을 비교하기 위해 첫 번째 열에 있는 추정된 잠재 특성을 세 가지 추정 방법에서 추출하고 이를 latent라는 하나의 데이터 프레임에 결합합니다.\n\nlatent <- data.frame(MLE = latent_mle[ ,1],\n                     MAP = latent_map[ ,1],\n                     EAP = latent_eap[ ,1])\nhead(latent)\n\n         MLE        MAP        EAP\n1 -1.7233250 -1.3365328 -1.4067370\n2 -0.7311886 -0.6307885 -0.6505215\n3 -0.6771320 -0.5854772 -0.6028731\n4 -1.3901749 -1.1338101 -1.1870565\n5 -0.7127487 -0.6153768 -0.6343019\n6  1.8175250  1.4356287  1.4935857\n\n\n세 가지 추정 방법이 비슷한 결과를 제공하며, MAP와 EAP의 추정치가 거의 동일하다는 것을 알 수 있습니다. 앞서 언급했듯이, 모든 응답이 정답이거나 오답인 경우 MLE 방법은 잠재 특성을 추정할 수 없습니다. SAPA 데이터 세트에는 모든 문항에 정답(예: 피험자 73, 89, 103)이나 오답(예: 피험자 105)으로 답한 피험자가 여러 명 있으므로 MLE는 이러한 피험자에 대한 잠재 특성을 추정할 수 없습니다. 아래에는 latent 데이터 프레임에서 이러한 피험자의 추정치를 출력하여 이를 보여줍니다.\n\nlatent[c(73, 89, 103, 105), ]\n\n     MLE       MAP       EAP\n73   Inf  1.985339  2.096258\n89   Inf  1.985339  2.096258\n103  Inf  1.985339  2.096258\n105 -Inf -1.864351 -1.980879\n\n\n잠재 특성 추정치 간의 기술통계 및 상관관계를 계산하려면 먼저 is.finite 함수를 사용하여 MLE 열에서 Inf 또는 -Inf 점수가 있는 피험자를 제거하고 나머지 데이터를 latent_est로 저장합니다. 결과 데이터 프레임에는 MLE, MAP 및 EAP 방법에서 유효한 잠재 특성 추정치가 있는 1461명의 피험자가 포함됩니다.\n\nlatent_est <- latent[is.finite(latent$MLE), ]\n\n다음으로 summary 및 apply 함수를 사용하여 기술통계를 얻습니다. 다시 한 번 설명하자면, apply 함수를 사용하려면 데이터, 함수를 적용하려는 데이터의 한계(행의 경우 1, 열의 경우 2), 적용하려는 함수를 지정해야 합니다. 아래에서는 apply 함수를 사용하여 추정치의 요약 통계 및 표준 편차(sd 함수를 통해)를 계산하고 데이터에서 열로 정렬되어 있으므로 2를 지정합니다.\n\napply(latent_est, 2, summary)\n\n                 MLE         MAP          EAP\nMin.    -2.439114424 -1.62922178 -1.725578545\n1st Qu. -0.689406667 -0.59580053 -0.613718783\nMedian  -0.025201555 -0.02195921 -0.019611185\nMean     0.002659148  0.00357282  0.001146392\n3rd Qu.  0.664415606  0.57240513  0.584675590\nMax.     2.590186515  1.76241571  1.851380586\n\napply(latent_est, 2, sd)\n\n      MLE       MAP       EAP \n1.0112851 0.8021994 0.8345610 \n\n\n세 가지 추정 방법의 잠재 특성의 평균과 중앙값은 매우 유사합니다. 그러나 MLE 접근법의 잠재 특성 추정치의 범위와 표준 편차는 다른 두 방법의 추정치보다 큽니다. 이는 MAP 및 EAP 방법이 추정 과정에서 잠재 특성 분포를 이전 평균으로 정의된 모집단 평균으로 축소하는 것으로 알려져 있기 때문에 예상되는 결과입니다(Reise & Revicki, 2014).\n다음으로 cor 함수를 사용하여 잠재 특성 추정치 간의 상관관계를 계산합니다.\n\ncor(latent_est)\n\n          MLE       MAP       EAP\nMLE 1.0000000 0.9973045 0.9978970\nMAP 0.9973045 1.0000000 0.9999447\nEAP 0.9978970 0.9999447 1.0000000\n\n\n잠재 특성 추정치 간의 상관관계가 매우 높다는 것은 세 가지 추정 방법 간의 높은 일치도를 나타냅니다. 그러나 MAP 및 EAP 방법을 사용할 때 강력한 사전 분포를 포함하면 사후 추정치에 영향을 미칠 수 있으므로 항상 그런 것은 아닙니다. 세 가지 추정 방법 간의 연관성을 더 잘 이해하기 위해 pair 함수를 사용하여 각 방법에 대해 추정된 잠재 특성의 산점도 행렬을 생성합니다.\n\npairs(latent_est)\n\n\n\n\n그림 5.13은 MAP 방법과 EAP 방법의 잠재 특성 추정치가 높은 상관관계와 선형적 연관성을 보이는 반면, MLE 방법의 잠재 특성 추정치는 MAP 방법과 약간 비선형적인 관계를 보여줍니다. 비선형성은 특히 분포의 꼬리 부분에서 두드러집니다.\n마지막으로, MLE, MAP 및 EAP 방법으로 추정된 잠재 특성 값 간의 차이에 대한 표본 표준 편차, 즉 평균 제곱 편차근(RMSD)를 계산합니다. RMSD는 다음과 같이 계산할 수 있습니다.\n\\[\nRMSD=\\sqrt{\\sum_{j=1}^N (\\hat\\theta_{1j}-\\hat\\theta_{2j})^2 \\over N}\n\\]\n\n여기서 \\(\\hat\\theta_{1j}\\) 및 \\(\\hat\\theta_{2j}\\)는 첫 번째 및 두 번째 추정 방법에서 피험자 \\(j\\)에 대한 잠재 특성 추정치입니다.\n\n추정 방법의 순서(예: MLE-MAP 대 MAP-MLE)는 방정식에서 이 차이를 제곱하기 때문에 RMSD 값에 영향을 미치지 않는다는 점에 유의하세요. hemp에서 rmsd 함수를 사용하여 RMSD를 계산할 수 있습니다.\n\nrmsd(latent_est$MLE, latent_est$MAP)\n\n[1] 0.03492328\n\n\n\nrmsd(latent_est$MLE, latent_est$EAP)\n\n[1] 0.05782215\n\n\n\nrmsd(latent_est$MAP, latent_est$EAP)\n\n[1] 0.09274544\n\n\n결과는 MLE 방법과 MAP 방법의 잠재 특성 추정치 간의 차이가 가장 작은 반면, MAP 방법과 EAP 방법의 잠재 특성 추정치 간의 차이가 가장 크다는 것을 나타냅니다."
  },
  {
    "objectID": "chap05.html#모델-진단",
    "href": "chap05.html#모델-진단",
    "title": "5  이분 문항반응이론",
    "section": "5.5 모델 진단",
    "text": "5.5 모델 진단\n이 장의 시작 부분에서 IRT의 가정(예: 단일차원성, 지역 독립성, 문항 모수의 불변성)에 대해 간략하게 소개했습니다. 이러한 가정이 어느 정도 충족되면 다음 단계는 특정 IRT 모델을 선택하여 응답 데이터에 적용하는 것입니다. 모든 통계적 노력에서와 마찬가지로 선택한 IRT 모델과 문항 응답 데이터 간에 불일치가 관찰될 수 있습니다. 선택한 IRT 모델의 근거를 제공하려면 이러한 잠재적 불일치를 식별하는 데 도움이 되는 모델 진단을 수행하는 것이 중요합니다.\nIRT에서 모델 진단은 문항, 개인 및 모델 수준(즉, 모델의 적합도)의 세 가지 수준에서 검토할 수 있습니다. 다음 섹션에서는 IRT에서 모델 진단 방법에 대해 간략하게 설명하고 mirt 패키지를 사용하여 이러한 방법의 사용을 시연합니다. IRT의 모델 진단에 대한 자세한 논의는 Maydeu-Olivares(2013), Swaminathan, Hambleton, Rogers(2006) 및 기타 리소스를 검토해 보시기 바랍니다.\n\n5.5.1 문항 적합\nIRT에서 문항 적합도를 평가하는 방법에는 일반적으로 문항 적합도 통계와 문항 적합도의 그래픽 분석이라는 두 가지 접근 방식이 있습니다. 가장 자주 사용되는 문항 적합도 통계로는 signed \\(\\chi^2\\) 검사(Orlando & Thissen, 2000), Bock’s \\(\\chi^2\\) 방법(Bock, 1972), Yen의 \\(Q1\\) 통계(Yen, 1981), \\(G2\\) 통계(McKinley & Mills, 1985), 특히 Rasch 계열의 IRT 모델에 대한 infit 및 outfit 통계가 있습니다. Bock의 \\(\\chi^2\\) 방법, Yen의 \\(Q1\\) 통계, \\(G2\\) 통계와 같은 일부 방법은 경험적 확률과 모델 예측 확률을 비교하는 데 의존합니다. 이러한 방법의 경우 선택한 IRT 모델이 데이터에 적절히 부합한다는 귀무가설 하에서 유의성 검정을 사용할 수 있습니다. 일반적인 형식에서 이분 문항에 대한 \\(\\chi^2\\) 문항 적합도 통계는 다음과 같이 계산할 수 있습니다.\n\\[\n\\chi^2=\\sum_{j=1} ^J N_j{(O_j-E_j) ^2 \\over E_j(1-E_j)}\n\\]\n\n여기서 \\(j\\)는 잠재 특성 구간(예: \\theta = -2 ~ \\theta = -1.5)\n\\(O_j\\)는 잠재 특성 구간 \\(j\\)에서 관찰된(즉, 경험적) 정답을 맞힐 확률\n\\(E_j\\)는 적합된 IRT 모델을 기반으로 잠재 특성 구간 \\(j\\)에서 기대된(즉, 이론적) 정답을 맞힐 확률\n\\(N_j\\)는 잠재 특성 구간 \\(j\\)에 위치한 피험자 수입니다.\n\nBock의 \\(\\chi^2\\) 방법에서는 각 잠재 특성 구간은 동일한 크기를 가지며 각 구간의 잠재 특성 중앙값을 사용하여 정답 예상 비율을 계산합니다. 이와 대조적으로, Yen의 Q1 통계에서는 동일한 빈도를 가진 10개의 잠재 특성 구간이 필요하며, 예상 확률은 정답 확률의 평균이 됩니다. 두 통계의 자유도는 모두 \\(J-m\\)으로 같으며, 여기서 \\(m\\)은 IRT 모델에서 문항 모수의 수입니다(예: 2PL 모델의 경우 m = 2).\nOrlando와 Thissen(2000)은 유의미한 문항 부적합이 존재하면 잠재 특성 추정치가 편향되어 \\(\\chi^2\\) 방법의 문항 적합도 검사에 영향을 미칠 수 있다고 주장했습니다. 따라서 Orlando와 Thissen(2000)은 잠재 특성 추정치 대신 원점수에 따라 피험자를 그룹화할 것을 제안했습니다. 이 대체 방법을 signed \\(\\chi^2\\) 통계라고 하며, \\(S - X^2\\) 통계라고도 합니다. 주어진 문항에 대한 signed \\(\\chi^2\\) 통계는 다음과 같이 작성할 수 있습니다.\n\\[\nS-X^2=\\sum_{k} ^{n-1} N_k{(O_k-E_k) ^2 \\over E_k(1-E_k)}\n\\]\n\n여기서 \\(n\\)은 검사의 문항 수이고, \\(k\\)는 원점수(즉, 정답 수)이며, 다른 요소는 방정식 5.11의 요소와 동일합니다.\n\nsigned \\(\\chi^2\\) 통계의 자유도는 \\((n - 1) - m\\) 이며, 여기서 \\(m\\)은 다시 IRT 모형의 문항 모수 수입니다.\n\\(\\chi^2\\) 문항 적합도 통계와 달리 \\(G2\\) 통계는 우도비 검정을 기반으로 합니다. 방정식 5.11의 동일한 요소를 사용하여 \\(G2\\) 통계는 다음과 같이 계산할 수 있습니다.\n\\[\nG^2=2\\sum_{j=1} ^{J} N_j(O_j log{O_j \\over E_j} + (1 - O_j)log{1 - O_j \\over 1 - E_j})\n\\]\n\\(G2\\) 통계의 자유도는 \\(J - m\\)과 같습니다. 앞서 언급했듯이, Bock의 \\(\\chi^2\\) 통계, Yen의 \\(Q1\\) 통계 및 \\(G2\\) 통계는 문항이 IRT 모델에 적절하게 적합하다는 영가설 하에서 작동합니다. 따라서 특정 문항에 대한 영가설을 기각한다는 것은 해당 문항이 모델에 적절하게 맞지 않을 수 있음을 의미합니다.\n다음 예에서는 mirt 패키지의 itemfit 함수를 사용하여 Rasch 모델의 문항 모수에 대한 문항 적합도 통계를 검사합니다. itemfit 함수에서 fit_stats = c(“S-X2”, “G2”)를 지정하여 \\(S - X^2\\) 및 \\(G2\\) 문항 적합도 통계를 얻습니다. impute 옵션은 결측 데이터가 있을 때 수행할 대체 횟수를 지정합니다. SAPA 데이터 세트에 결측 응답이 여러 개 있으므로 impute = 10을 사용하여 10개의 대체된 데이터 세트를 만듭니다. 결과를 rasch_itemfit으로 저장하고 head 함수를 사용하여 결과의 처음 여섯 행을 출력합니다.\n\nrasch_itemfit <- itemfit(rasch_fit,\n                         fit_stats = c(\"S_X2\", \"G2\"),\n                         na.rm=T)\n\nSample size after row-wise response data removal: 1523\n\nhead(rasch_itemfit)\n\n       item     G2 df.G2 RMSEA.G2  p.G2   S_X2 df.S_X2 RMSEA.S_X2 p.S_X2\n1  reason.4 53.846     9    0.057 0.000 20.604      12      0.022  0.056\n2 reason.16 30.648     9    0.040 0.000 10.862      12      0.000  0.541\n3 reason.17 47.332     9    0.053 0.000 19.907      12      0.021  0.069\n4 reason.19 28.971     9    0.038 0.001 26.680      12      0.028  0.009\n5  letter.7 29.814     9    0.039 0.000 12.495      12      0.005  0.407\n6 letter.33 15.784     9    0.022 0.072 26.988      13      0.027  0.012\n\n\n결과에서 G2, df.G2 및 p.G2 열은 \\(G2\\) 통계, \\(G2\\) 통계의 자유도 및 \\(G2\\) 통계의 p값을 나타냅니다. 마찬가지로 S_X2, df.S_X2 및 p.S_X2 열은 \\(S - X^2\\) 통계, \\(S - X^2\\) 통계의 자유도 및 \\(S - X^2\\) 통계의 p값을 나타냅니다. \\(\\alpha\\) = .05를 유의 수준으로 사용하는 경우 특정 문항에 대한 p값이 .05 미만이면 해당 문항이 Rasch 모형에 맞지 않음을 나타냅니다.\nitemfit 함수는 선택한 IRT 모델과 응답 데이터 간의 전반적인 불일치 정도를 정량화하는 \\(Z_h\\), infit 및 outfit 통계와 같은 다른 문항 적합도 측정값도 제공합니다. infit 및 outfit 통계는 Rasch 모델 제품군(예: Rasch 모델, 부분 점수 모델 및 등급 척도 모델)에 대해서만 사용할 수 있습니다. 다음 예에서는 fit_stats = c(“Zh”, “infit”)를 사용하여 Rasch 모델에 대한 \\(Z_h\\), infit 및 outfit 통계를 구하는 방법을 보여 줍니다.\n\nitemfit(rasch_fit, \n        fit_stats = c(\"Zh\", \"infit\"), \n        na.rm=T)\n\nSample size after row-wise response data removal: 1523\n\n\n        item     Zh outfit z.outfit infit z.infit\n1   reason.4  4.937  0.777   -4.604 0.865  -5.118\n2  reason.16  2.928  0.836   -2.723 0.911  -2.983\n3  reason.17  5.250  0.749   -4.349 0.836  -5.689\n4  reason.19  3.404  0.869   -2.795 0.904  -3.681\n5   letter.7  4.642  0.819   -4.085 0.874  -4.998\n6  letter.33  2.969  0.903   -2.267 0.918  -3.275\n7  letter.34  5.179  0.836   -3.563 0.850  -5.911\n8  letter.58  3.873  0.841   -3.963 0.901  -3.993\n9  matrix.45  0.304  0.969   -0.738 0.995  -0.183\n10 matrix.46  0.622  0.963   -0.853 0.985  -0.604\n11 matrix.47  2.869  0.866   -2.856 0.926  -2.819\n12 matrix.55 -2.507  1.101    2.021 1.068   2.406\n13  rotate.3  3.067  0.975   -0.231 0.834  -4.185\n14  rotate.4  4.517  0.782   -2.685 0.803  -5.364\n15  rotate.6  3.541  0.858   -2.392 0.878  -4.042\n16  rotate.8  2.103  0.894   -1.086 0.888  -2.666\n\n\n문헌에는 \\(Z_h\\), infit 및 outfit 통계치를 해석하기 위한 컷오프 값과 관련하여 다양한 권장 사항이 있습니다. 이 장에서는 이러한 권장 사항에 대한 자세한 내용은 다루지 않습니다. 일반적으로 문항에 대한 결정을 문항 적합도 통계에만 근거하여 내리는 것은 권장하지 않습니다. 이러한 통계는 종종 일치하지 않는 경우가 많으므로(위의 reason.19 문항에서 볼 수 있듯이) 주의해서 사용해야 합니다. 따라서 위에 제시된 통계는 독자들에게 통계를 알리기 위한 것이며 교훈적인 목적으로만 표시됩니다.\nitemfit 함수는 문항에 대한 경험적 그래프를 만드는 데도 사용할 수 있으며, 이는 문항 적합도 통계보다 문항 부적합을 감지하는 데 더 유용할 수 있습니다. 다음 예에서는 SAPA 데이터 집합의 item 1에 대한 경험적 그래프를 만듭니다. 이 그래프는 경험적 데이터 요소와 Rasch 모델에 대한 이론적 ICC를 함께 보여줍니다. 경험적 데이터가 ICC에 가까울수록 문항 적합도가 더 좋으며, 그림 5.14에 따르면 문항 1의 경우가 이에 해당합니다.\n\nitemfit(rasch_fit, empirical.plot = 1)\n\n\n\n\n\n\n5.5.2 피험자 적합도\nIRT의 맥락에서, 피험자 적합도는 피험자의 반응 패턴과 응답 데이터를 모델링하기 위해 선택한 IRT 모델 간의 정렬을 의미합니다. 피험자 적합도 지수는 피험자 수준에서 선택한 모델의 타당성과 추정된 잠재 특성 수준의 유의성을 평가하는 데 사용됩니다(Embretson & Reise, 2000). 문헌에는 IRT 모델에 대해 다양한 피험자 적합도 지수가 제안되어 있습니다. 이 섹션에서는 특히 Drasgow, Levine, Williams(1985)가 처음 제안한 표준화된 적합도 지수인 \\(Z_h\\)에 초점을 맞춥니다. 잠재 특성 수준 \\(\\theta_j\\)를 가진 피험자 \\(j\\)에 대한 \\(Z_h\\) 통계는 다음과 같이 계산할 수 있습니다.\n\\[\nZ_h={\\sum [logL|\\theta_j-\\sum E(LogL|\\theta_j)] \\over \\sqrt(\\sum V(LogL|\\theta_j))}\n\\]\n여기서 \\(LogL\\)은 피험자 \\(j\\)의 반응 패턴에 대한 로그 확률 값이고, \\(E(LogL|\\theta_j)\\)는 \\(\\theta_j\\)에 조건부 로그 확률의 표집 분포에 대한 평균 로그 확률 값이며, \\(V(LogL|\\theta_j\\))는 로그 확률 값의 표집 분포의 분산입니다. \\(Z_h\\)는 표준 정규 분포를 따르는 표준화된 통계이므로 피험자의 반응 패턴이 선택한 IRT 모델과 일치하는 경우 \\(Z_h\\)의 기대값은 0입니다. 큰 음의 \\(Z_h\\) 값(예: \\(Z_h < -2\\))은 피험자 부적합을 나타냅니다. 큰 양의 \\(Z_h\\) 값은 피험자의 반응 패턴에 대한 우도가 선택한 IRT 모델에 따라 예측된 우도보다 높음을 나타내며(Embretson & Reise, 2000), 이는 잠재 특성 추정에도 문제가 될 수 있습니다.\n다음 예에서는 mirt 패키지의 personfit 함수를 사용하여 SAPA 데이터 세트에서 피험자의 응답 패턴에 대한 \\(Z_h\\) 통계를 얻습니다. personfit 함수를 사용하려면 반응 데이터에 결측치가 없어야 합니다. 따라서 먼저 SAPA 데이터 세트에서 결측치가 있는 피험자를 제거하고, 전체 데이터 세트를 사용하여 Rasch 모델을 다시 적합하고, 피험자 적합도 통계를 계산한 다음, 처음 몇 명의 피험자에 대한 적합도 통계를 출력합니다. 이번에는 mirt가 로그 우도 변경에 대한 정보를 R 콘솔에 출력하지 못하도록 verbose = FALSE 인수를 지정합니다.\n\nSAPA_nomiss <- na.omit(SAPA)\nrasch_mod <- \"F = 1 - 16\"\nrasch_fit <- mirt(data = SAPA_nomiss, model = rasch_mod,\n                  itemtype = \"Rasch\", SE = TRUE,\n                  verbose = FALSE)\nrasch_personfit <- personfit(rasch_fit)\nhead(rasch_personfit)\n\n     outfit   z.outfit     infit    z.infit         Zh\n1 1.2568894  0.5629416 1.0167398  0.1760094 -0.2366800\n2 1.1913429  0.5135685 1.0413377  0.2503287 -0.3039963\n3 0.7145810 -0.5621469 0.8733417 -0.5890664  0.6562832\n4 0.5611157 -0.3596852 0.7938685 -0.4142847  0.5659128\n5 0.7357641 -0.5034390 0.8989894 -0.4512733  0.5565218\n6 0.4846891 -0.6398586 0.7733773 -0.4545129  0.6154778\n\n\n결과에서 처음 네 개의 열인 outfit, z.outfit, infit, z.infit은 각각 infit 및 outfit 피험자 적합도 통계에 해당합니다. 마지막 열인 Zh는 \\(Z_h\\) 통계를 기반으로 피험자 적합도를 검사하는 데 사용할 수 있습니다. 결과는 처음 6명의 피험자의 반응 패턴이 \\(Z_h\\) 통계가 -2보다 크기 때문에 Rasch 모델과 일치한다는 것을 보여줍니다. hist 함수를 사용하여 \\(Z_h\\) 통계 분포의 히스토그램을 쉽게 만들 수도 있습니다. abline(v = -2, lwd = 2, lty = 2)을 사용하여 피험자 부적합이 있는 피험자를 식별하기 위한 기준점으로 Zh = -2 에 수직 점선을 그립니다. 그림 5.15는 대부분의 피험자에 대한 \\(Z_h\\) 통계가 -2보다 크다는 것을 보여 주며, 이는 대부분의 피험자가 선택된 IRT 모델에 적합하다는 것을 의미합니다.\n\nhist(rasch_personfit$Zh, xlab=\"Zh Statistic\")\nabline(v = -2, lwd = 2, lty = 2)\n\n\n\n\n마지막으로 rownames 함수를 사용하여 \\(Z_h\\) 통계가 -2보다 작은 피험자를 하위 세트로 만들어 출력합니다. nrow 함수를 사용하여 Rasch 모델에 맞지 않는 피험자가 40명임을 알 수 있습니다.\n\nrasch_misfits <- subset(rasch_personfit, Zh < -2)\nrownames(rasch_misfits)\n\n [1] \"41\"   \"63\"   \"65\"   \"98\"   \"214\"  \"227\"  \"268\"  \"269\"  \"275\"  \"354\" \n[11] \"368\"  \"393\"  \"411\"  \"445\"  \"466\"  \"470\"  \"503\"  \"524\"  \"534\"  \"537\" \n[21] \"560\"  \"566\"  \"597\"  \"619\"  \"668\"  \"684\"  \"735\"  \"804\"  \"806\"  \"818\" \n[31] \"849\"  \"889\"  \"946\"  \"1017\" \"1092\" \"1109\" \"1326\" \"1337\" \"1394\" \"1464\"\n\n\n\nnrow(rasch_misfits)\n\n[1] 40\n\n\n\n\n5.5.3 모델 선택\nIRT에서 모델 선택은 평가의 기반이 되는 이론과 반응 데이터의 특성에 따라 달라집니다. 예를 들어, 모든 문항의 변별도가 동일하다고 가정하면 다른 모델(예: 2PL 및 3PL)보다 1PL 모델(또는 Rasch 모델)을 사용하는 것이 더 좋습니다. 그러나 문항의 변별도 모수가 크게 다를 경우 문항 변별도 모수를 모든 문항에서 동일하도록 제한하는 것이 최선의 결정이 아닐 수 있습니다. 따라서 동일한 데이터에 서로 다른 IRT 모델을 적용하고 이러한 모델의 적합도를 비교할 수 있습니다. 단일차원 IRT 모델에서 이 비교는 여러 가지 방법으로 수행할 수 있습니다. 1PL, 2PL 및 3PL IRT 모델은 내재된 것으로 간주되므로(예: 변별도 모수가 문항 전체에서 동일하도록 제한하는 경우 1PL은 2PL 내에 내재되고, 의사 추측도 모수가 문항 전체에서 0이라는 추가 제약을 하는 경우 3PL 안에 내재됨) 모델의 전체 적합도를 비교하기 위해 확률 기반 통계를 사용할 수 있습니다. mirt 패키지에서 모델 비교는 anova 함수를 사용하여 수행할 수 있습니다.\n다음 예에서는 SAPA 데이터 세트에 대해 이전에 적합화된 모델을 사용하여 모델 비교를 수행하는 방법을 보여 줍니다. 첫 번째 비교는 1PL 모델과 2PL 모델 간의 비교입니다. 모델 적합도와 관련하여 2PL 모델이 1PL 모델에 비해 유의미한 개선을 제공하는지 알고 싶습니다. 앞서 1PL 모델과 2PL 모델을 적합하고 그 결과를 onepl_fit 및 twopl_fit으로 저장했습니다. 두 모델을 비교하기 위해 anova 함수를 사용합니다.\n\nanova(onepl_fit, twopl_fit)\n\n               AIC    SABIC       HQ      BIC    logLik     X2 df p\nonepl_fit 26566.50 26603.10 26600.23 26657.11 -13266.25            \ntwopl_fit 26464.79 26533.69 26528.28 26635.34 -13200.40 131.71 15 0\n\n\n여러 가지 모델 적합도 지수인 AIC, AICc(표본 크기 보정 AIC), SABIC 및 BIC가 출력에 표시됩니다. 이러한 적합도 지수가 작을수록 모델이 데이터에 더 잘 맞는다는 의미입니다. 결과에서 모든 적합도 지수가 2PL 모델이 더 작다는 것을 알 수 있으며, 이는 2PL 모델이 1PL 모델보다 SAPA 데이터 집합에 더 잘 맞는다는 것을 의미합니다. 또한 anova 함수는 두 모델의 로그 우도 값을 기반으로 우도비 검정을 수행합니다. 두 모델의 로그 우도 값의 절대 차이는 두 모델 간에 모델 적합도에 차이가 없다는 영가설 하에서 두 모델 간의 추정된 모수 수 차이와 동일한 자유도를 갖는 카이제곱(\\(\\chi^2\\)) 분포를 갖습니다. 즉, 모수가 더 많은 모델은 모수가 더 적은 모델보다 데이터에 더 잘 맞는 것으로 가정합니다. 두 통계의 \\(\\chi^2\\) 에 대한 p값이 .05 미만인 경우(사실상 \\(\\alpha = . 05\\) 사용), 더 복잡한 모델이 더 단순한 모델보다 더 잘 맞는다고 결론을 내릴 수 있습니다.\n결과에서 \\(\\chi_{15}^2 = 131.71, p < .001\\)을 볼 수 있는데, 이는 2PL 모델이 SAPA 데이터 세트에 대해 1PL 모델보다 더 잘 맞는다는 것을 의미합니다. 이 결과는 1PL 모델보다 2PL 모델을 선호하는 모델 적합도 지수와 일치합니다. 다음 단계에서는 2PL 모델과 3PL 모델의 적합도를 비교합니다. 이 비교에서는 모델에 의사 추측도 모수를 포함하면 모델 적합도가 향상되는지 여부를 테스트합니다. 모든 모델 적합도 지수는 3PL 모델에서 더 작으며, 이는 2PL 모델보다 3PL 모델을 선호합니다. 우도비 검정( \\(\\chi^2_{16} = 160.058, p < .001)\\)은 통계적으로 유의미하며, 이는 3PL 모델이 2PL 모델에 비해 모델 적합도가 통계적으로 유의미하게 개선되었음을 의미합니다.\n\nanova(twopl_fit, threepl_fit)\n\n                 AIC    SABIC       HQ      BIC    logLik      X2 df p\ntwopl_fit   26464.79 26533.69 26528.28 26635.34 -13200.40             \nthreepl_fit 26336.74 26440.08 26431.96 26592.56 -13120.37 160.058 16 0\n\n\n마지막 비교는 3PL 모델과 4PL 모델 간의 비교입니다. 결과는 다시 한 번 더 복잡한 모델(즉, 4PL 모델)이 덜 복잡한 모델보다 SAPA 데이터 세트에 더 잘 맞는다는 것을 시사합니다.\n\nanova(threepl_fit, fourpl_fit)\n\n                 AIC    SABIC       HQ      BIC    logLik      X2 df p\nthreepl_fit 26336.74 26440.08 26431.96 26592.56 -13120.37             \nfourpl_fit  26260.10 26397.89 26387.07 26601.20 -13066.05 108.636 16 0\n\n\n모수가 많은 모델이 모수가 적은 모델보다 데이터에 더 잘 맞는 경향이 있다는 점에 유의해야 합니다. 따라서 전체 모델 적합도의 비교가 항상 어떤 모델을 선택해야 하는지에 대한 올바른 결정으로 이어지지는 않을 수 있습니다. 앞서 설명했듯이, 모델 선택은 단순히 모델 적합도 테스트나 평가에 대한 이론적 가정/예측에만 근거해서는 안 됩니다. 평가의 운명을 결정하기 위한 독립적인 단계가 아니라 검사 설계의 일부로 문항 모수 추정 및 모델 적합도를 검토할 것을 권장합니다."
  },
  {
    "objectID": "chap05.html#요약",
    "href": "chap05.html#요약",
    "title": "5  이분 문항반응이론",
    "section": "5.6 요약",
    "text": "5.6 요약\n이 장에서는 이분 문항 응답에 대한 단일차원 IRT 모델을 소개하고 mirt 패키지의 mirt 함수를 사용하여 이러한 모델을 추정하는 방법을 설명했습니다. 이 장에서 소개한 IRT 모델은 단일차원 검사 구조에서 이분법적으로 채점된 문항(예: 옳음 또는 그름, 동의 또는 비동의, 예 또는 아니오)에 적합합니다. mirt 함수는 이분 문항에 대한 일반적인 IRT 모델을 추정할 수 있습니다. 또한 사용자는 추가 요소를 추가하여 보다 전문화되거나 제약된 모델을 만들 수 있습니다(예: 모든 문항에서 하부 점근 모수가 동일하도록 제약). mirt 함수 외에도 문항 및 검사 수준에서 IRT 그래프를 생성하기 위한 mirt 패키지의 여러 그래픽 도구를 설명했습니다. 그런 다음 mirt 패키지의 fscores 함수를 사용하여 잠재 특성 추정치를 얻는 방법을 보여주었습니다. 이 함수는 MLE, EAP, MAP 접근법을 사용하여 잠재 특성 수준을 추정할 수 있습니다. 마지막으로 IRT의 모델 진단에 대한 섹션을 제공했습니다. 이 섹션에서는 문항 적합도, 피험자 적합도 및 전체 모델 적합도를 검사하기 위한 itemfit, personfit 및 anova 함수를 보여줍니다. 관심 있는 독자는 IRT 모델링에 사용할 수 있는 다른 R 패키지에 대한 설명을 보려면 CRAN의 “심리측정 작업 보기(Psychometrics Task View)”(Mair & Hatzinger, 2007b)를 확인해 보시기 바랍니다(CRAN 작업 보기에 대한 자세한 내용은 제12장 참조). 다음 장에서는 다분 문항에 대한 단일차원 IRT 모델에 중점을 둡니다."
  },
  {
    "objectID": "chap06.html#개요",
    "href": "chap06.html#개요",
    "title": "6  다분 문항반응이론",
    "section": "6.1 개요",
    "text": "6.1 개요\n제5장에서는 두 가지 응답 범주(예: 옳다 또는 그르다, 예 또는 아니오, 동의 또는 비동의)로 이분법적으로 채점된 문항에 대한 단일차원 IRT 모델을 소개했습니다. 문항이 두 개 이상의 응답 범주(서열 또는 명목척도)로 구성된 경우 이러한 문항을 다분 채점 문항(또는 다분 문항)이라고 합니다. 제6장에서는 다분 채점 문항에 대한 문항반응모델을 중점적으로 다룹니다. 다분 문항에 대한 IRT 모델은 이분으로 채점된 문항에 대한 IRT 모델(예: Rasch 모델, 1PL 모델 또는 2PL 모델)의 일반화된 형태라고 볼 수 있습니다. 제5장과 마찬가지로 제6장에서는 다분 채점 문항에 대해 설계된 다양한 IRT 모형을 제시하고 R에서 이러한 모형을 추정하는 방법을 설명합니다. 이 장에서 다루는 다분 IRT 모형에는 부분 점수 모델(Masters, 1982), 일반화 부분 점수 모델(Muraki, 1992), 평정 척도 모델(Andrich, 1978), 등급 반응 모델(Samejima, 1969), 명명 반응 모델(Bock, 1972), 내재 로짓 모델(Suh & Bolt, 2010) 등이 있습니다. 여기서는 다분 채점 문항에 대한 IRT 모델 추정을 시연하기 위해 mirt 패키지(Chalmers, 2012)를 사용하겠습니다.\n이 장에서는 측정 척도(예: 서열 또는 명목척도)와 Rasch 모형 계열에 속하는지 여부에 따라 다분 IRT 모형을 세 가지 그룹으로 분류합니다:\n\n서열 척도 문항에 대한 다분 Rasch 모델\n서열 척도 문항에 대한 다분 비-Rasch 모델\n명목 척도 문항에 대한 다분 IRT 모델\n\n다른 연구자들도 다분 IRT 모델에 대해 위와 유사한 분류를 제안했습니다(예: De Ayala, 2013)."
  },
  {
    "objectID": "chap06.html#서열-척도-문항에-대한-다분-rasch-모델",
    "href": "chap06.html#서열-척도-문항에-대한-다분-rasch-모델",
    "title": "6  다분 문항반응이론",
    "section": "6.2 서열 척도 문항에 대한 다분 Rasch 모델",
    "text": "6.2 서열 척도 문항에 대한 다분 Rasch 모델\n부분 점수 모델(Masters, 1982)과 평정 척도 모델(Andrich, 1978)은 다분 형태의 Rasch 모델로 간주됩니다. 이러한 모델에서는 다분으로 채점된 서열척도 문항에서 인접한 범주(예, 매우 동의하지 않음, 동의하지 않음, 동의함, 또는 매우 동의함)는 이분 IRT 모델에서와 마찬가지로 실제로는 두 개의 이분법적 범주입니다. 따라서 이 모델에서는 응답자의 잠재 특성 수준을 기반으로 상위 범주(예: 매우 동의함 vs 동의함)를 얻을 확률을 추정하기 위해 이분 IRT 모델과 동일한 논리를 사용합니다. 문항 모수를 추정하는 데 동일한 메커니즘을 사용하지만, 부분 점수 모델(Masters, 1982)과 평정 척도 모델(Andrich, 1978)은 범주 경계(즉, 임계값)를 추정하는 데 있어 서로 다릅니다. 다음 섹션에서는 이러한 모델에 대해 간략하게 설명하고 R의 mirt 패키지(Chalmers, 2012)를 사용하여 추정하는 방법을 설명합니다.\n\n6.2.1 부분 점수 모델\n인접 범주 로짓 모델이라고도 하는 부분 점수 모델(PCM; Masters, 1982)은 Rasch 모델의 다분 형태입니다. PCM은 다분 문항이 다중 서열 범주로 구성되어 있다고 가정합니다. 이 모델은 서열화된 응답 범주 사이의 임계값(즉, 난이도)을 추정할 때 인접한 범주에 중점을 둡니다. 문항이 K개의 서열 범주가 있다고 가정하면 PCM은 해당 문항의 K-1 임계값을 추정합니다. 예를 들어 문항에 4개의 응답 범주(매우 동의하지 않음, 동의하지 않음, 동의함, 매우 동의함)가 있는 경우, PCM은 인접한 범주 간에 3개의 임계값(\\(\\delta_1, \\delta_2, \\delta_3\\))을 추정합니다. 그림 6.1은 네 가지 범주를 가진 문항에 대한 임계값을 보여줍니다.\nPCM에서 문항 \\(i\\)에 대해 \\(X_i\\) 점수(\\(X_i = 0, 1, … m_i\\))를 얻을 확률은 다음과 같이 쓸 수 있습니다.\n\\[\nP(X_i|\\theta, \\delta_{ih})={ exp[\\sum_{h=0}^{X_i} (\\theta-\\delta_{ih}] \\over \\sum_{k=0}^{m_i} exp[\\sum_{h=0} ^k (\\theta-\\delta_ih)]}\n\\]\n\n여기서 \\(\\theta\\)는 잠재 특성이고,\n\\(\\theta_{ih}\\)는 단계 모수(단계 난이도라고도 함)로 (\\(h-1\\)) 점보다 \\(h\\) 점을 얻는 상대적 난이도를 나타냅니다(De Ayala, 2013).\n첨자 \\(m_i\\)는 각 문항의 최대 반응 범주를 개별적으로 설정하기 때문에 PCM을 사용하면 문항마다 응답 범주의 수가 달라도 됩니다.\n\n\n\n\n4개의 순서화된 반응 범주 간의 임계값\n\n\nPCM에서는 임계값이 반응 범주와 동일한 서열이 아니어도 된다는 점에 유의해야 합니다. PCM은 각 단계에서 인접 범주를 고려하기 때문에 인접한 반응 범주는 이분 문항으로 취급되지만 인접한 범주를 넘어서는 순서에 대한 제약은 없습니다. 그림 6.1에서 반응 범주 1과 2 사이의 임계값(즉, \\(\\delta_1\\))은 반응 범주 2와 3 사이의 임계값(\\(\\delta_2\\))보다 클 수 있습니다.\n이러한 특징은 응답자가 낮은 범주보다 높은 범주를 더 자주 선택할 수 있기 때문에 리커트형 평가 척도 및 설문조사의 문항 모수를 추정할 때 매우 유연하게 사용할 수 있는 PCM 기능입니다. 예를 들어, 설문조사 질문에 하루 동안 스마트폰을 얼마나 자주 사용하는지 묻는 질문이 있고 응답 옵션이 전혀, 매우 드물게, 가끔, 매우 자주라고 가정해 보겠습니다. 대부분의 응답자가 하루 중 스마트폰을 매우 자주 사용하는 경향이 있는 경우, 전혀 또는 매우 드물게 사용한다는 응답 옵션보다 가끔 및 매우 자주 사용한다는 응답 옵션을 선택할 가능성이 높습니다. 따라서 가끔과 매우 자주 사이의 임계값은 전혀 없음과 매우 드물게 사이의 임계값보다 작을 수 있습니다.\n리커트형 문항과 달리 성취도 또는 적성을 측정하는 다분 문항은 응답 범주와 동일한 순서를 따라야 합니다. 예를 들어 0점, 1점, 2점이 가능한 수학 문제에서 2점을 얻는 것이 0점이나 1점을 얻는 것보다 더 어려울 수 있습니다. 따라서 1과 2 사이의 임계값이 0과 1 사이의 임계값보다 클 것으로 예상됩니다. 문항 내용 및 측정하려는 잠재 특성에 따라 사용자는 PCM의 응답 범주 순서가 예상대로 작동하는지 확인해야 합니다.\n다음 예에서는 hemp 패키지의 rse 데이터 세트를 사용하여 PCM을 적합하는 방법을 보여줍니다. rse 데이터 세트는 개인의 자존감을 측정하는 Rosenberg 자존감 척도(Rosenberg, 1965)에서 가져온 것입니다. 이 척도는 4개의 응답 옵션(1 = 전혀 동의하지 않음, 2 = 동의하지 않음, 3 = 동의함, 4 = 매우 동의함)이 있는 10개의 문항으로 구성되어 있습니다. RSE 데이터 세트는 설문지의 모든 문항을 완료한 응답자 1,000명의 무선 표본으로 구성됩니다. 문항 3, 5, 8, 9, 10의 문항은 부정적으로 표현되어 있으므로(예: Q3: 나는 전반적으로 실패자라고 느끼는 경향이 있다), 이 문항에 대한 응답은 역코딩되었습니다(예: 1 = 매우 동의함, 2 = 동의함, 3 = 동의하지 않음, 4 = 매우 동의하지 않음). 따라서 모든 문항에서 점수가 높을수록 자존감이 높음을 나타냅니다. rse 데이터 세트에 대한 자세한 내용은 hemp 패키지에서 확인할 수 있습니다.\n분석을 시작하기 전에 먼저 library 함수를 사용하여 hemp 및 mirt 패키지(Chalmers, 2012)를 활성화합니다.\n\nlibrary(\"hemp\")\n\nLoading required package: psych\n\n\nLoading required package: lattice\n\n\nLoading required package: lavaan\n\n\nThis is lavaan 0.6-16\nlavaan is FREE software! Please report any bugs.\n\n\n\nAttaching package: 'lavaan'\n\n\nThe following object is masked from 'package:psych':\n\n    cor2cov\n\n\nLoading required package: mirt\n\n\nLoading required package: stats4\n\n\nLoading required package: lme4\n\n\nLoading required package: Matrix\n\n\n\nAttaching package: 'lme4'\n\n\nThe following object is masked from 'package:mirt':\n\n    fixef\n\n\nLoading required package: reshape2\n\n\nLoading required package: boot\n\n\n\nAttaching package: 'boot'\n\n\nThe following object is masked from 'package:lattice':\n\n    melanoma\n\n\nThe following object is masked from 'package:psych':\n\n    logit\n\n\nLoading required package: equate\n\nlibrary(\"mirt\")\n\n제5장에서 이분 IRT 모델에 대해 수행한 것과 마찬가지로, 먼저 rse 데이터 세트의 처음 10개 변수(rse[, 1:10])를 사용하여 로젠버그 자존감 척도의 문항에 해당되는 잠재 특성(예제에서는 자존감이라고 함)을 정의하는 것으로 시작합니다. 다음으로, 모델을 pcm_mod로 정의하여 저장하고 mirt 함수를 사용하여 추정합니다. itemtype = “Rasch”로 설정했지만, mirt 함수는 문항에 두 개 이상의 응답 범주가 있을 수 있음을 자동으로 인식하므로 PCM에 적합합니다. rse 데이터 세트에서는 모든 문항에 4개의 응답 범주가 있습니다. 그러나 앞서 언급했듯이 PCM을 사용할 경우 응답 범주의 수가 문항마다 달라도 됩니다. 모델이 추정되면 coef 함수를 사용하여 결과를 추출하고 이를 pcm_params로 저장합니다.\n\npcm_mod <- \"selfesteem = 1 - 10\"\npcm_fit <- mirt(data = rse[, 1:10], model = pcm_mod,\n                itemtype = \"Rasch\", SE = TRUE)\n\n\nIteration: 1, Log-Lik: -10723.481, Max-Change: 1.08191\nIteration: 2, Log-Lik: -10458.320, Max-Change: 0.34832\nIteration: 3, Log-Lik: -10393.617, Max-Change: 0.29629\nIteration: 4, Log-Lik: -10361.707, Max-Change: 0.23100\nIteration: 5, Log-Lik: -10346.161, Max-Change: 0.17221\nIteration: 6, Log-Lik: -10338.624, Max-Change: 0.12507\nIteration: 7, Log-Lik: -10334.979, Max-Change: 0.08960\nIteration: 8, Log-Lik: -10333.210, Max-Change: 0.06277\nIteration: 9, Log-Lik: -10332.344, Max-Change: 0.04411\nIteration: 10, Log-Lik: -10331.754, Max-Change: 0.06344\nIteration: 11, Log-Lik: -10331.537, Max-Change: 0.01332\nIteration: 12, Log-Lik: -10331.500, Max-Change: 0.00762\nIteration: 13, Log-Lik: -10331.465, Max-Change: 0.01214\nIteration: 14, Log-Lik: -10331.449, Max-Change: 0.00314\nIteration: 15, Log-Lik: -10331.445, Max-Change: 0.00281\nIteration: 16, Log-Lik: -10331.433, Max-Change: 0.00244\nIteration: 17, Log-Lik: -10331.431, Max-Change: 0.00114\nIteration: 18, Log-Lik: -10331.430, Max-Change: 0.00103\nIteration: 19, Log-Lik: -10331.428, Max-Change: 0.00066\nIteration: 20, Log-Lik: -10331.428, Max-Change: 0.00047\nIteration: 21, Log-Lik: -10331.428, Max-Change: 0.00045\nIteration: 22, Log-Lik: -10331.428, Max-Change: 0.00022\nIteration: 23, Log-Lik: -10331.428, Max-Change: 0.00019\nIteration: 24, Log-Lik: -10331.428, Max-Change: 0.00017\nIteration: 25, Log-Lik: -10331.428, Max-Change: 0.00011\nIteration: 26, Log-Lik: -10331.428, Max-Change: 0.00009\n\nCalculating information matrix...\n\npcm_params <- coef(pcm_fit, IRTpars = TRUE, simplify = TRUE)\n\n제5장에서 언급했듯이 coef 함수는 문항 모수와 추가 정보를 list 형태로 저장합니다. 따라서 이 list에서 문항 모수를 선택하고 pcm_items라는 새 데이터 프레임으로 저장한 다음 문항 모수를 출력합니다.\n\npcm_items <- as.data.frame(pcm_params$items)\npcm_items\n\n    a        b1          b2        b3\nQ1  1 -2.862042 -1.64077330 0.9905625\nQ2  1 -3.054770 -2.16512310 1.0886014\nQ3  1 -2.221979 -0.53647976 1.7623047\nQ4  1 -3.350465 -1.45471086 1.8055387\nQ5  1 -1.849287 -0.08036912 1.4718083\nQ6  1 -2.183136 -0.16563775 2.0228220\nQ7  1 -1.783421  0.13737615 2.3139199\nQ8  1 -1.581591  0.87429384 1.9704605\nQ9  1 -1.235867  1.21716766 2.0236661\nQ10 1 -1.399355  0.61258736 1.1601113\n\n\n결과에서 rse 데이터 세트의 문항 이름이 행 이름으로 출력됩니다. 첫 번째 열에는 변별도 모수(a)가 표시되는데, PCM은 Rasch 모델과 같이 변별도 모수를 1로 제약하기 때문에 모든 문항은 1로 출력됩니다. 다음 열 집합(b1~b3)에는 추정 임계값(즉, 단계) 모수가 표시됩니다. rse 데이터 세트의 문항에는 네 개의 응답 옵션이 있으므로 PCM은 각 문항에 대해 세 개의 임계값 모수를 추정했습니다. 결과에서 b1 ~ b3으로 레이블이 지정된 열은 방정식 6.1의 \\(\\delta\\) 모수에 해당합니다.\n다음으로, mirt 패키지의 plot 함수를 사용하여 문항을 시각적으로 살펴봅니다. 이분 IRT 모델과 달리 다분 IRT 모델에는 다분 문항에 대한 ICC의 확장으로 간주할 수 있는 범주 특성 곡선(OCC)이 있습니다. 문항에 두 개 이상의 응답 범주가 있기 때문에 문항당 여러 개의 OCC가 그려집니다. 각 곡선은 잠재 특성(\\(\\theta\\))의 함수로서 특정 응답 범주를 선택할 확률을 나타냅니다.\n\nplot(pcm_fit, type = \"trace\", which.items = c(2, 5),\n     par.settings = simpleTheme(lty = 1:4, lwd = 2),\n     auto.key = list(points = FALSE, lines = TRUE, columns = 4))\n\n\n\n\nplot 함수를 호출할 때 적합된 모델(pcm_fit)을 제공하고 사용하려는 그래프 유형(type = “trace”)을 지정합니다. 두 문항에 대해서만 OCC를 그리는 방법을 보여주기 위해, which.items = c(2, 5)를 지정하여 rse 데이터 세트에서 Q2와 Q5를 그립니다. plot 함수에서 이 인수를 제거하면 기본적으로 모든 문항에 대한 OCC를 단일 격자형 그래프에 그립니다. 다음으로, par.settings 인수와 simpleTheme 함수를 사용하여 그래프에 대한 몇 가지 추가 설정을 지정합니다. 각 OCC에 대해 서로 다른 선 유형을 요청하기 위해 lty = 1:4로 설정하고, 곡선을 더 두껍게 만들기 위해 선 너비를 나타내는 lwd = 2로 설정합니다. 마지막으로 auto.key를 사용하여 범례를 만듭니다. 이 범례에는 4개의 열이 있으며, 이 열은 OCC의 점이 아닌 선을 표시합니다. 그림 6.2에서 응답 범주는 P1 ~ P4로 레이블이 지정되어 있습니다. 두 문항 모두 OCC는 응답 범주와 동일한 예상 순서를 따릅니다. 첫 번째 응답 범주(P1)에 대한 OCC는 그래프의 맨 왼쪽에 있고 마지막 응답 범주(P4)는 그래프의 맨 오른쪽에 있습니다. 중간에 있는 다른 OCC도 적절하게 정렬되어 있습니다.\n다음으로, 각 문항이 설명하는 정보의 양을 잠재 특성 수준의 함수로 보여주기 위해 IIF를 그래프로 그립니다. plot 함수를 다시 사용하지만 이번에는 type = “infotrace”를 설정하여 IIF를 요청합니다. par.settings 옵션에서 다시 선의 너비를 변경하여 선이 더 잘 보이도록 합니다. 그림 6.3은 rse 데이터 세트의 문항 2와 5에 대한 IIF 그래프를 보여줍니다.\n\nplot(pcm_fit, type = \"infotrace\", which.items = c(2, 5),\n     par.settings = simpleTheme(lwd = 2))\n\n\n\n\n개별 문항에 대한 IIF 외에도 문항들로부터의 총 정보량(즉, 검사 정보 함수 - TIF)과 rse 데이터 세트의 조건부 측정의 표준오차(cSEM) 분포를 그래프로 그릴 수도 있습니다. 다음 예에서는 -6~6의 잠재 특성 범위에 대해 TIF 및 cSEM을 그래프로 그리는 방법을 보여 줍니다. TIF 그래프는 type = “info”를, cSEM 플롯에는 type = “SE”를 사용합니다.\n\nplot(pcm_fit, type = \"info\", theta_lim = c(-6, 6))\n\n\n\nplot(pcm_fit, type = \"SE\", theta_lim = c(-6, 6))\n\n\n\n\n\n\n6.2.2 평정 척도 모형\n평정 척도 모델(RSM; Andrich, 1978)은 PCM의 제한된 형태로 볼 수 있습니다. RSM은 모든 문항의 구조적 반응 형태가 동일한 검사도구(즉, 응답 형태가 모든 문항에서 동일한 방식으로 작동한다고 가정)에서 잘 작동합니다. 대표적인 예로 리커트 척도가 포함된 설문지를 들 수 있습니다. RSM은 인접 서열 반응 범주를 구분하는 일련의 서열 임계값이 있다고 가정합니다(De Ayala, 2013). 각 문항은 고유한 위치 모수가 있지만 위치 모수를 둘러싼 반응 범주 간의 차이는 모든 문항에서 동일하도록 제약됩니다. 따라서 검사도구의 문항은 전체 위치 측면에서는 서로 다르지만 문항 내 범주 임계값의 분포는 동일하게 유지됩니다.\nRSM의 경우, 문항 \\(i\\)에 대해 범주 \\(c\\)를 선택할 확률(\\(c = 0, 1, …, m\\))은 다음과 같이 작성할 수 있습니다.\n\\[\nP(X_{ic}|\\theta, \\lambda_i,\\delta_1, … , \\delta_m)={exp[\\sum_{j=0} ^ c (\\theta-(\\lambda_i+\\delta_j))] \\over \\sum_{h=0} ^m exp[\\sum_{j=0} ^h (\\theta-(\\lambda_i+\\delta_j))]}\n\\]\n\n여기서 \\(\\lambda_i\\)는 문항 \\(i\\)의 위치 모수이고\n\\(\\delta_1, …, \\delta_m\\)는 범주 임계값 모수입니다.\n문항의 범주(즉, \\(c\\))에는 아래 첨자 \\(i\\)가 없으므로 PCM과 달리 모든 문항의 범주 수가 동일해야 한다는 것을 의미합니다.\n\n그림 6.4는 연속성이 있는 잠재 특성 상에서 두 가지 평정 척도 문항을 보여줍니다. item 1과 item 2는 전체 위치(\\(\\lambda\\))가 다르지만 범주 임계값(\\(\\delta\\))의 분포는 두 문항이 동일합니다.\n\n\n\n두 평정 척도 문항의 위치 및 임계값 모수\n\n\n다음 예에서는 RSM을 rse 데이터 세트에 적합합니다. rse 데이터 세트의 모든 문항에는 4개의 범주가 있으므로 모든 문항에 대해 동일한 수의 범주 임계값 모수를 추정할 수 있습니다. 이번에 모델을 정의할 때에는 itemtype = “rsm”을 지정하여 RSM을 추정합니다. itemtype = “rsm” 옵션은 변별도 모수와 범주 임계값이 모든 문항에서 동일하도록 제약합니다. RSM에 대한 추정 결과를 rsm_fit으로 저장하고, coef 함수를 사용하여 결과를 추출한 다음, 추정된 문항 모수를 rsm_items로 저장하고 출력합니다.\n\nrsm_mod <- \"selfesteem = 1 - 10\"\nrsm_fit <- mirt(data = rse[,1:10], model = rsm_mod,\n                itemtype = \"rsm\")\n\n\nIteration: 1, Log-Lik: -11753.833, Max-Change: 1.77450\nIteration: 2, Log-Lik: -10565.131, Max-Change: 0.26737\nIteration: 3, Log-Lik: -10548.079, Max-Change: 0.16992\nIteration: 4, Log-Lik: -10539.958, Max-Change: 0.12057\nIteration: 5, Log-Lik: -10535.794, Max-Change: 0.08251\nIteration: 6, Log-Lik: -10533.549, Max-Change: 0.05673\nIteration: 7, Log-Lik: -10531.142, Max-Change: 0.07350\nIteration: 8, Log-Lik: -10530.477, Max-Change: 0.01508\nIteration: 9, Log-Lik: -10530.132, Max-Change: 0.01149\nIteration: 10, Log-Lik: -10529.045, Max-Change: 0.01680\nIteration: 11, Log-Lik: -10528.929, Max-Change: 0.00454\nIteration: 12, Log-Lik: -10528.857, Max-Change: 0.00402\nIteration: 13, Log-Lik: -10528.575, Max-Change: 0.00304\nIteration: 14, Log-Lik: -10528.560, Max-Change: 0.00203\nIteration: 15, Log-Lik: -10528.547, Max-Change: 0.00179\nIteration: 16, Log-Lik: -10528.497, Max-Change: 0.00128\nIteration: 17, Log-Lik: -10528.494, Max-Change: 0.00076\nIteration: 18, Log-Lik: -10528.492, Max-Change: 0.00072\nIteration: 19, Log-Lik: -10528.483, Max-Change: 0.00038\nIteration: 20, Log-Lik: -10528.482, Max-Change: 0.00033\nIteration: 21, Log-Lik: -10528.482, Max-Change: 0.00031\nIteration: 22, Log-Lik: -10528.480, Max-Change: 0.00028\nIteration: 23, Log-Lik: -10528.480, Max-Change: 0.00013\nIteration: 24, Log-Lik: -10528.480, Max-Change: 0.00013\nIteration: 25, Log-Lik: -10528.479, Max-Change: 0.00010\n\nrsm_params <- coef(rsm_fit, simplify = TRUE)\nrsm_items <- as.data.frame(rsm_params$items)\nrsm_items\n\n    a1        b1        b2        b3          c\nQ1   1 -3.101277 -1.339018 0.7754061  0.0000000\nQ2   1 -3.101277 -1.339018 0.7754061  0.1813616\nQ3   1 -3.101277 -1.339018 0.7754061 -0.8685415\nQ4   1 -3.101277 -1.339018 0.7754061 -0.2943773\nQ5   1 -3.101277 -1.339018 0.7754061 -1.0881595\nQ6   1 -3.101277 -1.339018 0.7754061 -1.1163858\nQ7   1 -3.101277 -1.339018 0.7754061 -1.4311120\nQ8   1 -3.101277 -1.339018 0.7754061 -1.7382407\nQ9   1 -3.101277 -1.339018 0.7754061 -2.0169933\nQ10  1 -3.101277 -1.339018 0.7754061 -1.4522739\n\n\n결과에서 a1은 문항 변별도 모수로, RSM은 다분 형태의 Rasch 모델로서 모든 문항이 동일한 변별도 모수를 가져야 하므로 모든 문항에 대해 1로 고정되어 있습니다. 다음 열(즉, b1부터 b3까지)은 모든 문항에 대해 동일한 범주 임계값 모수를 나타내며, c는 rse 데이터 세트의 각 문항에 대해 고유하게 추정된 위치 모수입니다. 추정된 위치 모수는 가장 쉬운 문항이 Q9이고 가장 어려운 문항이 Q2임을 보여줍니다. 이 두 문항의 시각적 비교를 확인하기 위해 문항 2와 9의 OCC를 그래프로 그립니다. 이 그래프를 생성하는 코드는 PCM의 경우 이전과 동일하지만, 대신 which.items = c(2, 9)를 지정한다는 점이 다릅니다.\n\nplot(rsm_fit, type = \"trace\", which.items = c(2, 9),\n     par.settings = simpleTheme(lty = 1:4, lwd = 2),\n     auto.key = list(points = FALSE, lines = TRUE, columns = 4))\n\n\n\n\n그림 6.5는 Q9에 대해 더 높은 응답 범주(예: 4 = 매우 동의함 또는 3 = 동의함)를 선택하는 것이 Q2에 대해 동일한 응답 범주를 선택하는 것보다 더 쉽다는 것을 보여줍니다. 또한 TIF 그래프에 type = “info”를 지정하고 cSEM 그래프에 type = “SE”를 지정하여 RSM에 대한 TIF 및 cSEM 그래프를 그릴 수도 있습니다.\n\nplot(rsm_fit, type = \"info\", theta_lim = c(-6, 6))\n\n\n\nplot(rsm_fit, type = \"SE\", theta_lim = c(-6, 6))"
  },
  {
    "objectID": "chap06.html#서열척도-문항에-대한-다분-비-rasch-모델",
    "href": "chap06.html#서열척도-문항에-대한-다분-비-rasch-모델",
    "title": "6  다분 문항반응이론",
    "section": "6.3 서열척도 문항에 대한 다분 비-Rasch 모델",
    "text": "6.3 서열척도 문항에 대한 다분 비-Rasch 모델\n일반화 부분 점수 모델(Muraki, 1992)과 등급 반응 모델(Samejima, 1969)은 2모수(2PL) IRT 모델의 다분 형태로 볼 수 있습니다. 다분 Rasch 모델과 달리 일반화 부분 점수 모델과 등급 반응 모델은 잠재 특성이 낮거나 높은 피험자 또는 응답자를 구별하는 데 있어 문항의 변별도 수준이 다르다고 가정합니다. 이 두 모델은 범주 특성 곡선의 개념화에 따라 서로 조금씩 다릅니다(De Ayala, 2013). 다음 섹션에서는 이러한 모델에 대해 간략하게 설명하고 R의 mirt 패키지(Chalmers, 2012)를 사용하여 모델을 추정하는 방법을 보여줍니다.\n\n6.3.1 일반화 부분 점수 모델\n일반화 부분 점수 모형(GPCM; Muraki, 1992)은 범주 특성 곡선을 개념화하는 방식에서 PCM과 유사하며, 문항 변별도 모수가 문항에 따라 다를 수 있다는 점에서 2PL 모형과도 유사합니다. 모든 문항에 대해 문항 변별도 모수를 1로 고정하는 대신, GPCM은 각 문항에 대해 고유한 문항 변별도 모수를 추정합니다. Muraki(1992)에 따르면 문항 변별도 모수는 잠재 특성이 변화함에 따라 범주형 응답이 문항마다 달라지는 정도를 나타냅니다. GPCM에서 문항 \\(i\\)에 대해 \\(X_{ik}\\) 점수(\\(X_{ik} = 0, 1, …, m_i\\))를 얻을 확률은 다음과 같이 쓸 수 있습니다.\n\\[\nP(x_{ik}|\\theta, a_i, \\delta_{ik}) = {exp[\\sum_{h=1}^{X_{ik}} a_i(\\theta-\\delta_{ih})] \\over \\sum_{c=1}^{m_i} exp[\\sum_{h=1}^c a_i(\\theta-\\delta_ih)]}\n\\] (6.3)\n\n여기서 \\(a_i\\)는 문항 \\(i\\)에 대한 변별도 모수이며 나머지 용어는 방정식 6.1의 용어와 동일합니다.\n\nPCM과 마찬가지로 임계값(\\(\\delta_{ik}\\))은 응답 범주와 동일한 순서로 제약되지 않습니다.\n다음 예에서는 GPCM을 사용하여 rse 데이터 세트의 문항에 대한 범주 임계값과 문항 변별도 모수를 추정합니다. 이번에는 itemtype = “Rasch” 대신 itemtype = “gpcm”을 사용하여 GPCM을 기반으로 문항 모수를 추정합니다.\n\ngpcm_mod <- \"selfesteem = 1 - 10\"\ngpcm_fit <- mirt(data = rse[, 1:10], model = gpcm_mod,\n                 itemtype = \"gpcm\", SE = TRUE)\n\n\nIteration: 1, Log-Lik: -10776.362, Max-Change: 2.86983\nIteration: 2, Log-Lik: -10351.776, Max-Change: 0.80786\nIteration: 3, Log-Lik: -10283.772, Max-Change: 0.23823\nIteration: 4, Log-Lik: -10261.491, Max-Change: 0.15392\nIteration: 5, Log-Lik: -10249.603, Max-Change: 0.13059\nIteration: 6, Log-Lik: -10242.348, Max-Change: 0.10220\nIteration: 7, Log-Lik: -10237.530, Max-Change: 0.09347\nIteration: 8, Log-Lik: -10234.445, Max-Change: 0.06972\nIteration: 9, Log-Lik: -10232.291, Max-Change: 0.06364\nIteration: 10, Log-Lik: -10231.438, Max-Change: 0.03688\nIteration: 11, Log-Lik: -10230.008, Max-Change: 0.03037\nIteration: 12, Log-Lik: -10229.195, Max-Change: 0.02323\nIteration: 13, Log-Lik: -10228.554, Max-Change: 0.01831\nIteration: 14, Log-Lik: -10228.158, Max-Change: 0.01575\nIteration: 15, Log-Lik: -10227.896, Max-Change: 0.01344\nIteration: 16, Log-Lik: -10227.479, Max-Change: 0.00796\nIteration: 17, Log-Lik: -10227.440, Max-Change: 0.00461\nIteration: 18, Log-Lik: -10227.415, Max-Change: 0.00412\nIteration: 19, Log-Lik: -10227.383, Max-Change: 0.00213\nIteration: 20, Log-Lik: -10227.377, Max-Change: 0.00186\nIteration: 21, Log-Lik: -10227.372, Max-Change: 0.00115\nIteration: 22, Log-Lik: -10227.370, Max-Change: 0.00143\nIteration: 23, Log-Lik: -10227.369, Max-Change: 0.00081\nIteration: 24, Log-Lik: -10227.368, Max-Change: 0.00094\nIteration: 25, Log-Lik: -10227.365, Max-Change: 0.00071\nIteration: 26, Log-Lik: -10227.365, Max-Change: 0.00018\nIteration: 27, Log-Lik: -10227.365, Max-Change: 0.00048\nIteration: 28, Log-Lik: -10227.365, Max-Change: 0.00050\nIteration: 29, Log-Lik: -10227.365, Max-Change: 0.00034\nIteration: 30, Log-Lik: -10227.365, Max-Change: 0.00037\nIteration: 31, Log-Lik: -10227.365, Max-Change: 0.00029\nIteration: 32, Log-Lik: -10227.364, Max-Change: 0.00042\nIteration: 33, Log-Lik: -10227.364, Max-Change: 0.00017\nIteration: 34, Log-Lik: -10227.364, Max-Change: 0.00013\nIteration: 35, Log-Lik: -10227.364, Max-Change: 0.00033\nIteration: 36, Log-Lik: -10227.364, Max-Change: 0.00010\n\nCalculating information matrix...\n\ngpcm_params <- coef(gpcm_fit, IRTpars = TRUE, simplify = TRUE)\ngpcm_items <- gpcm_params$items\ngpcm_items\n\n            a         b1          b2        b3\nQ1  1.8238891 -1.7202941 -0.95938961 0.5885070\nQ2  1.7307657 -1.8564721 -1.28862013 0.6510270\nQ3  1.8710897 -1.3231835 -0.31308686 1.0425363\nQ4  1.2811061 -2.2085974 -1.00156932 1.2138474\nQ5  1.4939839 -1.1502285 -0.04606415 0.9041157\nQ6  2.7132868 -1.2057255 -0.09730049 1.1220286\nQ7  2.3609630 -1.0210663  0.07245970 1.3106380\nQ8  0.8945663 -1.1800257  0.81206980 1.2679593\nQ9  1.4911761 -0.7707405  0.78235286 1.2329194\nQ10 1.9005838 -0.8381950  0.33153091 0.7308140\n\n\nPCM의 추정된 문항 모수와 달리 GPCM 결과의 첫 번째 열(즉, 문항 변별도)은 1로 고정되지 않습니다. 대신, 각 문항에는 고유한 문항 변별도 모수가 있습니다.결과는 rse 데이터 세트의 문항이 문항 변별도 측면에서 다소 다르다는 것을 보여줍니다. 나머지 3개의 열은 GPCM에서 추정된 범주 임계값 모수를 보여줍니다.\nGPCM에서 다양한 문항 변별도 모수의 영향을 보여주기 위해 Q6 및 Q8에 대한 OCC를 그래프로 그립니다. 그림 6.2와 달리 GPCM에서 추정된 문항 기울기(즉, 변별도)가 동일하지 않음을 알 수 있습니다. 그림 6.6은 Q6의 문항 변별도가 더 높기 때문에 Q6의 OCC 기울기가 Q8의 OCC 기울기보다 더 가파른 것을 보여줍니다.\n\nplot(gpcm_fit, type = \"trace\", which.items = c(6, 8),\n     par.settings = simpleTheme(lty = 1:4, lwd = 2),\n     auto.key=list(points = FALSE, lines = TRUE, columns = 4))\n\n\n\n\nPCM 및 RSM에 대해 살펴본 것처럼, TIF 그래프에 type = “info”를 지정하고 cSEM 그래프에 type = “SE”를 지정하여 GPCM에 대한 TIF 및 cSEM 그래프를 그릴 수도 있습니다.\n\nplot(gpcm_fit, type = \"info\", theta_lim = c(-6, 6))\n\n\n\nplot(gpcm_fit, type = \"SE\", theta_lim = c(-6, 6))\n\n\n\n\n\n\n6.3.2 등급 반응 모델\n누적 로짓 모델이라고도 하는 등급 반응 모델(GRM; Samejima, 1969)은 2PL 모델을 다분으로 확장한 것입니다. GRM은 기저 반응 연속성이 명확한 문항에 적합합니다. GRM은 응답 옵션과 동일한 순서에 따라 주어진 응답 범주 이상의 확률을 모델링합니다. GRM에서 각 응답 범주는 피험자가 특정 응답 범주를 선택할 확률에 일부 정보를 기여합니다. \\(K\\)개의 순서화된 응답 범주를 가진 문항의 경우, GRM은 응답 범주를 누적 방식으로 분할하여 \\(K-1\\)개의 이분 문항을 생성합니다. 이러한 인위적인 이분 문항은 각각 고유한 난이도 모수를 가지지만 동일한 변별도 모수를 공유합니다. 예를 들어, 네 개(\\(X = 0, 1, 2, 3\\))의 순서화된 반응 범주를 가진 다분 문항을 생각해 보겠습니다. 그림 6.7은 4개의 응답 범주를 누적 방식으로 분할하는 3개의 임계값(\\(\\delta_1, \\delta_2, \\delta_3\\))을 보여줍니다. 즉, 각 임계값 모수는 특정 응답 범주를 선택할 확률이 50% 이상일 때 필요한 잠재 특성 수준을 나타냅니다.\n\n\n\n4개의 반응 범주 간의 누적 경계값\n\n\nGRM의 문항 \\(i\\)에서 \\(X_i\\) 점수 이상(\\(X_i = 0, 1, …, m_i\\))을 얻을 확률은 다음과 같이 작성할 수 있습니다.\n\\[\nP^*(X_i|\\theta, a_i, \\delta_{X_i})={e^{a_i(\\theta-\\delta_{X_i})} \\over 1 + e^{a_i(\\theta-\\delta_{X_i})}}\n\\]\n\n여기서, \\(\\theta\\)는 잠재 특성,\n\\(a_i\\)는 문항 \\(i\\)에 대한 변별도 모수,\n\\(\\delta_{X_i}\\)는 범주 \\(X_i\\)의 범주 경계 위치(이전 모델의 범주 임계값 모수와 유사함),\n\\(P^*(X_i|\\theta, a_i, \\delta_{X_i})\\)는 피험자가 \\(X_i\\) 이상의 점수를 받을 확률입니다(De Ayala, 2013).\n\n앞서 언급했듯이 GRM은 누적 확률을 사용하여 다분 문항을 일련의 이분 문항으로 분할합니다. 즉, 문항 \\(i\\)는 변별도 모수(\\(a_i\\))는 같지만 난이도 모수(\\(\\delta_{X_i}\\))가 다른 이분 문항으로 구성됩니다.\n다음 예에서는 GRM을 사용하여 rse 데이터 세트에 대한 문항 모수를 추정합니다. GRM에 맞게 itemtype = “graded”를 사용합니다.\n\ngrm_mod <- \"selfesteem = 1-10\"\ngrm_fit <- mirt(data = rse[, 1:10], model = grm_mod,\n                itemtype = \"graded\", SE = TRUE)\n\n\nIteration: 1, Log-Lik: -10938.356, Max-Change: 1.14654\nIteration: 2, Log-Lik: -10328.666, Max-Change: 0.61890\nIteration: 3, Log-Lik: -10229.875, Max-Change: 0.22391\nIteration: 4, Log-Lik: -10191.013, Max-Change: 0.16811\nIteration: 5, Log-Lik: -10167.607, Max-Change: 0.10413\nIteration: 6, Log-Lik: -10154.483, Max-Change: 0.09683\nIteration: 7, Log-Lik: -10145.741, Max-Change: 0.07175\nIteration: 8, Log-Lik: -10139.704, Max-Change: 0.07150\nIteration: 9, Log-Lik: -10135.689, Max-Change: 0.04666\nIteration: 10, Log-Lik: -10131.784, Max-Change: 0.03194\nIteration: 11, Log-Lik: -10130.343, Max-Change: 0.02962\nIteration: 12, Log-Lik: -10129.342, Max-Change: 0.02603\nIteration: 13, Log-Lik: -10127.304, Max-Change: 0.03155\nIteration: 14, Log-Lik: -10127.020, Max-Change: 0.01449\nIteration: 15, Log-Lik: -10126.873, Max-Change: 0.01115\nIteration: 16, Log-Lik: -10126.717, Max-Change: 0.01022\nIteration: 17, Log-Lik: -10126.670, Max-Change: 0.00499\nIteration: 18, Log-Lik: -10126.641, Max-Change: 0.00591\nIteration: 19, Log-Lik: -10126.582, Max-Change: 0.00322\nIteration: 20, Log-Lik: -10126.573, Max-Change: 0.00150\nIteration: 21, Log-Lik: -10126.570, Max-Change: 0.00114\nIteration: 22, Log-Lik: -10126.566, Max-Change: 0.00095\nIteration: 23, Log-Lik: -10126.565, Max-Change: 0.00118\nIteration: 24, Log-Lik: -10126.564, Max-Change: 0.00120\nIteration: 25, Log-Lik: -10126.562, Max-Change: 0.00025\nIteration: 26, Log-Lik: -10126.561, Max-Change: 0.00071\nIteration: 27, Log-Lik: -10126.561, Max-Change: 0.00078\nIteration: 28, Log-Lik: -10126.561, Max-Change: 0.00029\nIteration: 29, Log-Lik: -10126.561, Max-Change: 0.00032\nIteration: 30, Log-Lik: -10126.561, Max-Change: 0.00044\nIteration: 31, Log-Lik: -10126.561, Max-Change: 0.00023\nIteration: 32, Log-Lik: -10126.561, Max-Change: 0.00029\nIteration: 33, Log-Lik: -10126.561, Max-Change: 0.00034\nIteration: 34, Log-Lik: -10126.561, Max-Change: 0.00020\nIteration: 35, Log-Lik: -10126.561, Max-Change: 0.00024\nIteration: 36, Log-Lik: -10126.561, Max-Change: 0.00031\nIteration: 37, Log-Lik: -10126.561, Max-Change: 0.00017\nIteration: 38, Log-Lik: -10126.561, Max-Change: 0.00022\nIteration: 39, Log-Lik: -10126.561, Max-Change: 0.00026\nIteration: 40, Log-Lik: -10126.561, Max-Change: 0.00015\nIteration: 41, Log-Lik: -10126.561, Max-Change: 0.00018\nIteration: 42, Log-Lik: -10126.561, Max-Change: 0.00024\nIteration: 43, Log-Lik: -10126.561, Max-Change: 0.00013\nIteration: 44, Log-Lik: -10126.561, Max-Change: 0.00016\nIteration: 45, Log-Lik: -10126.561, Max-Change: 0.00020\nIteration: 46, Log-Lik: -10126.561, Max-Change: 0.00011\nIteration: 47, Log-Lik: -10126.561, Max-Change: 0.00014\nIteration: 48, Log-Lik: -10126.561, Max-Change: 0.00018\nIteration: 49, Log-Lik: -10126.561, Max-Change: 0.00010\nIteration: 50, Log-Lik: -10126.561, Max-Change: 0.00012\nIteration: 51, Log-Lik: -10126.561, Max-Change: 0.00015\nIteration: 52, Log-Lik: -10126.561, Max-Change: 0.00009\n\nCalculating information matrix...\n\ngrm_params <- coef(grm_fit, IRTpars = TRUE, simplify = TRUE)\n\n다음으로 추정된 문항 모수를 grm_items로 저장하고 출력합니다.\n\ngrm_items <- as.data.frame(grm_params$items)\ngrm_items\n\n           a         b1          b2        b3\nQ1  2.324817 -1.9096256 -0.86459285 0.6212696\nQ2  2.136179 -2.1468087 -1.15272898 0.6594750\nQ3  2.435460 -1.3941348 -0.25807123 1.0778067\nQ4  1.650816 -2.4179124 -0.86144982 1.2003060\nQ5  2.172579 -1.2073811 -0.05750731 1.0257647\nQ6  3.202812 -1.2249932 -0.08533037 1.1446882\nQ7  2.810958 -1.0605179  0.09078729 1.3417869\nQ8  1.420458 -1.2018548  0.51592382 1.7199115\nQ9  2.163341 -0.7728069  0.63992017 1.4899442\nQ10 2.645276 -0.8719370  0.23061101 0.9486129\n\n\n결과에서 a1은 문항 변별도 모수이고 나머지 열(즉, b1~b3)은 rse 데이터 세트에 있는 문항의 범주 경계 위치를 나타냅니다. GPCM의 결과와 마찬가지로 각 문항에는 고유한 변별도 모수가 있습니다. GRPM과 마찬가지로, Q6과 Q8은 rse 데이터 세트에서 가장 높은 변별도 모수와 가장 낮은 변별도 모수를 가지고 있습니다.\n다음으로, 변별도 수준은 비슷하지만 범주 경계 위치가 다른 Q5와 Q9에 대한 OCC 그래프를 그리고 범주 특성 곡선의 기울기를 살펴봅니다. 그림 6.8은 Q5와 Q9의 OCC 기울기가 매우 유사하지만, Q5가 Q9보다 더 쉬운 것으로 보입니다.\n\nplot(grm_fit, type = \"trace\", which.items = c(5, 9),\n     par.settings = simpleTheme(lty = 1:4,lwd = 2),\n     auto.key = list(points = FALSE, lines = TRUE, columns = 4))\n\n\n\n\n마지막으로, 이전 모델에서 수행한 것처럼 TIF 그래프에 type = “info”를 사용하고 cSEM 그래프에 type = “SE”를 사용하여 GRM에 대한 TIF 및 cSEM의 그래프를 그릴 수 있습니다.\n\nplot(grm_fit, type = \"info\", theta_lim = c(-6, 6))\n\n\n\nplot(grm_fit, type = \"SE\", theta_lim = c(-6, 6))\n\n\n\n\nmirt 함수는 기존 GRM 외에도 RSM과 GRM의 특정 특성을 단일 모델로 결합한 하이브리드 모델을 추정할 수도 있습니다. 이 모델을 mirt 패키지 설명서에서는 등급-척도 등급 반응 모델이라고 합니다. 이 하이브리드 모델을 추정하려면 mirt 함수의 itemtype을 itemtype = “grsm” 또는 itemtype = “grsmIRT”로 설정해야 합니다. 등급-척도 등급 반응 모델에 대한 자세한 내용은 Muraki(1990)에서 확인할 수 있습니다."
  },
  {
    "objectID": "chap06.html#명목척도-문항에-대한-다분-irt-모델",
    "href": "chap06.html#명목척도-문항에-대한-다분-irt-모델",
    "title": "6  다분 문항반응이론",
    "section": "6.4 명목척도 문항에 대한 다분 IRT 모델",
    "text": "6.4 명목척도 문항에 대한 다분 IRT 모델\n앞의 두 섹션에서는 반응 범주가 서열화된 다분 문항에 대한 Rasch 및 비-Rasch IRT 모델에 중점을 두었습니다. 이러한 모델에서는 다분 문항의 응답 범주가 본질적으로 서열화되어 있다고 가정합니다. 다분 문항의 반응 범주가 순서와 관계가 없는 경우, 잠재 특성의 함수로서 한 반응 범주에서 다른 반응 범주로 순서화된 전이를 가정할 수 없습니다. 순서를 매길 수 없는 뚜렷한 반응 범주를 가진 문항을 명목척도 문항이라고 합니다(명목 척도에 대한 자세한 내용은 제2장 참조). 명목척도 IRT 모델은 명목척도로 채점된 문항의 다른 모든 범주에 대해 특정 응답 범주를 선택할 확률을 직접 추정합니다. 즉, 각 문항은 명목 범주를 기준으로 일련의 이분 문항으로 나뉩니다. 예를 들어 전자 제품 회사의 고객을 대상으로 기술 및 엔터테인먼트 제품에 대한 설문조사를 실시한다고 가정해 보겠습니다. 설문조사의 질문 중 하나는 고객에게 다음 제품(노트북, 스마트폰, 태블릿) 중 향후 6개월 이내에 구매할 가능성이 가장 높은 제품을 묻는 것입니다. 이 문항에 명목척도 IRT 모델을 적용하면 노트북 대 스마트폰 또는 태블릿, 스마트폰 대 노트북 또는 태블릿, 태블릿 대 노트북 또는 스마트폰과 같이 각 제품에 대해 여러 이분법적 비교를 할 수 있습니다. 이러한 명목척도 문항에 대한 문헌에는 여러 가지 IRT 모델이 있지만, 이 섹션에서는 명목 반응 모델(Bock, 1972)과 내재된 로짓 모델(Suh & Bolt, 2010)이라는 두 가지 모델에 중점을 둡니다.\n\n6.4.1 명목 반응 모델\n명목 반응 모델(NRM; Bock, 1972)은 상호 배타적인 반응 범주가 있는 다분 채점 문항에 적합합니다. NRM은 나머지 범주에 대해 상호 배타적인 범주 중 하나를 선택할 확률을 결정합니다. 따라서 각 반응 범주에는 고유한 변별도 및 난이도 모수가 있습니다. NRM에서 문항 \\(i\\)에서 \\(k\\)번째 응답 범주(\\(k = 0, 1, …, m\\))를 선택할 확률은 다음과 같이 쓸 수 있습니다.\n\\[\nP(X_{ik}|\\theta, a, \\gamma) = {e^{\\gamma_{ik}+a_{ik}\\theta} \\over \\sum_{h=1} ^m e^{\\gamma_{ik}+a_{ik}\\theta}}\n\\] (6.5)\n\n여기서 \\(a\\)는 문항 \\(i\\)에 대한 문항 변별도 모수 벡터(\\(a = [a_{i1}, a_{i2}, …a_{im}]\\))이고,\n\\(\\gamma\\)는 문항 \\(i\\)에 대한 난이도 모수 벡터( \\(\\gamma = [\\gamma_{i1}, \\gamma_{i2}, …,\\gamma_{im}]\\))이며,\n\\(m\\)은 문항 \\(i\\)의 응답 범주 수입니다.\n\nNRM에서는 모델 식별을 보장하기 위해 문항 모수와 관련된 두 가지 모델 제약 조건이 있습니다. (1) 문항 변별도 모수의 합이 0이고(즉, \\(\\sum_{k=1} ^ m a_{ik} = 0\\)), (2) 문항 난이도 모수의 합이 0이어야 합니다(즉, \\(\\sum_{k=1} ^ m \\gamma_{ik} = 0\\)).\nNRM의 문항 난이도 모수는 이분 IRT 모델의 문항 난이도 모수나 서열척도 문항에 대한 다분 IRT 모형의 단계 모수와 같은 의미를 갖지 않는다는 점에 유의해야 합니다. De Ayala(2013)는 NRM의 문항 난이도 모수를 특정 반응 범주를 선택하는 응답자의 성향(예: 태블릿이나 노트북 대신 스마트폰 선택)으로 설명합니다. \\(a_k\\) 값이 클수록 반응 범주 \\(k\\)가 측정되는 잠재 특성과 더 강하게 연관되어 있습니다. 예를 들어, 여러 개의 반응 범주(예: A, B, C, D)이 있는 선다형 문항의 경우, 정답 범주는 잠재 특성과 직접적으로 관련되어 있기 때문에 정적이고 높은 변별도 모수를 가질 것으로 예상됩니다.\nNRM을 적합하는 방법을 보여드리기 위해 hemp 패키지의 VerbAggWide 데이터 세트를 사용합니다. 이 데이터 세트는 언어적 공격성에 대한 연구에서 가져온 것입니다(Vansteelandt, 2000). 응답자 316명(여성 243명, 남성 73명)의 표본이 24개 문항의 설문지에 답변했습니다. 각 문항에는 “버스가 나를 위해 정차하지 않는다”와 같은 시나리오가 제시되었고, 응답자는 욕을 할 것인지, 꾸짖을 것인지, 소리를 지를 것인지, 그리고 실제로 이러한 언어적 공격 행동을 할 것인지 아니면 하고 싶기만 할 것인지를 물었습니다. 세 가지 언어적 공격성 행동(욕설, 꾸중, 소리 지르기)과 두 가지 행동 유형(원한다, 한다)이 포함된 네 가지 시나리오를 조합하여 총 24개의 문항을 만들었습니다. 응답자는 각 문항에 대해 다음 반응 범주(0(아니오), 1(아마도), 2(예)) 중 하나를 선택했습니다.\n다음 예에서는 세 가지 반응 옵션(아니요, 아마도, 예)을 명목 반응 범주로 간주하고 NRM에 대한 문항 모수를 추정합니다. VerbAggWide 데이터 세트의 처음 세 열은 응답자 식별자, 다양한 측정으로부터의 분노 점수, 성별로 구성됩니다. 따라서 VerbAggWide[, 4:27]을 지정하여 나머지 열을 선택합니다. mirt 함수에서 itemtype = “nominal”을 사용하여 NRM에 적합합니다. 그런 다음 결과를 nrm_fit으로 저장하고, 추정된 모수를 nrm_params로 추출하고, 문항 모수를 별도의 데이터 프레임(nrm_items)으로 재조합한 다음, head 함수를 사용하여 결과의 처음 네 행을 출력합니다.\n\nnrm_mod <- \"agression = 1 - 24\"\nnrm_fit <- mirt(data = VerbAggWide[, 4:27], model = nrm_mod,\n                itemtype = \"nominal\", SE = TRUE)\n\n\nIteration: 1, Log-Lik: -7361.548, Max-Change: 3.04745\nIteration: 2, Log-Lik: -6417.292, Max-Change: 1.45860\nIteration: 3, Log-Lik: -6356.532, Max-Change: 0.94437\nIteration: 4, Log-Lik: -6333.562, Max-Change: 0.26105\nIteration: 5, Log-Lik: -6320.915, Max-Change: 0.21419\nIteration: 6, Log-Lik: -6311.822, Max-Change: 0.14707\nIteration: 7, Log-Lik: -6304.815, Max-Change: 0.19469\nIteration: 8, Log-Lik: -6299.558, Max-Change: 0.13035\nIteration: 9, Log-Lik: -6295.048, Max-Change: 0.15974\nIteration: 10, Log-Lik: -6287.249, Max-Change: 0.14721\nIteration: 11, Log-Lik: -6285.096, Max-Change: 0.13860\nIteration: 12, Log-Lik: -6283.467, Max-Change: 0.07366\nIteration: 13, Log-Lik: -6281.546, Max-Change: 0.10654\nIteration: 14, Log-Lik: -6280.442, Max-Change: 0.05999\nIteration: 15, Log-Lik: -6279.681, Max-Change: 0.07004\nIteration: 16, Log-Lik: -6278.323, Max-Change: 0.09805\nIteration: 17, Log-Lik: -6277.926, Max-Change: 0.04460\nIteration: 18, Log-Lik: -6277.621, Max-Change: 0.02906\nIteration: 19, Log-Lik: -6277.143, Max-Change: 0.02425\nIteration: 20, Log-Lik: -6276.982, Max-Change: 0.02160\nIteration: 21, Log-Lik: -6276.849, Max-Change: 0.01957\nIteration: 22, Log-Lik: -6276.360, Max-Change: 0.01799\nIteration: 23, Log-Lik: -6276.338, Max-Change: 0.01329\nIteration: 24, Log-Lik: -6276.320, Max-Change: 0.00773\nIteration: 25, Log-Lik: -6276.305, Max-Change: 0.00681\nIteration: 26, Log-Lik: -6276.293, Max-Change: 0.00567\nIteration: 27, Log-Lik: -6276.284, Max-Change: 0.00511\nIteration: 28, Log-Lik: -6276.250, Max-Change: 0.00245\nIteration: 29, Log-Lik: -6276.248, Max-Change: 0.00190\nIteration: 30, Log-Lik: -6276.247, Max-Change: 0.00259\nIteration: 31, Log-Lik: -6276.245, Max-Change: 0.00145\nIteration: 32, Log-Lik: -6276.244, Max-Change: 0.00169\nIteration: 33, Log-Lik: -6276.243, Max-Change: 0.00111\nIteration: 34, Log-Lik: -6276.243, Max-Change: 0.00134\nIteration: 35, Log-Lik: -6276.242, Max-Change: 0.00102\nIteration: 36, Log-Lik: -6276.242, Max-Change: 0.00094\nIteration: 37, Log-Lik: -6276.241, Max-Change: 0.00019\nIteration: 38, Log-Lik: -6276.241, Max-Change: 0.00064\nIteration: 39, Log-Lik: -6276.241, Max-Change: 0.00063\nIteration: 40, Log-Lik: -6276.241, Max-Change: 0.00023\nIteration: 41, Log-Lik: -6276.241, Max-Change: 0.00057\nIteration: 42, Log-Lik: -6276.241, Max-Change: 0.00015\nIteration: 43, Log-Lik: -6276.241, Max-Change: 0.00014\nIteration: 44, Log-Lik: -6276.241, Max-Change: 0.00053\nIteration: 45, Log-Lik: -6276.241, Max-Change: 0.00063\nIteration: 46, Log-Lik: -6276.241, Max-Change: 0.00020\nIteration: 47, Log-Lik: -6276.241, Max-Change: 0.00051\nIteration: 48, Log-Lik: -6276.241, Max-Change: 0.00020\nIteration: 49, Log-Lik: -6276.241, Max-Change: 0.00017\nIteration: 50, Log-Lik: -6276.241, Max-Change: 0.00051\nIteration: 51, Log-Lik: -6276.241, Max-Change: 0.00011\nIteration: 52, Log-Lik: -6276.241, Max-Change: 0.00049\nIteration: 53, Log-Lik: -6276.241, Max-Change: 0.00021\nIteration: 54, Log-Lik: -6276.241, Max-Change: 0.00050\nIteration: 55, Log-Lik: -6276.241, Max-Change: 0.00025\nIteration: 56, Log-Lik: -6276.240, Max-Change: 0.00009\n\nCalculating information matrix...\n\nnrm_params <- coef(nrm_fit, IRTpars = TRUE)\n\nrow.name <- names(nrm_params)[1:24]\ncol.names <- c(\"a1\", \"a2\", \"a3\", \"c1\", \"c2\", \"c3\")\n\nnrm_items <- do.call(rbind, lapply(nrm_params[1:24], function(x) {\n  df <- as.data.frame(x)\n  df <- df[1, ]\n  names(df) <- col.names\n  return(df)\n}))\n\nrownames(nrm_items) <- row.name\n\n결과에서, a1, a2, a3은 세 가지 반응 범주(즉, 아니요, 아마도, 예)의 변별도 모수를 나타냅니다. c1, c2, c3으로 레이블이 지정된 열은 난이도 모수(즉, 방정식 6.5의 \\(\\gamma_k\\))를 나타냅니다. 결과는 세 번째 응답 범주(즉, 예)가 모든 문항에 대해 가장 높은 변별도 모수를 가지고 있음을 보여줍니다. 이는 VerbAggWide 데이터 세트의 문항이 언어적 공격성의 잠재적 특성을 측정하고 예 범주가 더 높은 공격성을 나타내기 때문에 예상되는 결과입니다. 즉, 예 범주는 언어적 공격성 수준이 낮거나 높은 응답자를 더 잘 식별할 수 있습니다.\n앞서 설명한 것처럼 세 가지 응답 범주에 대한 변별도 및 난이도 모수의 합은 0으로 제약됩니다. 문항의 모수를 합산하면 이러한 제약 조건을 확인할 수 있습니다. rowSums 함수를 사용하여 변별도 및 난이도 모수를 합산하고 결과를 sum_constraints라는 데이터 프레임에 저장합니다. head 함수를 사용하여 sum_constraints 데이터 세트의 처음 여섯 행을 출력하면 NRM에 대한 모수화의 결과로 모수가 실제로 0으로 합산되는 것을 볼 수 있습니다.\n\nsum_constraints <- data.frame(\n  discrimination = round(rowSums(nrm_items[, 1:3]), 3),\n  difficulty = round(rowSums(nrm_items[, 4:6]), 3))\nhead(sum_constraints)\n\n            discrimination difficulty\nS1WantCurse              0          0\nS1WantScold              0          0\nS1WantShout              0          0\nS2WantCurse              0          0\nS2WantScold              0          0\nS2WantShout              0          0\n\n\n다음으로, 문항 3과 15(즉, VerbAggWide 데이터 세트의 S1WantShout 및 S1DoShout)에 대한 OCC 그래프를 그립니다. 그림 6.9는 시나리오 1(즉, 버스가 나를 위해 정차하지 않는 상황)의 맥락에서 소리를 지르는 행동을 하려면 소리를 지르고 싶다는 것보다 더 높은 수준의 언어적 공격성이 필요하다는 것을 보여줍니다. 문항 15에서 예(즉, 그래프의 P3)라는 반응 범주를 선택하면 더 높은 수준의 언어적 공격성이 요구되는 반면, 문항 3에서는 아마도 또는 예를 선택하면 상대적으로 낮은 수준의 언어적 공격성이 요구됩니다.\n\nplot(nrm_fit, type = \"trace\", which.items = c(3, 15),\n     par.settings = simpleTheme(lty = 1:3, lwd = 2),\n     auto.key = list(points = FALSE, lines = TRUE, columns = 3))\n\n\n\n\n또한 특정 문항의 각 응답 범주에 대한 OCC를 개별적으로 볼 수도 있습니다. 그림 6.10은 VerbAggWide 데이터 세트의 문항 15에 대한 OCC를 보여줍니다. CE = TRUE를 포함하여 OCC 라인 주위에 95% 신뢰 구간을 그립니다.\n\nitemplot(nrm_fit, item = 15, CE = TRUE)\n\n\n\n\n\n\n6.4.2 내재된 로짓 모델\n내재된 로짓 모델(NLM; Suh & Bolt, 2010)은 정답 범주와 모든 오답 범주(즉, 방해 요인)가 개별적으로 모델링되는 선다형 문항에 적합합니다. 따라서 NLM은 이분 IRT 모델(예: 2PL 또는 3PL 모델)을 NRM과 결합한 NRM의 변형으로 간주할 수 있습니다. Suh와 Bolt(2010)에 따르면 NLM은 오답범주가가 제공하는 정보가 유익할 때는 이를 유지하고, 정답 범주를 모델링하는 것이 주요 관심사인 경우에는 오답 범주의 정보를 무시할 수 있는 잠재력을 가지고 있습니다. 일반적인 NLM은 두 가지 수준으로 구성됩니다. 레벨 1은 오답 범주 대 정답범주를 선택할 확률을 설명하고, 레벨 2는 각 오답범주와 관련된 확률을 모델링하는 것을 다룹니다.\nNLM에는 여러 가지 변형이 있지만, 다른 버전의 NLM은 변별도 및 추측도 모수에 대한 추가 제약이 있는 3PL-NLM의 특수한 경우이므로 3PL-NLM 버전부터 시작합니다. 3PL-NLM은 수학적으로 다음과 같이 표현할 수 있습니다.\n\\[\nP(X_i=0, D_{iv}=1|\\theta)=P(X_i=0|\\theta)P(D_{iv}=1|X_i=0,\\theta)\n\\]\n\\[\n=\\{1-[c_i+(1-c_i) {1 \\over 1 + exp^{-(b_i+a_i\\theta)}}]\\}[{exp^{Z_{iv}(\\theta)} \\over \\sum_{k=1}^m exp^{Z_{ik}(\\theta)}}]\n\\]\n\n여기서 \\(P(X_i=0, D_{iv}=1|\\theta)\\)는 피험자가 잠재 특성 \\(\\theta\\)가 주어졌을 때 문항 \\(i\\)를 오답하고 오답범주 \\(v\\)를 선택할 확률이고,\n\\(c_i\\)는 문항 \\(i\\)의 추측도 모수,\n\\(b_i\\)는 문항 \\(i\\)의 난이도 모수,\n\\(a_i\\)는 문항 \\(i\\)의 변별도 모수이며,\n\\(Z_{ik}(\\theta) = \\gamma_{iv} + a_{iv}\\theta\\)는 방정식 6.5의 분자와 같습니다.\n\n3PL-NLM에서 방정식 6.6의 첫 번째 부분은 정답 확률을 모델링하고 방정식 6.6의 두 번째 부분은 각 오답 범주를 선택할 수 있는 개별 확률을 모델링합니다.\n2PL-NLM은 문항 \\(i\\)에 대한 추측도 모수(즉, \\(c_i\\))가 0으로 제한되는 3PL-NLM의 특수한 형태로 정의할 수 있습니다. 따라서 2PL-NLM은 다음과 같이 작성할 수 있습니다.\n\\[\nP(X_i=0, D_{iv}=1|\\theta)=\\{1-[{1 \\over 1 + exp^{-(b_i+a_i\\theta)}}]\\}[{exp^{Z_{iv}(\\theta)} \\over \\sum_{k=1}^m exp^{Z_{ik}(\\theta)}}]\n\\]\n2PL-NLM과 3PL-NLM을 적합하는 방법을 보여드리기 위해 hemp 패키지의 multiplechoice 데이터 세트를 사용합니다. 이 데이터 세트에는 496명의 수험생에게 27개의 선다형 문항으로 구성된 가상 검사의 문항 응답이 포함되어 있습니다. 각 문항에는 4개의 응답 선택지(A, B, C, D)가 있지만 응답 선택지는 데이터 세트에서 숫자로 표시됩니다(예: A = 1, B = 2, C = 3, D = 4). 다음 예에서는 네 가지 응답 선택지를 명목 범주로 간주하여 문항에 대한 정답 선택지를 정의하는 정답 키를 제공합니다.\n2PL-NLM으로 예제를 시작합니다. mirt 함수에서 itemtype = “2PLNRM”을 사용하여 문항 모수를 추정하기 위해 2PL-NLM을 선택합니다. 그런 다음 추정된 문항 모수를 추출하여 twoplnlm_items에 저장한 다음 head 함수를 사용하여 처음 여섯 행을 출력합니다.\n\nkey = c(4, 3, 2, 3, 4, 3, 2, 3, 1,\n        4, 3, 2, 3, 3, 4, 2, 4, 3,\n        3, 2, 2, 1, 2, 1, 1, 2, 1)\ntwoplnlm_mod <- \"ability = 1 - 27\"\ntwoplnlm_fit <- mirt(data = multiplechoice,\n                     model = twoplnlm_mod, itemtype = \"2PLNRM\",\n                     SE = TRUE, key = key)\n\n\nIteration: 1, Log-Lik: -13582.345, Max-Change: 3.30946\nIteration: 2, Log-Lik: -12310.488, Max-Change: 0.77348\nIteration: 3, Log-Lik: -12270.217, Max-Change: 0.25349\nIteration: 4, Log-Lik: -12263.086, Max-Change: 0.13490\nIteration: 5, Log-Lik: -12261.361, Max-Change: 0.07300\nIteration: 6, Log-Lik: -12260.853, Max-Change: 0.03835\nIteration: 7, Log-Lik: -12260.699, Max-Change: 0.02494\nIteration: 8, Log-Lik: -12260.622, Max-Change: 0.01726\nIteration: 9, Log-Lik: -12260.584, Max-Change: 0.00646\nIteration: 10, Log-Lik: -12260.571, Max-Change: 0.00413\nIteration: 11, Log-Lik: -12260.559, Max-Change: 0.00576\nIteration: 12, Log-Lik: -12260.550, Max-Change: 0.00225\nIteration: 13, Log-Lik: -12260.546, Max-Change: 0.00220\nIteration: 14, Log-Lik: -12260.542, Max-Change: 0.00158\nIteration: 15, Log-Lik: -12260.539, Max-Change: 0.00155\nIteration: 16, Log-Lik: -12260.534, Max-Change: 0.00051\nIteration: 17, Log-Lik: -12260.534, Max-Change: 0.00019\nIteration: 18, Log-Lik: -12260.534, Max-Change: 0.00019\nIteration: 19, Log-Lik: -12260.533, Max-Change: 0.00088\nIteration: 20, Log-Lik: -12260.533, Max-Change: 0.00065\nIteration: 21, Log-Lik: -12260.533, Max-Change: 0.00012\nIteration: 22, Log-Lik: -12260.533, Max-Change: 0.00010\nIteration: 23, Log-Lik: -12260.533, Max-Change: 0.00048\nIteration: 24, Log-Lik: -12260.533, Max-Change: 0.00008\n\nCalculating information matrix...\n\ntwoplnlm_params <- coef(twoplnlm_fit, IRTpars = TRUE,\n                        simplify = TRUE)\ntwoplnlm_items <- as.data.frame(twoplnlm_params$items)\nhead(twoplnlm_items)\n\n              a          b g u         a1          a2          a3         c1\nitem1 0.5235573 -3.4086260 0 1 -0.4839230 -0.59603034  1.07995330 -0.2490648\nitem2 0.4940809 -2.8496901 0 1  0.2270783 -0.35252767  0.12544933  0.6741845\nitem3 0.5226378 -0.5159370 0 1  0.1343142 -0.05036814 -0.08394604  0.4162664\nitem4 0.6871739 -1.6939763 0 1  0.2516607  0.29305060 -0.54471132 -0.6398626\nitem5 0.2097941  2.9218435 0 1  0.2643272 -0.03633783 -0.22798933  0.8475738\nitem6 0.5709976 -0.4476874 0 1  0.1282541 -0.41405909  0.28580500 -0.4715466\n               c2         c3\nitem1 -0.05884263  0.3079074\nitem2 -0.04293720 -0.6312473\nitem3 -0.79558238  0.3793160\nitem4  0.66367996 -0.0238174\nitem5  0.50175068 -1.3493244\nitem6  0.22261253  0.2489341\n\n\n결과에서 처음 몇 개의 열(a, b, g, u)은 제5장에서 설명한 2PL 모델의 일반적인 문항 모수입니다. 이 열은 변별도, 난이도, 하한 점근값(즉, 추측도) 및 상한 점근값 모수를 나타냅니다. 2PL 모델에는 추측도 및 상위 점근 모수가 포함되지 않으므로 모든 문항에 대해 각각 0과 1로 고정됩니다. 결과의 다음 열(A1, A2, A3, C1, C2, C3)은 선다형 문항의 세 가지 오답 범주에 대한 NRM 기반 모수입니다.\n그림 6.11에서는 2PL-NLM에서 추정된 모수를 기반으로 한 item 8 및 21의 OCC를 볼 수 있습니다. item 8의 세 번째 응답 범주(P3)와 item 21의 두 번째 응답 범주(P2)는 양의 기울기를 가지며, 이는 문항 8과 21의 정답 범주이기 때문입니다. 이러한 범주의 곡선은 2PL-NLM에서 추측도 모수가 0과 같기 때문에 \\(P(\\theta) = 0\\) 주변에서 시작됩니다. 두 문항 모두에서 P4로 표시된 네 번째 응답 선택지 D가 저능력 피험자에게 가장 그럴듯한 오답지로 보입니다. 특히 8번 문항에서 저능력 피험자(예: \\(\\theta < -4\\))가 이 문항의 오답지인 네 번째 응답 선택지를 선택할 가능성이 매우 높습니다. 그러나 item 8의 첫 번째 응답 선택지인 P1의 곡선이 거의 평탄하다는 점을 고려할 때, 이는 가장 가능성이 낮은 오답 범주입니다. 즉, 이 특정 오답 범주를 선택하는 피험자는 거의 없을 것입니다. item 21의 세 번째 응답 선택지인 P3에 대해서도 비슷한 해석을 내릴 수 있습니다.\n\nplot(twoplnlm_fit, type = \"trace\", which.items = c(8, 21),\n     par.settings = simpleTheme(lty = 1:4, lwd = 2),\n     auto.key = list(points = FALSE, lines = TRUE, columns = 4))\n\n\n\n\n다음으로 동일한 데이터 세트를 사용하여 3PL-NLM에 적합합니다. 이번에는 itemtype = “3PLNRM”을 사용하여 3PLNLM을 기반으로 문항 모수를 추정하고, 추정된 문항 모수를 threeplnlm_items에 저장한 다음 다시 heat 함수를 사용하여 처음 몇 행을 출력합니다.\n\nthreeplnlm_mod <- \"ability = 1 - 27\"\nthreeplnlm_fit <- mirt(data = multiplechoice, \n                       model = threeplnlm_mod, itemtype = \"3PLNRM\",\n                       SE = TRUE, key = key)\n\n\nIteration: 1, Log-Lik: -13661.836, Max-Change: 3.87503\nIteration: 2, Log-Lik: -12307.749, Max-Change: 1.11248\nIteration: 3, Log-Lik: -12257.837, Max-Change: 0.95567\nIteration: 4, Log-Lik: -12242.241, Max-Change: 0.52467\nIteration: 5, Log-Lik: -12237.344, Max-Change: 0.37765\nIteration: 6, Log-Lik: -12235.181, Max-Change: 0.33943\nIteration: 7, Log-Lik: -12233.057, Max-Change: 0.23537\nIteration: 8, Log-Lik: -12232.620, Max-Change: 0.51075\nIteration: 9, Log-Lik: -12232.377, Max-Change: 0.58432\nIteration: 10, Log-Lik: -12234.480, Max-Change: 0.25394\nIteration: 11, Log-Lik: -12231.935, Max-Change: 0.06795\nIteration: 12, Log-Lik: -12231.899, Max-Change: 0.00457\nIteration: 13, Log-Lik: -12231.898, Max-Change: 0.00434\nIteration: 14, Log-Lik: -12231.890, Max-Change: 0.15134\nIteration: 15, Log-Lik: -12231.871, Max-Change: 0.00662\nIteration: 16, Log-Lik: -12231.871, Max-Change: 0.00663\nIteration: 17, Log-Lik: -12231.868, Max-Change: 0.00169\nIteration: 18, Log-Lik: -12231.866, Max-Change: 0.00092\nIteration: 19, Log-Lik: -12231.865, Max-Change: 0.00188\nIteration: 20, Log-Lik: -12231.864, Max-Change: 0.00139\nIteration: 21, Log-Lik: -12231.863, Max-Change: 0.00032\nIteration: 22, Log-Lik: -12231.863, Max-Change: 0.00024\nIteration: 23, Log-Lik: -12231.863, Max-Change: 0.00110\nIteration: 24, Log-Lik: -12231.863, Max-Change: 0.00122\nIteration: 25, Log-Lik: -12231.863, Max-Change: 0.00030\nIteration: 26, Log-Lik: -12231.863, Max-Change: 0.00121\nIteration: 27, Log-Lik: -12231.862, Max-Change: 0.00121\nIteration: 28, Log-Lik: -12231.862, Max-Change: 0.00044\nIteration: 29, Log-Lik: -12231.862, Max-Change: 0.00116\nIteration: 30, Log-Lik: -12231.862, Max-Change: 0.00027\nIteration: 31, Log-Lik: -12231.862, Max-Change: 0.00023\nIteration: 32, Log-Lik: -12231.862, Max-Change: 0.00113\nIteration: 33, Log-Lik: -12231.862, Max-Change: 0.00109\nIteration: 34, Log-Lik: -12231.862, Max-Change: 0.00038\nIteration: 35, Log-Lik: -12231.862, Max-Change: 0.00107\nIteration: 36, Log-Lik: -12231.862, Max-Change: 0.00029\nIteration: 37, Log-Lik: -12231.862, Max-Change: 0.00023\nIteration: 38, Log-Lik: -12231.862, Max-Change: 0.00102\nIteration: 39, Log-Lik: -12231.862, Max-Change: 0.00020\nIteration: 40, Log-Lik: -12231.862, Max-Change: 0.00101\nIteration: 41, Log-Lik: -12231.862, Max-Change: 0.00034\nIteration: 42, Log-Lik: -12231.862, Max-Change: 0.00096\nIteration: 43, Log-Lik: -12231.861, Max-Change: 0.00039\nIteration: 44, Log-Lik: -12231.861, Max-Change: 0.00094\nIteration: 45, Log-Lik: -12231.861, Max-Change: 0.00031\nIteration: 46, Log-Lik: -12231.861, Max-Change: 0.00026\nIteration: 47, Log-Lik: -12231.861, Max-Change: 0.00090\nIteration: 48, Log-Lik: -12231.861, Max-Change: 0.00021\nIteration: 49, Log-Lik: -12231.861, Max-Change: 0.00090\nIteration: 50, Log-Lik: -12231.861, Max-Change: 0.00034\nIteration: 51, Log-Lik: -12231.861, Max-Change: 0.00086\nIteration: 52, Log-Lik: -12231.861, Max-Change: 0.00045\nIteration: 53, Log-Lik: -12231.861, Max-Change: 0.00092\nIteration: 54, Log-Lik: -12231.861, Max-Change: 0.00036\nIteration: 55, Log-Lik: -12231.861, Max-Change: 0.00030\nIteration: 56, Log-Lik: -12231.861, Max-Change: 0.00082\nIteration: 57, Log-Lik: -12231.861, Max-Change: 0.00024\nIteration: 58, Log-Lik: -12231.861, Max-Change: 0.00100\nIteration: 59, Log-Lik: -12231.861, Max-Change: 0.00040\nIteration: 60, Log-Lik: -12231.861, Max-Change: 0.00081\nIteration: 61, Log-Lik: -12231.861, Max-Change: 0.00054\nIteration: 62, Log-Lik: -12231.861, Max-Change: 0.00109\nIteration: 63, Log-Lik: -12231.861, Max-Change: 0.00044\nIteration: 64, Log-Lik: -12231.861, Max-Change: 0.00036\nIteration: 65, Log-Lik: -12231.861, Max-Change: 0.00077\nIteration: 66, Log-Lik: -12231.860, Max-Change: 0.00029\nIteration: 67, Log-Lik: -12231.860, Max-Change: 0.00024\nIteration: 68, Log-Lik: -12231.860, Max-Change: 0.00077\nIteration: 69, Log-Lik: -12231.860, Max-Change: 0.00096\nIteration: 70, Log-Lik: -12231.860, Max-Change: 0.00039\nIteration: 71, Log-Lik: -12231.860, Max-Change: 0.00078\nIteration: 72, Log-Lik: -12231.860, Max-Change: 0.00031\nIteration: 73, Log-Lik: -12231.860, Max-Change: 0.00026\nIteration: 74, Log-Lik: -12231.860, Max-Change: 0.00074\nIteration: 75, Log-Lik: -12231.860, Max-Change: 0.00104\nIteration: 76, Log-Lik: -12231.860, Max-Change: 0.00039\nIteration: 77, Log-Lik: -12231.860, Max-Change: 0.00078\nIteration: 78, Log-Lik: -12231.860, Max-Change: 0.00031\nIteration: 79, Log-Lik: -12231.860, Max-Change: 0.00026\nIteration: 80, Log-Lik: -12231.860, Max-Change: 0.00073\nIteration: 81, Log-Lik: -12231.860, Max-Change: 0.00021\nIteration: 82, Log-Lik: -12231.860, Max-Change: 0.00087\nIteration: 83, Log-Lik: -12231.860, Max-Change: 0.00035\nIteration: 84, Log-Lik: -12231.860, Max-Change: 0.00073\nIteration: 85, Log-Lik: -12231.860, Max-Change: 0.00046\nIteration: 86, Log-Lik: -12231.860, Max-Change: 0.00091\nIteration: 87, Log-Lik: -12231.860, Max-Change: 0.00037\nIteration: 88, Log-Lik: -12231.860, Max-Change: 0.00030\nIteration: 89, Log-Lik: -12231.860, Max-Change: 0.00072\nIteration: 90, Log-Lik: -12231.860, Max-Change: 0.00024\nIteration: 91, Log-Lik: -12231.860, Max-Change: 0.00101\nIteration: 92, Log-Lik: -12231.860, Max-Change: 0.00041\nIteration: 93, Log-Lik: -12231.859, Max-Change: 0.00081\nIteration: 94, Log-Lik: -12231.859, Max-Change: 0.00055\nIteration: 95, Log-Lik: -12231.859, Max-Change: 0.00109\nIteration: 96, Log-Lik: -12231.859, Max-Change: 0.00044\nIteration: 97, Log-Lik: -12231.859, Max-Change: 0.00036\nIteration: 98, Log-Lik: -12231.859, Max-Change: 0.00072\nIteration: 99, Log-Lik: -12231.859, Max-Change: 0.00029\nIteration: 100, Log-Lik: -12231.859, Max-Change: 0.00024\nIteration: 101, Log-Lik: -12231.859, Max-Change: 0.00070\nIteration: 102, Log-Lik: -12231.859, Max-Change: 0.00097\nIteration: 103, Log-Lik: -12231.859, Max-Change: 0.00039\nIteration: 104, Log-Lik: -12231.859, Max-Change: 0.00077\nIteration: 105, Log-Lik: -12231.859, Max-Change: 0.00031\nIteration: 106, Log-Lik: -12231.859, Max-Change: 0.00026\nIteration: 107, Log-Lik: -12231.859, Max-Change: 0.00070\nIteration: 108, Log-Lik: -12231.859, Max-Change: 0.00103\nIteration: 109, Log-Lik: -12231.859, Max-Change: 0.00039\nIteration: 110, Log-Lik: -12231.859, Max-Change: 0.00076\nIteration: 111, Log-Lik: -12231.859, Max-Change: 0.00031\nIteration: 112, Log-Lik: -12231.859, Max-Change: 0.00026\nIteration: 113, Log-Lik: -12231.859, Max-Change: 0.00071\nIteration: 114, Log-Lik: -12231.859, Max-Change: 0.00103\nIteration: 115, Log-Lik: -12231.859, Max-Change: 0.00038\nIteration: 116, Log-Lik: -12231.859, Max-Change: 0.00075\nIteration: 117, Log-Lik: -12231.859, Max-Change: 0.00030\nIteration: 118, Log-Lik: -12231.859, Max-Change: 0.00025\nIteration: 119, Log-Lik: -12231.859, Max-Change: 0.00070\nIteration: 120, Log-Lik: -12231.859, Max-Change: 0.00020\nIteration: 121, Log-Lik: -12231.859, Max-Change: 0.00085\nIteration: 122, Log-Lik: -12231.859, Max-Change: 0.00034\nIteration: 123, Log-Lik: -12231.859, Max-Change: 0.00070\nIteration: 124, Log-Lik: -12231.859, Max-Change: 0.00045\nIteration: 125, Log-Lik: -12231.858, Max-Change: 0.00088\nIteration: 126, Log-Lik: -12231.858, Max-Change: 0.00036\nIteration: 127, Log-Lik: -12231.858, Max-Change: 0.00029\nIteration: 128, Log-Lik: -12231.858, Max-Change: 0.00071\nIteration: 129, Log-Lik: -12231.858, Max-Change: 0.00024\nIteration: 130, Log-Lik: -12231.858, Max-Change: 0.00099\nIteration: 131, Log-Lik: -12231.858, Max-Change: 0.00040\nIteration: 132, Log-Lik: -12231.858, Max-Change: 0.00079\nIteration: 133, Log-Lik: -12231.858, Max-Change: 0.00054\nIteration: 134, Log-Lik: -12231.858, Max-Change: 0.00021\nIteration: 135, Log-Lik: -12231.858, Max-Change: 0.00071\nIteration: 136, Log-Lik: -12231.858, Max-Change: 0.00025\nIteration: 137, Log-Lik: -12231.858, Max-Change: 0.00071\nIteration: 138, Log-Lik: -12231.858, Max-Change: 0.00100\nIteration: 139, Log-Lik: -12231.858, Max-Change: 0.00038\nIteration: 140, Log-Lik: -12231.858, Max-Change: 0.00075\nIteration: 141, Log-Lik: -12231.858, Max-Change: 0.00031\nIteration: 142, Log-Lik: -12231.858, Max-Change: 0.00025\nIteration: 143, Log-Lik: -12231.858, Max-Change: 0.00072\nIteration: 144, Log-Lik: -12231.858, Max-Change: 0.00101\nIteration: 145, Log-Lik: -12231.858, Max-Change: 0.00038\nIteration: 146, Log-Lik: -12231.858, Max-Change: 0.00074\nIteration: 147, Log-Lik: -12231.858, Max-Change: 0.00030\nIteration: 148, Log-Lik: -12231.858, Max-Change: 0.00025\nIteration: 149, Log-Lik: -12231.858, Max-Change: 0.00071\nIteration: 150, Log-Lik: -12231.858, Max-Change: 0.00101\nIteration: 151, Log-Lik: -12231.858, Max-Change: 0.00037\nIteration: 152, Log-Lik: -12231.858, Max-Change: 0.00073\nIteration: 153, Log-Lik: -12231.858, Max-Change: 0.00030\nIteration: 154, Log-Lik: -12231.858, Max-Change: 0.00025\nIteration: 155, Log-Lik: -12231.858, Max-Change: 0.00072\nIteration: 156, Log-Lik: -12231.858, Max-Change: 0.00099\nIteration: 157, Log-Lik: -12231.858, Max-Change: 0.00037\nIteration: 158, Log-Lik: -12231.858, Max-Change: 0.00072\nIteration: 159, Log-Lik: -12231.857, Max-Change: 0.00029\nIteration: 160, Log-Lik: -12231.857, Max-Change: 0.00024\nIteration: 161, Log-Lik: -12231.857, Max-Change: 0.00072\nIteration: 162, Log-Lik: -12231.857, Max-Change: 0.00097\nIteration: 163, Log-Lik: -12231.857, Max-Change: 0.00036\nIteration: 164, Log-Lik: -12231.857, Max-Change: 0.00072\nIteration: 165, Log-Lik: -12231.857, Max-Change: 0.00029\nIteration: 166, Log-Lik: -12231.857, Max-Change: 0.00024\nIteration: 167, Log-Lik: -12231.857, Max-Change: 0.00072\nIteration: 168, Log-Lik: -12231.857, Max-Change: 0.00096\nIteration: 169, Log-Lik: -12231.857, Max-Change: 0.00035\nIteration: 170, Log-Lik: -12231.857, Max-Change: 0.00072\nIteration: 171, Log-Lik: -12231.857, Max-Change: 0.00028\nIteration: 172, Log-Lik: -12231.857, Max-Change: 0.00023\nIteration: 173, Log-Lik: -12231.857, Max-Change: 0.00072\nIteration: 174, Log-Lik: -12231.857, Max-Change: 0.00094\nIteration: 175, Log-Lik: -12231.857, Max-Change: 0.00035\nIteration: 176, Log-Lik: -12231.857, Max-Change: 0.00072\nIteration: 177, Log-Lik: -12231.857, Max-Change: 0.00028\nIteration: 178, Log-Lik: -12231.857, Max-Change: 0.00023\nIteration: 179, Log-Lik: -12231.857, Max-Change: 0.00072\nIteration: 180, Log-Lik: -12231.857, Max-Change: 0.00092\nIteration: 181, Log-Lik: -12231.857, Max-Change: 0.00034\nIteration: 182, Log-Lik: -12231.857, Max-Change: 0.00072\nIteration: 183, Log-Lik: -12231.857, Max-Change: 0.00027\nIteration: 184, Log-Lik: -12231.857, Max-Change: 0.00023\nIteration: 185, Log-Lik: -12231.857, Max-Change: 0.00072\nIteration: 186, Log-Lik: -12231.857, Max-Change: 0.00091\nIteration: 187, Log-Lik: -12231.857, Max-Change: 0.00034\nIteration: 188, Log-Lik: -12231.857, Max-Change: 0.00072\nIteration: 189, Log-Lik: -12231.857, Max-Change: 0.00027\nIteration: 190, Log-Lik: -12231.857, Max-Change: 0.00022\nIteration: 191, Log-Lik: -12231.857, Max-Change: 0.00072\nIteration: 192, Log-Lik: -12231.857, Max-Change: 0.00089\nIteration: 193, Log-Lik: -12231.857, Max-Change: 0.00033\nIteration: 194, Log-Lik: -12231.857, Max-Change: 0.00072\nIteration: 195, Log-Lik: -12231.857, Max-Change: 0.00026\nIteration: 196, Log-Lik: -12231.857, Max-Change: 0.00022\nIteration: 197, Log-Lik: -12231.857, Max-Change: 0.00072\nIteration: 198, Log-Lik: -12231.857, Max-Change: 0.00087\nIteration: 199, Log-Lik: -12231.856, Max-Change: 0.00032\nIteration: 200, Log-Lik: -12231.856, Max-Change: 0.00072\nIteration: 201, Log-Lik: -12231.856, Max-Change: 0.00026\nIteration: 202, Log-Lik: -12231.856, Max-Change: 0.00021\nIteration: 203, Log-Lik: -12231.856, Max-Change: 0.00072\nIteration: 204, Log-Lik: -12231.856, Max-Change: 0.00086\nIteration: 205, Log-Lik: -12231.856, Max-Change: 0.00032\nIteration: 206, Log-Lik: -12231.856, Max-Change: 0.00072\nIteration: 207, Log-Lik: -12231.856, Max-Change: 0.00025\nIteration: 208, Log-Lik: -12231.856, Max-Change: 0.00021\nIteration: 209, Log-Lik: -12231.856, Max-Change: 0.00072\nIteration: 210, Log-Lik: -12231.856, Max-Change: 0.00084\nIteration: 211, Log-Lik: -12231.856, Max-Change: 0.00031\nIteration: 212, Log-Lik: -12231.856, Max-Change: 0.00072\nIteration: 213, Log-Lik: -12231.856, Max-Change: 0.00025\nIteration: 214, Log-Lik: -12231.856, Max-Change: 0.00021\nIteration: 215, Log-Lik: -12231.856, Max-Change: 0.00072\nIteration: 216, Log-Lik: -12231.856, Max-Change: 0.00082\nIteration: 217, Log-Lik: -12231.856, Max-Change: 0.00030\nIteration: 218, Log-Lik: -12231.856, Max-Change: 0.00072\nIteration: 219, Log-Lik: -12231.856, Max-Change: 0.00024\nIteration: 220, Log-Lik: -12231.856, Max-Change: 0.00020\nIteration: 221, Log-Lik: -12231.856, Max-Change: 0.00072\nIteration: 222, Log-Lik: -12231.856, Max-Change: 0.00080\nIteration: 223, Log-Lik: -12231.856, Max-Change: 0.00030\nIteration: 224, Log-Lik: -12231.856, Max-Change: 0.00072\nIteration: 225, Log-Lik: -12231.856, Max-Change: 0.00024\nIteration: 226, Log-Lik: -12231.856, Max-Change: 0.00020\nIteration: 227, Log-Lik: -12231.856, Max-Change: 0.00072\nIteration: 228, Log-Lik: -12231.856, Max-Change: 0.00079\nIteration: 229, Log-Lik: -12231.856, Max-Change: 0.00029\nIteration: 230, Log-Lik: -12231.856, Max-Change: 0.00072\nIteration: 231, Log-Lik: -12231.856, Max-Change: 0.00023\nIteration: 232, Log-Lik: -12231.856, Max-Change: 0.00019\nIteration: 233, Log-Lik: -12231.856, Max-Change: 0.00072\nIteration: 234, Log-Lik: -12231.856, Max-Change: 0.00077\nIteration: 235, Log-Lik: -12231.856, Max-Change: 0.00028\nIteration: 236, Log-Lik: -12231.856, Max-Change: 0.00072\nIteration: 237, Log-Lik: -12231.856, Max-Change: 0.00023\nIteration: 238, Log-Lik: -12231.856, Max-Change: 0.00019\nIteration: 239, Log-Lik: -12231.856, Max-Change: 0.00072\nIteration: 240, Log-Lik: -12231.856, Max-Change: 0.00075\nIteration: 241, Log-Lik: -12231.856, Max-Change: 0.00028\nIteration: 242, Log-Lik: -12231.856, Max-Change: 0.00072\nIteration: 243, Log-Lik: -12231.855, Max-Change: 0.00022\nIteration: 244, Log-Lik: -12231.855, Max-Change: 0.00018\nIteration: 245, Log-Lik: -12231.855, Max-Change: 0.00072\nIteration: 246, Log-Lik: -12231.855, Max-Change: 0.00073\nIteration: 247, Log-Lik: -12231.855, Max-Change: 0.00027\nIteration: 248, Log-Lik: -12231.855, Max-Change: 0.00072\nIteration: 249, Log-Lik: -12231.855, Max-Change: 0.00022\nIteration: 250, Log-Lik: -12231.855, Max-Change: 0.00018\nIteration: 251, Log-Lik: -12231.855, Max-Change: 0.00072\nIteration: 252, Log-Lik: -12231.855, Max-Change: 0.00072\nIteration: 253, Log-Lik: -12231.855, Max-Change: 0.00026\nIteration: 254, Log-Lik: -12231.855, Max-Change: 0.00072\nIteration: 255, Log-Lik: -12231.855, Max-Change: 0.00021\nIteration: 256, Log-Lik: -12231.855, Max-Change: 0.00017\nIteration: 257, Log-Lik: -12231.855, Max-Change: 0.00072\nIteration: 258, Log-Lik: -12231.855, Max-Change: 0.00072\nIteration: 259, Log-Lik: -12231.855, Max-Change: 0.00026\nIteration: 260, Log-Lik: -12231.855, Max-Change: 0.00072\nIteration: 261, Log-Lik: -12231.855, Max-Change: 0.00020\nIteration: 262, Log-Lik: -12231.855, Max-Change: 0.00017\nIteration: 263, Log-Lik: -12231.855, Max-Change: 0.00072\nIteration: 264, Log-Lik: -12231.855, Max-Change: 0.00072\nIteration: 265, Log-Lik: -12231.855, Max-Change: 0.00025\nIteration: 266, Log-Lik: -12231.855, Max-Change: 0.00072\nIteration: 267, Log-Lik: -12231.855, Max-Change: 0.00020\nIteration: 268, Log-Lik: -12231.855, Max-Change: 0.00016\nIteration: 269, Log-Lik: -12231.855, Max-Change: 0.00072\nIteration: 270, Log-Lik: -12231.855, Max-Change: 0.00072\nIteration: 271, Log-Lik: -12231.855, Max-Change: 0.00024\nIteration: 272, Log-Lik: -12231.855, Max-Change: 0.00072\nIteration: 273, Log-Lik: -12231.855, Max-Change: 0.00019\nIteration: 274, Log-Lik: -12231.855, Max-Change: 0.00016\nIteration: 275, Log-Lik: -12231.855, Max-Change: 0.00072\nIteration: 276, Log-Lik: -12231.855, Max-Change: 0.00072\nIteration: 277, Log-Lik: -12231.855, Max-Change: 0.00023\nIteration: 278, Log-Lik: -12231.855, Max-Change: 0.00072\nIteration: 279, Log-Lik: -12231.855, Max-Change: 0.00019\nIteration: 280, Log-Lik: -12231.855, Max-Change: 0.00015\nIteration: 281, Log-Lik: -12231.855, Max-Change: 0.00072\nIteration: 282, Log-Lik: -12231.855, Max-Change: 0.00072\nIteration: 283, Log-Lik: -12231.855, Max-Change: 0.00023\nIteration: 284, Log-Lik: -12231.855, Max-Change: 0.00072\nIteration: 285, Log-Lik: -12231.855, Max-Change: 0.00018\nIteration: 286, Log-Lik: -12231.855, Max-Change: 0.00015\nIteration: 287, Log-Lik: -12231.855, Max-Change: 0.00072\nIteration: 288, Log-Lik: -12231.855, Max-Change: 0.00072\nIteration: 289, Log-Lik: -12231.855, Max-Change: 0.00022\nIteration: 290, Log-Lik: -12231.855, Max-Change: 0.00072\nIteration: 291, Log-Lik: -12231.854, Max-Change: 0.00018\nIteration: 292, Log-Lik: -12231.854, Max-Change: 0.00015\nIteration: 293, Log-Lik: -12231.854, Max-Change: 0.00072\nIteration: 294, Log-Lik: -12231.854, Max-Change: 0.00072\nIteration: 295, Log-Lik: -12231.854, Max-Change: 0.00021\nIteration: 296, Log-Lik: -12231.854, Max-Change: 0.00072\nIteration: 297, Log-Lik: -12231.854, Max-Change: 0.00017\nIteration: 298, Log-Lik: -12231.854, Max-Change: 0.00014\nIteration: 299, Log-Lik: -12231.854, Max-Change: 0.00072\nIteration: 300, Log-Lik: -12231.854, Max-Change: 0.00071\nIteration: 301, Log-Lik: -12231.854, Max-Change: 0.00021\nIteration: 302, Log-Lik: -12231.854, Max-Change: 0.00072\nIteration: 303, Log-Lik: -12231.854, Max-Change: 0.00017\nIteration: 304, Log-Lik: -12231.854, Max-Change: 0.00014\nIteration: 305, Log-Lik: -12231.854, Max-Change: 0.00072\nIteration: 306, Log-Lik: -12231.854, Max-Change: 0.00072\nIteration: 307, Log-Lik: -12231.854, Max-Change: 0.00020\nIteration: 308, Log-Lik: -12231.854, Max-Change: 0.00071\nIteration: 309, Log-Lik: -12231.854, Max-Change: 0.00016\nIteration: 310, Log-Lik: -12231.854, Max-Change: 0.00014\nIteration: 311, Log-Lik: -12231.854, Max-Change: 0.00072\nIteration: 312, Log-Lik: -12231.854, Max-Change: 0.00071\nIteration: 313, Log-Lik: -12231.854, Max-Change: 0.00019\nIteration: 314, Log-Lik: -12231.854, Max-Change: 0.00072\nIteration: 315, Log-Lik: -12231.854, Max-Change: 0.00015\nIteration: 316, Log-Lik: -12231.854, Max-Change: 0.00014\nIteration: 317, Log-Lik: -12231.854, Max-Change: 0.00071\nIteration: 318, Log-Lik: -12231.854, Max-Change: 0.00072\nIteration: 319, Log-Lik: -12231.854, Max-Change: 0.00019\nIteration: 320, Log-Lik: -12231.854, Max-Change: 0.00071\nIteration: 321, Log-Lik: -12231.854, Max-Change: 0.00015\nIteration: 322, Log-Lik: -12231.854, Max-Change: 0.00014\nIteration: 323, Log-Lik: -12231.854, Max-Change: 0.00071\nIteration: 324, Log-Lik: -12231.854, Max-Change: 0.00071\nIteration: 325, Log-Lik: -12231.854, Max-Change: 0.00018\nIteration: 326, Log-Lik: -12231.854, Max-Change: 0.00071\nIteration: 327, Log-Lik: -12231.854, Max-Change: 0.00014\nIteration: 328, Log-Lik: -12231.854, Max-Change: 0.00014\nIteration: 329, Log-Lik: -12231.854, Max-Change: 0.00071\nIteration: 330, Log-Lik: -12231.854, Max-Change: 0.00071\nIteration: 331, Log-Lik: -12231.854, Max-Change: 0.00017\nIteration: 332, Log-Lik: -12231.854, Max-Change: 0.00071\nIteration: 333, Log-Lik: -12231.854, Max-Change: 0.00014\nIteration: 334, Log-Lik: -12231.854, Max-Change: 0.00014\nIteration: 335, Log-Lik: -12231.854, Max-Change: 0.00071\nIteration: 336, Log-Lik: -12231.854, Max-Change: 0.00071\nIteration: 337, Log-Lik: -12231.854, Max-Change: 0.00017\nIteration: 338, Log-Lik: -12231.854, Max-Change: 0.00071\nIteration: 339, Log-Lik: -12231.854, Max-Change: 0.00014\nIteration: 340, Log-Lik: -12231.854, Max-Change: 0.00014\nIteration: 341, Log-Lik: -12231.854, Max-Change: 0.00071\nIteration: 342, Log-Lik: -12231.854, Max-Change: 0.00071\nIteration: 343, Log-Lik: -12231.853, Max-Change: 0.00017\nIteration: 344, Log-Lik: -12231.853, Max-Change: 0.00071\nIteration: 345, Log-Lik: -12231.853, Max-Change: 0.00014\nIteration: 346, Log-Lik: -12231.853, Max-Change: 0.00014\nIteration: 347, Log-Lik: -12231.853, Max-Change: 0.00071\nIteration: 348, Log-Lik: -12231.853, Max-Change: 0.00071\nIteration: 349, Log-Lik: -12231.853, Max-Change: 0.00017\nIteration: 350, Log-Lik: -12231.853, Max-Change: 0.00071\nIteration: 351, Log-Lik: -12231.853, Max-Change: 0.00014\nIteration: 352, Log-Lik: -12231.853, Max-Change: 0.00014\nIteration: 353, Log-Lik: -12231.853, Max-Change: 0.00071\nIteration: 354, Log-Lik: -12231.853, Max-Change: 0.00071\nIteration: 355, Log-Lik: -12231.853, Max-Change: 0.00017\nIteration: 356, Log-Lik: -12231.853, Max-Change: 0.00071\nIteration: 357, Log-Lik: -12231.853, Max-Change: 0.00014\nIteration: 358, Log-Lik: -12231.853, Max-Change: 0.00014\nIteration: 359, Log-Lik: -12231.853, Max-Change: 0.00071\nIteration: 360, Log-Lik: -12231.853, Max-Change: 0.00071\nIteration: 361, Log-Lik: -12231.853, Max-Change: 0.00017\nIteration: 362, Log-Lik: -12231.853, Max-Change: 0.00071\nIteration: 363, Log-Lik: -12231.853, Max-Change: 0.00014\nIteration: 364, Log-Lik: -12231.853, Max-Change: 0.00014\nIteration: 365, Log-Lik: -12231.853, Max-Change: 0.00071\nIteration: 366, Log-Lik: -12231.853, Max-Change: 0.00071\nIteration: 367, Log-Lik: -12231.853, Max-Change: 0.00017\nIteration: 368, Log-Lik: -12231.853, Max-Change: 0.00071\nIteration: 369, Log-Lik: -12231.853, Max-Change: 0.00014\nIteration: 370, Log-Lik: -12231.853, Max-Change: 0.00014\nIteration: 371, Log-Lik: -12231.853, Max-Change: 0.00071\nIteration: 372, Log-Lik: -12231.853, Max-Change: 0.00071\nIteration: 373, Log-Lik: -12231.853, Max-Change: 0.00017\nIteration: 374, Log-Lik: -12231.853, Max-Change: 0.00071\nIteration: 375, Log-Lik: -12231.853, Max-Change: 0.00014\nIteration: 376, Log-Lik: -12231.853, Max-Change: 0.00014\nIteration: 377, Log-Lik: -12231.853, Max-Change: 0.00071\nIteration: 378, Log-Lik: -12231.853, Max-Change: 0.00071\nIteration: 379, Log-Lik: -12231.853, Max-Change: 0.00018\nIteration: 380, Log-Lik: -12231.853, Max-Change: 0.00071\nIteration: 381, Log-Lik: -12231.853, Max-Change: 0.00014\nIteration: 382, Log-Lik: -12231.853, Max-Change: 0.00014\nIteration: 383, Log-Lik: -12231.853, Max-Change: 0.00071\nIteration: 384, Log-Lik: -12231.853, Max-Change: 0.00071\nIteration: 385, Log-Lik: -12231.853, Max-Change: 0.00018\nIteration: 386, Log-Lik: -12231.853, Max-Change: 0.00071\nIteration: 387, Log-Lik: -12231.853, Max-Change: 0.00014\nIteration: 388, Log-Lik: -12231.853, Max-Change: 0.00014\nIteration: 389, Log-Lik: -12231.853, Max-Change: 0.00071\nIteration: 390, Log-Lik: -12231.853, Max-Change: 0.00071\nIteration: 391, Log-Lik: -12231.853, Max-Change: 0.00018\nIteration: 392, Log-Lik: -12231.853, Max-Change: 0.00071\nIteration: 393, Log-Lik: -12231.853, Max-Change: 0.00014\nIteration: 394, Log-Lik: -12231.853, Max-Change: 0.00014\nIteration: 395, Log-Lik: -12231.853, Max-Change: 0.00071\nIteration: 396, Log-Lik: -12231.853, Max-Change: 0.00071\nIteration: 397, Log-Lik: -12231.853, Max-Change: 0.00018\nIteration: 398, Log-Lik: -12231.853, Max-Change: 0.00071\nIteration: 399, Log-Lik: -12231.852, Max-Change: 0.00014\nIteration: 400, Log-Lik: -12231.852, Max-Change: 0.00014\nIteration: 401, Log-Lik: -12231.852, Max-Change: 0.00071\nIteration: 402, Log-Lik: -12231.852, Max-Change: 0.00071\nIteration: 403, Log-Lik: -12231.852, Max-Change: 0.00018\nIteration: 404, Log-Lik: -12231.852, Max-Change: 0.00071\nIteration: 405, Log-Lik: -12231.852, Max-Change: 0.00014\nIteration: 406, Log-Lik: -12231.852, Max-Change: 0.00014\nIteration: 407, Log-Lik: -12231.852, Max-Change: 0.00071\nIteration: 408, Log-Lik: -12231.852, Max-Change: 0.00071\nIteration: 409, Log-Lik: -12231.852, Max-Change: 0.00018\nIteration: 410, Log-Lik: -12231.852, Max-Change: 0.00071\nIteration: 411, Log-Lik: -12231.852, Max-Change: 0.00014\nIteration: 412, Log-Lik: -12231.852, Max-Change: 0.00014\nIteration: 413, Log-Lik: -12231.852, Max-Change: 0.00071\nIteration: 414, Log-Lik: -12231.852, Max-Change: 0.00070\nIteration: 415, Log-Lik: -12231.852, Max-Change: 0.00018\nIteration: 416, Log-Lik: -12231.852, Max-Change: 0.00071\nIteration: 417, Log-Lik: -12231.852, Max-Change: 0.00014\nIteration: 418, Log-Lik: -12231.852, Max-Change: 0.00014\nIteration: 419, Log-Lik: -12231.852, Max-Change: 0.00070\nIteration: 420, Log-Lik: -12231.852, Max-Change: 0.00071\nIteration: 421, Log-Lik: -12231.852, Max-Change: 0.00018\nIteration: 422, Log-Lik: -12231.852, Max-Change: 0.00070\nIteration: 423, Log-Lik: -12231.852, Max-Change: 0.00014\nIteration: 424, Log-Lik: -12231.852, Max-Change: 0.00014\nIteration: 425, Log-Lik: -12231.852, Max-Change: 0.00070\nIteration: 426, Log-Lik: -12231.852, Max-Change: 0.00070\nIteration: 427, Log-Lik: -12231.852, Max-Change: 0.00019\nIteration: 428, Log-Lik: -12231.852, Max-Change: 0.00070\nIteration: 429, Log-Lik: -12231.852, Max-Change: 0.00015\nIteration: 430, Log-Lik: -12231.852, Max-Change: 0.00014\nIteration: 431, Log-Lik: -12231.852, Max-Change: 0.00070\nIteration: 432, Log-Lik: -12231.852, Max-Change: 0.00070\nIteration: 433, Log-Lik: -12231.852, Max-Change: 0.00019\nIteration: 434, Log-Lik: -12231.852, Max-Change: 0.00070\nIteration: 435, Log-Lik: -12231.852, Max-Change: 0.00015\nIteration: 436, Log-Lik: -12231.852, Max-Change: 0.00014\nIteration: 437, Log-Lik: -12231.852, Max-Change: 0.00070\nIteration: 438, Log-Lik: -12231.852, Max-Change: 0.00070\nIteration: 439, Log-Lik: -12231.852, Max-Change: 0.00019\nIteration: 440, Log-Lik: -12231.852, Max-Change: 0.00070\nIteration: 441, Log-Lik: -12231.852, Max-Change: 0.00015\nIteration: 442, Log-Lik: -12231.852, Max-Change: 0.00014\nIteration: 443, Log-Lik: -12231.852, Max-Change: 0.00070\nIteration: 444, Log-Lik: -12231.852, Max-Change: 0.00070\nIteration: 445, Log-Lik: -12231.852, Max-Change: 0.00019\nIteration: 446, Log-Lik: -12231.852, Max-Change: 0.00070\nIteration: 447, Log-Lik: -12231.852, Max-Change: 0.00015\nIteration: 448, Log-Lik: -12231.852, Max-Change: 0.00014\nIteration: 449, Log-Lik: -12231.852, Max-Change: 0.00070\nIteration: 450, Log-Lik: -12231.852, Max-Change: 0.00070\nIteration: 451, Log-Lik: -12231.852, Max-Change: 0.00019\nIteration: 452, Log-Lik: -12231.852, Max-Change: 0.00070\nIteration: 453, Log-Lik: -12231.852, Max-Change: 0.00015\nIteration: 454, Log-Lik: -12231.852, Max-Change: 0.00014\nIteration: 455, Log-Lik: -12231.852, Max-Change: 0.00070\nIteration: 456, Log-Lik: -12231.852, Max-Change: 0.00070\nIteration: 457, Log-Lik: -12231.852, Max-Change: 0.00019\nIteration: 458, Log-Lik: -12231.851, Max-Change: 0.00070\nIteration: 459, Log-Lik: -12231.851, Max-Change: 0.00015\nIteration: 460, Log-Lik: -12231.851, Max-Change: 0.00014\nIteration: 461, Log-Lik: -12231.851, Max-Change: 0.00070\nIteration: 462, Log-Lik: -12231.851, Max-Change: 0.00070\nIteration: 463, Log-Lik: -12231.851, Max-Change: 0.00019\nIteration: 464, Log-Lik: -12231.851, Max-Change: 0.00070\nIteration: 465, Log-Lik: -12231.851, Max-Change: 0.00015\nIteration: 466, Log-Lik: -12231.851, Max-Change: 0.00014\nIteration: 467, Log-Lik: -12231.851, Max-Change: 0.00070\nIteration: 468, Log-Lik: -12231.851, Max-Change: 0.00070\nIteration: 469, Log-Lik: -12231.851, Max-Change: 0.00019\nIteration: 470, Log-Lik: -12231.851, Max-Change: 0.00070\nIteration: 471, Log-Lik: -12231.851, Max-Change: 0.00015\nIteration: 472, Log-Lik: -12231.851, Max-Change: 0.00014\nIteration: 473, Log-Lik: -12231.851, Max-Change: 0.00070\nIteration: 474, Log-Lik: -12231.851, Max-Change: 0.00070\nIteration: 475, Log-Lik: -12231.851, Max-Change: 0.00019\nIteration: 476, Log-Lik: -12231.851, Max-Change: 0.00070\nIteration: 477, Log-Lik: -12231.851, Max-Change: 0.00015\nIteration: 478, Log-Lik: -12231.851, Max-Change: 0.00014\nIteration: 479, Log-Lik: -12231.851, Max-Change: 0.00070\nIteration: 480, Log-Lik: -12231.851, Max-Change: 0.00070\nIteration: 481, Log-Lik: -12231.851, Max-Change: 0.00019\nIteration: 482, Log-Lik: -12231.851, Max-Change: 0.00070\nIteration: 483, Log-Lik: -12231.851, Max-Change: 0.00015\nIteration: 484, Log-Lik: -12231.851, Max-Change: 0.00014\nIteration: 485, Log-Lik: -12231.851, Max-Change: 0.00070\nIteration: 486, Log-Lik: -12231.851, Max-Change: 0.00070\nIteration: 487, Log-Lik: -12231.851, Max-Change: 0.00019\nIteration: 488, Log-Lik: -12231.851, Max-Change: 0.00070\nIteration: 489, Log-Lik: -12231.851, Max-Change: 0.00015\nIteration: 490, Log-Lik: -12231.851, Max-Change: 0.00014\nIteration: 491, Log-Lik: -12231.851, Max-Change: 0.00070\nIteration: 492, Log-Lik: -12231.851, Max-Change: 0.00070\nIteration: 493, Log-Lik: -12231.851, Max-Change: 0.00019\nIteration: 494, Log-Lik: -12231.851, Max-Change: 0.00069\nIteration: 495, Log-Lik: -12231.851, Max-Change: 0.00015\nIteration: 496, Log-Lik: -12231.851, Max-Change: 0.00014\nIteration: 497, Log-Lik: -12231.851, Max-Change: 0.00070\nIteration: 498, Log-Lik: -12231.851, Max-Change: 0.00069\nIteration: 499, Log-Lik: -12231.851, Max-Change: 0.00019\nIteration: 500, Log-Lik: -12231.851, Max-Change: 0.00070\n\n\nEM cycles terminated after 500 iterations.\n\n\n\n\nCalculating information matrix...\n\nthreeplnlm_params <- coef(threeplnlm_fit, IRTpars = TRUE,\n                          simplify = TRUE)\nthreeplnlm_items <- as.data.frame(threeplnlm_params$items)\nhead(threeplnlm_items)\n\n              a          b           g u         a1          a2         a3\nitem1 0.6873658 -1.0233198 0.551153069 1 -0.2967092 -0.67962769  0.9763369\nitem2 0.5021189 -2.7622922 0.017602428 1  0.2133060 -0.38265481  0.1693488\nitem3 0.5758925 -0.3280405 0.040817867 1  0.1493895 -0.04323140 -0.1061581\nitem4 0.6464317 -1.7031732 0.033366261 1  0.1639110  0.34386566 -0.5077766\nitem5 0.2191565  2.8837062 0.006357466 1  0.2337259 -0.01384423 -0.2198817\nitem6 0.8618303  0.6144894 0.278055808 1  0.1428856 -0.39399345  0.2511079\n              c1          c2           c3\nitem1 -0.1297868 -0.13729788  0.267084710\nitem2  0.6785206 -0.06675201 -0.611768626\nitem3  0.4217714 -0.79242730  0.370655896\nitem4 -0.6653963  0.66942491 -0.004028606\nitem5  0.8452579  0.50423298 -1.349490876\nitem6 -0.4748976  0.23579308  0.239104488\n\n\n결과에서, g는 문항에 대한 추정된 추측도 모수를 보여줍니다. 결과에 따르면 multiplechoice 데이터 세트의 일부 문항(예: 문항 1, 7, 17, 19, 25)은 추측도의 효과가 높은 것으로 나타났습니다. 따라서 3PL-NLM에서 이러한 문항에서 추측도의 효과를 고려한 후 추정된 문항 난이도 및 문항 변별도 모수는 2PL-NLM의 문항 모수와 비교하여 크게 변경되었습니다.\n추측도의 영향을 보여주기 위해 3PL-NLM에서 추정된 모수를 기반으로 item 1과 17에 대한 OCC를 그립니다. 그림 6.12는 네 번째 응답 선택지(P4)가 item 1과 item 17 모두에 대해 정답 선택지임을 보여줍니다. item 1은 item 17보다 추측도 모수가 더 높습니다. P2로 표시된 두 번째 응답 선택지는 item 1에 가장 적합한 오답지인 반면, P3으로 표시된 세 번째 응답 선택지는 item 17에 가장 적합한 오답지인 것으로 보입니다. 그림 6.12는 또한 능력이 낮은 피험자가 item 17에서 높은 수준의 추측도가 포함된 문항임에도 불구하고 가장 좋은 오답지인 P3을 선택할 가능성이 높다는 것을 시사합니다.\n\nplot(threeplnlm_fit, type = \"trace\", which.items = c(1, 17),\n     par.settings = simpleTheme(lty = 1:4, lwd = 2),\n     auto.key = list(points = FALSE, lines=TRUE, columns=4))"
  },
  {
    "objectID": "chap06.html#모델-선택",
    "href": "chap06.html#모델-선택",
    "title": "6  다분 문항반응이론",
    "section": "6.5 모델 선택",
    "text": "6.5 모델 선택\nIRT에서 모델 선택은 평가 설계에 관한 이론적 가정과 문항 반응 데이터의 조건(즉, 문항 및 피험자 적합도)에 따라 달라집니다. 제5장에서 이분 문항에 대한 IRT 모델에 대한 문항 및 피험자 적합도를 검사하기 위해 itemfit 및 personfit 함수를 사용하는 방법에 대해 설명했습니다. 제6장에서 설명한 다분 문항에 대한 IRT 모델에도 동일한 절차가 적용됩니다.\n서열 척도인 다분 문항의 경우, 모든 문항의 변별도가 동일하다고 가정하면 PCM 또는 RSM 중 하나를 사용하는 것이 좋습니다. 그러나 문항의 변별도가 크게 다를 것으로 예상되는 경우, GRM 또는 GPCM이 문항 모수를 추정하는 데 더 적합할 수 있습니다. 문항 응답 범주가 서열척도가 아닌 명목척도인 경우, 문항 반응 데이터를 분석하는 데 NRM을 사용할 수 있습니다."
  },
  {
    "objectID": "chap06.html#요약",
    "href": "chap06.html#요약",
    "title": "6  다분 문항반응이론",
    "section": "6.6 요약",
    "text": "6.6 요약\n이 장에서는 다분 문항 반응에 대한 단일차원 IRT 모델을 소개하고 mirt 패키지의 mirt 함수를 사용하여 PCM, GPCM, RSM, GRM, NRM, NLM을 추정하는 방법을 시연했습니다. mirt 함수는 전통적인 IRT 모델뿐만 아니라 다분 문항에 대한 특수한 형태의 모델도 추정할 수 있습니다. 또한 관심 있는 독자는 다분 IRT 모델 추정을 위한 또 다른 포괄적인 R 패키지인 TAM 패키지(Kiefer et al., 2016)를 살펴볼 것을 권하고 싶습니다. 이 장에서 제시된 IRT 모델은 서열 또는 명목 척도인 다분 문항으로 구성된 단일차원 검사 구조에 적합합니다. 제5장에서 소개한 것과 동일한 그래픽 도구 및 모델 진단 옵션을 이 장에 제시된 다분 IRT 모델에도 사용할 수 있습니다. 다음 장에서는 제5장과 제6장에서 소개한 단일차원 IRT 모델의 다차원 확장에 중점을 둡니다."
  },
  {
    "objectID": "chap07.html#개요",
    "href": "chap07.html#개요",
    "title": "7  다차원 문항반응이론",
    "section": "7.1 개요",
    "text": "7.1 개요\n제5장과 제6장에서는 이분 및 다분 문항에 대한 IRT 모델을 제시하고 R에서 이러한 모델을 추정하는 방법을 살펴봤습니다. 제5장과 제6장에 제시된 IRT 모델의 공통적인 특징은 문항의 기저에 하나의 잠재 특성이 있다는 점입니다. 즉, 검사의 구조가 단일 차원이라고 가정합니다. 그러나 대부분의 교육 및 심리검사는 두 개 이상의 잠재 특성 또는 차원을 측정하는 경향이 있습니다(Ackerman, Gierl, & Walker, 2003). 문항이 2개 이상의 잠재 특성을 측정하는 경우, 이러한 검사 구조를 다차원이라고 합니다. 다차원 검사의 문항 모수와 잠재 특성 수준을 추정하려면 다차원 IRT(MIRT)를 사용해야 합니다.\n제7장에서는 다차원성과 R에서 MIRT 모델을 적합하는 것에 초점을 둡니다. 교육 및 심리 측정의 맥락에서 다차원성에 대한 정의로 시작한 다음, MIRT와 관련된 개념(예: 보상 모델과 비보상 모델, 문항 내 다차원성과 문항 간 다차원성, 탐색적 MIRT와 확인적 MIRT)에 대해 간략하게 논의합니다. 그리고나서, mirt 패키지를 사용하여 공통 MIRT 모델, 특히 다차원 Rasch 모델, 다차원 2모수 모델, 다차원 등급반응모델, bi-factor 모델을 적합하는 방법을 보여줍니다(Chalmers, 2012). mirt 패키지는 다양한 MIRT 모델을 추정할 수 있지만, flirt(Jeon, Rijmen, & Rabe-Hesketh, 2014), TAM (Kiefer et al., 2016), eRm(Mair & Hatzinger, 2007a), and sirt (Robitzsch, 2017) 등 일부 MIRT 모형을 추정할 수 있는 다른 R 패키지도 있습니다."
  },
  {
    "objectID": "chap07.html#다차원-문항반응모델링",
    "href": "chap07.html#다차원-문항반응모델링",
    "title": "7  다차원 문항반응이론",
    "section": "7.2 다차원 문항반응모델링",
    "text": "7.2 다차원 문항반응모델링\n제5장과 제6장에서 논의한 바와 같이, 단일차원 IRT 모델은 단일 잠재 특성 또는 구인을 측정하는 문항에 대한 피험자의 응답을 분석하는 데 적합합니다. 그러나 여러 잠재 특성을 동시에 측정하는 복잡한 문항의 경우, 정답 확률이 더 이상 단일 잠재 특성의 함수가 아니므로 단일 차원 IRT 모델을 사용하여 문항 응답을 모델링해서는 안 됩니다. 여러 잠재 특성이 포함된 복잡한 문항을 분석하려면 다차원 IRT 접근 방식(즉, MIRT 모델)을 사용해야 합니다. MIRT 모델은 주어진 문항에 정답할 확률을 단일 잠재 특성이 아닌 잠재 특성 벡터의 함수로 설명합니다. MIRT는 다양한 용도로 사용할 수 있지만, 이 모델링 프레임워크는 특히 다음과 같은 경우에 유용합니다.\n\n하나 이상의 문항이 동시에 여러 잠재 특성을 측정할 때 문항 반응 데이터를 모델링하는 데 사용됩니다(Reckase, 2009).\n상관관계가 있는 잠재 특성을 측정하는 개별 검사 또는 하위 검사가 있을 때 측정의 정밀도를 향상시키기 위해 사용됩니다(Wang, Chen, & Cheng, 2004).\n\n1980년대 초부터 연구자들은 다양한 MIRT 모델을 제안해 왔는데(예: Adams, Wilson, & Wang, 1997; Reckase, 1985; Yao & Schwarz, 2006), 이는 종종 단일 차원 IRT 모델을 다차원으로 확장한 것입니다. 이 장에서, 우리는 몇 가지 MIRT 모델에 초점을 맞추고 R의 mirt 패키지를 사용하여 모델을 맞추고 추정하는 방법을 보여줍니다. 다차원 문항 반응 모델링에 대한 보다 포괄적인 논의는 Reckase(2009)의 다차원 문항반응이론을 검토하는 것이 좋습니다.\nMIRT 모델은 여러 가지 방법으로 분류할 수 있습니다. 예를 들어, 하나의 차원(즉, 잠재 특성)의 약점(또는 결점)이 다른 차원의 강점으로 보완될 수 있는지 여부에 따라 MIRT 모델을 분류할 수 있습니다. 또한 각 문항이 단일 잠재 특성과 연관되어 있는지 또는 여러 잠재 특성과 연관되어 있는지에 따라 MIRT 모델을 그룹화할 수 있습니다. 다음 섹션에서는 이러한 분류에 대해 간략하게 설명합니다.\n\n7.2.1 보상적 MIRT와 비보상적 MIRT\nMIRT 모델은 잠재 특성 간의 보상 관계의 존재 여부에 따라 보상적 또는 비보상적으로 특징지을 수 있습니다(Sijtsma & Junker, 2006). 보상적 MIRT 모델의 부가적 특성은 서로 다른 기울기(즉, 변별도) 모수로 가중치를 부여한 일련의 잠재 특성의 합을 기반으로 정의합니다. 보상적 MIRT 모델을 사용하면 한 잠재 특성의 약점을 다른 잠재 특서의 강점으로 보상할 수 있습니다(Reckase, 1997; Yao & Boughton, 2007). 예를 들어, 수학 실력이 낮은 피험자가 대수 실력이 높으면 수학 문제를 정답으로 맞힐 수 있습니다.\n그림 7.1은 2차원 보상적 MIRT 모델의 이분 문항에 대한 그래픽 그림입니다. 단일차원 IRT 모델의 문항특성곡선(item characteristic curve)과 달리, MIRT 모델은 문항이 두 개의 잠재 차원, 즉 \\(\\theta_1\\)과 \\(\\theta_2\\)와 연관되어 있기 때문에 문항특성표면(item characteristic surface)을 산출합니다. 이 특정 문항의 경우, 두 차원은 상보적 관계를 갖습니다. 문항 표면은 차원 1의 숙련도가 낮고(예: \\(\\theta_1\\)=0), 차원 2의 숙련도가 높은(예: \\(\\theta_2\\)=2)피험자도 차원 1의 낮은 숙련도가 차원 2의 높은 숙련도로 보상되기 때문에 문항에 정답할 확률이 여전히 높다는 것을 보여줍니다.\n\n\n\n보상적 MIRT 모델에 대한 문항특성표면\n\n\n보상적 모델과 달리, 비보상적 MIRT 모델의 곱셈적 특성은 각각 다른 잠재적 특성을 기반으로 한 확률의 곱셈을 기반으로 정합할 확률을 정의합니다. 따라서 한 차원에서의 약점은 다른 차원의 강점으로 보상할 수 없습니다. 예를 들어, 수학 실력이 낮은 피험자가 읽기 실력이 높다고 해서 단어 문제에서 정답을 못 맞힐 수 있는데, 이는 문항이 두 가지 능력이 모두 필요로 하기 때문입니다. 비보상적 MIRT 모델은 부분 보상적 모델이라고도 하는데, 이는 비보상적 모델도 일부 보상을 허용하기 때문입니다(Reckase, 2009). 인지평가 문헌에서 비보상적 MIRT 모델이 여러 번 적용되었지만(예: Embretson, 1997; Junker & Sijtsma, 2001; Maris, 1995), 보상적 모델과 요인분석 모델 간의 이론적 유사성 때문에 연구자들 사이에서 보상적 MIRT 모델이 더 많이 사용되었습니다(Sijtsma & Junker, 2006).\n그림 7.2는 2차원 비보상적 MIRT 모델에서 이분 문항에 대한 문항특성표면을 보여줍니다. 문항 표면도를 보면 두 차원 모두에서 높은 숙련도가 있어야 문항 정답을 맞힐 수 있음을 알 수 있습니다. 즉, 한 차원에서의 숙련도가 낮은 피험자는 다른 차원에서의 숙련도가 높더라도 해당 문항의 정답을 맞힐 수 없습니다.\n\n\n\n비보상적 MIRT 모델에 대한 문항특성표면\n\n\n\n\n7.2.2 문항 간 및 문항 내 다차원성\nMIRT 모델은 검사 구조에 따라 두 가지 그룹으로 분류할 수 있습니다. 문항 간 모델과 문항 내 MIRT 모델이 그것입니다(Adams et al., 1997; Wang et al., 2004). 문항 간 MIRT 모델에서는 각 잠재 특성이 고유한 문항 세트로 측정됩니다. 즉, 각 문항은 검사에서 측정된 잠재 특성 중 하나에만 연관됩니다. 이러한 유형의 검사 구조는 문항이 단일 요인에 적재되는 요인 분석 해와 마찬가지로 단순 구조라고도 합니다(요인 분석에 대한 검토는 제4장 참조). 문항 간 MIRT 모델은 일반적으로 상호 연관된 잠재 특성을 측정하는 하위 검사에서 하위 점수를 추정하는 데 사용됩니다(예: Bulut, Davison, & Rodriguez, 2017; de la Torre, Song, & Hong, 2011; Wang et al., 2004). 문항 내 MIRT 모델에서 각 문항은 검사에서 측정된 두 개 이상의 잠재 특성과 연관될 수 있습니다. 이러한 유형의 검사 구조를 비단순 또는 복합 구조라고 합니다. 문항 내 다차원성의 좋은 예는 인지 능력 평가의 이중 요인 검사 구조로, 모든 문항은 일반적인 잠재 특성(예: 일반 지능)과 연관되고 각 문항은 이차 잠재 특성(예: 특정 인지 능력)과 연관됩니다.\n그림 7.3은 두 개의 잠재 특성을 측정하는 검사에 대한 문항 간 및 문항 내 MIRT 모델을 보여줍니다. 문항 간 모델에서 문항 1부터 문항 5는 첫 번째 잠재 특성인 \\(\\theta_1\\)과 연관되고, 문항 6부터 문항 10은 두 번째 잠재 특성인 \\(\\theta_2\\)와 연관됩니다. \\(\\theta_1\\)과 \\(\\theta_2\\)는 공통 문항을 공유하지 않습니다. 따라서 검사 구조는 각 잠재 특성이 일련의 단차원 문항으로 정의되고 전체 구조는 다차원 구조가 되는 다차원 구조가 됩니다. 문항 내 모델에서는 문항이 \\(\\theta_1\\)과 \\(\\theta_2\\) 모두와 연관되어 있으므로 검사의 구조가 단순하지 않습니다. 그림 7.3에 제시된 MIRT 모델에서는 \\(\\theta_1\\)과 \\(\\theta_2\\)가 상관관계가 있을 가능성이 높습니다. 그러나 잠재 특성 간의 상관관계가 커질수록 추정 결과의 신뢰도가 낮아질 가능성이 높습니다(Bulut et al., 2017).\n\n\n\n문항 간 구조(왼쪽)와 문항 내 구조(오른쪽)\n\n\n\n\n7.2.3 탐색적 MIRT와 확인적 MIRT 분석\nMIRT 모델로 반응 데이터를 분석할 때 검사 구조는 탐색적 또는 확인적 방식으로 정의될 수 있습니다. 문항의 기저에 있는 검사 구조에 대한 선험적 가설이 없는 경우, 문항 모수와 잠재 특성 수준을 추정하기 전에 예상되는 차원 수만 지정하면 됩니다. 이것이 바로 데이터에서 잠재 특성과 문항 간의 연관성을 도출하는 탐색적 MIRT 접근 방식입니다. 검사 구조에 관한 가설이 있는 경우, 차원 수와 문항과 차원 간의 관계를 모두 지정해야 합니다(Reckase, 2009, 179쪽). 연구자가 이론에 근거하여 검사 구조를 지정하기만 하면 되기 때문에 이를 확인적 MIRT 접근법이라고 합니다. 탐색적 MIRT 분석은 데이터의 기초가 되는 차원 수를 찾는 데 자주 사용됩니다. 이러한 유형의 분석은 제4장에서 설명한 탐색적 요인 분석과 유사합니다. 이 장에서는 차원 수와 문항과 잠재 특성 간의 관계를 정의하는 확인적 MIRT 모델에 중점을 둡니다(제4장에서 설명한 확인적 요인 분석과 유사함)."
  },
  {
    "objectID": "chap07.html#일반적-mirt-모델",
    "href": "chap07.html#일반적-mirt-모델",
    "title": "7  다차원 문항반응이론",
    "section": "7.3 일반적 MIRT 모델",
    "text": "7.3 일반적 MIRT 모델\n이 장에서는 몇 가지 일반적인 MIRT 모델을 살펴봅니다. 이러한 모델에는 다차원 2모수 모델, 다차원 Rasch 모델, 다차원 등급반응모델, 이요인 모델이 포함됩니다. 이어지는 섹션에서는 이러한 MIRT 모델에 대해 간략하게 설명하고 mirt 패키지를 사용해 이러한 모델을 적합하고 추정하는 방법을 보여줍니다.\n\n7.3.1 다차원 2모수 모델\n다차원 2모수(M2PL) 모델은 단일차원 2모수 모델을 확장한 것입니다. M2PL 모델은 다차원 검사에서 문항 난이도와 변별도 모수를 추정할 수 있는 보상적 MIRT 모델입니다. 검사 구조는 문항 간일 수도 있고 문항 내일 수도 있습니다. M2PL 모델은 다음과 같이 작성할 수 있습니다.\n\\[\nP(X_{ij}=1|\\theta_j, a_i, d_i)={exp(a_i\\theta_j\\prime+d_i) \\over 1+exp(a_i\\theta_j\\prime+d_i)}\n\\]\n\n\\(\\theta_j\\)는 피험자 \\(j\\)에 대한 잠재 특성 1 X \\(M\\) 벡터( \\(\\theta_j\\) = \\(\\theta_{j1}, \\theta_{j2},..., \\theta_{jM}\\)))\n\\(a_i\\)는 문항 \\(i\\)에 대한 기울기 모수(예: 문항 변별도) 1 X \\(M\\) 벡터( \\(a_i\\) = \\(a_{i1}, a_{i2},..., a_{iM}\\)))\n\\(d_i\\)는 문항 \\(i\\)에 대한 절편항\n\n절편 모수 \\(d_i\\)는 문항의 난이도를 나타내는 고유한 지표로 간주할 수 없기 때문에 단일차원 IRT 모델에서의 문항 난이도 모수와는 유사하지 않습니다(Reckase, 2009). 절편 모수로부터 전통적인 난이도 모수를 얻기 위해 변환을 수행할 수 있습니다. 이 변환 공식은 다음과 같습니다.\n\\[\nB_i= {-d_i \\over \\sqrt{\\sum_{m=1}^M a^2_{im}}}\n\\]\n\n\\(B_i\\)는 문항 \\(i\\)의 다차원 난이도 모수(MDIFF라고도 함)\n\n\\(B_i\\) 값이 높을수록 문항의 난이도가 높아집니다.\nMIRT 모델의 문항 변별도 모수는 변환을 사용해 단일 값으로 요약할 수 있습니다. 실제로 이 변환은 방정식 7.2의 분모로 다음과 같습니다.\n\\[\nA_i=\\sqrt{\\sum_{m=1}^M a^2_{im}}\n\\]\n\n여기서 \\(A_i\\)는 다차원 변별도 모수로 문헌에서는 MDISC라고도 합니다.\n\n다차원 변별도 모수는 단일차원 IRT 모델의 문항 변별도 모수와 유사합니다. 이 모수는 다차원 문항의 전반적인 변별도 수준을 나타냅니다. 문항이 단일 잠재 특성과만 연관된 경우, 방정식 7.1의 \\(a_i\\)는 0이 아닌 요소가 하나만 있습니다(예: 3차원 검사에서 \\(a_i\\)=(1.4,0,0). 이 경우에 다차원 변별도 모수는 \\(a_i\\)의 0이 아닌 요소와 같습니다.\nM2PL 모델을 적합하고 추정하는 방법을 보여드리기 위해 hemp 패키지의 mimic 데이터 세트를 사용합니다. 분석을 시작하기 전에 먼저 library 명령으로 hemp 및 mirt 패키지를 활성화합니다.\n\nlibrary(hemp)\n\nLoading required package: psych\n\n\nLoading required package: lattice\n\n\nLoading required package: lavaan\n\n\nThis is lavaan 0.6-16\nlavaan is FREE software! Please report any bugs.\n\n\n\nAttaching package: 'lavaan'\n\n\nThe following object is masked from 'package:psych':\n\n    cor2cov\n\n\nLoading required package: mirt\n\n\nLoading required package: stats4\n\n\nLoading required package: lme4\n\n\nLoading required package: Matrix\n\n\n\nAttaching package: 'lme4'\n\n\nThe following object is masked from 'package:mirt':\n\n    fixef\n\n\nLoading required package: reshape2\n\n\nLoading required package: boot\n\n\n\nAttaching package: 'boot'\n\n\nThe following object is masked from 'package:lattice':\n\n    melanoma\n\n\nThe following object is masked from 'package:psych':\n\n    logit\n\n\nLoading required package: equate\n\nlibrary(mirt)\n\nmimic 데이터 세트에는 24문항, 2000명의 피험자에 대한 응답이 포함되어 있습니다. 문항은 이분으로 채점되어 있습니다(예: 1=정답, 0=오답). 문항의 레이블은 item1, item2, …, item24로 표시됩니다. 검사 구조는 문항 내 다차원(복합)으로 item1부터 item6, item13부터 item21, item 23, item24가 첫 번째 잠재 특성과 연관되고, item7부터 item20, item22부터 item24는 두 번째 잠재 특성과 연관됩니다.\nM2PL 모델에 적합하기 위해 제5장과 제6장에서 단일차원 IRT 모델을 추정할 때와 마찬가지로 mirt 패키지의 mirt 함수를 다시 사용합니다. 다차원 IRT 모델을 추정하기 위한 R 명령은 제5장 및 제6장에서 설명한 명령과 매우 유사합니다. 가장 큰 차이점은 다차원 검사 구조는 단일 잠재 특성이 아닌 두 개 이상의 잠재 특성을 포함하므로 검사 구조의 정의입니다.\nmimic 데이터 세트는 2차원 구조를 가지고 있기 때문에 두 개의 잠재 특성(F1, F2)을 정의합니다. 검사 구조를 정의할 때 각 잠재 특성과 연관된 문항을 지정합니다. 각 문항을 하나씩 나열하는 대신 제5장과 제6장에서와 같이 각 잠재 특성에 대한 문항의 범위를 지정할 수 있습니다. 예를 들어 1-6은 item1부터 item6까지를 의미합니다. 쉼표를 사용해 문항 집합을 구분합니다(예: 1-6, 13-21, 23-24). mimic 데이터 세트에는 문항 내 검사 구조가 있으므로 item13부터 item 20, item 23, item24가 두 잠재 특성에 대해 나타납니다. 모델 정의의 마지막 줄 COV=F1 * F2는 추정하려는 공분산 항을 정의합니다. 이 예에서는 두 잠재 특성 간의 공분산을 추정하고자 합니다. 따라서 모델 정의에 COV=F1 * F2를 포함합니다. 이 줄을 건너뛰면 F1과 F2 사이의 공분산을 0으로 고정하고, 이것은 잠재 특성이 직교라고 가정합니다. 기본적으로 mirt 함수는 잠재 특성 F1 및 F2의 분산을 1로 고정합니다. 모델에서 이러한 분산을 추정하려면 현재 cov 구문을 COV=F1 * F2, F1 * F1, F2 * F2로 대체할 수 있습니다. 또한 잠재 특성의 평균은 0으로 고정됩니다. 만일 평균을 추정해야 한다면 검사 구조에 이를 지정해야 합니다(예: MEAN=F1, F2). 이러한 제약 조건은 제4장에서 요인 분석의 맥락에서 설명한 것처럼 식별을 위해 만들어졌습니다. 이 검사 구조를 m2pl2_mod로 저장합니다.\n\nm2pl_mod <- 'F1 = 1 - 6, 13 - 21, 23 - 24\n             F2 = 7 - 20, 22 - 24\n             COV = F1 * F2'\n\nmirt 함수에서 적합할 모델을 model = mod2pl_mod로 지정하고 itemtype = “2PL”로 문항 유형을 지정합니다. mirt 함수의 기본 추정 알고리즘은 method = “EM”이며, 이는 기대치 최대화 알고리즘입니다. 차원이 최대 3개인 MIRT 모델의 경우 EM 알고리즘이 효과적인 것으로 간주되지만, 3차원 이상의 검사 구조일 때에는 다른 추정 알고리즘(예: method = “MHRM”)을 권장합니다(자세한 내용은 mirt 패키지 매뉴얼 참조). 적합된 모델을 m2pl_fit으로 저장하고, 추정된 모수를 coef 함수를 이용해 추출한 다음 m2pl_params로 저장합니다.\n\nm2pl_fit <- mirt(data = mimic, model = m2pl_mod, \n                 itemtype = \"2PL\", method = \"EM\", \n                 SE = TRUE)\n\n\nIteration: 1, Log-Lik: -29633.944, Max-Change: 0.22211\nIteration: 2, Log-Lik: -29536.223, Max-Change: 0.09403\nIteration: 3, Log-Lik: -29512.690, Max-Change: 0.05431\nIteration: 4, Log-Lik: -29502.680, Max-Change: 0.03441\nIteration: 5, Log-Lik: -29497.895, Max-Change: 0.02708\nIteration: 6, Log-Lik: -29495.001, Max-Change: 0.02022\nIteration: 7, Log-Lik: -29493.137, Max-Change: 0.01722\nIteration: 8, Log-Lik: -29491.960, Max-Change: 0.01206\nIteration: 9, Log-Lik: -29491.290, Max-Change: 0.00994\nIteration: 10, Log-Lik: -29490.819, Max-Change: 0.00801\nIteration: 11, Log-Lik: -29490.517, Max-Change: 0.00559\nIteration: 12, Log-Lik: -29490.343, Max-Change: 0.00504\nIteration: 13, Log-Lik: -29490.209, Max-Change: 0.00466\nIteration: 14, Log-Lik: -29490.108, Max-Change: 0.00252\nIteration: 15, Log-Lik: -29490.062, Max-Change: 0.00200\nIteration: 16, Log-Lik: -29490.029, Max-Change: 0.00148\nIteration: 17, Log-Lik: -29490.008, Max-Change: 0.00323\nIteration: 18, Log-Lik: -29489.970, Max-Change: 0.00085\nIteration: 19, Log-Lik: -29489.966, Max-Change: 0.00303\nIteration: 20, Log-Lik: -29489.940, Max-Change: 0.00221\nIteration: 21, Log-Lik: -29489.927, Max-Change: 0.00146\nIteration: 22, Log-Lik: -29489.921, Max-Change: 0.00098\nIteration: 23, Log-Lik: -29489.919, Max-Change: 0.00065\nIteration: 24, Log-Lik: -29489.917, Max-Change: 0.00043\nIteration: 25, Log-Lik: -29489.917, Max-Change: 0.00030\nIteration: 26, Log-Lik: -29489.916, Max-Change: 0.00020\nIteration: 27, Log-Lik: -29489.916, Max-Change: 0.00014\nIteration: 28, Log-Lik: -29489.916, Max-Change: 0.00012\nIteration: 29, Log-Lik: -29489.916, Max-Change: 0.00008\n\nCalculating information matrix...\n\nm2pl_params <- coef(m2pl_fit, simplify = TRUE)\n\n추정된 문항 모수는 m2pl_params 끝에 $items를 추가하여 직접 출력할 수도 있습니다. 이전 장에서는 추정된 문항 모수를 별도의 데이터 세트로 저장했지만 여기서는 m2pl_params에서 직접 출력합니다.\n\nhead(m2pl_params$items)\n\n             a1 a2           d g u\nitem1 1.0451546  0  0.03009274 0 1\nitem2 0.9549557  0 -0.30599493 0 1\nitem3 1.0843917  0  0.23204938 0 1\nitem4 1.2282254  0  0.20808671 0 1\nitem5 0.9071266  0  0.16610451 0 1\nitem6 0.8660056  0  0.77031887 0 1\n\n\n결과는 단일차원 IRT 모델에서 보았던 출력과 매우 유사합니다. 그러나 변별도 모수가 하나만 있는 대신, 첫 번째 및 두 번째 잠재 특성에 대한 변별도(즉, 기울기) 모수를 각각 나타내는 두 개의 열, a1 및 a2가 있습니다. 일부 변별도 모수는 0과 같다는 것을 알 수 있습니다. 이는 일부 문항이 첫 번째 또는 두 번째 잠재 특성과만 연관되어 있고 두 가지 모두와 연관되어 있지 않기 때문입니다. 예를 들어, item1의 문항 변별도 값은 a1에 대해서는 0이 아니고 a2에 대해서는 0입니다. 이는 item1이 첫 번째 잠재 특성(즉, F1)과는 연관되어 있지만 두 번째 잠재 특성(즉, F2)과는 연관되어 있지 않음을 나타냅니다. item1과 달리 item13은 F1과 F2 모두에 연관되어 있기 때문에 a1 및 a2 모두 0이 아닌 문항 변별도 모수를 갖습니다. 다음 열인 d는 문항의 추정된 절편 모수를 나타냅니다. 마지막 두 열인 g와 u는 다시 하부 점근(즉, 추측도) 및 상부 점근 모수입니다. M2PL 모델을 사용했기 때문에 모든 문항에 대해 하한 점근 모수는 0으로 고정되고 상한 점근 모수는 1로 고정됩니다.\n다음으로, mirt 패키지의 MDIFF 및 MDISC 함수를 사용하여 변별도 및 절편 모수를 방정식 7.2 및 7.3에 따라 다차원 문항 난이도 및 변별도 모수로 변환합니다. 그런 다음 data.frame 함수를 사용하여 변환된 모수를 데이터 프레임으로 결합하고 이를 m2pl_items로 저장합니다. 마지막으로 다차원 문항 모수의 이름을 바꾸고 head 함수를 사용하여 처음 6개의 문항을 출력합니다.\n\nm2pl_items <- data.frame(MDISC(m2pl_fit),\n                         MDIFF(m2pl_fit))\ncolnames(m2pl_items) <- c(\"m2pl_mdisc\", \"m2pl_mdiff\")\nhead(m2pl_items)\n\n      m2pl_mdisc  m2pl_mdiff\nitem1  1.0451546 -0.02879262\nitem2  0.9549557  0.32042841\nitem3  1.0843917 -0.21399037\nitem4  1.2282254 -0.16942062\nitem5  0.9071266 -0.18311061\nitem6  0.8660056 -0.88950791\n\n\n문항 모수 외에도 m2pl_params 끝에 $cov를 추가하여 두 잠재 특성의 추정 분산-공분산 행렬을 볼 수도 있습니다. 결과에는 2 X 2 행렬이 표시되며, 대각선 요소는 잠재 특성인 F1 및 F2의 분산이고 대각선 아래쪽 요소는 두 잠재 특성의 공분산입니다. 아래 결과에서 F1과 F2의 분산은 위에서 언급한 식별상의 이유로 1이며, 두 잠재 특성의 공분산은 0.588로 추정됩니다.\n\nm2pl_params$cov\n\n         F1       F2\nF1 1.000000 0.588067\nF2 0.588067 1.000000\n\n\n잠재 특성의 분산은 1로 고정되어 있으므로 분산-공분산 행렬은 실제로 잠재 특성의 상관 관계 행렬입니다. 따라서 F1과 F2의 상관관계도 .588이 됩니다. 그러나 모델에서 F1과 F2의 분산을 추정했다면 다음 공식을 사용하여 추정된 공분산을 상관 계수로 변환할 수 있습니다.\n\\[\nr_{F1,F2}={cov(F1, F1) \\over (S_{F1})(S_{F2})}={0.588 \\over (\\sqrt{1})(\\sqrt{1})}=.588\n\\]\n\n여기서 \\(S_{F1}\\)과 \\(S_{F2}\\)는 잠재 특성 F1과 F2의 표준 편차이고 \\(cov(F1, F1)\\)는 두 잠재 특성 간의 공분산을 나타냅니다.\n\n단일차원 IRT 모델에서와 마찬가지로 MIRT 모델의 문항 및 검사 특성을 그래픽으로 살펴볼 수 있습니다. MIRT 모델은 중다 잠재 특성을 함께 사용하여 문항에 정답할 확률을 계산하고, 문항 및 검사 정보를 계산하고, 기타 속성을 조사하는 문항 및 검사 표면 그래프를 생성합니다. 표면 그래프와 동일한 정보를 전달할 수 있는 등고선 그래프도 있습니다. 등고선 그래프는 조감도에서 정보를 표시합니다. 즉, 등고선 그래프는 표면 그래프를 위에서 본 것처럼 보여줍니다. 등고선 그래프는 표면 그래프에 비해 해석하기 쉬운 경우가 많습니다. 두 개 이상의 잠재 특성을 포함하는 MIRT 모델은 어떤 유형의 그래프를 선택하든 그래픽으로 요약하기가 더 어렵다는 점에 유의해야 하는데, 그 이유는 (1) mirt 패키지의 plot 함수는 2차원만 처리할 수 있고 (2) R의 다른 그래픽 함수는 2차원 및 3차원 공간의 데이터로 제한되어 있기 때문입니다.\n다음 예제에서도 itemplot 함수를 사용하여 문항을 플롯합니다. item13은 두 잠재 특성과 연관된 문항 중 하나이므로 아래 예제에서는 이 문항을 사용합니다. itemplot 함수를 type = “trace” 옵션과 함께 사용하여 먼저 item13에 대한 문항 특성 표면 그래프를 만듭니다. 이 그래프는 x축에 첫 번째 잠재 특성, y축에 두 번째 잠재 특성, z축에 item13의 정답할 확률을 축으로 하는 3차원 그래프입니다. 그런 다음 type = “tracecontour”를 사용하여 동일한 문항에 대한 문항 등고선 그래프 그립니다.\n\nitemplot(m2pl_fit, type = \"trace\", item = 13)\n\n\n\nitemplot(m2pl_fit, type = \"tracecontour\", item = 13)\n\n\n\n\n그림 7.4와 7.5는 모두 첫 번째 잠재 특성(\\(\\theta_1\\))과 두 번째 잠재 특성(\\(\\theta_2\\))의 함수에 따라 item13의 정답 확률이 어떻게 변하는지를 보여줍니다. M2PL 모델은 보상적 MIRT 모델이기 때문에 한 잠재 특성의 약점은 다른 잠재 특성의 강점으로 보상될 수 있습니다. 예를 들어, \\(\\theta_1 = 0\\)이고 \\(\\theta_2 = 2\\)인 경우 \\(\\theta_1\\)이 \\(\\theta_2\\)보다 상대적으로 낮음에도 불구하고 item13의 정답 확률은 거의 .80(즉, 80%)입니다.\n문항 특성 표면 외에도, 잠재 특성 수준을 기반으로 문항이 제공하는 정보를 조사할 수도 있습니다. 문항 정보 그래프를 만들려면 itemplot 함수에서 type = “info”를 설정합니다. 결과 그래프는 문항 특성 표면 그래프과 유사하지만 이번에는 z축에 문항의 성공 확률 대신 문항 정보 수준이 표시됩니다. 그림 7.6은 두 잠재 특성이 모두 0에 가까울 때 문항 정보 수준이 가장 높은 반면, 두 잠재 특성이 모두 매우 낮거나 매우 높을 때 문항 정보가 가장 낮다는 것을 보여줍니다.\n\nitemplot(m2pl_fit, type=\"info\", item = 13)\n\n\n\n\n문항 특성 표면 그래프와 마찬가지로 문항 정보 그래프도 등고선 그래프로 그릴 수 있습니다. 또한 문항의 기대 점수 및 표준 오차 값을 검사하는 데 문항 플롯 함수를 사용할 수 있습니다. 이러한 그래프를 그리기 위한 R 명령은 다음과 같습니다.\n\nitemplot(m2pl_fit, type = \"infocontour\", item = 13)\n\n\n\nitemplot(m2pl_fit, type = \"score\", item = 13)\n\n\n\nitemplot(m2pl_fit, type = \"SE\", item = 13)\n\n\n\n\n위에 요약된 문항 수준 그래프 외에도 검사 수준에서 그래프를 그릴 수도 있습니다. 이러한 그래프는 검사 정보 함수 및 조건부 측정의 표준 오차를 요약합니다. 다음 명령은 TIF 그래프 및 cSEM 그래프를 만들기 위한 plot 함수의 사용을 보여줍니다. 그림 7.7은 mimic 데이터 세트에 포함된 모든 문항에 대한 TIF 및 cSEM 그래프를 보여줍니다.\n\nplot(m2pl_fit, type = \"info\")\n\n\n\nplot(m2pl_fit, type = \"SE\")\n\n\n\n\n제5장에서는 잠재 특성 수준을 추정하기 위해 mirt 패키지의 fscores 함수를 사용하는 방법을 보여드렸습니다. MIRT 모델의 경우, 동일한 절차에 따라 다차원 평가에서 잠재 특성 수준을 추정할 수 있습니다. 아래 예에서는 M2PL 모델에서 잠재 특성 수준을 추정하기 위해 최대 사후 추정(MAP) 및 기대 사후 추정(EAP) 방법을 사용합니다. MAP 및 EAP 추정량에 대해서는 각각 method = “MAP” 및 method = “EAP”를 지정합니다. ML 기반 추정치는 fscores 함수에서 method = “ML”을 사용하여 얻을 수도 있습니다. 제5장에서 설명했듯이 최대 우도(ML) 추정에서는 피험자가 모든 문항의 응답이 틀리거나 정답인 경우 결과를 제공하지 못합니다. MIRT 모델에서 잠재 특성 수준을 추정할 때도 동일한 문제가 지속됩니다. 아래에서는 잠재 특성 수준을 추정하고 결과를 m2pl_map 및 m2pl_eap으로 저장한 다음 head 함수를 사용하여 처음부터 6행을 출력합니다.\n\nm2pl_map <- fscores(m2pl_fit, method = \"MAP\", full.scores = TRUE, full.scores.SE = TRUE)\nhead(m2pl_map)\n\n             F1          F2     SE_F1     SE_F2\n[1,]  0.4244960  0.03977301 0.4836689 0.4734518\n[2,]  0.8752283  1.29303637 0.5318044 0.5312877\n[3,]  1.1437356  0.51740865 0.5330358 0.4934871\n[4,] -0.2365629 -0.45059857 0.4752881 0.4787024\n[5,]  0.9421421 -0.12299459 0.5066176 0.4782289\n[6,]  0.3985295  1.09251385 0.4975982 0.5062713\n\n\n\nm2pl_eap <- fscores(m2pl_fit, method = \"EAP\", full.scores = TRUE, full.scores.SE = TRUE)\nhead(m2pl_eap)\n\n             F1         F2     SE_F1     SE_F2\n[1,]  0.4453246  0.0453828 0.4918731 0.4803416\n[2,]  0.9311577  1.3492089 0.5424382 0.5421459\n[3,]  1.1960052  0.5477967 0.5417752 0.5022786\n[4,] -0.2446835 -0.4667777 0.4834888 0.4855015\n[5,]  0.9780828 -0.1158884 0.5144185 0.4850905\n[6,]  0.4324385  1.1331393 0.5072794 0.5155978\n\n\n결과에서 F1 및 F2 열은 잠재 특성 추정치이고 SE_F1 및 SE_F2는 추정된 잠재 특성에 대한 표준 오차입니다. 다음으로, MAP 및 EAP 방법의 잠재 특성 추정치를 m2pl_scores라는 새 데이터 세트에 결합한 다음 잠재 특성 추정치 간의 상관 관계를 살펴봅니다. 결과는 MAP 방법과 EAP 방법의 잠재 특성 추정치가 높은 상관관계가 있음을 보여줍니다. 또한 두 잠재 특성 간의 점수도 높은 상관관계가 있음을 알 수 있습니다(MAP와 EAP의 경우 약 0.78).\n\nm2pl_scores <- data.frame(map1 = m2pl_map[, 1], map2 = m2pl_map[, 2], eap1 = m2pl_eap[, 1], eap2 = m2pl_eap[, 2])\ncor(m2pl_scores)\n\n          map1      map2      eap1      eap2\nmap1 1.0000000 0.7788795 0.9999633 0.7838897\nmap2 0.7788795 1.0000000 0.7841330 0.9999640\neap1 0.9999633 0.7841330 1.0000000 0.7890935\neap2 0.7838897 0.9999640 0.7890935 1.0000000\n\n\n문항 및 검사 구조에 대한 이론적 가정과 기대치에 따라 검사 구조의 정의를 수정하여 보다 구체적인 MIRT 모델을 추정할 수도 있습니다. 예를 들어, 일부 문항은 동일한 기울기 및 절편 모수를 갖도록 제약할 수 있습니다. 두 잠재 특성 사이의 고유 문항이 동일한 기울기 모수를 가질 것으로 예상한다고 가정하면 모델 정의에서 CONSTRAIN 문을 사용할 수 있습니다.\n\nm2pl_mod_constrant <- '\n        F1 = 1 - 6, 13 - 21, 23 - 24\n        F2 = 7 - 20, 22 - 24\n        COV = F1 * F2\n        CONSTRAIN = (1 - 6, 21, a1), (7 - 12, 22, a2)'\n\nM2PL 모델의 비보상적 버전도 있습니다. 비보상적 M2PL을 추정하려면 itemtype = “2PL”을 itemtype = “PC2PL”로 바꿔야 합니다. 보상적 M2PL 모델과 달리 문항은 두 잠재 특성 각각에 대해 별도의 기울기 및 절편 모수를 갖게 됩니다. 또한 비보상적 M2PL 모델에서는 잠재 특성 간에 보상이 이루어지지 않습니다.\n\nm2pl_fit <- mirt(data = mimic, model = m2pl_mod, itemtype = \"PC2PL\", SE = TRUE)\n\n\nIteration: 1, Log-Lik: -31012.172, Max-Change: 1.76320\nIteration: 2, Log-Lik: -29807.467, Max-Change: 0.74238\nIteration: 3, Log-Lik: -29701.719, Max-Change: 0.27453\nIteration: 4, Log-Lik: -29671.810, Max-Change: 0.10395\nIteration: 5, Log-Lik: -29662.257, Max-Change: 0.10827\nIteration: 6, Log-Lik: -29657.956, Max-Change: 0.10588\nIteration: 7, Log-Lik: -29655.308, Max-Change: 0.04655\nIteration: 8, Log-Lik: -29653.744, Max-Change: 0.05054\nIteration: 9, Log-Lik: -29653.039, Max-Change: 0.04176\nIteration: 10, Log-Lik: -29652.375, Max-Change: 0.05004\nIteration: 11, Log-Lik: -29651.894, Max-Change: 0.06030\nIteration: 12, Log-Lik: -29651.501, Max-Change: 0.06543\nIteration: 13, Log-Lik: -29651.159, Max-Change: 0.09873\nIteration: 14, Log-Lik: -29650.505, Max-Change: 0.08045\nIteration: 15, Log-Lik: -29650.283, Max-Change: 0.06853\nIteration: 16, Log-Lik: -29650.062, Max-Change: 0.05434\nIteration: 17, Log-Lik: -29649.924, Max-Change: 0.04601\nIteration: 18, Log-Lik: -29649.831, Max-Change: 0.02968\nIteration: 19, Log-Lik: -29649.749, Max-Change: 0.02124\nIteration: 20, Log-Lik: -29649.687, Max-Change: 0.03626\nIteration: 21, Log-Lik: -29649.640, Max-Change: 0.00528\nIteration: 22, Log-Lik: -29649.609, Max-Change: 0.00468\nIteration: 23, Log-Lik: -29649.582, Max-Change: 0.00571\nIteration: 24, Log-Lik: -29649.559, Max-Change: 0.00718\nIteration: 25, Log-Lik: -29649.536, Max-Change: 0.00257\nIteration: 26, Log-Lik: -29649.519, Max-Change: 0.00106\nIteration: 27, Log-Lik: -29649.508, Max-Change: 0.00114\nIteration: 28, Log-Lik: -29649.498, Max-Change: 0.00079\nIteration: 29, Log-Lik: -29649.492, Max-Change: 0.00092\nIteration: 30, Log-Lik: -29649.487, Max-Change: 0.00083\nIteration: 31, Log-Lik: -29649.482, Max-Change: 0.00120\nIteration: 32, Log-Lik: -29649.479, Max-Change: 0.00164\nIteration: 33, Log-Lik: -29649.476, Max-Change: 0.00193\nIteration: 34, Log-Lik: -29649.473, Max-Change: 0.00111\nIteration: 35, Log-Lik: -29649.471, Max-Change: 0.00164\nIteration: 36, Log-Lik: -29649.469, Max-Change: 0.00175\nIteration: 37, Log-Lik: -29649.468, Max-Change: 0.00163\nIteration: 38, Log-Lik: -29649.466, Max-Change: 0.00020\nIteration: 39, Log-Lik: -29649.466, Max-Change: 0.00019\nIteration: 40, Log-Lik: -29649.465, Max-Change: 0.00018\nIteration: 41, Log-Lik: -29649.464, Max-Change: 0.00016\nIteration: 42, Log-Lik: -29649.464, Max-Change: 0.00015\nIteration: 43, Log-Lik: -29649.464, Max-Change: 0.00014\nIteration: 44, Log-Lik: -29649.463, Max-Change: 0.00013\nIteration: 45, Log-Lik: -29649.463, Max-Change: 0.00012\nIteration: 46, Log-Lik: -29649.463, Max-Change: 0.00011\nIteration: 47, Log-Lik: -29649.463, Max-Change: 0.00010\nIteration: 48, Log-Lik: -29649.462, Max-Change: 0.00009\n\nCalculating information matrix...\n\n\nmimic 데이터 세트에서 문항에는 추측도가 포함되지 않습니다. 그러나 문항 응답이 추측도의 영향을 받는 것으로 의심되는 경우 itemtype = “3PL”을 사용하여 다차원 3PL 모델을 선택할 수 있습니다. 또는 mirt 함수에서 추측도 모수를 설정하여 모든 문항에 대해 고정된 낮은 점근값을 정의할 수 있습니다(예: guess = 0.10).\n\n\n7.3.2 다차원 Rasch 모델\nAdams 외(1997)는 중다 잠재 특성을 측정하는 검사에서 문항 모수를 추정할 수 있는 다차원 형태의 Rasch 모델을 도입했습니다. 이 모델은 문헌에서 다차원 무선 계수 다항식 로짓 모델이라고도 알려져 있습니다. Adams 외(1997)가 설명한 이 모델은 Rasch 모델의 일반적인 형태이며 이분 및 다분 문항을 모두 처리할 수 있습니다. Adams 외(1997)의 표기법을 사용하여, 다차원 Rasch 모형은 피험자 \\(j\\)가 \\(M\\)-차원 검사의 문항 \\(i\\)에서 응답 범주 \\(k(k = 0, 1, 2, ..., K)\\)를 선택할 확률을 다음과 같이 정의합니다.\n\\[\nP(X_{ijk}=1|\\xi,\\theta_j)={exp(b_{ik}\\prime\\theta_j + a_{ik}\\prime\\xi) \\over \\sum_{k=0}^K exp(b_{ik}\\prime\\theta_j + a_{ik}\\prime\\xi)}\n\\]\n\n여기서 \\(b_{ik}\\)는 \\(M\\)-차원에 걸쳐 문항 \\(i\\)의 점수 범주 \\(k\\)에 대한 점수 벡터이고,\n\\(a_{ik}\\)은 문항 난이도 모수 간의 관계를 정의하는 문항 \\(i\\)의 점수 범주 \\(k\\)에 대한 설계 벡터이며,\n\\(\\theta_j\\)는 잠재 특성( \\(\\theta_j = (\\theta_{j1}, \\theta_{j2}, ..., \\theta_{jM})\\))이며,\n\\(\\xi\\)는 문항 \\(i\\)의 문항 난이도 모수 벡터입니다.\n\n\\(a_{ik}\\)과 \\(b_{ik}\\)는 문항 변별도와 문항 난이도 모수를 나타내는 것이 아니라 가설을 바탕으로 검사 구조에서 도출된 가중치라는 점에 주의해야 합니다. 방정식 7.5에서 추정되는 유일한 모수는 \\(\\xi\\) 및 \\(\\theta_j\\)입니다.\n다차원 Rasch 모델은 중다 잠재 특성을 측정하는 문항 간 및 문항 내 검사 구조에 모두 사용할 수 있습니다. 다차원 Rasch 모델에서 잠재 특성 간의 상관관계는 추가 정보로 사용됩니다. 잠재 특성 간의 상관관계를 통해, 특히 검사가 짧고 추정되는 잠재 특성의 수가 많은 경우 정밀도를 크게 향상시킬 수 있습니다(Wang et al., 2004). 다음 예에서는 mimic 데이터 세트를 사용하여 다차원 Rasch 모델을 적합하는 방법을 보여줍니다. 예상된 검사 구조가 모델 간에 변경되지 않기 때문에 모델 정의는 M2PL 모델의 정의와 동일합니다. 다차원 Rasch 모델을 추정하려면 itemtype = “Rasch”를 지정하기만 하면 됩니다. 나머지 요소는 M2PL 모델의 이전 예와 동일합니다.\n\nmrasch_mod <- 'F1 = 1 - 6, 13 - 21, 23 - 24\nF2 = 7 - 20, 22 - 24\nCOV = F1 * F2'\nmrasch_fit <- mirt(data = mimic, model = mrasch_mod, itemtype = \"Rasch\", SE = TRUE)\n\n\nIteration: 1, Log-Lik: -29656.952, Max-Change: 0.10045\nIteration: 2, Log-Lik: -29637.972, Max-Change: 0.05761\nIteration: 3, Log-Lik: -29628.772, Max-Change: 0.03570\nIteration: 4, Log-Lik: -29623.389, Max-Change: 0.02400\nIteration: 5, Log-Lik: -29619.969, Max-Change: 0.01717\nIteration: 6, Log-Lik: -29617.689, Max-Change: 0.01287\nIteration: 7, Log-Lik: -29616.114, Max-Change: 0.01013\nIteration: 8, Log-Lik: -29614.997, Max-Change: 0.00794\nIteration: 9, Log-Lik: -29614.206, Max-Change: 0.00648\nIteration: 10, Log-Lik: -29613.633, Max-Change: 0.00545\nIteration: 11, Log-Lik: -29613.199, Max-Change: 0.00445\nIteration: 12, Log-Lik: -29612.883, Max-Change: 0.00378\nIteration: 13, Log-Lik: -29612.649, Max-Change: 0.00330\nIteration: 14, Log-Lik: -29612.464, Max-Change: 0.00273\nIteration: 15, Log-Lik: -29612.328, Max-Change: 0.00237\nIteration: 16, Log-Lik: -29612.225, Max-Change: 0.00215\nIteration: 17, Log-Lik: -29612.142, Max-Change: 0.00177\nIteration: 18, Log-Lik: -29612.080, Max-Change: 0.00155\nIteration: 19, Log-Lik: -29612.032, Max-Change: 0.00143\nIteration: 20, Log-Lik: -29611.994, Max-Change: 0.00118\nIteration: 21, Log-Lik: -29611.965, Max-Change: 0.00104\nIteration: 22, Log-Lik: -29611.942, Max-Change: 0.00098\nIteration: 23, Log-Lik: -29611.924, Max-Change: 0.00080\nIteration: 24, Log-Lik: -29611.910, Max-Change: 0.00071\nIteration: 25, Log-Lik: -29611.899, Max-Change: 0.00068\nIteration: 26, Log-Lik: -29611.890, Max-Change: 0.00055\nIteration: 27, Log-Lik: -29611.883, Max-Change: 0.00049\nIteration: 28, Log-Lik: -29611.878, Max-Change: 0.00047\nIteration: 29, Log-Lik: -29611.874, Max-Change: 0.00039\nIteration: 30, Log-Lik: -29611.870, Max-Change: 0.00034\nIteration: 31, Log-Lik: -29611.868, Max-Change: 0.00033\nIteration: 32, Log-Lik: -29611.865, Max-Change: 0.00027\nIteration: 33, Log-Lik: -29611.864, Max-Change: 0.00024\nIteration: 34, Log-Lik: -29611.862, Max-Change: 0.00023\nIteration: 35, Log-Lik: -29611.861, Max-Change: 0.00019\nIteration: 36, Log-Lik: -29611.861, Max-Change: 0.00017\nIteration: 37, Log-Lik: -29611.860, Max-Change: 0.00016\nIteration: 38, Log-Lik: -29611.859, Max-Change: 0.00013\nIteration: 39, Log-Lik: -29611.859, Max-Change: 0.00012\nIteration: 40, Log-Lik: -29611.859, Max-Change: 0.00011\nIteration: 41, Log-Lik: -29611.858, Max-Change: 0.00009\n\nCalculating information matrix...\n\nmrasch_params <- coef(mrasch_fit, simplify = TRUE)\n\n다음으로 head 함수를 사용하여 추정된 문항 모수의 첫 열 행을 출력합니다. 결과는 M2PL 모델에서 보았던 결과와 매우 유사합니다. 그러나 다차원 Rasch 모델의 문항에 대해서는 문항 변별도 모수가 1로 고정되어 있습니다.\n\nhead(mrasch_params$items, 10)\n\n       a1 a2           d g u\nitem1   1  0  0.02939223 0 1\nitem2   1  0 -0.29424422 0 1\nitem3   1  0  0.21640938 0 1\nitem4   1  0  0.18627651 0 1\nitem5   1  0  0.16313753 0 1\nitem6   1  0  0.76289969 0 1\nitem7   0  1  0.02322099 0 1\nitem8   0  1 -0.90995145 0 1\nitem9   0  1  0.53984398 0 1\nitem10  0  1  0.88886343 0 1\n\n\n다음으로 MDIFF 함수를 사용하여 절편 모수를 문항 난이도 모수로 변환합니다. 결과에서 단일 잠재 특성과 관련된 문항의 경우 d 모수의 부호만 변경된 반면, 두 잠재 특성과 관련된 문항의 경우 변환 후 문항 난이도 모수가 달라진 것을 확인할 수 있습니다. 다차원 Rasch 모델에 따르면 item10이 가장 쉬운 문항이고 item11(출력되지 않음)이 가장 어려운 문항입니다.\n\nmrasch_mdiff <- MDIFF(mrasch_fit)\nhead(mrasch_mdiff)\n\n          MDIFF_1\nitem1 -0.02939223\nitem2  0.29424422\nitem3 -0.21640938\nitem4 -0.18627651\nitem5 -0.16313753\nitem6 -0.76289969\n\n\n마지막으로 두 잠재 특성의 추정된 분산-공분산 행렬을 출력합니다. 출력에 따르면 F1과 F2의 분산은 각각 0.689와 0.739입니다. 두 잠재 특성의 공분산은 0.344입니다.\n\nmrasch_params$cov\n\n          F1        F2\nF1 0.6892990 0.3436748\nF2 0.3436748 0.7388482\n\n\nM2PL 모델에서와 마찬가지로 itemplot 및 plot 함수를 사용하여 문항 및 검사 특성을 시각적으로 조사할 수 있습니다. 이러한 그래프에 대한 R 명령은 아래에 나와 있습니다.\n\nitemplot(mrasch_fit, type = \"trace\", item = 13)\n\n\n\nitemplot(mrasch_fit, type = \"tracecontour\", item = 13)\n\n\n\nplot(mrasch_fit, type = \"info\")\n\n\n\nplot(mrasch_fit, type = \"SE\")\n\n\n\nplot(mrasch_fit, type = \"score\")\n\n\n\n\n\n\n7.3.3 다차원 등급 반응 모델\n앞서 소개한 M2PL 모델과 다차원 Rasch 모델 모두 이분 문항에 적합합니다. 다분 문항에도 MIRT 프레임워크를 사용할 수 있습니다. 제6장에서는 서열 및 명목형 응답 범주가 있는 다분 문항에 대한 단일차원 IRT 모형을 제시했습니다. 제6장에서 제시된 각 IRT 모델에는 다차원 형태가 있지만, 이 섹션에서는 특히 다차원 등급 반응 모델(MGRM)에 중점을 둡니다. 다른 다차원 IRT 모델(예: 부분 점수 모델 및 등급 척도 모델)의 다차원 형태도 유사한 방식으로 추정할 수 있습니다.\nMGRM에서 피험자 \\(j\\)가 문항 \\(i\\), \\(\\theta_j\\)에서 응답 범주 \\(k\\)를 선택할 확률은 다음과 같이 쓸 수 있습니다.\n\\[\nP(X_{ij}=k|\\theta_j,a_i,\\delta_{ik})={1 \\over 1 + exp \\begin{bmatrix}-\\sum_{m=1}^M = [a_{im}(\\theta_{jm}-\\delta_{ik})]\\end{bmatrix}}\n\\]\n\n여기서 \\(\\theta_j\\)는 피험자 \\(j\\)에 대한 잠재 특성의 1 X \\(M\\) 벡터( \\(\\theta_j =(\\theta_{j1}, \\theta_{ j2}, ... , \\theta_{jM})\\)),\n\\(a_i\\)는 문항 \\(i\\)에 대한 기울기(즉, 문항의 변별도) 모수의 1 X \\(M\\) 벡터이고(\\(a_i =(a_{i1}, a_{i2}, ... , a_{iM})\\)),\n\\(\\delta_{ik}\\)는 문항 \\(i\\)의 반응 범주 \\(k\\)에 대한 범주 경계 위치입니다.\n또한 \\(P(X_{ij} = 0|\\theta_j, a_i, \\delta_{ik}) = 1\\)과 \\(P(X_{ij}=K + 1|\\theta_j, a_i, \\delta_{ik})=0\\)\n\nMGRM을 추정하는 방법을 설명하기 위해, hemp 패키지의 depression 데이터 세트를 사용합니다. depression 데이터 세트에는 2000명의 피험자가 가상의 우울 척도 20개 문항에 대해 응답한 내용이 포함되어 있습니다. 간단한 다차원 구조 내에서, 첫 번째 10개 문항은 우울의 인지적 증상을 측정하고, 두 번째 10개 문항 세트는 우울의 신체적 증상을 측정합니다. 문항 이름은 depression 데이터 세트의 item1, item2, …, item20에 해당합니다. 모든 문항은 5개의 반응 범주로 다분으로 채점됩니다(0 = 매우 동의하지 않음, 1 = 동의하지 않음, 2 = 동의나 동의하지도 않음, 3 = 동의함, 4 = 매우 동의함).\nMGRM을 추정하기 위해 다시 mirt 패키지의 mirt 함수를 사용합니다. mirt의 모델 구문을 사용하여 인지적 특성과 신체적 특성이라는 두 가지 잠재적 특성을 정의하고 이를 mgrm_mod로 저장합니다. 구조가 단순하기 때문에 두 잠재 특성 간에 공통 문항이 없습니다. mirt 함수에서 itemtype = “graded”를 지정하여 mgrm_mod에 정의된 2차원 구조를 기반으로 MGRM을 추정합니다. 모델을 적합하고, 문항 모수를 추출하고, 아래에 처음부터 6개 문항을 출력합니다.\n\nmgrm_mod <- 'Cognitive = 1 - 10\n             Somatic = 11 - 20\n             COV = Cognitive * Somatic'\nmgrm_fit <- mirt(data = depression, model = mgrm_mod, \n                 itemtype = \"graded\", SE = TRUE)\n\n\nIteration: 1, Log-Lik: -52635.219, Max-Change: 0.44654\nIteration: 2, Log-Lik: -52322.125, Max-Change: 0.31998\nIteration: 3, Log-Lik: -52229.422, Max-Change: 0.12739\nIteration: 4, Log-Lik: -52203.970, Max-Change: 0.04304\nIteration: 5, Log-Lik: -52196.405, Max-Change: 0.02456\nIteration: 6, Log-Lik: -52193.744, Max-Change: 0.01904\nIteration: 7, Log-Lik: -52192.102, Max-Change: 0.00851\nIteration: 8, Log-Lik: -52191.797, Max-Change: 0.00482\nIteration: 9, Log-Lik: -52191.673, Max-Change: 0.00280\nIteration: 10, Log-Lik: -52191.596, Max-Change: 0.00235\nIteration: 11, Log-Lik: -52191.571, Max-Change: 0.00103\nIteration: 12, Log-Lik: -52191.565, Max-Change: 0.00074\nIteration: 13, Log-Lik: -52191.559, Max-Change: 0.00053\nIteration: 14, Log-Lik: -52191.558, Max-Change: 0.00022\nIteration: 15, Log-Lik: -52191.558, Max-Change: 0.00046\nIteration: 16, Log-Lik: -52191.557, Max-Change: 0.00016\nIteration: 17, Log-Lik: -52191.557, Max-Change: 0.00029\nIteration: 18, Log-Lik: -52191.557, Max-Change: 0.00013\nIteration: 19, Log-Lik: -52191.557, Max-Change: 0.00027\nIteration: 20, Log-Lik: -52191.556, Max-Change: 0.00010\n\nCalculating information matrix...\n\nmgrm_params <- coef(mgrm_fit, simplify = TRUE)\nhead(mgrm_params$items)\n\n             a1 a2         d1          d2         d3         d4\nitem1 1.1614261  0  0.6317042  0.08701621 -0.9142739 -1.3964973\nitem2 1.3414987  0  1.9962391  1.29332975  0.8924567 -0.1588539\nitem3 1.7877303  0  0.2533062 -0.41532154 -0.9713472 -1.7667465\nitem4 1.1584236  0 -0.6316110 -0.96876368 -1.9789404 -2.3165054\nitem5 1.1091947  0  0.7715137 -0.05149029 -0.9521263 -1.3720682\nitem6 0.8885139  0  2.3027712  1.81327409  1.1001075  0.6448772\n\n\n결과에서 열 a1 및 a2는 기울기 모수이고 나머지 열은 절편 모수(즉, 범주 임계값)입니다. 앞서 설명했듯이 기울기 및 절편 모수는 방정식 7.6에 정의된 모수와 동일하지 않습니다. 추정된 문항 모수(즉, 기울기 및 절편)를 다차원 문항 변별도 및 범주 임계값 모수로 변환하기 위해 다시 MDISC 및 MDIFF 함수를 사용합니다.\n\nmgrm_items <- cbind(MDISC(mgrm_fit), \n                    MDIFF(mgrm_fit))\nhead(mgrm_items)\n\n                   MDIFF_1     MDIFF_2    MDIFF_3    MDIFF_4\nitem1 1.1614261 -0.5439039 -0.07492186  0.7871993  1.2023988\nitem2 1.3414987 -1.4880664 -0.96409322 -0.6652684  0.1184152\nitem3 1.7877303 -0.1416915  0.23231779  0.5433410  0.9882623\nitem4 1.1584236  0.5452332  0.83627756  1.7083046  1.9997049\nitem5 1.1091947 -0.6955621  0.04642133  0.8583942  1.2369949\nitem6 0.8885139 -2.5917108 -2.04079420 -1.2381432 -0.7257930\n\n\n또한 잠재 특성의 추정된 분산-공분산 행렬을 출력합니다. 아래 결과는 인지적 특성과 신체적 특성의 분산이 1이고 두 잠재 특성의 공분산(상관 관계)이 0.462임을 보여줍니다.\n\nmgrm_params$cov\n\n          Cognitive   Somatic\nCognitive 1.0000000 0.4616181\nSomatic   0.4616181 1.0000000\n\n\n마지막으로 depression 데이터 세트의 문항을 시각적으로 살펴봅니다. 문항 표면 그래프는 이분 문항에 대한 다차원 IRT 모델에 비해 다분 문항에 대한 다차원 IRT 모델의 경우 약간 더 복잡합니다. 다음 예에서는 item7과 item13에 대한 문항 표면 그래프를 만듭니다. 그림 7.8은 두 문항 모두 중다 반응 범주가 있기 때문에 각 문항 표면 그래프에 여러 개의 표면이 있음을 보여줍니다. 각 표면은 문항에서 특정 응답 범주를 선택할 확률을 표시합니다.\n\nitemplot(mgrm_fit, type = \"trace\", item = 7)\n\n\n\nitemplot(mgrm_fit, type = \"trace\", item = 13)\n\n\n\n\nplot 함수를 사용하여 검사 특성을 시각적으로 살펴볼 수도 있습니다. 아래에는 다양한 검사 특성 그래프를 생성하기 위한 R 명령이 나와 있습니다. 각 그래프는 검사 수준에서 다양한 유형의 정보(예: 정보, cSEM 및 기대점수)를 요약합니다.\n\nplot(mgrm_fit, type = \"info\")\n\n\n\nplot(mgrm_fit, type = \"SE\")\n\n\n\nplot(mgrm_fit, type = \"score\")\n\n\n\n\n\n\n7.3.4 이요인 IRT 모델\n이요인 IRT 모델은 문항 내 검사 구조를 위한 MIRT 모델링 프레임워크의 특수한 형태입니다. 이요인 IRT 모델에서는 모든 문항이 일반 잠재 특성과 연관되며, 각 문항은 보조 잠재 특성과도 연관됩니다. 일반 잠재 특성은 문항의 공통된 변산성을 설명하는 반면, 보조 잠재 특성은 문항의 고유한 변산성을 포착합니다. 모델 식별을 보장하기 위해, 일반 잠재 특성과 보조 잠재 특성은 이요인 모델에서 상관 관계가 없는 것으로 제약합니다. 이요인 구조는 다양한 MIRT 모델에 적용될 수 있지만, 문항 변별도 모수가 문항에 따라 달라지는 MIRT 모델(예: M2PL, M3PL 및 MGRM 모델)에 특히 유용합니다. 이요인 IRT 모델은 이분 및 다분 채점 문항 모두에 사용할 수 있습니다.\n그림 7.9는 문항 1부터 문항 5까지는 첫 번째 잠재 특성(\\(\\theta_1\\)), 문항 6부터 문항 10까지는 두 번째 잠재 특성(\\(\\theta_2\\)), 모든 문항은 일반 잠재 특성(\\(\\theta_G\\))과 연관된 이요인 구조의 예시를 보여줍니다. 잠재 특성 \\(\\theta_1\\), \\(\\theta_2\\), \\(\\theta_G\\)는 이요인 구조에서 서로 상관관계가 없습니다.\n\n\n\n이요인 검사 구조\n\n\n이요인 IRT 모델을 추정하는 방법을 보여드리기 위해 다시 한 번 mirt 패키지의 depression 데이터 세트와 bfactor 함수를 사용합니다. 먼저, 각 문항과 두 잠재 특성(즉, 인지 및 신체) 간의 연관성을 지정하는 차원이라는 벡터를 정의합니다. 이 벡터의 길이는 depression 데이터 세트의 문항 수와 동일합니다. 다음으로 bfactor 함수의 model = dimensions을 사용하여 검사 구조를 지정합니다. bfactor 함수는 차원 벡터에 지정된 모든 문항을 기반으로 추가적인 잠재 특성(즉, 일반 잠재 특성)이 있다고 가정합니다. depression 데이터 집합의 문항은 다분이기 때문에 결과 모델은 이요인 등급 반응 모델(GRM)이 됩니다. 모델을 적합하고, 추정된 모수를 추출하고, 처음 6개의 모수 추정치를 출력합니다.\n\ndimensions <- rep(c(1, 2), each = 10)\nbifactor_fit <- bfactor(data = depression, model = dimensions)\n\n\nIteration: 1, Log-Lik: -53157.515, Max-Change: 0.68532\nIteration: 2, Log-Lik: -52437.900, Max-Change: 0.30837\nIteration: 3, Log-Lik: -52267.074, Max-Change: 0.12316\nIteration: 4, Log-Lik: -52216.821, Max-Change: 0.07036\nIteration: 5, Log-Lik: -52201.304, Max-Change: 0.04233\nIteration: 6, Log-Lik: -52193.343, Max-Change: 0.02895\nIteration: 7, Log-Lik: -52190.831, Max-Change: 0.02384\nIteration: 8, Log-Lik: -52188.845, Max-Change: 0.01867\nIteration: 9, Log-Lik: -52187.574, Max-Change: 0.01462\nIteration: 10, Log-Lik: -52185.087, Max-Change: 0.00700\nIteration: 11, Log-Lik: -52184.880, Max-Change: 0.00610\nIteration: 12, Log-Lik: -52184.704, Max-Change: 0.00492\nIteration: 13, Log-Lik: -52184.272, Max-Change: 0.00338\nIteration: 14, Log-Lik: -52184.201, Max-Change: 0.00291\nIteration: 15, Log-Lik: -52184.162, Max-Change: 0.00229\nIteration: 16, Log-Lik: -52184.070, Max-Change: 0.00154\nIteration: 17, Log-Lik: -52184.054, Max-Change: 0.00111\nIteration: 18, Log-Lik: -52184.046, Max-Change: 0.00106\nIteration: 19, Log-Lik: -52184.016, Max-Change: 0.00026\nIteration: 20, Log-Lik: -52184.016, Max-Change: 0.00042\nIteration: 21, Log-Lik: -52184.015, Max-Change: 0.00012\nIteration: 22, Log-Lik: -52184.015, Max-Change: 0.00044\nIteration: 23, Log-Lik: -52184.014, Max-Change: 0.00046\nIteration: 24, Log-Lik: -52184.013, Max-Change: 0.00019\nIteration: 25, Log-Lik: -52184.013, Max-Change: 0.00015\nIteration: 26, Log-Lik: -52184.013, Max-Change: 0.00030\nIteration: 27, Log-Lik: -52184.012, Max-Change: 0.00033\nIteration: 28, Log-Lik: -52184.012, Max-Change: 0.00027\nIteration: 29, Log-Lik: -52184.011, Max-Change: 0.00026\nIteration: 30, Log-Lik: -52184.011, Max-Change: 0.00013\nIteration: 31, Log-Lik: -52184.011, Max-Change: 0.00010\nIteration: 32, Log-Lik: -52184.011, Max-Change: 0.00022\nIteration: 33, Log-Lik: -52184.011, Max-Change: 0.00007\n\nbifactor_params <- coef(bifactor_fit, simplify = TRUE)\nhead(bifactor_params$items)\n\n             a1        a2 a3         d1          d2         d3         d4\nitem1 0.8636558 0.7747101  0  0.6326557  0.08814625 -0.9124955 -1.3943250\nitem2 0.8937414 1.0200484  0  2.0073519  1.30153921  0.8989060 -0.1573527\nitem3 1.2319292 1.3070443  0  0.2570879 -0.41338002 -0.9709465 -1.7684132\nitem4 0.8702281 0.7613767  0 -0.6294679 -0.96622324 -1.9754034 -2.3128019\nitem5 0.9002669 0.6639381  0  0.7746956 -0.05007499 -0.9528938 -1.3737999\nitem6 0.7307330 0.5215354  0  2.3086226  1.81822267  1.1036505  0.6473923\n\n\n결과에서 처음 세 열(a1, a2, a3)은 일반 잠재 특성 및 보조 잠재 특성(인지 및 신체)에 대한 기울기 모수를 표시합니다. 첫 번째 기울기 모수는 모든 문항에 대해 0보다 크지만, 두 번째 및 세 번째 기울기 모수는 특정 잠재 특성과 연관되지 않은 문항에 대해 0 요소를 갖습니다. 예를 들어 item1은 일반 잠재 특성 및 첫 번째 보조 잠재 특성과 연관되어 있습니다. 따라서 item1의 첫 번째 및 두 번째 기울기 모수는 a1 = 0.8637, a2 = 0.7747이고 세 번째 기울기 모수는 a3 = 0입니다. 다음 열(d1, d2, d3 및 d4)은 이요인 GRM의 절편 모수입니다.\n또한 MDISC 및 MDIFF 함수를 사용하여 추정된 기울기 및 절편 모수를 다차원 문항 변별도 및 범주 임계값 모수로 변환할 수 있습니다.\n\nbifactor_items <- cbind(MDISC(bifactor_fit), \n                        MDIFF(bifactor_fit))\nhead(bifactor_items)\n\n                   MDIFF_1     MDIFF_2    MDIFF_3    MDIFF_4\nitem1 1.1602056 -0.5452962 -0.07597468  0.7864947  1.2017913\nitem2 1.3561978 -1.4801320 -0.95969715 -0.6628133  0.1160249\nitem3 1.7961109 -0.1431359  0.23015284  0.5405827  0.9845791\nitem4 1.1562834  0.5443890  0.83562838  1.7084076  2.0002033\nitem5 1.1186127 -0.6925504  0.04476526  0.8518532  1.2281283\nitem6 0.8977583 -2.5715413 -2.02529196 -1.2293403 -0.7211209\n\n\n앞서 설명했듯이 이요인 모델에서 잠재 특성 간의 상관관계는 0으로 제약하며, 잠재 특성의 공분산 행렬을 출력하면 이러한 제약을 확인할 수 있습니다. 이 행렬에서 대각선 요소는 1이고 대각선이 아닌 요소는 모두 0이므로 모델에서 정의한 세 가지 잠재 특성이 직교(즉, 상관관계가 없음)임을 나타냅니다.\n\nbifactor_params$cov\n\n   G S1 S2\nG  1  0  0\nS1 0  1  0\nS2 0  0  1"
  },
  {
    "objectID": "chap07.html#요약",
    "href": "chap07.html#요약",
    "title": "7  다차원 문항반응이론",
    "section": "7.4 요약",
    "text": "7.4 요약\n이 장에서는 MIRT 프레임워크를 소개하고 mirt 패키지를 사용하여 여러 MIRT 모델을 추정하고 적합하는 방법을 시연했습니다. MIRT 모델은 두 개 이상의 잠재 특성을 측정하려는 다차원 검사 구조에 적합합니다. 반응 데이터 세트에 MIRT 모델을 적용하기 전에는 몇 가지 단계가 있습니다. 첫 번째 단계는 검사 구조를 결정하는 것입니다. 검사 구조를 알 수 없는 경우, 탐색적 MIRT 접근 방식을 사용하여 반응 패턴을 기반으로 검사 구조를 결정할 수 있습니다. 이는 데이터 기반 접근 방식으로 간주할 수 있습니다. 문항과 잠재 특성 간의 관계를 이미 알고 있는 경우에는 확인적 MIRT 접근법을 사용해야 합니다. 검사 구조는 문항 내 다차원성 또는 문항 간 다차원성을 나타낼 수 있습니다. 두 번째 단계는 잠재 특성 간에 보상 관계가 있는지 여부를 결정하는 것입니다. 보상적 MIRT 모델은 한 잠재 특성의 강점이 다른 잠재 특성의 약점을 보완할 수 있도록 합니다. 비보상적 MIRT 모델은 잠재 특성 간에 어떠한 보상도 허용하지 않습니다. 세 번째 단계는 MIRT 모델을 선택하는 것입니다. 제5장과 제6장에서 설명한 단일차원 IRT 모델은 MIRT 모델로 추정할 수 있습니다. 즉, 이분 문항과 다분 문항 모두에 MIRT 모델을 사용할 수 있습니다. mirt 패키지는 다양한 MIRT 모델을 추정할 수 있지만, 여기서는 교육 및 심리 측정에 사용되는 일반적인 MIRT 모델만 시연했습니다. mirt의 기능에 대한 자세한 내용은 mirt 패키지 매뉴얼(Chalmers, 2012)을 참조하시기 바랍니다."
  },
  {
    "objectID": "chap08.html#개요",
    "href": "chap08.html#개요",
    "title": "8  설명적 문항반응이론",
    "section": "8.1 개요",
    "text": "8.1 개요\n제5장부터 제7장까지는 이분 및 다분으로 채점된 문항에 대한 단일차원 및 다차원 IRT 모델에 대해 설명했습니다. 이러한 IRT 모델은 응답 범주의 수에 관계없이 피험자의 잠재적 특성 수준에 대한 직접적인 정보를 제공하며, 선택한 IRT 모델에 따라 각 문항의 난이도, 변별도 및 추측도에 관한 정보를 제공합니다. 개별 문항과 피험자에 대한 정보를 제공하지만, 전통적인 IRT 모델은 측정 도구의 설계 또는 이론에 따라 문항이나 피험자 간의 공통된 변산을 설명할 수 없습니다. De Boeck과 Wilson(2004)은 문항군, 피험자 그룹 또는 문항군과 피험자 그룹 간의 상호 작용에서 공통적인 변산을 측정하는 데 사용할 수 있는 설명적 IRT 모델링(EIRM)을 소개했습니다. 기존의 IRT 모델과 달리 EIRM은 문항(예: 내용, 인지 복합성, 문항 형식) 및 피험자(예: 성별, 인종, 학년 수준)와 관련된 설명 변수(공변량이라고도 함)를 사용하여 문항 응답의 공통성을 설명하는 것을 목표로 합니다. 제8장에서는 다양한 설명적 IRT 모델에 대한 요약을 제공하고 R의 lme4 패키지(Bates et al., 2015)를 사용하여 이러한 모델을 추정하는 방법을 보여줍니다. 설명적 IRT 모델은 mirt(Chalmers, 2012), flirt(Jeon et al., 2014) 및 eRm(Mair & Hatzinger, 2007a) 패키지로도 추정할 수 있습니다."
  },
  {
    "objectID": "chap08.html#설명적-문항-반응-모델링",
    "href": "chap08.html#설명적-문항-반응-모델링",
    "title": "8  설명적 문항반응이론",
    "section": "8.2 설명적 문항 반응 모델링",
    "text": "8.2 설명적 문항 반응 모델링\n설명적 IRT 모델링(EIRM)은 측정과 설명적 목적 모두에 IRT를 활용할 수 있습니다(De Boeck & Wilson, 2004). 기존 IRT 모델에 비해 EIRM의 주요 장점은 문항과 피험자를 유연하게 분석하는 동시에 문항과 피험자 간의 공통 변산를 분해할 수 있다는 점입니다(Briggs, 2008). EIRM 프레임워크에서 전통적인 IRT 모델은 더 큰 종류의 모델인 일반화된 선형 혼합 모델(GLMM)에 속하는 모델의 하위 집합으로 간주됩니다. GLMM은 모델에 문항 응답의 예측 변수로 설명 변수가 포함되어 있는 경우 설명적 IRT 모델로 기능할 수 있습니다. 이러한 설명 변수는 문항 군집, 피험자 그룹 또는 문항과 피험자 간의 상호 작용에서 공통적인 변산성을 설명할 수 있습니다(De Boeck & Wilson, 2004).\nEIRM 접근법에서는 피험자를 군집으로, 문항을 반복 관찰로, 문항 반응을 다층 구조 내의 종속 변수로 정의합니다. 설명 공변량을 사용하면 종속 변수(즉, 문항 반응)를 보다 간결한 방식으로 예측할 수 있습니다. 예를 들어 수학 표현, 표기법, 용어가 포함된 대수 문항과 시나리오 내에서 수학 문제를 구두로 설명하는 단어 문제라는 두 가지 유형의 문항으로 구성된 수학 시험이 있다고 가정해 보겠습니다. 문항 난이도 모수를 추정할 때 각 문항에 대해 고유한 문항 난이도 모수를 추정하는 대신 문항 유형(예: 수학 시험의 대수 문항 및 단어 문제)을 공변량으로 사용하여 문항 유형에 따른 문항 난이도의 변산성을 설명할 수 있습니다. 이렇게 하면 대수 문항이 단어 문제보다 더 어렵거나 더 쉬울 가능성이 있는지 조사할 수 있습니다. 그런 다음 문항 유형이 문항에 미치는 전반적인 영향을 설명할 수 있습니다.\n다음 섹션에서는 선형 로지스틱 검사 모델, 잠재 회귀 모델, 상호작용 모델 등 세 가지 EIRM의 적용 사례를 보여드리겠습니다. 간결성을 위해, 이분 문항 응답에만 초점을 맞추었지만, 다분 문항 응답에도 EIRM을 사용할 수 있습니다. 위에서 언급한 세 가지 적용 사례는 EIRM 프레임워크 내에서 가능한 것의 일부에 불과하다는 점에 유의해야 합니다. EIRM 프레임워크에 대한 보다 포괄적인 논의는 다른 자료에서 찾을 수 있습니다(예: De Boeck & Wilson, 2004).\n\n8.2.1 데이터 구조\n이 장에서는 설명적 IRT 모델을 추정하기 위해 lme4(Bates et al., 2015) 패키지를 사용합니다. 이 패키지는 제3장에서 일반화 가능성 이론을 논의할 때 사용한 것과 동일한 패키지입니다. 지금까지 다양한 IRT 모형을 추정하기 위해 mirt 패키지를 사용하는 방법을 살펴보았습니다. mirt 패키지를 사용하려면 문항 응답 데이터가 피험자당 하나의 행과 하나의 열이 있는 와이드 또는 깔끔한(Wickham, 2017) 포맷으로 구성되어야 합니다.\nmirt 패키지와 달리 lme4 패키지는 피험자와 문항의 고유한 조합마다 행이 하나씩 있는 롱 포맷으로 데이터를 구성해야 합니다. 예를 들어, 500명의 피험자가 있는 10문항 검사의 롱 포맷은 5000행(10문항 x 500명의 피험자)의 문항 응답이 있는 단일 열을 갖습니다. 추가 식별 변수(예: 문항 및 피험자 식별자)도 lme4 패키지의 추정 프로세스에 필요합니다.\n다음 예에서는 hemp 패키지의 multiplechoice 데이터 세트를 사용하여 데이터 세트를 와이드 포맷에서 롱 포맷으로 변환하는 방법을 보여줍니다. multiplechoice 데이터 세트는 item1부터 item27까지 레이블이 지정된 27개 문항에 대한 27개 열의 응답으로 구성됩니다. 행은 496개로, 데이터 세트에 496명의 피험자가 있음을 나타냅니다. 이 변환에는 reshape 함수를 사용합니다. reshape 함수에는 몇 가지 인수가 필요합니다:\n\n포맷을 변경하려는 데이터 세트의 이름, multiplechoice;\n응답이 포함된 원래 데이터 세트의 열(이 경우 열 1부터 27까지, varying = 1:27);\n변경할 데이터의 목표 포맷, direction = “long”;\n새 시간 변수의 이름(이 경우 시간이 아닌 문항에 대한 측정을 반복했기 때문에 시간 변수는 실제로 item이라고 함, timevar = “item”);\n새(또는 기존) 식별자 변수의 이름, idvar = “id”;\n마지막으로 문항 응답을 포함하는 새 변수의 이름, v.names = “response”.\n\n변환된 데이터 세트를 각 피험자가 27개의 행(즉, multiplechoice 데이터 세트의 문항당 하나의 행)을 갖는 mc_long이라는 새 데이터 세트로 저장합니다.\n\nlibrary(hemp)\n\nLoading required package: psych\n\n\nLoading required package: lattice\n\n\nLoading required package: lavaan\n\n\nThis is lavaan 0.6-16\nlavaan is FREE software! Please report any bugs.\n\n\n\nAttaching package: 'lavaan'\n\n\nThe following object is masked from 'package:psych':\n\n    cor2cov\n\n\nLoading required package: mirt\n\n\nLoading required package: stats4\n\n\nLoading required package: lme4\n\n\nLoading required package: Matrix\n\n\n\nAttaching package: 'lme4'\n\n\nThe following object is masked from 'package:mirt':\n\n    fixef\n\n\nLoading required package: reshape2\n\n\nLoading required package: boot\n\n\n\nAttaching package: 'boot'\n\n\nThe following object is masked from 'package:lattice':\n\n    melanoma\n\n\nThe following object is masked from 'package:psych':\n\n    logit\n\n\nLoading required package: equate\n\nmc_long <- reshape(multiplechoice,\n                   varying = 1:27,\n                   direction = \"long\",\n                   timevar = \"item\",\n                   idvar = \"id\",\n                   v.names = \"response\")\n\nmc_long 데이터 세트는 기본적으로 ’문항’을 기준으로 정렬됩니다. 피험자 식별자(즉, id)를 먼저 정렬한 다음 문항 식별자(즉, item)를 기준으로 데이터를 정렬하고 싶으면 order 함수를 사용하여 이 작업을 수행할 수 있습니다. head 함수를 사용하여 롱 포맷의 데이터 세트의 처음 여섯 행을 출력합니다.\n\nmc_long <- mc_long[order(mc_long$id, mc_long$item), ]\nhead(mc_long)\n\n    item response id\n1.1    1        4  1\n1.2    2        1  1\n1.3    3        2  1\n1.4    4        3  1\n1.5    5        4  1\n1.6    6        3  1\n\n\n\n\n8.2.2 GLMM으로서 Rasch 모델\n제5장에서는 1PL IRT 모델의 특수한 경우로 Rasch 모델을 제시했습니다. Rasch 모델은 문항 난이도와 피험자의 잠재 특성 수준이 주어졌을 때 문항에 정답을 맞힐 확률을 예측하는 모형입니다. Rasch 모형에서는 모든 문항에 대해 문항 변별도 모수가 1로 가정되며, 낮은 점근값(즉, 추측도 모수가 없음)을 추정하는 모델이 없습니다. Rasch 모델은 종속 변수(이분 문항 응답)가 무선 효과(피험자의 잠재 특성 수준)와 함께 일부 고정 효과(문항)에 의해 예측되는 GLMM으로 정의할 수 있습니다.\nGLMM에서 문항 응답은 \\(Y_{ij} = 0\\) 또는 \\(Y_{ij} = 1\\)로 표시되며, 여기서 \\(j = 1, …, J\\)는 피험자의 지수이고 \\(i = 1, …, K\\)는 문항의 지수입니다. \\(Y_{ij}\\) 는 베르누이 분포를 가지며 평균은 \\(\\pi_{ij}\\) 입니다. 일반적으로 로짓 연결 함수1를 적용하여 \\(\\pi_{ij}\\)를 \\(-\\infty\\) 에서 \\(\\infty\\) 사이의 연속 척도에 배치합니다.\n\\[\n\\eta_{ij} = log({\\pi_{ij} \\over 1-\\pi_{ij}})\n\\]\nDe Boeck과 Wilson(2004)의 표기법에 따라 Rasch 모델의 GLMM 공식은 다음과 같이 작성할 수 있습니다.\n\\[\n\\eta_{ij}=\\theta_j+\\sum_{k=1}^K \\beta_i X_{ik}\n\\]\n\n여기서 \\(\\theta_j\\)는 피험자 \\(j\\)의 잠재 특성 수준이고,\n\\(\\beta_i\\)는 전통적인 IRT 모델에서의 문항 난이도와는 반대로 문항 \\(i(i = 1, 2, …, K)\\)에 대한 문항의 쉬움을 의미하며,\n\\(X_{ik}\\)는 \\(i = k\\)이면 1이고 그렇지 않으면 0입니다.\n방정식 8.2에서 \\(\\theta_j\\)는 정규 분포를 갖는 무선 절편, 즉 \\(\\theta_j \\sim N(0, \\sigma^2)\\)이고\n\\(X_{ik}\\)는 모델에서 고정 절편 역할을 하는 문항 지표입니다.\n\n방정식 8.2는 다음과 같이 더 간결하게 작성할 수 있습니다:\n\\[\n\\eta_{ij}=\\theta_j+\\beta_i\n\\]\n여기서 \\(\\beta_i\\)는 \\(\\beta_i\\)와 \\(X_{ik}\\)의 곱의 합입니다. 방정식 8.3에서 \\(\\beta_i\\)에 -1을 곱하면 문항의 쉬움 모수의 부호가 반전되어 문항의 쉬움에서 문항 난이도로 해석이 바뀔 수 있습니다.\n설명적 IRT 모델을 추정하는 방법을 보여드리기 위해 hemp 패키지의 eirm 데이터 세트를 사용합니다. 분석을 시작하기 전에 먼저 library 명령을 사용하여 hemp 및 lme4 패키지를 활성화합니다.\n\nlibrary(\"hemp\")\nlibrary(\"lme4\")\n\neirm 데이터 세트에는 10개의 문항으로 구성된 가상 퀴즈에 대한 1000명의 피험자의 응답이 포함되어 있습니다. 문항은 이분법적으로 채점되었습니다(1 = 정답, 0 = 오답). eirm 데이터 세트는 이미 롱 포캣으로 되어 있으므로 데이터 변환이 필요하지 않습니다. 피험자(person), 문항(item), 문항에 대한 응답(response)을 식별하는 세 개의 열 외에 gender(F = 여성, M = 남성)과 문항에 시각적 요소(예: 그래프, 차트, 이미지)가 포함되어 있는지 여부와 관련된 itemtype(비시각적 또는 시각적)이라는 두 가지 설명 변수가 있습니다. 성별과 문항 유형은 모두 데이터 세트의 문자 변수입니다. head 함수를 사용하여 eirm 데이터 세트의 처음 열 행을 출력합니다.\n\nhead(eirm, 10)\n\n   person item response gender  itemtype\n1       1    1        0      F Nonvisual\n2       1    2        0      F Nonvisual\n3       1    3        0      F Nonvisual\n4       1    4        0      F Nonvisual\n5       1    5        0      F Nonvisual\n6       1    6        0      F    Visual\n7       1    7        0      F    Visual\n8       1    8        0      F    Visual\n9       1    9        0      F    Visual\n10      1   10        0      F    Visual\n\n\n다음으로 table 함수를 사용하여 문항 유형별로 문항에 대한 피험자의 응답을 2원으로 표시하는 표를 생성합니다.\n\ntable(eirm$item, eirm$itemtype)\n\n    \n     Nonvisual Visual\n  1       1000      0\n  2       1000      0\n  3       1000      0\n  4       1000      0\n  5       1000      0\n  6          0   1000\n  7          0   1000\n  8          0   1000\n  9          0   1000\n  10         0   1000\n\n\n위의 결과는 eirm 데이터 세트의 처음 5개 문항은 비시각적 문항이고 마지막 5개 문항은 시각적 요소를 포함하고 있음을 보여줍니다. 모든 피험자는 퀴즈의 모든 문항에 응답했습니다(즉, 문항과 피험자가 완전히 교차되어 있습니다. 교차 설계에 대한 자세한 내용은 제3장 참조). 또한 성별에 따라 피험자의 균형을 맞췄습니다.\nRasch 모델을 사용하여 eirm 데이터 세트에 대한 IRT 분석을 시작합니다. Rasch 모델을 추정할 때는 설명 변수의 영향을 무시하고 개별 문항과 피험자에 초점을 맞춥니다. Rasch 모델을 추정하기 위해 lme4 패키지의 glmer 함수를 사용합니다. glmer 함수는 고정 효과와 무선 효과가 있는 일반화 선형 혼합 모델을 추정할 수 있습니다. 제3장과 달리 glmer 함수를 사용하기 전에 최적화 프로그램과 최대 함수 평가 횟수를 지정하는 것으로 시작합니다. 다음 설정만으로도 대부분의 설명적 IRT 모델을 추정할 수 있지만, 제어 옵션에 대한 자세한 내용은 lme4 패키지 설명서를 살펴보는 것이 좋습니다.\n\ncontrol <- glmerControl(optimizer = \"bobyqa\",\n                        optCtrl = list(maxfun = 100000))\n\n다음으로 glmer 함수를 사용하여 Rasch 모델을 추정하고 결과를 rasch_mod로 저장합니다. 아래 glmer 함수 호출에서 response는 응답을 모델의 종속 변수로 정의하고, -1 + item은 응답을 예측하는 고정 효과로 문항을 정의하며, -1은 모델에서 절편을 제거하고, (1 | person)은 피험자를 무선 효과로 정의하고, family = binomial은 로짓 연결 함수가 있는 이항 분포를 지정하고, control = control은 위에서 정의한 제어문을 활성화합니다.\n\nrasch_mod <- glmer(response ~ -1 + item + (1 | person),\n                   family = binomial, data = eirm,\n                   control = control)\n\n다음으로 추정된 모수를 rasch_params라는 데이터 프레임에 저장합니다. fixef 함수는 rasch_mod에서 추정된 고정 효과(Rasch 모델의 문항 모수)를 검색합니다.\n\nrasch_params <- data.frame(easiness = fixef(rasch_mod))\nrasch_params\n\n         easiness\nitem1   1.7265649\nitem2   0.8168163\nitem3   0.4346284\nitem4   0.4157487\nitem5   0.2385415\nitem6  -0.2482371\nitem7  -0.7259674\nitem8  -0.9741760\nitem9  -0.9741735\nitem10 -1.3409841\n\n\n앞서 설명했듯이 GLMM에서 문항 난이도를 양수로 모수화하기 때문에 GLM 함수에서 얻은 모수는 문항 난이도가 아닌 문항의 쉬운 정도를 나타냅니다(방정식 8.3 참조). 결과에 따르면 item 1이 가장 쉬운 문항이고 item 10이 가장 어려운 문항임을 알 수 있습니다. 문항 난이도 모수 외에도 rasch_mod에서 무선 효과(잠재 특성 추정치)를 추출할 수도 있습니다. 나머지 열은 문항 모수이므로 coef 함수를 사용하여 피험자에 대한 추정 계수의 첫 번째 열만 검색합니다. 잠재 특성 추정치를 rasch_ability로 저장합니다.\n\nrasch_ability <- coef(rasch_mod)$person[, 1]\n\n마지막으로, 문항 모수와 잠재 특성 추정치를 모두 사용하여 hemp 패키지의 itemperson_map 함수를 사용하여 Rasch 모델에 대한 문항-피험자 맵을 그립니다. 먼저 문항 모수를 난이도라는 새 데이터 세트에 저장하고 열 이름을 1부터 10까지로 바꿉니다(item 1부터 item 10까지 참조). 그런 다음 difficulty와 rasch_ability를 모두 사용하여 문항-피험자 맵을 그립니다. 그림 8.1은 피험자의 잠재 특성 수준과 관련된 문항 난이도 모수의 분포를 보여줍니다. 이 도표는 피험자의 잠재 특성 수준 범위를 고려할 때 검사의 난이도 범위가 적절한지 검토하는 데 특히 유용합니다.\n\ndifficulty <- rasch_params$easiness\nnames(difficulty) <- 1:10\nitemperson_map(difficulty, rasch_ability, n = 50)\n\n\n\n\n각 문항에는 고유한 난이도 모수가 있고 각 피험자에게는 고유한 잠재 특성 추정치가 있기 때문에, De Boeck과 Wilson(2004)은 Rasch 모형을 이중 설명적 모델이라고 설명했습니다. 문항과 피험자의 개별 효과를 설명하는 예측 변수를 Rasch 모형에 통합하면 결과 모형은 설명적 IRT 모형이 되며, 이는 종종 Rasch 모델의 더 간결한 형태(즉, 문항을 설명하는 모수가 더 적음)가 됩니다. 다음으로, 문항 관련 예측 변수와 피험자 관련 예측 변수를 포함하여 기존의 Rasch 모형을 설명적 IRT 모형으로 변환하는 방법을 설명합니다.\n\n\n8.2.3 선형 로지스틱 검사 모델\n선형 로지스틱 검사 모델(LLTM; Fischer, 1973)은 문항 속성을 예측 변수로 통합하여 문항이 성공 확률(즉, \\(\\eta_{ij}\\) )에 미치는 영향에 관한 문항 간 차이를 설명합니다. Rasch 모델의 고유한 문항 난이도 모수와 달리 LLTM은 문항 속성에 기반한 난이도 모수가 더 적습니다. LLTM의 수학적 공식은 다음과 같습니다:\n\\[\n\\eta_{ij}=\\theta_j+\\sum_{m=1}^M \\beta_mX_{im}\n\\]\n\n여기서 \\(\\eta_{ij}\\)는 피험자 \\(j\\)의 문항 \\(i\\)에 대한 성공 확률(로짓 척도로 표시),\n\\(\\theta_j\\)는 피험자 \\(j\\)의 잠재 특성 수준,\n\\(X_{im}\\)은 문항 속성 \\(m\\) (\\(m=1,2,…,M\\))에 대한 문항 \\(i\\)의 값\n\\(\\beta_m\\)은 문항 속성 \\(m\\)의 회귀 가중치입니다.\n\nLLTM에서는 여러 문항 속성 변수와 그 상호작용을 예측 요인으로 함께 사용할 수 있습니다. 문항 속성 변수의 수(\\(M\\))가 시험의 문항 수(\\(K\\))보다 적을 것으로 예상되므로 예측의 정확도가 떨어질 수 있습니다. 즉, 방정식 8.4의 \\(\\sum_{m=1}^M \\beta_mX_{im}\\)은 방정식 8.3의 \\(\\beta_i\\)와 같지 않을 것입니다. 그러나 문항 속성의 질에 따라 더 적은 난이도 모수로도 매우 정밀한 예측을 달성할 수 있습니다.\n대안적으로 잔차 항을 LLTM에 포함할 수도 있습니다. 결과 모델을 종종 오차가 있는 LLTM이라고 합니다. 이 모델을 사용하려면 추정 과정에서 문항을 무작선 효과로 처리해야 합니다. 오차가 있는 LLTM은 회귀 기반의 완벽한 예측을 하는 일반 LLTM과 달리 불완전한 예측을 허용합니다(De Boeck, 2008; Doran, Bates, Bliese, & Dowling, 2007). 오차가 있는 LLTM의 수학적 공식은 다음과 같습니다.\n\\[\n\\eta_{ij}=\\theta_j+\\sum_{m=1}^M \\beta_mX_{im}+\\epsilon_i\n\\]\n\n여기서 \\(\\epsilon_i\\)는 정규 분포의 잔차 항, \\(\\epsilon_i \\sim N(0, \\sigma_\\epsilon^2\\) )이고 나머지 요소는 방정식 8.4의 요소와 동일합니다.\n\n오차가 있는 LLTM은 잔차 분산에 대해 등분산성을 가정합니다(De Boeck et al., 2011).\nLLTM과 오차가 있는 LLTM을 추정하는 방법을 설명하기 위해, eirm 데이터 세트의 “itemtype” 변수를 사용하여 문항에 성공적으로 응답할 확률을 예측합니다. 개별 문항 난이도 모수를 추정하는 대신, 문항에 시각적 요소가 포함되어 있는지 여부에 따라 문항 난이도를 설명하는 단일 난이도 모수를 추정합니다. 즉, eirm 데이터 세트의 itemtype을 LLTM의 문항 관련 예측 변수로 사용합니다.\nlme4 패키지로 LLTM을 추정하기 위해 다시 glmer 함수를 사용합니다. 이 코드는 item 대신 itemtype을 사용한다는 점을 제외하면 Rasch 모델용 코드와 매우 유사합니다. 이렇게 수정하면 두 개의 문항 난이도 모수(하나는 비시각적 문항, 다른 하나는 시각적 문항)를 추정할 수 있습니다. 문항 난이도 모수가 두 개뿐이므로(Rasch 모델의 모수가 10개인 것과는 대조적으로) LLTM의 추정 속도가 약간 빨라집니다. summary 함수를 사용하여 결과를 출력합니다.\n\nlltm_mod <- glmer(response ~ -1 + itemtype + (1 | person),\n                  family = binomial, data = eirm,\n                  control = control)\nsummary(lltm_mod)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: response ~ -1 + itemtype + (1 | person)\n   Data: eirm\nControl: control\n\n     AIC      BIC   logLik deviance df.resid \n 12496.0  12517.6  -6245.0  12490.0     9997 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.3908 -0.7656 -0.4033  0.7917  2.4795 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n person (Intercept) 0.548    0.7403  \nNumber of obs: 10000, groups:  person, 1000\n\nFixed effects:\n                  Estimate Std. Error z value Pr(>|z|)    \nitemtypeNonvisual  0.67779    0.03949   17.16   <2e-16 ***\nitemtypeVisual    -0.82425    0.04014  -20.53   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            itmtyN\nitemtypeVsl 0.321 \n\n\n위의 glmer 함수의 결과 중 일부, 특히 무선 효과 및 고정 효과 섹션만 출력했습니다. LLTM은 피험자에 대한 분산 추정치를 \\(\\sigma_{\\theta_j}^2\\) = 0.548로 제공하며, 이는 잠재 특성 수준에 따른 피험자 간의 변산을 나타냅니다. 시각적 문항과 비시각적 문항에 대한 추정된 난이도 모수는 각각 0.677과 -0.824입니다. 앞서 언급했듯이 glmer 함수의 문항 모수는 문항의 쉬운 정도를 나타냅니다. 즉, 값이 높을수록 쉬운 문항을 의미합니다. 결과는 eirm 데이터 세트에서 비시각적 문항이 시각적 문항보다 더 쉽다는 것을 보여줍니다. 같은 표에서 추정된 모수에 대한 표준 오차, \\(z\\) 통계 및 해당 \\(p\\)값을 확인할 수 있습니다. 이러한 유의성 검정은 추정된 모수가 0과 유의하게 다른지 여부를 나타냅니다. 이 예에서는 두 난이도 모수 모두 \\(\\alpha\\) 수준 .05에서 0과 유의하게 다릅니다.\n다음으로 오차가 있는 LLTM을 추정합니다. 이 모델에서는 문항을 무선 효과로 모델에 추가합니다. 오차가 있는 LLTM을 사용하면 문항 난이도 모수와 잠재 특성 추정치가 무선 효과로 변화하면서 문항 유형의 영향을 설명 변수로 제어할 수 있습니다. 추정 결과를 lltme_mod로 저장하고 summary 함수를 사용하여 결과를 확인합니다.\n\nlltme_mod <- glmer(response ~ -1 + itemtype + (1 | person) +\n                     (1 | item), family = binomial, data = eirm,\n                   control = control)\nsummary(lltme_mod)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: response ~ -1 + itemtype + (1 | person) + (1 | item)\n   Data: eirm\nControl: control\n\n     AIC      BIC   logLik deviance df.resid \n 12178.1  12206.9  -6085.0  12170.1     9996 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.4102 -0.7376 -0.3627  0.7624  3.1882 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n person (Intercept) 0.6124   0.7825  \n item   (Intercept) 0.1983   0.4453  \nNumber of obs: 10000, groups:  person, 1000; item, 10\n\nFixed effects:\n                  Estimate Std. Error z value Pr(>|z|)    \nitemtypeNonvisual   0.7218     0.2033   3.551 0.000384 ***\nitemtypeVisual     -0.8495     0.2032  -4.180 2.92e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            itmtyN\nitemtypeVsl 0.014 \n\n\n다시 glmer 함수에서 반환된 결과 중 일부를 표시합니다. 문항을 추가하면 무선 효과 섹션에 잠재 특성과 문항의 분산이 모두 표시됩니다. 이 결과를 LLTM과 비교하면 오차가 있는 LLTM의 잠재 특성의 분산이 더 큽니다(\\(\\sigma_{\\theta_j}^2\\) = 0.612). 왜냐하면 LLTM은 잔차 항이 0이라고 가정하고 itemtype만을 기준으로 문항 간의 변산을 설명하기 때문입니다. 문항 분산 추정치는 0.198입니다. 고정 효과 섹션에는 시각적 문항과 비시각적 문항의 추정 효과가 표시됩니다. 오차가 있는 LLTM의 추정 효과가 LLTM의 추정 효과보다 약간 더 큽니다.\nanova 함수를 사용하여 지금까지 추정했던 두 가지 설명적 IRT 모델과 Rasch 모델을 비교할 수 있습니다. anova 함수는 여러 가지 적합도 통계(예: 로그-우도, AIC, BIC)를 제공합니다. anova 함수는 우도비 검정도 제공하지만, Rasch 모델과 설명적 IRT 모델이 서로 내재되어 있지 않기 때문에 이 검사는 여기서는 적절하지 않습니다. 먼저 Rasch 모델을 LLTM과 비교합니다.\n\nanova(rasch_mod, lltm_mod)\n\nData: eirm\nModels:\nlltm_mod: response ~ -1 + itemtype + (1 | person)\nrasch_mod: response ~ -1 + item + (1 | person)\n          npar   AIC   BIC  logLik deviance  Chisq Df Pr(>Chisq)    \nlltm_mod     3 12496 12518 -6245.0    12490                         \nrasch_mod   11 12142 12221 -6059.8    12120 370.33  8  < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n결과에서 Rasch 모델이 로그 우도, AIC, BIC 값이 더 작아 LLTM보다 데이터에 더 잘 맞는다는 것을 알 수 있습니다. Rasch 모델은 각 문항에 대해 고유한 난이도 모수와 잠재 특성에 대한 분산 추정치를 제공하기 때문에 이 결과는 놀라운 일이 아닙니다. 모델 적합도가 더 떨어지는 것으로 나타났지만, LLTM은 3개의 모수(2개의 문항 모수와 잠재 특성에 대한 분산)만 가지고 있기 때문에 더 간결한 모델입니다.\n두 번째 비교는 Rasch 모델과 오차가 있는 LLTM을 비교하는 것입니다. 오차가 있는 LLTM에는 각 문항에 대한 고유한 문항 난이도 모수와 itemtype(예: 시각적 및 비시각적)에 대한 두 개의 추가 모수가 포함됩니다. 따라서 오차가 있는 LLTM이 LLTM보다 더 나은 모델 적합도를 제공할 것으로 예상됩니다.\n\nanova(rasch_mod, lltme_mod)\n\nData: eirm\nModels:\nlltme_mod: response ~ -1 + itemtype + (1 | person) + (1 | item)\nrasch_mod: response ~ -1 + item + (1 | person)\n          npar   AIC   BIC  logLik deviance  Chisq Df Pr(>Chisq)    \nlltme_mod    4 12178 12207 -6085.0    12170                         \nrasch_mod   11 12142 12221 -6059.8    12120 50.416  7  1.197e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n두 번째 비교의 결과는 AIC 및 로그-우도 값에 기반한 오차에서 Rasch 모델이 LLTM보다 더 잘 맞는다는 것을 보여줍니다. 그러나 잔차 항을 LLTM에 추가한 결과 적합도가 더 좋아졌으며, 이는 세 모델 중 가장 낮은 BIC 값으로 반영됩니다. 오차가 있는 LLTM은 문항의 변산성을 고려하여 보다 정확한 모수 추정이 가능하기 때문에 문항 속성 변수의 효과를 검토하는 데 더 적합한 옵션으로 보입니다.\n\n\n8.2.4 잠재 회귀 Rasch 모델\n잠재 회귀 Rasch 모델(Zwinderman, 1991)은 측정되는 잠재 특성과 관련하여 피험자 간의 차이를 설명하기 위해 피험자 관련 변수를 Rasch 모델에 통합합니다. GLMM에서 피험자 관련 예측 변수는 일반적으로 고정 효과로 사용되지만, 그 효과는 무선 효과로 추정할 수도 있습니다. 잠재 회귀 라쉬 모형의 수학적 공식은 다음과 같습니다.\n\\[\n\\eta_{ij}=(\\sum_{p=1}^P \\vartheta_pZ_{jp}+\\theta_j)+\\beta_i\n\\]\n\n여기서 \\(\\eta_{ij}\\)는 피험자 \\(j\\)가 문항 \\(i\\)에 정답을 맞출 확률(로짓 척도 기준)이고,\n\\(Z_{jp}\\)는 피험자 속성 \\(p(p = 1, 2, ..., P)\\)에 대한 피험자 \\(j\\)의 값이며,\n\\(\\vartheta_p\\)는 피험자 속성 \\(p\\)의 회귀 가중치이고,\n\\(\\theta_j\\)는 피험자 속성 효과를 고려한 후 피험자 \\(j\\)의 잠재 특성 수준이고,\n\\(\\beta_i\\)는 문항 \\(i\\)의 난이도 모수(즉, GLMM의 문항의 쉬운 정도)입니다.\n\n여러 피험자 속성 변수(예: 성별, 인종, SES)와 이들의 상호 작용을 잠재 회귀 Rasch 모델에서 예측 변수로 함께 사용할 수 있습니다.\n잠재 회귀 Rasch 모델을 추정하는 방법을 설명하기 위해, eirm 데이터 세트의 성별 변수를 사용하여 문항에 올바르게 응답할 확률을 예측합니다. 이 모델에서 두 가지 고정 효과는 문항 난이도 모수를 추정하기 위한 문항과 피험자의 성별 효과를 추정하기 위한 성별입니다. 성별 변수는 두 가지 값을 갖는 문자 변수입니다: 여성 피험자는 F, 남성 피험자는 M입니다. 성별 변수의 경우 여성을 기준 집단으로 합니다.2\n\nlrrm_mod <- glmer(response ~ -1 + item + gender + (1 | person),\n                  family = binomial, data = eirm,\n                  control = control)\nsummary(lrrm_mod)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: response ~ -1 + item + gender + (1 | person)\n   Data: eirm\nControl: control\n\n     AIC      BIC   logLik deviance df.resid \n 11990.3  12076.8  -5983.1  11966.3     9988 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.3928 -0.7211 -0.3459  0.7617  3.4728 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n person (Intercept) 0.4626   0.6802  \nNumber of obs: 10000, groups:  person, 1000\n\nFixed effects:\n        Estimate Std. Error z value Pr(>|z|)    \nitem1    1.32578    0.09398  14.107  < 2e-16 ***\nitem2    0.41592    0.08043   5.171 2.32e-07 ***\nitem3    0.03392    0.07814   0.434   0.6643    \nitem4    0.01505    0.07807   0.193   0.8472    \nitem5   -0.16203    0.07765  -2.087   0.0369 *  \nitem6   -0.64844    0.07830  -8.281  < 2e-16 ***\nitem7   -1.12592    0.08149 -13.817  < 2e-16 ***\nitem8   -1.37408    0.08418 -16.323  < 2e-16 ***\nitem9   -1.37408    0.08417 -16.324  < 2e-16 ***\nitem10  -1.74095    0.08955 -19.442  < 2e-16 ***\ngenderM  0.80083    0.06325  12.661  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n        item1  item2  item3  item4  item5  item6  item7  item8  item9  item10\nitem2    0.175                                                               \nitem3    0.179  0.218                                                        \nitem4    0.179  0.218  0.228                                                 \nitem5    0.179  0.220  0.232  0.232                                          \nitem6    0.176  0.221  0.235  0.236  0.241                                   \nitem7    0.167  0.215  0.231  0.231  0.237  0.247                            \nitem8    0.161  0.209  0.226  0.226  0.232  0.244  0.246                     \nitem9    0.161  0.209  0.226  0.226  0.232  0.244  0.246  0.244              \nitem10   0.151  0.198  0.215  0.216  0.222  0.235  0.238  0.237  0.237       \ngenderM -0.282 -0.361 -0.387 -0.388 -0.398 -0.414 -0.417 -0.412 -0.412 -0.399\n\n\n성별의 추정 효과는 0.801로 \\(\\alpha = .001\\)에서 통계적으로 유의미했습니다. 성별에 대한 정적(+) 효과는 eirm 데이터 세트에서 남성 피험자가 여성 피험자에에 비해 문항에 정답을 맞힐 가능성이 더 높다는 것을 의미합니다.\n성별에 대한 고정 효과 추정치 외에도, 무선 효과는 잠재 특성 추정치의 추정 분산(0.463)이 Rasch 모델의 잠재 특성 분산(0.622)보다 작다는 것을 보여줍니다. 이 결과는 성별이 피험자 간 잠재 특성 변산의 일부를 설명한다는 것을 시사합니다. 잠재 회귀 Rasch 모델은 피험자 특성 변수의 효과가 고정되어 있으므로 오차를 포함하지 않는다고 가정합니다. 이 가정은 피험자 속성 변수에 무선 효과 구성 요소를 추가하여 부분적으로 완화할 수 있습니다. 다음 예에서는 (gender | person)을 사용하여 무선 효과 섹션에 성별을 포함합니다. 이렇게 변경하면 성별에 대한 고정 효과에 더해 피험자에 따라 성별의 효과가 달라질 수 있습니다.\n\nlrrme_mod <- glmer(response ~ -1 + item + gender +\n                     (gender | person), family = binomial,\n                   data = eirm, control = control)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nunable to evaluate scaled gradient\n\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge: degenerate Hessian with 1 negative eigenvalues\n\nsummary(lrrme_mod)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: response ~ -1 + item + gender + (gender | person)\n   Data: eirm\nControl: control\n\n     AIC      BIC   logLik deviance df.resid \n 11994.3  12095.2  -5983.1  11966.3     9986 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.3893 -0.7222 -0.3448  0.7598  3.4840 \n\nRandom effects:\n Groups Name        Variance Std.Dev. Corr \n person (Intercept) 0.4696   0.6853        \n        genderM     0.5313   0.7289   -0.55\nNumber of obs: 10000, groups:  person, 1000\n\nFixed effects:\n        Estimate Std. Error z value Pr(>|z|)    \nitem1    1.32582    0.09409  14.092  < 2e-16 ***\nitem2    0.41553    0.08058   5.157 2.51e-07 ***\nitem3    0.03341    0.07833   0.427   0.6697    \nitem4    0.01454    0.07826   0.186   0.8526    \nitem5   -0.16258    0.07784  -2.088   0.0368 *  \nitem6   -0.64900    0.07849  -8.269  < 2e-16 ***\nitem7   -1.12639    0.08163 -13.798  < 2e-16 ***\nitem8   -1.37447    0.08429 -16.306  < 2e-16 ***\nitem9   -1.37447    0.08429 -16.306  < 2e-16 ***\nitem10  -1.74119    0.08963 -19.427  < 2e-16 ***\ngenderM  0.80103    0.06327  12.660  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n        item1  item2  item3  item4  item5  item6  item7  item8  item9  item10\nitem2    0.176                                                               \nitem3    0.180  0.220                                                        \nitem4    0.180  0.221  0.232                                                 \nitem5    0.180  0.223  0.235  0.236                                          \nitem6    0.177  0.224  0.239  0.239  0.244                                   \nitem7    0.169  0.218  0.234  0.235  0.240  0.251                            \nitem8    0.163  0.212  0.228  0.229  0.235  0.247  0.249                     \nitem9    0.163  0.212  0.228  0.229  0.235  0.247  0.249  0.247              \nitem10   0.152  0.200  0.217  0.218  0.224  0.237  0.241  0.239  0.239       \ngenderM -0.284 -0.364 -0.390 -0.391 -0.401 -0.417 -0.419 -0.415 -0.415 -0.401\noptimizer (bobyqa) convergence code: 0 (OK)\nunable to evaluate scaled gradient\nModel failed to converge: degenerate  Hessian with 1 negative eigenvalues\n\n\n위의 결과는 또한 성별에 대한 분산 추정치가 0.511이고 잠재 특성 추정치와 성별에 대한 무선 효과 간의 상관관계가 r = -.54임을 보여줍니다. 다음으로, anova 함수를 사용하여 성별의 고정 효과와 무선 효과가 Rasch 모델(즉, 기준 모델)에 유의미한 기여를 했는지 확인합니다. 첫 번째 비교에서는 성별이 고정 효과 변수로서 미치는 영향을 평가하고, 두 번째 비교에서는 성별의 변산 효과가 무선 효과 변수로서 미치는 영향을 평가합니다.\n\nanova(rasch_mod, lrrm_mod)\n\nData: eirm\nModels:\nrasch_mod: response ~ -1 + item + (1 | person)\nlrrm_mod: response ~ -1 + item + gender + (1 | person)\n          npar   AIC   BIC  logLik deviance  Chisq Df Pr(>Chisq)    \nrasch_mod   11 12142 12221 -6059.8    12120                         \nlrrm_mod    12 11990 12077 -5983.1    11966 153.37  1  < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nanova(lrrm_mod, lrrme_mod)\n\nData: eirm\nModels:\nlrrm_mod: response ~ -1 + item + gender + (1 | person)\nlrrme_mod: response ~ -1 + item + gender + (gender | person)\n          npar   AIC   BIC  logLik deviance  Chisq Df Pr(>Chisq)\nlrrm_mod    12 11990 12077 -5983.1    11966                     \nlrrme_mod   14 11994 12095 -5983.1    11966 0.0212  2     0.9895\n\n\n결과에 따르면 잠재 회귀 Rasch 모델에서 성별을 고정 효과 변수로 사용하면 Rasch 모델에 비해 적합도 통계가 개선되었습니다. 이는 잠재 회귀 Rasch 모델에서 성별이 통계적으로 유의미한 영향을 미치기 때문에 예상되는 결과입니다. 두 번째 비교에서는 lrrme_mod에서 성별을 가변 무선 효과 변수로 사용해도 모델 적합도가 개선되지 않았음을 보여줍니다. 두 개의 추가 모수(성별에 대한 분산 추정치 및 성별과 잠재 특성 추정치 간의 상관관계)가 있는 경우, lrrme_mod는 잠재 회귀 Rasch 모델에 비해 더 나은 적합도 통계를 얻지 못했습니다. 이 결과는 성별의 영향이 피험자에 따라 크게 다르지 않음을 시사합니다.\n앞서 언급한 바와 같이, 잠재 회귀 Rasch 모델에 피험자의 특성 변수를 포함시키는 방법에는 여러 가지가 있습니다. 예를 들어, 설명되지 않은 잠재 특성 분산의 이산성은 피험자 속성 변수에 대한 다양한 효과만 추가하여 (-1 + gender | person)을 사용하여 모델링할 수 있습니다. 또는 문항(수준 1) 및 피험자(수준 2) 외에 피험자 특성 변수를 세 번째 수준(1 | 성별)으로 사용하여 다층 Rasch 모형을 추정할 수도 있습니다. 다양한 잠재 회귀 Rasch 모형에 대한 자세한 설명은 De Boeck 외(2011)에서 확인할 수 있습니다.\n\n\n8.2.5 상호작용 모델\n이 장의 서두에서 설명했듯이, 동일한 설명적 IRT 모델 내에 문항 속성 변수와 피험자 속성 변수를 모두 포함할 수 있습니다. 예를 들어, 방정식 8.4의 LLTM과 방정식 8.6의 잠재 회귀 Rasch 모델을 결합할 수 있습니다. 이렇게 하면 문항 및 피험자 관련 설명 변수를 모두 포함하는 잠재 회귀 LLTM이 산출됩니다. 잠재 회귀 LLTM은 다음과 같이 공식화할 수 있습니다.\n\\[\n\\eta_{ij}=(\\sum_{p=1}^P \\vartheta_pZ_{jp}+\\theta_j)+\\sum_{m=1}^M\\beta_mX_{im\\cdot}\n\\]\n잔차 항 (\\(\\epsilon_i\\))를 방정식 8.7에 포함시켜 문항의 다양한 효과(즉, 고유한 문항 난이도 모수)를 추정할 수 있습니다. 또한, 문항 속성 변수(또는 문항)와 피험자 속성 변수의 곱을 모델의 상호작용항으로 포함할 수 있습니다. 이 상호작용항은 고정 효과 또는 무선효과 변수일 수 있습니다. 방정식 8.8은 문항 속성 변수와 피험자 속성 변수의 곱을 고정 효과 변수로 사용한 상호작용 모델을 보여줍니다.\n\\[\n\\eta_{ij}=(\\sum_{p=1}^P \\vartheta_pZ_{jp}+\\theta_j)+\\sum_{m=1}^M\\beta_mX_{im}+\\sum_{h=1}^H \\omega_hW_{(ij)h}\n\\]\n\n여기서 \\(\\omega_h\\)는 상호작용항에 대한 회귀 가중치이고,\n\\(W_{(ij)h}\\)는 상호작용 변수이며, 나머지 요소는 방정식 8.7의 요소와 동일합니다.\n\n예를 들어, 두 수준(1 = 비시각적, 0 = 시각적)의 문항 유형과 두 수준(0 = 여성, 1 = 남성)의 성별의 곱은 문항 유형과 성별이 모두 1이면 \\(W_{(ij)h} = 1\\)이 되고, 그렇지 않으면 \\(W_{(ij)h} = 0\\)이 됩니다.\n다음 섹션에서는 eirm 데이터 세트를 사용한 상호작용 모델에 대한 두 가지 예를 제시합니다. 먼저, 문항 유형, 성별, 그리고 이들의 상호작용으로 상호작용 모델을 추정합니다. 이 모델은 성별에 따른 문항 유형의 차별적 효과를 보여줍니다. 두 번째 예에서는 성별과 문항과의 상호작용을 사용하여 잠재 회귀 Rasch 모델을 추정합니다. 이 모델은 유사한 잠재 특성 수준을 가진 피험자가 속한 성별 그룹에 따라 응답 확률이 달라지는지 여부를 조사합니다. 그런 다음 성별과 유의미한 상호작용을 보이는 개별 문항은 차별기능문항(DIF)에 대해 플래그를 지정합니다. 제11장에서 DIF 및 측정 불변성에 대한 자세한 내용을 설명합니다.\n아래에 제시된 첫 번째 상호작용 모델은 오차가 있는 LLTM과 잠재 회귀 Rasch 모델을 결합한 것입니다. 이 모델에서는 문항 유형 * 성별을 사용하여 문항 유형과 성별의 주 효과뿐만 아니라 이들의 상호작용에 대한 추가 고정 효과를 추정합니다. 이 상호작용 모델의 결과를 int_mod로 저장합니다.\n\nint_mod <- glmer(response ~ -1 + itemtype * gender +\n                   (1 | person) + (1 | item), family = binomial,\n                 data = eirm, control = control)\nsummary(int_mod)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: response ~ -1 + itemtype * gender + (1 | person) + (1 | item)\n   Data: eirm\nControl: control\n\n     AIC      BIC   logLik deviance df.resid \n 12022.1  12065.4  -6005.1  12010.1     9994 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.3095 -0.7407 -0.3648  0.7663  3.2095 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n person (Intercept) 0.4554   0.6748  \n item   (Intercept) 0.2000   0.4472  \nNumber of obs: 10000, groups:  person, 1000; item, 10\n\nFixed effects:\n                       Estimate Std. Error z value Pr(>|z|)    \nitemtypeNonvisual       0.27439    0.20676   1.327   0.1845    \nitemtypeVisual         -1.18847    0.20803  -5.713 1.11e-08 ***\ngenderM                 0.90748    0.07779  11.666  < 2e-16 ***\nitemtypeVisual:genderM -0.21751    0.09165  -2.373   0.0176 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            itmtyN itmtyV gendrM\nitemtypeVsl  0.021              \ngenderM     -0.171 -0.060       \nitmtypVsl:M  0.098 -0.120 -0.590\n\n\n상호작용 모형의 결과는 문항 유형 및 성별 변수의 주 효과에 관한 이전 모형의 결과와 유사합니다. 시각적 문항이 비시각적 문항보다 더 어렵습니다. 또한 남자 피험자가 여자 피험자보다 문항에 정답을 맞힐 가능성이 더 높습니다. itemtypeVisaul:genderM으로 레이블이 지정된 마지막 행은 모델에서 상호작용항을 나타냅니다. 상호작용항에 대한 추정 회귀 가중치는 -0.218이며, 유의 수준 \\(\\alpha = .05\\)에서 통계적으로 유의합니다. 이 회귀 가중치의 부호를 통해 남자 피험자는 잠재 특성 수준에 관계없이 여자 피험자에 비해 시각적 문항에 대해 정답을 맞힐 가능성이 낮다는 결론을 내릴 수 있습니다.\n두 번째 예는 개별 문항과 성별 간의 상호작용에 초점을 맞춥니다. 앞서 언급했듯이, 특정 문항과 성별 간에 유의미한 상호작용항은 균일 DIF를 나타냅니다. 균일 DIF는 특정 그룹(성별과 같은 특정 피험자 특성 변수로 정의됨)의 피험자가 다른 그룹의 피험자보다 일관되게 더 나은 성적을 거둔다는 것을 의미합니다. eirm 데이터 세트를 사용하여 문항이 균일한 DIF를 나타내는지 여부를 검사하고, 문항 * 성별을 사용하여 문항과 성별에 대한 주 효과와 그 상호작용을 추정합니다. 모델 결과를 dif_mod로 저장합니다.\n\ndif_mod <- glmer(response ~ -1 + item * gender +\n                   (1 | person), family = binomial,\n                 data = eirm, control = control)\nsummary(dif_mod)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: response ~ -1 + item * gender + (1 | person)\n   Data: eirm\nControl: control\n\n     AIC      BIC   logLik deviance df.resid \n 11978.5  12129.9  -5968.2  11936.5     9979 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.4375 -0.7096 -0.3626  0.7538  2.9507 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n person (Intercept) 0.4696   0.6853  \nNumber of obs: 10000, groups:  person, 1000\n\nFixed effects:\n                Estimate Std. Error z value Pr(>|z|)    \nitem1           1.316774   0.115000  11.450  < 2e-16 ***\nitem2           0.276166   0.099786   2.768  0.00565 ** \nitem3           0.008133   0.099066   0.082  0.93457    \nitem4           0.034809   0.099076   0.351  0.72534    \nitem5          -0.241583   0.099505  -2.428  0.01519 *  \nitem6          -0.686259   0.103046  -6.660 2.74e-11 ***\nitem7          -1.280303   0.113626 -11.268  < 2e-16 ***\nitem8          -1.198439   0.111711 -10.728  < 2e-16 ***\nitem9          -1.316335   0.114490 -11.497  < 2e-16 ***\nitem10         -1.415472   0.117090 -12.089  < 2e-16 ***\ngenderM         0.829144   0.183183   4.526 6.00e-06 ***\nitem2:genderM   0.300539   0.230594   1.303  0.19246    \nitem3:genderM   0.029133   0.224984   0.129  0.89697    \nitem4:genderM  -0.068132   0.224521  -0.303  0.76154    \nitem5:genderM   0.139064   0.224358   0.620  0.53537    \nitem6:genderM   0.045144   0.224245   0.201  0.84045    \nitem7:genderM   0.246263   0.229391   1.074  0.28302    \nitem8:genderM  -0.346863   0.230264  -1.506  0.13197    \nitem9:genderM  -0.132322   0.231139  -0.572  0.56700    \nitem10:genderM -0.614687   0.236864  -2.595  0.00946 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nCorrelation matrix not shown by default, as p = 20 > 12.\nUse print(x, correlation=TRUE)  or\n    vcov(x)        if you need it\n\n\n결과의 첫 번째 부분에는 문항 난이도 모수와 성별에 대한 고정 효과가 표시됩니다. 개별 문항과 성별 간의 상호작용을 보여주는 결과의 두 번째 부분에 중점을 둡니다. 유의 수준 \\(\\alpha = .01\\)에서 유일하게 유의미한 상호작용은 item10:genderM입니다. 이 상호작용의 부호를 통해 남자 피험자가 여자 피험자보다 문항 10을 정답으로 맞힐 가능성이 낮다는 결론을 내릴 수 있습니다. 즉, 여자 피험자에 비해 남자 피험자가 10번 문항을 더 어렵게 느낀다는 것입니다.\n모든 상호 작용을 함께 검정하는 옴니버스 검정 대신 특정 문항과 성별 간의 단일 상호 작용항을 포함하여 각 문항을 개별적으로 검정할 수도 있습니다. 예를 들어, 문항(즉, 항목 식별자)이 10이고 성별이 M이면 dif10이 1이 되고 그렇지 않으면 0이 되는 문항 10에 대한 더미 변수(dif10이라고 함)를 만들 수 있습니다. 문항 * 성별 대신 문항 + 성별 + diff10을 사용하여 문항 10에 대한 문항 난이도 모수, 성별 효과 및 상호 작용 효과를 추정해야 합니다. 그런 다음 이 모델의 확률과 Rasch 모형의 확률을 비교할 수 있습니다. Rasch 모델이 상호작용 모형 내에 내재되어 있기 때문에 anova 함수의 우도비검정이 이 비교에 적합합니다.\n\ndif10 <- with(eirm, ifelse(gender == \"M\" & item == \"10\", 1, 0))\ndif10_mod <- glmer(response ~ -1 + item + gender +\n                     dif10 + (1 | person), family = binomial,\n                   data = eirm, control = control)\nanova(rasch_mod, dif10_mod)\n\nData: eirm\nModels:\nrasch_mod: response ~ -1 + item + (1 | person)\ndif10_mod: response ~ -1 + item + gender + dif10 + (1 | person)\n          npar   AIC   BIC  logLik deviance  Chisq Df Pr(>Chisq)    \nrasch_mod   11 12142 12221 -6059.8    12120                         \ndif10_mod   13 11977 12071 -5975.6    11951 168.57  2  < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n우도비검정에서 유의미한 \\(\\chi^2\\) 통계는 모수가 더 많은 큰 모델이 모수가 더 적은 작은 모델보다 데이터에 더 잘 맞는다는 것을 나타냅니다. 위의 결과에서, 더 복잡한 모델인 dif10_mod와 기준 모델인 rasch_mod의 차이가 \\(\\chi^2(2) = 168:57, p < .001\\)로 통계적으로 유의미하여 dif10_mod의 모델이 더 잘 맞는다는 것을 알 수 있습니다. 이 결과는 또한 문항 10에 대한 추정된 DIF 모수가 두 모델 간의 유일한 차이이기 때문에 통계적으로 유의미하다는 것을 시사합니다. 이 프로세스를 각 문항에 대해 반복하여 균일한 DIF를 나타내는 문항을 찾을 수 있습니다."
  },
  {
    "objectID": "chap08.html#요약",
    "href": "chap08.html#요약",
    "title": "8  설명적 문항반응이론",
    "section": "8.3 요약",
    "text": "8.3 요약\n이 장에서는 EIRM 프레임워크를 소개하고 lme4 패키지를 사용하여 몇 가지 설명적 IRT 모델을 추정하는 방법을 시연했습니다. GLMM 프레임워크는 문항 속성 변수, 피험자 속성 변수 및 이들의 상호작용의 효과를 EIRM의 맥락에서 조사하는 데 매우 유연하게 사용할 수 있습니다. 이 장에서 제시된 모델은 Rasch 모델과 설명적 IRT 모델 간의 주요 차이점을 보여줍니다.\nlme4 패키지의 glmer 함수를 사용하면 설명 변수의 효과를 고정 효과 또는 무선 효과로 추정할 수 있습니다. 고정 효과와 무선 효과의 다양한 조합을 통해 매우 다양한 설명적 IRT 모델을 만들 수 있습니다. EIRM 프레임워크와 glmer 함수에 대한 보다 포괄적인 논의는 De Boeck and Wilson(2004) 및 De Boeck 외.(2011)에서 확인할 수 있습니다.\nglmer 함수는 다양한 설명적 IRT 모델을 추정하는 데 유용한 도구이지만, Rasch 모델과 그 설명적 변형 모델만 추정할 수 있습니다. 제5장과 제6장에 제시된 다른 IRT 모델(예: 2PL 모델, 3PL 모델, GRM)을 추정하는 데는 glmer 함수를 사용할 수 없습니다. 또한 다른 R 패키지와 비교할 때, glmer 함수는 고정 효과와 무선 효과가 많은 복잡한 모델에 대해 더 긴 추정 시간이 필요한 경우가 많습니다. 따라서 Rasch 모형 이외의 IRT 모형에 대한 설명이 필요하고 반응 데이터 세트에 문항과 피험자의 수가 많은 경우에는 mirt(Chalmers, 2012) 및 flirt(Jeon et al., 2014) 패키지를 사용하는 것을 권장합니다."
  },
  {
    "objectID": "chap09.html#개요",
    "href": "chap09.html#개요",
    "title": "9  데이터 시각화 및 측정 모델",
    "section": "9.1 개요",
    "text": "9.1 개요\n이 장에서는 R을 사용하여 데이터 및 측정 모델을 그래픽으로 표현하는 방법에 중점을 두고, 요인 분석 및 문항 반응 이론(IRT) 모델에 사용할 수 있는 진단 그래프를 만드는 방법부터 설명합니다. 이 장에 제시된 그래프를 통해 모델링 가정의 타당성을 평가하고 이상값이거나 영향력이 있을 수 있는 관측치를 찾을 수 있습니다. 다음으로, semPlot 패키지를 사용하여 출판물이나 프레젠테이션에 사용할 수 있는 경로 다이어그램을 만드는 방법을 보여줍니다(Epskamp & Stuber, 2017). 마지막으로, shiny 패키지로 대화형 데이터 시각화를 응용한 두 가지 사례를 소개합니다(Chang, Cheng, Allaire, Xie, & McPherson, 2017). 첫 번째 응용 프로그램은 이 장에서 제시한 진단 그래프에 대한 이해를 돕고, 두 번째 응용 프로그램은 단일차원 IRT 모델에서 다양한 모수가 문항 특성 곡선의 모양에 미치는 영향을 탐색하는 방법을 보여줍니다."
  },
  {
    "objectID": "chap09.html#소개",
    "href": "chap09.html#소개",
    "title": "9  데이터 시각화 및 측정 모델",
    "section": "9.2 소개",
    "text": "9.2 소개\n그래픽 데이터 분석은 통계 분석의 중요한 구성 요소입니다. 특히 모델링 단계에 앞서 데이터를 탐색하는 것은 변수 간의 관계를 식별, 확인, 설명(예: 선형 또는 비선형)하고 잠재적으로 영향력 있는 관측치 또는 이상값을 식별하는 데 필수적입니다. 통계 또는 측정 모델을 데이터에 맞추고 나면, 그래픽 분석을 사용하여 모델링 가정의 적절성, 데이터에 대한 모델의 적합성, 데이터 내 관계를 설명하는 모델의 전반적인 적절성을 평가하고 영향력 있는 관측치 및 이상값이 모델 결과에 영향을 미치는지 여부를 확인합니다.\n그래프는 공식적으로(예: 원고 및 프레젠테이션) 또는 비공식적으로(예: 동료 또는 스스로에게) 모델 결과를 전달하고 이해하는 데 훌륭한 매개체입니다. 그래프는 일반적으로 표보다 인지적 요구가 적으며 표로 설명하기 어렵거나 출판물에서 상당한 지면을 차지하는 복잡한 관계를 요약하고 설명하는 데 사용할 수 있습니다. 그래프는 이 책 전체에서 설명한 측정 모델에 대해 학습하는 데에도 훌륭한 도구입니다. 예를 들어, 문항 난이도, 문항 변별도, 추측도 모수의 다양한 값에 따라 3모수 로지스틱(3PL) IRT 모델의 문항 특성 곡선(ICC)이 어떻게 변화하는지 살펴볼 수 있습니다. 이를 보여주기 위해 사용자가 지정한 모델 모수 값을 기반으로 ICC를 그립니다. 이를 통해 난이도, 변별도, 추측도가 ICC의 형태에 어떤 영향을 미치는지 이해할 수 있습니다.\n본서 전체에서 측정 모델을 소개할 때와 측정 모델의 결과를 제시할 때 다양한 그래프를 제시했습니다. 제2장에서는 연속형 데이터와 범주형 데이터를 설명하기 위한 그래프를, 제3장에서는 신뢰도 계수가 다양한 D 연구의 함수에 따라 어떻게 변화하는지 보여주기 위해 그래프를, 제4장에서는 데이터에서 추출할 수 있는 요인 수를 결정하고 영향력 있는 사례를 식별하기 위한 그래프를, 마지막으로 제5장부터 제8장까지는 문항 반응 이론(IRT) 프레임워크 내에서 문항, 검사 및 정보의 기능을 설명하기 위해 그래프를 사용했습니다. 이 장에서는 이러한 측정 모델의 맥락에서 그래프를 활용할 수 있는 잠재력을 확장합니다."
  },
  {
    "objectID": "chap09.html#진단-그래프",
    "href": "chap09.html#진단-그래프",
    "title": "9  데이터 시각화 및 측정 모델",
    "section": "9.3 진단 그래프",
    "text": "9.3 진단 그래프\n통계 모델은 교육 측정 및 심리 측정의 핵심 요소입니다. 모든 통계 모델에는 가정이 있으며, 모수 추정치로 표현되는 추정된 관계는 모델에 들어가는 데이터에 따라 불균형하게 영향을 받습니다. 따라서 레버리지, 영향력 및 이상값을 평가하는 것은 모든 통계 모델링에서 필수적인 작업이며, 측정 모델도 예외는 아닙니다. 특히 유용한 R 패키지 중 하나인 faoutlier 패키지(Chalmers & Flora, 2015)는 Flora, LaBrish, Chalmers(2012)에 설명된 몇 가지 진단 및 영향력 있는 방법과 Mavridis와 Moustaki(2008)에 설명된 순방향 검색 알고리즘을 구현합니다. 다음 섹션에서는 측정 모델에서 영향력 있는 관측치와 이상값을 식별하는 데 널리 사용되는 몇 가지 진단 도구에 대해 설명합니다. 첫 번째 단계로, faoutlier 패키지를 설치하고 library 명령을 사용하여 hemp 패키지와 함께 활성화합니다.\n\n#install.packages(\"faoutlier\")\nlibrary(\"faoutlier\")\n\nLoading required package: sem\n\n\nLoading required package: mvtnorm\n\n\nLoading required package: parallel\n\nlibrary(\"hemp\")\n\nLoading required package: psych\n\n\nLoading required package: lattice\n\n\nLoading required package: lavaan\n\n\nThis is lavaan 0.6-16\nlavaan is FREE software! Please report any bugs.\n\n\n\nAttaching package: 'lavaan'\n\n\nThe following object is masked from 'package:psych':\n\n    cor2cov\n\n\nThe following objects are masked from 'package:sem':\n\n    cfa, sem\n\n\nLoading required package: mirt\n\n\nLoading required package: stats4\n\n\n\nAttaching package: 'mirt'\n\n\nThe following object is masked from 'package:sem':\n\n    fscores\n\n\nLoading required package: lme4\n\n\nLoading required package: Matrix\n\n\n\nAttaching package: 'lme4'\n\n\nThe following object is masked from 'package:mirt':\n\n    fixef\n\n\nLoading required package: reshape2\n\n\nLoading required package: boot\n\n\n\nAttaching package: 'boot'\n\n\nThe following object is masked from 'package:lattice':\n\n    melanoma\n\n\nThe following object is masked from 'package:psych':\n\n    logit\n\n\nLoading required package: equate\n\n\n제4장에서는 레버리지가 높은 다변량 사례를 탐지하기 위해 Bollen(1989)에서 설명한 그래프를 소개했습니다. 다른 접근 방식은 마하라노비스 거리를 그리는 것입니다.1 레버리지는 일부 변수(예: 독립 변수, 종속 변수 또는 명시 변수)에 대한 값 세트의 고유성을 측정하는 척도입니다. 특정 관측값에 대한 데이터에서 이러한 변수 값의 조합이 고유할수록 해당 관측값에 대한 레버리지가 높아집니다. 마하라노비스 거리는 다음과 같이 정의할 수 있습니다.\n\\[\nD_i^2=(X_i-\\bar{X})T\\sum^{-1}(X_i-\\bar{X})\n\\]\n\n여기서 \\(X_i\\)는 관측값 \\(i\\)에 대한 변수 벡터이고,\n\\(\\bar{X}\\)는 이러한 변수의 평균 벡터이며,\n\\(\\sum\\)는 변수의 표본 공분산 행렬입니다.\n\n개념적으로 마하라노비스 거리는 공분산 행렬에 의해 척도화된 변수의 다변량 중심으로부터 관측값까지의 거리를 제곱한 값입니다.\n마하라노비스 거리는 mahalanobis 함수를 사용하거나 faoutlier 패키지의 robustMD 함수를 사용하여 계산할 수 있습니다. robustMD 함수는 변수의 다변량 위치 및 규모에 대한 견고한 추정치를 계산하기 위해 MASS 패키지의 cov.rob 함수(Venables & Ripley, 2002)에 의존합니다. 요인 분석의 맥락에서 명시 변수는 일반적으로 기본 요인과의 관계를 통해 서로 관련되어 있다고 가정합니다. 관측값의 마하라노비스 거리가 높다는 것은 명시 변수 중 하나 이상의 값이 다른 명시 변수의 값에 비해 비정상적이며, 이 관측값으로 인해 모델 적합도가 떨어지거나 추정 오류가 발생할 수 있음을 의미합니다.\n아래에서는 robustMD 함수를 사용하여 interest 데이터 세트의 인지 측정값에 대한 마하라노비스 거리를 계산하고(이 예에서는 interest 데이터 세트의 4~9번째 열을 cognitive으로 저장함), 결과를 D2로 저장한 다음 마지막으로 그래프를 그립니다.\n\ncognitive <- interest[, c(4:9)]\nD2 <- robustMD(cognitive)\nplot(D2, ylab = \"D2\")\n\n\n\n\n그림 9.1에서 관측값 중 하나가 마하라노비스 거리의 값이 큰 것을 볼 수 있습니다. 다음 명령을 사용하여 이 관측값을 식별할 수 있습니다.\n\nD2$mah[which.max(D2$mah)]\n\n     202 \n33.15461 \n\n\n결과는 마할로노비스 거리가 가장 높은 관측값이 202(즉, 개인 ID가 202)임을 보여줍니다. 그림 9.1은 이 관측값의 \\(D^2\\)가 가장 가까운 관측의 거리보다 거의 두 배나 크다는 것을 보여줍니다. apply 함수를 사용하여 이 관찰값과 관련된 값과 각 변수의 최대값을 출력하여 이 관찰값을 자세히 살펴봅니다.\n\ncognitive[202,]\n\n    vocab reading sentcomp mathmtcs geometry analyrea\n202  2.63    2.23     2.55     1.38     3.86      3.5\n\n\n\napply(cognitive, 2, max)\n\n   vocab  reading sentcomp mathmtcs geometry analyrea \n    2.63     2.70     2.73     3.06     3.86     3.50 \n\n\n이 관찰값에서는 vocab, geometry, analyrea이 최대값이고, reading, sentcomp, mathmtcs의 값이 크다는 것을 알 수 있습니다(최대값은 아니지만). 이것이 높은 \\(D^2\\)의 원인일 가능성이 높습니다. 마하라노비스 거리를 통해 레버리지를 평가할 때 가장 큰 문제는 레버리지가 반드시 영향력의 척도가 아니며, 적합 모델을 기반으로 하는 것이 아니라 명시 변수의 관계에만 기반한다는 것입니다. 더 유용한 통계는 적합도 모델과 모수가 추정 적합도 및 모수에 미치는 영향을 고려하는 것입니다. 이를 영향력이라고 합니다. 영향력을 평가하는 가장 일반적인 통계는 Cook의 거리(Cook, 1977)와 일반화된 Cook의 거리(Pek & MacCallum, 2011)입니다. 이러한 통계는 이 책 전체에서 논의되는 많은 모델인 sem(Fox et al., 2017), lavaan(Rosseel, 2012), mirt(Chalmers, 2012)로 추정된 측정 모델과 함께 계산하여 사용할 수 있습니다. 일반화된 Cook의 거리는 다음과 같이 정의됩니다."
  },
  {
    "objectID": "chap10.html",
    "href": "chap10.html",
    "title": "10  동등화",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "chap11.html#개요",
    "href": "chap11.html#개요",
    "title": "11  측정 불변성과 차별기능문항",
    "section": "11.1 개요",
    "text": "11.1 개요\n이 장에서는 측정 편향을 감지하기 위한 두 가지 프레임워크에 중점을 둡니다. 먼저 척도 수준(즉, 전체) 편향을 탐지하기 위한 요인분석적 접근법으로서 측정 불변성에 대한 간략한 설명으로 시작하여, lavaan 패키지를 사용하여 측정 불변성을 평가하는 방법을 시연합니다(Rosseel, 2012). 그런 다음 문항 수준 편향의 지표로 차별기능문항(DIF)을 소개하고 균일 및 비균일 DIF에 대해 설명한 다음 R의 difR(Magis, Beland, Tuerlinckx, & De Boeck, 2010) 및 mirt(Chalmers, 2012) 패키지를 사용하여 Mantel-Haenszel(MH) 방법, 로지스틱 회귀, 문항 반응 이론 우도비(IRT-LR) 검정을 통해 DIF를 탐지하는 방법을 시연합니다."
  },
  {
    "objectID": "chap11.html#측정불변성",
    "href": "chap11.html#측정불변성",
    "title": "11  측정 불변성과 차별기능문항",
    "section": "11.2 측정불변성",
    "text": "11.2 측정불변성\n측정 도구의 점수를 사용하여 서로 다른 개인 그룹 간에 비교하려는 경우, 잠재 변수가 표본의 하위 그룹(예: 남성 및 여성 참가자)에서 유사하게 기능하고 있음을 보여 주어야 합니다. 이러한 절차를 측정 불변성이라고 합니다. 예를 들어, 일상 생활에서 개인의 영성을 측정하는 검사도구를 개발한다고 가정해 보겠습니다. 이 검사도구를 참가자 표본에게 시행한 후, 남성과 여성 참가자의 영성 수준을 비교하고자 합니다. 검사도구의 일부 문항 또는 전체가 남성과 여성 참가자에게 유사하게 기능하지 않으면 잠재 변수(즉, 일상 생활에서의 영성)가 성별 그룹 간에 동일한 의미를 갖지 않을 수 있습니다. 이러한 문제가 발생하면, 예를 들어 한 그룹이 다른 그룹보다 영성 수준이 더 높다고 말하는 것은 의미가 없는데, 이는 동일한 잠재 변수를 기준으로 비교한 것이 아니기 때문입니다.\n측정 불변성이 필수적인 또 다른 상황은 시점 1의 검사도구 점수를 시점 2의 동일한 검사도구 점수와 비교하고자 할 때 발생합니다. 이 두 시점을 비교하려면 시간이 지남에 따라 측정 도구의 안정성을 보장할 수 있어야 합니다. 동일한 영성의 예를 계속 이어서 하면, 영성 도구의 두 번의 시행(예: 2002년과 2017년)에서 얻은 점수를 비교하려면 시간에 따른 도구의 측정 불변성을 입증해야 합니다. 영성에 대한 조작적 정의(즉, 사람들이 영성을 바라보고 정의하는 방식)가 시점에 따라(2002년에서 2017년으로) 바뀌었다면, 동일한 도구를 사용했음에도 불구하고 두 번의 시행에서 비교 가능한 점수를 얻지 못할 수도 있습니다.\n우리는 종종 그룹 간에 어떤 구인을 비교할 때 암묵적으로 측정 불변성을 가정합니다. 예를 들어 회귀분석과 t검정을 수행할 때 구인이 유사하게 기능한다고 가정합니다. 잠재 변수 모델링은 이러한 가정을 엄격하게 평가할 수 있는 방법을 제공합니다.\n\n11.2.1 측정 불변성 평가하기\n다음 예에서는, 제4장에서 처음 소개한 interest 데이터 세트를 사용합니다. 이 데이터 세트는 인지, 성격 및 직업 흥미에 대한 측정값을 포함하는 조작 데이터 세트입니다. interest 데이터 세트의 인지 측정값을 사용하여 성별에 따른 측정 불변성을 평가합니다. 분석을 시작하기 전에 먼저 library 명령을 사용하여 lavaan 및 hemp 패키지를 로드합니다.\n\nlibrary(\"hemp\")\n\nLoading required package: psych\n\n\nLoading required package: lattice\n\n\nLoading required package: lavaan\n\n\nThis is lavaan 0.6-16\nlavaan is FREE software! Please report any bugs.\n\n\n\nAttaching package: 'lavaan'\n\n\nThe following object is masked from 'package:psych':\n\n    cor2cov\n\n\nLoading required package: mirt\n\n\nLoading required package: stats4\n\n\nLoading required package: lme4\n\n\nLoading required package: Matrix\n\n\n\nAttaching package: 'lme4'\n\n\nThe following object is masked from 'package:mirt':\n\n    fixef\n\n\nLoading required package: reshape2\n\n\nLoading required package: boot\n\n\n\nAttaching package: 'boot'\n\n\nThe following object is masked from 'package:lattice':\n\n    melanoma\n\n\nThe following object is masked from 'package:psych':\n\n    logit\n\n\nLoading required package: equate\n\nlibrary(\"lavaan\")\n\ninterest 데이터 세트에서 성별 변수는 남성은 1, 여성은 2가 되도록 코딩되었습니다. 분석을 더 쉽게 따라갈 수 있도록 ifelse 함수를 사용하여 성별 변수를 질적 변수로 다시 코딩합니다. 새로운 성별 변수에는 참가자에 대해 1과 2 대신 ‘남성’ 및 ’여성’이라는 레이블이 있습니다.\n\ninterest$gender_f <- ifelse(interest$gender == 1,\n                            \"male\", \"female\")\n\n제4장에서 탐색적 요인 분석을 통해 언어적 요인과 수학적 요인이라는 두 가지 인지 요인을 확인했음을 기억하세요. 이 요인 구조를 lavaan 구문을 사용하여 정의하고 cog_mod 에 저장합니다. 그런 다음 cfa 함수를 사용하여 확인적 요인 분석(CFA)을 실행하고 결과를 cog_fit으로 저장한 다음 마지막으로 fitMeasures 함수를 사용하여 추정 모델에 대한 적합도 지수를 출력합니다.\n\ncog_mod <- 'verb =~ vocab + reading + sentcomp\n            math =~ mathmtcs + geometry + analyrea'\ncog_fit <- cfa(cog_mod, data = interest)\nfitMeasures(cog_fit, fit.measures = c(\"cfi\", \"tli\", \"rmsea\"))\n\n  cfi   tli rmsea \n0.996 0.992 0.051 \n\n\n우리 모델은 CFI, TLI 및 RMSEA에 근거해 좋은 적합도를 가집니다. 모델이 데이터에 잘 맞지 않는다면 측정 불변성을 고려하는 것은 의미가 없을 것입니다. 우리 모델은 데이터에 잘 맞기 때문에 성별에 따른 측정값 불변성을 조사할 수 있습니다.\n\n11.2.1.1 형태 불변성\n측정 불변성을 입증하는 첫 번째 단계는 모델이 각 집단에 적합하다는 것을 보여주는 것입니다. 이것은 두 가지 방법으로 수행할 수 있습니다. (1) 각 하위 집단에 데이터를 맞출 수 있고, (2) 다집단 CFA 모델을 사용할 수 있습니다. 여기서는 두 번째 접근 방식을 사용하며, cfa 함수를 사용할 때 group = “gender_f” 인수를 추가하여 lavaan에서 이 작업을 수행합니다. 이 인수를 사용하면 모든 모수를 동일성 제약 없이 집단 간에 자유롭게 추정할 수 있습니다. 따라서 두 모델(남성 모델과 여성 모델)은 요인 적재치, 절편 및 분산이 동일하지 않습니다. 선험적으로 집단 간에 분산이 동일하다고 예상할 이유가 없으므로 여기서는 표준화 계수를 사용해서는 안 됩니다.\n\nconfigural <- cfa(cog_mod, data = interest, group = \"gender_f\")\nfitMeasures(configural, fit.measures = c(\"cfi\", \"tli\", \"rmsea\"))\n\n  cfi   tli rmsea \n0.998 0.996 0.035 \n\n\n적합도 지수를 기준으로 각 집단에 대한 데이터가 모델에 매우 잘 맞습니다. 형태 모델이 잘 맞았으므로 이제 모수를 집단 간에 동일하게 제약하고 성별에 따른 측정 불변성을 보다 철저하게 조사할 수 있습니다.\n\n\n11.2.1.2 약한 불변성\n약한 (메트릭) 불변성을 평가하기 위해, 요인 부하가 집단 간에 동일하도록 제약합니다. 이 제약 조건은 요인이 집단 전체에서 동일한 의미를 갖는다는 것을 나타냅니다. 즉, 집단이 잠재 구인에 동일한 의미를 부여하고 있는지에 대한 문제를 해결합니다.\n약한 불변성 가정이 성립하지 않는다면, 명시 변수의 의미는 집단마다 다를 것입니다. 이 단계와 향후 모든 단계에서 부분 불변성만 있는 경우(평가할 수 있는 경우), 불변 모수는 동일하도록 제약하고 다른 모수는 집단 간에 자유롭게 사용할 수 있도록 허용합니다.\nlavaan에서 약한 불변성 모델을 적합하려면 cfa 함수에 group.equal = “loadings” 인수를 전달해야 합니다. 이 인수는 interest 데이터 세트의 남성 참가자와 여성 참가자 간에 요인 부하가 동일하도록 보장합니다.\n\nweak_invariance <- cfa(cog_mod, data = interest,\n                       group = \"gender_f\",\n                       group.equal = \"loadings\")\nfitMeasures(weak_invariance,\nfit.measures = c(\"cfi\", \"tli\", \"rmsea\"))\n\n  cfi   tli rmsea \n1.000 1.000 0.004 \n\n\nweak_invariance의 적합도 지수에 근거해, 우리 모델에 대한 약한 불변성 가정을 뒷받침하는 증거가 있습니다. 모든 측정 불변성 모델은 서로 내재되어 있기 때문에 제약이 적은 모델(형태 동일성 모델)이 제약이 많은 약한 불변성 모델보다 훨씬 더 잘 맞는지 여부를 카이제곱 차이 검정을 사용하여 공식적으로 평가할 수 있습니다. 우리의 목표는 측정 불변성을 보여주는 것이므로 형태 동일성 모델이 약한 불변성 모델에 비해 모델 적합도가 개선되지 않았다는 영가설을 기각하지 않는 것입니다.\n\nanova(weak_invariance, configural)\n\n\nChi-Squared Difference Test\n\n                Df    AIC    BIC  Chisq Chisq diff RMSEA Df diff Pr(>Chisq)\nconfigural      16 3081.8 3215.6 18.413                                    \nweak_invariance 20 3075.4 3195.2 20.048     1.6348     0       4     0.8025\n\n\n위의 결과에 따르면 영가설을 기각하지 못합니다. 이는 약한 불변성을 뒷받침하는 증거입니다. 이 결과를 바탕으로 약한 불변성을 가지고 있다는 결론을 내리고 강한 불변성을 평가하는 단계로 넘어갈 수 있습니다.\n\n\n11.2.1.3 강한 불변성\n강한(스칼라) 불변성에는 집단 간에 절편이 동일해야 한다는 제약 조건이 추가됩니다. 강한 불변성 모델에서는 요인적재치와 절편이 집단 간에 모두 동일하도록 설정됩니다. 이는 구인의 의미(요인 적재치)와 명시 변수의 기저 수준(절편)이 두 집단에서 동일하다는 것을 의미합니다. 강한 불변성을 가지면 잠재 구인의 평균 차이를 비교할 수 있습니다. 측정 불변성을 평가하는 이 단계에서 요인 평균을 추정하고 검토할 수 있습니다.\n강한 불변성을 검증하기 위해 모델에서 group.equal 인수를 group.equal = c(“loadings”, “intercepts”)로 업데이트하고 모델 결과를 strong_invariance로 저장한 다음 추정된 모델에 대한 모델 적합도 지수를 출력합니다.\n\nstrong_invariance <- cfa(cog_mod, data = interest,\n                         group = \"gender_f\",\n                         group.equal = c( \"loadings\", \"intercepts\"))\nfitMeasures(strong_invariance,\nfit.measures = c(\"cfi\", \"tli\", \"rmsea\"))\n\n  cfi   tli rmsea \n1.000 1.001 0.000 \n\n\n결과는 적합도 지수가 계속 개선되고 있음을 보여줍니다. 적합도 지수만 보면 강한 불변성 가정을 충족한 것으로 보입니다. 그러나 anova 함수를 사용하여 이 가정을 공식적으로 평가해야 합니다. 이번에는 제약 모델을 strong_invariace 모델이라고 하고 제약이 덜된 모델을 weak_invariance 모델이라고 합니다.\n\nanova(strong_invariance, weak_invariance)\n\n\nChi-Squared Difference Test\n\n                  Df    AIC    BIC  Chisq Chisq diff RMSEA Df diff Pr(>Chisq)\nweak_invariance   20 3075.4 3195.2 20.048                                    \nstrong_invariance 24 3070.6 3176.3 23.230     3.1816     0       4     0.5279\n\n\n결과는 다시 영가설을 기각하지 못했음을 보여줍니다. 이 시점에서 중단하고 요인 평균을 검토할 수도 있지만, 모델 결과를 검토하기 전에 엄격한 불변성을 입증하는 것이 더 유리할 것입니다.\n\n\n11.2.1.4 엄격한 불변성\n엄격한 불변성을 위해 집단 간 명시 변수에 대해 동일한 잔차 분산이라는 추가 제약 조건을 추가합니다. 원점수(예: 잠재 변수의 지표에 대한 점수의 합계 또는 평균)를 기준으로 비교하려는 경우 모델이 엄격한 불변성 가정을 충족하는지 확인해야 합니다. 관찰된 분산은 진점수 분산과 잔차/오차 분산이 합산된 값이기 때문입니다. 잔차 분산이 같으면 진점수 분산도 같은 양을 갖습니다. 강한 불변성과 마찬가지로 잠재 평균을 추정하고 비교할 수 있습니다.\n이전 모델 구문과 마찬가지로, 이 모델에 대한 group.equal 인수를 업데이트해야 합니다. 이번에는 group.equal = c(“loadings”, “intercept”, “residuals”)를 사용하여 이러한 모든 모수가 성별에 걸쳐 동일하도록 제약합니다. 결과를 strict_invariance로 저장합니다.\n\nstrict_invariance <- cfa(cog_mod, data = interest,\n                         group = \"gender_f\",\n                         group.equal = c( \"loadings\", \"intercepts\", \"residuals\"))\nfitMeasures(strict_invariance,\n            fit.measures = c(\"cfi\", \"tli\", \"rmsea\"))\n\n  cfi   tli rmsea \n1.000 1.002 0.000 \n\n\nstrict_invariance의 적합도 지수는 다시 꽤 좋아 보입니다. 다음으로, 이 모델이 적합도가 크게 개선되었는지 공식적으로 평가합니다. 이 검정에서는 strict_invariance와 strong_invariance를 비교합니다.\n\nanova(strict_invariance, strong_invariance)\n\n\nChi-Squared Difference Test\n\n                  Df    AIC    BIC  Chisq Chisq diff RMSEA Df diff Pr(>Chisq)\nstrong_invariance 24 3070.6 3176.3 23.230                                    \nstrict_invariance 30 3062.7 3147.2 27.264     4.0347     0       6      0.672\n\n\n결과는 이 검정에서 영가설을 기각하지 못하고 모델이 엄격한 불변성 가정을 충족한다는 결론을 내립니다. 엄격한 불변성 가정을 충족하는 경우는 실제로는 극히 드물며, 일반적으로 요인 평균을 비교하는 데는 강한 불변성만으로도 충분하다는 점에 유의해야 합니다.\n엄격한 불변성 결과를 바탕으로 집단 간에 동일한 신뢰도로 측정된 원점수 합계 또는 평균 점수를 기반으로 요인을 안전하게 비교할 수 있습니다. 그러나 이미 요인을 생성했기 때문에 summary 함수에서 얻을 수 있는 요인 평균을 살펴봅니다.\n\nsummary(strict_invariance)\n\nlavaan 0.6.16 ended normally after 42 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        40\n  Number of equality constraints                    16\n\n  Number of observations per group:                   \n    female                                         122\n    male                                           128\n\nModel Test User Model:\n                                                      \n  Test statistic                                27.264\n  Degrees of freedom                                30\n  P-value (Chi-square)                           0.609\n  Test statistic for each group:\n    female                                      15.063\n    male                                        12.201\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\n\nGroup 1 [female]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  verb =~                                             \n    vocab             1.000                           \n    reading (.p2.)    0.898    0.044   20.500    0.000\n    sentcmp (.p3.)    0.904    0.044   20.743    0.000\n  math =~                                             \n    mthmtcs           1.000                           \n    geomtry (.p5.)    0.857    0.046   18.552    0.000\n    analyre (.p6.)    0.932    0.044   21.273    0.000\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  verb ~~                                             \n    math              0.898    0.129    6.977    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .vocab   (.16.)    0.169    0.093    1.813    0.070\n   .reading (.17.)    0.206    0.088    2.343    0.019\n   .sentcmp (.18.)    0.145    0.088    1.642    0.101\n   .mthmtcs (.19.)   -0.048    0.097   -0.489    0.625\n   .geomtry (.20.)   -0.019    0.089   -0.208    0.835\n   .analyre (.21.)    0.032    0.094    0.345    0.730\n    verb              0.000                           \n    math              0.000                           \n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .vocab   (.p7.)    0.110    0.022    5.024    0.000\n   .reading (.p8.)    0.265    0.030    8.984    0.000\n   .sentcmp (.p9.)    0.258    0.029    8.887    0.000\n   .mthmtcs (.10.)    0.131    0.025    5.161    0.000\n   .geomtry (.11.)    0.348    0.037    9.479    0.000\n   .analyre (.12.)    0.265    0.032    8.383    0.000\n    verb              0.969    0.137    7.086    0.000\n    math              1.046    0.149    7.028    0.000\n\n\nGroup 2 [male]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  verb =~                                             \n    vocab             1.000                           \n    reading (.p2.)    0.898    0.044   20.500    0.000\n    sentcmp (.p3.)    0.904    0.044   20.743    0.000\n  math =~                                             \n    mthmtcs           1.000                           \n    geomtry (.p5.)    0.857    0.046   18.552    0.000\n    analyre (.p6.)    0.932    0.044   21.273    0.000\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  verb ~~                                             \n    math              0.628    0.098    6.415    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .vocab   (.16.)    0.169    0.093    1.813    0.070\n   .reading (.17.)    0.206    0.088    2.343    0.019\n   .sentcmp (.18.)    0.145    0.088    1.642    0.101\n   .mthmtcs (.19.)   -0.048    0.097   -0.489    0.625\n   .geomtry (.20.)   -0.019    0.089   -0.208    0.835\n   .analyre (.21.)    0.032    0.094    0.345    0.730\n    verb             -0.154    0.123   -1.247    0.212\n    math              0.299    0.129    2.320    0.020\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .vocab   (.p7.)    0.110    0.022    5.024    0.000\n   .reading (.p8.)    0.265    0.030    8.984    0.000\n   .sentcmp (.p9.)    0.258    0.029    8.887    0.000\n   .mthmtcs (.10.)    0.131    0.025    5.161    0.000\n   .geomtry (.11.)    0.348    0.037    9.479    0.000\n   .analyre (.12.)    0.265    0.032    8.383    0.000\n    verb              0.788    0.110    7.138    0.000\n    math              0.866    0.122    7.081    0.000\n\n\n측정 불변성을 검토할 때 제공되는 새로운 정보에 초점을 맞추기 위해 summary 함수의 출력 내용을 대부분 요약했습니다. cfa 함수의 결과에 대한 자세한 설명은 제4장을 참조하시기 바랍니다. 결과의 맨 위에는 집단별 샘플 수와 현재 모델의 카이제곱, 카이제곱 통계에 대한 각 집단의 기여도가 표시됩니다. 집단은 독립적이므로 각 집단의 기여도의 합이 총 카이제곱 통계입니다. 그런 다음 이 경우 기준 집단인 여성에 대한 추정 모수를 먼저 출력한 다음 비교 집단인 남성에 대한 모수를 출력합니다. 수학 요인에 대한 요인 적재치와 공분산 및 분산은 출력에서 삭제되었습니다. 읽기 요인 적재치에 초점을 맞추면 그 옆에 (.p2.)가 있는 것을 알 수 있습니다. 이것이 모수에 레이블을 지정하여 lavaan이 제약 조건을 처리하는 방식입니다. 이 예에서 .p2. 라는 이름은 여성과 남성 모두에 대한 언어 읽기의 요인 적재치에 해당합니다. 다른 모수도 마찬가지입니다(예: 동일한 결과에서 sentcmp의 경우 .p3.).\n절편 표의 맨 아래에는 남성 집단의 언어 및 수학 요인에 대한 평균이 나와 있습니다. 통계적으로 유의미한 절편은 해당 요인에 대해 집단 간에 유의미한 차이가 있음을 의미합니다. 언어 요인에서는 집단 간에 통계적으로 유의미한 차이가 없지만 수학 요인에서는 남성 집단이 여성 집단보다 0.299 더 높을 것으로 예상되는 것을 알 수 있습니다.\n전반적으로 엄격한 불변성이 있고, 언어 요인에서는 집단 간 차이가 없으며, 수학 요인에서는 남성이 여성보다 높을 것으로 예상된다는 결론을 내렸습니다.\n\n\n11.2.1.5 부분 불변성 평가하기\n어떤 단계에서도 완전한 불변성(즉, 약한 불변성, 강한 불변성, 엄격한 불변성)이 없는 경우 부분 불변성에 기반한 대체 솔루션에 집중할 수 있습니다. 부분 불변성은 lavaan의 lavTestScore 함수를 사용하여 살펴볼 수 있습니다. 이 함수를 사용하면 집단 간에 동일성 제약 조건이 해제되는 효과를 확인할 수 있습니다. 이는 새 경로와 관련된 새로 추가된 모수에 대한 수정 지수만 표시하는 modindices 함수와 반대되는 개념입니다. 부분 불변성의 맥락에서 모수는 모델에서 새로 추정되지 않고 대신 모델이 집단 간에 모수를 자유롭게 추정하도록 허용하므로 modindices가 아닌 lavTestScore를 사용합니다.\n다음 예에서는, lavTestScore 함수를 사용하여 강한 불변성(예: strong_invariance) 모델에 대한 부분 불변성을 살펴보겠습니다.\n\nlavTestScore(strong_invariance)\n\n$test\n\ntotal score test:\n\n   test    X2 df p.value\n1 score 4.822 10   0.903\n\n$uni\n\nunivariate score tests:\n\n     lhs op   rhs    X2 df p.value\n1   .p2. == .p25. 0.520  1   0.471\n2   .p3. == .p26. 0.669  1   0.414\n3   .p5. == .p28. 0.082  1   0.775\n4   .p6. == .p29. 0.000  1   0.997\n5  .p16. == .p39. 0.533  1   0.465\n6  .p17. == .p40. 0.247  1   0.619\n7  .p18. == .p41. 0.159  1   0.690\n8  .p19. == .p42. 2.540  1   0.111\n9  .p20. == .p43. 0.311  1   0.577\n10 .p21. == .p44. 1.765  1   0.184\n\n\n결과의 첫 번째 부분은 다변량 점수 검정(라그랑주 승수 검정)으로, 모든 제약 조건을 함께 해제하면 모델 개선이 없을 것이라는 영가설을 검정하는 것입니다. 결과는 이 영가설을 기각하지 못했음을 보여줍니다. 첫 번째, 두 번째 및 세 번째 열은 제약 조건이 없는 추정(즉, 그룹 간에 자유롭게 추정)을 위해 고려 중인 모수에 해당합니다. 네 번째 열은 단변량 점수 검정(즉, 카이제곱 차이 검정)입니다. 다시 한 번 강조하지만, 3.84는 1 자유도에 대한 임계값입니다. 강한 불변성을 발견했기 때문에 당연히 어떤 동일성을 해제해도 모델 적합도가 통계적으로 크게 개선되지 않는다는 것을 알 수 있습니다. 그러나 만일 그렇지 않았다면 X2 열에서 큰 카이제곱 값을 볼 수 있을 것으로 예상할 수 있습니다. 가장 큰 X2 값은 .p19. == .p42…와 연관되어 있습니다. 이것이 어떤 모수를 나타내는지 확인하려면 parTable 함수를 실행하여 표에서 .p19. 문항을 찾아야 합니다.\n\nparTable(strong_invariance)\n\n   id      lhs op      rhs user block group free ustart exo label plabel  start\n1   1     verb =~    vocab    1     1     1    0      1   0         .p1.  1.000\n2   2     verb =~  reading    1     1     1    1     NA   0  .p2.   .p2.  0.830\n3   3     verb =~ sentcomp    1     1     1    2     NA   0  .p3.   .p3.  0.839\n4   4     math =~ mathmtcs    1     1     1    0      1   0         .p4.  1.000\n5   5     math =~ geometry    1     1     1    3     NA   0  .p5.   .p5.  0.887\n6   6     math =~ analyrea    1     1     1    4     NA   0  .p6.   .p6.  0.939\n7   7    vocab ~~    vocab    0     1     1    5     NA   0         .p7.  0.563\n8   8  reading ~~  reading    0     1     1    6     NA   0         .p8.  0.500\n9   9 sentcomp ~~ sentcomp    0     1     1    7     NA   0         .p9.  0.482\n10 10 mathmtcs ~~ mathmtcs    0     1     1    8     NA   0        .p10.  0.590\n11 11 geometry ~~ geometry    0     1     1    9     NA   0        .p11.  0.572\n12 12 analyrea ~~ analyrea    0     1     1   10     NA   0        .p12.  0.572\n13 13     verb ~~     verb    0     1     1   11     NA   0        .p13.  0.050\n14 14     math ~~     math    0     1     1   12     NA   0        .p14.  0.050\n15 15     verb ~~     math    0     1     1   13     NA   0        .p15.  0.000\n16 16    vocab ~1             0     1     1   14     NA   0 .p16.  .p16.  0.159\n17 17  reading ~1             0     1     1   15     NA   0 .p17.  .p17.  0.220\n18 18 sentcomp ~1             0     1     1   16     NA   0 .p18.  .p18.  0.156\n19 19 mathmtcs ~1             0     1     1   17     NA   0 .p19.  .p19. -0.071\n20 20 geometry ~1             0     1     1   18     NA   0 .p20.  .p20.  0.001\n21 21 analyrea ~1             0     1     1   19     NA   0 .p21.  .p21.  0.070\n22 22     verb ~1             0     1     1    0      0   0        .p22.  0.000\n23 23     math ~1             0     1     1    0      0   0        .p23.  0.000\n24 24     verb =~    vocab    1     2     2    0      1   0        .p24.  1.000\n25 25     verb =~  reading    1     2     2   20     NA   0  .p2.  .p25.  0.943\n26 26     verb =~ sentcomp    1     2     2   21     NA   0  .p3.  .p26.  0.959\n27 27     math =~ mathmtcs    1     2     2    0      1   0        .p27.  1.000\n28 28     math =~ geometry    1     2     2   22     NA   0  .p5.  .p28.  0.837\n29 29     math =~ analyrea    1     2     2   23     NA   0  .p6.  .p29.  0.928\n30 30    vocab ~~    vocab    0     2     2   24     NA   0        .p30.  0.428\n31 31  reading ~~  reading    0     2     2   25     NA   0        .p31.  0.471\n32 32 sentcomp ~~ sentcomp    0     2     2   26     NA   0        .p32.  0.491\n33 33 mathmtcs ~~ mathmtcs    0     2     2   27     NA   0        .p33.  0.490\n34 34 geometry ~~ geometry    0     2     2   28     NA   0        .p34.  0.482\n35 35 analyrea ~~ analyrea    0     2     2   29     NA   0        .p35.  0.531\n36 36     verb ~~     verb    0     2     2   30     NA   0        .p36.  0.050\n37 37     math ~~     math    0     2     2   31     NA   0        .p37.  0.050\n38 38     verb ~~     math    0     2     2   32     NA   0        .p38.  0.000\n39 39    vocab ~1             0     2     2   33     NA   0 .p16.  .p39.  0.025\n40 40  reading ~1             0     2     2   34     NA   0 .p17.  .p40.  0.054\n41 41 sentcomp ~1             0     2     2   35     NA   0 .p18.  .p41. -0.005\n42 42 mathmtcs ~1             0     2     2   36     NA   0 .p19.  .p42.  0.274\n43 43 geometry ~1             0     2     2   37     NA   0 .p20.  .p43.  0.219\n44 44 analyrea ~1             0     2     2   38     NA   0 .p21.  .p44.  0.275\n45 45     verb ~1             0     2     2   39     NA   0        .p45.  0.000\n46 46     math ~1             0     2     2   40     NA   0        .p46.  0.000\n47 47     .p2. ==    .p25.    2     0     0    0     NA   0               0.000\n48 48     .p3. ==    .p26.    2     0     0    0     NA   0               0.000\n49 49     .p5. ==    .p28.    2     0     0    0     NA   0               0.000\n50 50     .p6. ==    .p29.    2     0     0    0     NA   0               0.000\n51 51    .p16. ==    .p39.    2     0     0    0     NA   0               0.000\n52 52    .p17. ==    .p40.    2     0     0    0     NA   0               0.000\n53 53    .p18. ==    .p41.    2     0     0    0     NA   0               0.000\n54 54    .p19. ==    .p42.    2     0     0    0     NA   0               0.000\n55 55    .p20. ==    .p43.    2     0     0    0     NA   0               0.000\n56 56    .p21. ==    .p44.    2     0     0    0     NA   0               0.000\n      est    se\n1   1.000 0.000\n2   0.896 0.044\n3   0.899 0.043\n4   1.000 0.000\n5   0.857 0.046\n6   0.932 0.044\n7   0.129 0.030\n8   0.259 0.040\n9   0.215 0.036\n10  0.146 0.035\n11  0.362 0.054\n12  0.241 0.041\n13  0.963 0.137\n14  1.042 0.149\n15  0.898 0.129\n16  0.171 0.093\n17  0.206 0.087\n18  0.146 0.087\n19 -0.045 0.097\n20 -0.019 0.089\n21  0.036 0.093\n22  0.000 0.000\n23  0.000 0.000\n24  1.000 0.000\n25  0.896 0.044\n26  0.899 0.043\n27  1.000 0.000\n28  0.857 0.046\n29  0.932 0.044\n30  0.086 0.030\n31  0.278 0.043\n32  0.305 0.046\n33  0.119 0.035\n34  0.333 0.050\n35  0.287 0.047\n36  0.790 0.110\n37  0.867 0.122\n38  0.625 0.097\n39  0.171 0.093\n40  0.206 0.087\n41  0.146 0.087\n42 -0.045 0.097\n43 -0.019 0.089\n44  0.036 0.093\n45 -0.153 0.123\n46  0.298 0.129\n47  0.000 0.000\n48  0.000 0.000\n49  0.000 0.000\n50  0.000 0.000\n51  0.000 0.000\n52  0.000 0.000\n53  0.000 0.000\n54  0.000 0.000\n55  0.000 0.000\n56  0.000 0.000\n\n\n이것은 집단 전체에서 이 절편을 자유모수로 추정해야 함을 나타내는 mathmtcs ~ 1에 해당한다는 것을 알 수 있습니다. 이 값을 cfa 호출에 포함하려면 mathmtcs ~ 1을 복사하여 group.partial 인수에 붙여넣으면 됩니다. 다음 코드는 절편 모수를 자유모수로 추정하는 방법을 보여줍니다.\n\nstrong_invariance_p <- cfa(cog_mod, data = interest,\n                           group = \"gender_f\",\n                           group.equal = c( \"loadings\",\n                                            \"intercepts\"),\n                           group.partial = \"mathmtcs ~ 1\")"
  },
  {
    "objectID": "chap11.html#차별기능문항",
    "href": "chap11.html#차별기능문항",
    "title": "11  측정 불변성과 차별기능문항",
    "section": "11.3 차별기능문항",
    "text": "11.3 차별기능문항\n차등 기능 문항(DIF)은 교육 및 심리 평가에서 문항 수준 편향을 감지하는 데 사용됩니다. DIF는 잠재적 특성을 통제한 후 피험자의 집단 구성원(예: 남성 대 여성)과 문항 수행 간의 조건부 의존성으로 인해 발생합니다. 문항이 이분으로 채점된 경우, 문항 수행은 문항에 정답을 맞출 확률을 의미하며, 문항이 다분으로 채점된 경우, 문항 수행은 다른 응답 범주(서열 또는 비서열)보다 특정 응답 범주를 선택하거나 지지할 확률을 의미합니다.\nDIF의 결과, 편향된 문항은 특정 집단에 일정한 이점을 제공하거나(균일 DIF), 잠재 특성 연속체에 걸쳐 크기 및/또는 방향에 따라 이점이 달라집니다(비균일 DIF). DIF의 맥락에서 초점 집단은 검사의 문항에 응답할 때 참조 집단의 피험자에 비해 불리한 것으로 의심되는 피험자를 의미합니다. 문항이 균일한 DIF를 보이는 경우, 초점 집단의 성적이 잠재 특성 연속체를 따라 기준 집단의 성적보다 지속적으로 떨어지는 경향이 있습니다. 잠재 특성 수준을 통제한 후 초점 집단은 참조 집단보다 문항에 정답을 맞힐 확률이 낮습니다. 문항이 균일하지 않은 DIF를 나타내는 경우 초점 집단과 참조 집단 간의 차이는 한 방향이 아닙니다. 즉, 한 집단이 다른 집단을 능가할 수 있지만 잠재 특성 연속체의 특정 지점 이후에는 이 관계가 역전됩니다.\n그림 11.1은 이분 문항에 대한 균일 및 비균일 DIF의 예를 보여줍니다. 각 플롯에는 초점 집단과 참조 집단에 대한 문항 특성 곡선(ICC, ICC에 대한 자세한 내용은 제5장 참조)이 별도로 표시되어 있습니다. 균일 DIF는 초점 집단이 참조 집단에 비해 문항에 정답할 확률이 낮습니다. 비균일 DIF는 참조 집단과 초점 집단의 ICC는 잠재 특성 연속체에서 \\(\\theta\\) = 0에서 교차합니다. 이는 \\(\\theta\\) = 0까지는 참조 집단이 초점 집단보다 문항에 정답할 확률이 높지만, \\(\\theta\\) = 0 이후에는 문항이 참조 집단보다 초점 집단에 유리해지기 시작한다는 것을 의미합니다.\n\n\n\n이분 문항에서 균일과 비균일 DIF\n\n\n이분 및 다분 채점 문항에서 균일 및 비균일 DIF를 감지하는 데 사용할 수 있는 통계적 방법은 여러 가지가 있습니다. 이 장에서는 맨텔-헨젤(MH) 방법(Mantel-Haenszel, 1959), 로지스틱 회귀(Swaminathan & Rogers, 1990), 문항 반응 이론 우도비(IRT-LR) 검정(Thissen, Steinberg, & Wainer, 1993) 등 세 가지 방법을 중점적으로 살펴봅니다. IRT-LR 검정은 문항 모수와 잠재 특성 수준을 추정하기 위해 특정 IRT 모델을 사용해야 하며, 이 모델은 DIF 분석 과정에서 사용되기 때문에 모수적 DIF 탐지 방법으로 간주됩니다. IRT-LR 검정과 달리 MH 및 로지스틱 회귀 방법은 비모수적 DIF 탐지 방법으로 간주되는데, 이 방법에서는 DIF를 탐지할 때 원 문항 및 검사 점수만 포함하기 때문입니다(즉, IRT가 필요하지 않음). 다음 섹션에서는 각 DIF 감지 방법에 대해 간략하게 설명하고 R에서 구현하는 방법을 보여 드리겠습니다.\n\n11.3.1 Mantel-Haenszel(MH) 방법\nMH 방법(Mantel & Haenszel, 1959)은 다른 DIF 검출 방법에 비해 계산과 해석이 쉽기 때문에 가장 널리 사용되는 DIF 검출 방법 중 하나입니다. MH 방법은 균일 DIF만 검출할 수 있습니다. 따라서 균일하지 않은 DIF가 존재하는 경우 MH 방법은 적절한 접근 방식이 아닐 수 있습니다.\nMH 방법은 총점 원점수에 따라 조건부로 집단 구성원(즉, 초점 집단 및 참조 집단)과 특정 문항에 대한 응답 간에 관계가 있는지 여부를 조사합니다. 주어진 문항에 대한 MH 통계를 산출하기 위해 집단 소속 및 응답 유형(정답 또는 오답)을 행과 열로 포함하는 2X3X2개의 분할표를 생성합니다. 표 11.1은 MH 통계를 산출하는 데 필요한 분할표의 요소를 보여줍니다. 총점 원점수를 기준으로 구분된 피험자 집단의 인덱스로 \\(k\\)를 사용하여(\\(k = 1, 2, 3, …, m\\)), \\(A_k\\) 및 \\(C_k\\)는 문항을 정답으로 답한 참조 및 초점 집단의 피험자 수, \\(B_k\\) 및 \\(D_k\\)는 문항을 오답으로 답한 참조 및 초점 집단의 피험자 수, \\(n_{1k}\\) 및 \\(n_{0k}\\)는 문항을 정답과 오답으로 답한 총 피험자 수, \\(n_{Rk}\\) 및 \\(n_{Fk}\\)는 참조 및 초점 집단의 총 피험자 수, \\(T_k\\)는 집단 \\(k\\)의 총 피험자 수입니다.\n\nMH 방법에 대한 2X3X2 분할표\n\n\n\n\n\n문항 반응\n\n\n\n\n\n1=정답\n0=오답\n합계\n\n\n집단\n참조\n\\(A_k\\)\n\\(B_k\\)\n\\(n_{Rk}\\)\n\n\n\n초점\n\\(C_k\\)\n\\(D_k\\)\n\\(n_{Fk}\\)\n\n\n\n전체\n\\(n_{1k}\\)\n\\(n_{0k}\\)\n\\(T_k\\)\n\n\n\n표 11.1에 나열된 빈도를 사용하여 MH 통계(\\(\\hat\\alpha_{MH}\\))는 다음과 같이 계산할 수 있습니다.\n\\[\n\\hat\\alpha_{MH} = {\\sum_{k=1}^m[{B_k C_k \\over T_k} {A_k D_k \\over B_k C_k}] \\over \\sum_{k=1}^m {B_k C_k \\over T_k}} = {\\sum_{k=1}^m {A_k D_k \\over T_k} \\over \\sum_{k=1}^m {B_k C_k \\over T_k}}\n\\]\n\\(\\hat\\alpha_{MH}\\) > 1은 참조 집단에 유리한 유의미한 DIF를 나타내며, \\(\\hat\\alpha_{MH}\\) < 1은 초점 집단에 유리한 유의미한 DIF를 나타냅니다. \\(\\hat\\alpha_{MH}\\) 통계치는 종종 \\(\\hat\\alpha_{MH}\\) 통계치의 자연 로그인 \\(\\hat\\lambda_{MH}\\) 로 변환됩니다. \\(\\hat\\lambda_{MH}=ln(\\hat\\alpha_{MH})\\). 이 대체 통계인 \\(\\lambda\\)는 DIF의 대칭 측정값으로, \\(\\lambda\\) = 0은 DIF가 없음을 나타내고, \\(\\lambda\\) > 0은 참조 집단에 유리한 DIF, \\(\\lambda\\) < 0은 초점 집단에 유리한 DIF를 나타냅니다. \\(\\hat\\lambda_{MH}\\)가 0에서 더 많이 벗어날수록 DIF가 더 중요해집니다.\nDIF가 통계적으로 유의미한지 테스트하기 위해 만텔-헨첼 카이스퀘어 검정(Mantel-Haenszel chi-square test)를 사용할 수 있습니다(Mantel & Haenszel, 1959). 맨텔-헨젤 카이제곱 통계(\\(\\chi^2_{MH}\\))는 다음과 같이 계산할 수 있습니다(Penfield & Camilli, 2006).\n\\[\n\\chi_{MH}^2={[\\left.|{\\sum_{k=1}^m[A_k-E(A_k)}\\right.|-0.5]^2 \\over \\sum_{k=1}^m V(A_k)}\n\\]\n\\[\nE(A_k)={n_{Rk} n_{1k} \\over T_k}\n\\]\n\\[\nV(A_K)={n_{Rk} n_{Fk} n_{1k} n_{0k} \\over T_k^2(T_k - 1)}\n\\]\n\\(\\chi_{MH}^2\\) 통계치는 대략 자유도 1의 카이제곱 변수로 분포됩니다. 특정 문항에 대해 \\(\\chi_{MH}^2\\) 통계치가 통계적으로 유의미한 경우, 해당 문항은 균일 DIF를 나타내는 것으로 표시되어야 합니다. 카이제곱 유의성 검정 외에도 Holland와 Thayer(1988)는 \\(\\hat\\alpha_{MH}\\) 통계치를 사용하여 MH 델타 지수라는 대체 지수를 제안했습니다. 이 지수는 효과 크기 측정과 같은 기능을 하며 DIF의 심각도를 분류합니다. 이 절차는 ETS 델타 분류라고도 합니다. MH 델타 지수는 다음과 같이 계산할 수 있습니다.\n\\[\n\\Delta_{MH}=-2.35\\hat\\alpha_{MH}\n\\]\n\n여기서 \\(\\Delta_{MH}\\) 통계치는 참조 집단에 유리한 DIF에 대해서는 음수이고\n초점 집단에 유리한 DIF에 대해서는 양수입니다.\n\\(\\left|\\Delta_{MH}\\right|\\le 0\\) 은 “A: 무시할 수 있는 DIF”,\n\\(1<\\left|\\Delta_{MH}\\right|\\le 1.5\\)는 “B: 중간 정도의 DIF”\n\\(\\left|\\Delta_{MH}\\right|> 1.5\\)는 “C: 큰 DIF”에 해당합니다(Holland & Thayer, 1988).\n\n다음 예에서는, hemp 패키지와 difR 패키지(Magis et al., 2010)의 VerbAggWide 데이터 세트를 사용하여 균일 DIF를 감지하는 MH 방법을 시연합니다. 제6장에서 설명한 것처럼 VerbAggWide 데이터 세트에는 언어적 공격성과 관련된 일련의 질문에 대한 316명의 참가자의 응답이 포함되어 있습니다. 데이터 세트의 처음 세 변수는 아이디(참가자 식별 번호), 분노(참가자의 분노 점수), 성별(참가자의 성별, 여기서 M은 남성, F는 여성을 나타냄)입니다. 나머지 변수(예: S1WantCurse, S1WantScold, S1WantShout)는 언어적 공격성에 관한 질문에 대한 응답입니다.\nDIF 분석을 시작하기 전에 먼저 VerbAgg라는 새 데이터 세트를 생성하고, 이 데이터 세트에는 성별과 VerbAggWide 데이터 세트의 질문만 포함됩니다. 그런 다음, difR 패키지에서는 응답이 이분이어야 하므로 VerbAgg의 원래 응답(0: 아니요, 1: 아마도, 2: 예)을 이분 응답(0: 아니요, 1: 아마도 또는 예)으로 다시 코딩합니다. apply 및 ifelse 함수를 사용하여 질문을 다시 코딩합니다(즉, 열 2~25).\n\nVerbAgg <- VerbAggWide[, c(3, 4:27)]\nVerbAgg[, 2:25] <- apply(VerbAgg[, 2:25], 2,\nfunction(x) ifelse(x == 0, 0, 1))\n\n다음으로, difR 패키지의 difMH 함수를 사용하여 MH 방법으로 DIF 분석을 수행합니다. diffMH 함수에서 사용할 데이터 세트(VerbAgg), 그룹화 변수를 나타내는 변수(Gender), 초점 집단을 지정하는 값(예: 여성 참가자의 경우 F)을 지정합니다. 결과를 results_MH로 저장한 다음 출력합니다.\n\nlibrary(\"difR\")\nresults_MH <- difMH(Data = VerbAgg, group = \"Gender\",\n                    focal.name = \"F\")\nresults_MH\n\n\nDetection of Differential Item Functioning using Mantel-Haenszel method \nwith continuity correction and without item purification\n\nResults based on asymptotic inference \n \nMatching variable: test score \n \nNo set of anchor items was provided \n \nNo p-value adjustment for multiple comparisons \n \nMantel-Haenszel Chi-square statistic: \n \n            Stat.  P-value   \nS1WantCurse 1.7076 0.1913    \nS1WantScold 2.1486 0.1427    \nS1WantShout 0.9926 0.3191    \nS2WantCurse 1.9302 0.1647    \nS2WantScold 2.9540 0.0857  . \nS2WantShout 9.6032 0.0019  **\nS3WantCurse 0.0013 0.9711    \nS3WantScold 0.6752 0.4112    \nS3WantShout 0.8185 0.3656    \nS4wantCurse 1.6292 0.2018    \nS4WantScold 0.0152 0.9020    \nS4WantShout 4.1188 0.0424  * \nS1DoCurse   0.1324 0.7160    \nS1DoScold   2.7501 0.0972  . \nS1DoShout   0.0683 0.7938    \nS2DoCurse   6.3029 0.0121  * \nS2DoScold   6.8395 0.0089  **\nS2DoShout   0.2170 0.6414    \nS3DoCurse   5.7817 0.0162  * \nS3DoScold   3.8880 0.0486  * \nS3DoShout   0.2989 0.5846    \nS4DoCurse   1.1220 0.2895    \nS4DoScold   1.4491 0.2287    \nS4DoShout   0.8390 0.3597    \n\nSignif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  \n\nDetection threshold: 3.8415 (significance level: 0.05)\n\nItems detected as DIF items: \n            \n S2WantShout\n S4WantShout\n S2DoCurse  \n S2DoScold  \n S3DoCurse  \n S3DoScold  \n\n \nEffect size (ETS Delta scale): \n \nEffect size code: \n 'A': negligible effect \n 'B': moderate effect \n 'C': large effect \n \n            alphaMH deltaMH  \nS1WantCurse  0.5881  1.2476 B\nS1WantScold  0.5649  1.3420 B\nS1WantShout  0.6906  0.8701 A\nS2WantCurse  0.5156  1.5567 C\nS2WantScold  0.5051  1.6052 C\nS2WantShout  0.3472  2.4861 C\nS3WantCurse  1.0595 -0.1358 A\nS3WantScold  1.3901 -0.7741 A\nS3WantShout  0.6544  0.9965 A\nS4wantCurse  0.5935  1.2260 B\nS4WantScold  0.9173  0.2028 A\nS4WantShout  0.4263  2.0036 C\nS1DoCurse    1.2551 -0.5340 A\nS1DoScold    2.0021 -1.6313 C\nS1DoShout    0.8499  0.3821 A\nS2DoCurse    3.1159 -2.6709 C\nS2DoScold    2.6693 -2.3072 C\nS2DoShout    1.2608 -0.5447 A\nS3DoCurse    2.1662 -1.8165 C\nS3DoScold    2.1153 -1.7606 C\nS3DoShout    1.5690 -1.0585 B\nS4DoCurse    1.5518 -1.0327 B\nS4DoScold    1.5661 -1.0541 B\nS4DoShout    0.6229  1.1123 B\n\nEffect size codes: 0 'A' 1.0 'B' 1.5 'C' \n (for absolute values of 'deltaMH') \n \nOutput was not captured! \n\n\n결과는 두 섹션으로 구성됩니다. 결과의 첫 번째 부분에는 문항에 대한 MH 카이제곱 통계와 해당 p 값이 표시됩니다. MH 카이제곱 검정의 결과에 따르면 VerbAgg 데이터 세트의 6개 문항이 알파 수준 \\(\\alpha\\) = .05로 플래그가 지정되어 남성과 여성 참가자 간에 균일 DIF를 나타내고 있습니다. 이러한 문항은 결과 하단에 나열되어 있습니다. 결과의 두 번째 부분에는 문항에 대한 ETS의 델타 분류를 사용하여 효과 크기가 표시됩니다. 결과에 따르면 9개 문항은 “C: 큰 DIF”를 나타내고, 7개 문항은 “B: 중간 정도의 DIF”를 나타내고, 나머지 문항은 “A: 무시할 수 있는 DIF”로 분류되었습니다.\ndifMH 함수로부터 저장된 결과는 DIF를 그래프로 검사하는 데에도 사용할 수 있습니다(그림 11.2). plot 함수를 사용하면 MH 카이제곱 검정에 따라 플래그가 지정된 문항을 확인할 수 있습니다. DIF로 플래그가 지정된 문항은 임계치 카이제곱 값의 수평선 위에 표시됩니다(유의 수준이 \\(\\alpha = .05\\)인 경우 \\(\\chi^2 = 3.84\\)). 알파 수준은 diffMH 함수에서 alpha 옵션을 설정하여 수정할 수 있습니다(예: alpha = .01).\n\nplot(results_MH)\n\n\n\n\nThe plot was not captured!\n\n\ndiffMH 함수에는 앵커 (DIF가 없는) 문항을 지정하는 anchor, 앵커 항목을 정제하는 반복 프로세스를 위한 purify, 다중 비교에서 p값 조정을 위한 p.adjust.method(예: Benjamini-Hochberg 조정) 등 다른 유용한 옵션이 포함되어 있습니다. 예를 들어, 정제 및 p값 조정을 통해 동일한 DIF 분석을 실행할 수 있습니다.\n\nresults_MH <- difMH(Data = VerbAgg, group = \"Gender\",\n                    focal.name = \"F\", purify = TRUE,\n                    p.adjust.method = \"BH\")\n\n\n\n11.3.2 로지스틱 회귀분석\n로지스틱 회귀분석 접근법(Swaminathan & Rogers, 1990)은 계산이 간단하고 균일 및 비균일 DIF를 모두 감지할 수 있기 때문에 가장 널리 사용되는 DIF 감지 방법 중 하나입니다. 이 DIF 탐지 방법은 이분 문항에 정답을 맞힐 확률(또는 특정 응답 옵션을 지지할 확률)을 피험자의 특성 추정치(X), 집단 소속(G), 피험자의 특성 추정치와 집단 소속(GX)의 상호작용으로 예측하는 일련의 로지스틱 회귀 모델을 비교하는 것을 기반으로 합니다. DIF를 감지하기 위한 로지스틱 회귀분석 접근 방식을 설명하기 위해 다음 로지스틱 회귀 모델을 고려합니다.\n\\[\nP(Y=1|z)={e^z \\over 1+e^z}\n\\]\n여기서 \\(P(Y = 1|z\\))는 DIF에 대해 조사 중인 문항에 정답을 제공할 확률이고, z는 하나 이상의 예측 변수에 기반한 선형 방정식입니다.\n로지스틱 회귀분석 접근 방식에서 기저 모델(모델 0)에는 피험자의 특성 추정치(X)만 단일 예측자로 포함됩니다.\n\\[\nz=\\beta_0+\\beta_1X\n\\]\n\n여기서 X는 피험자의 특성 추정치(예: 총점 원점수)입니다.\n\n다음 모델(모델 1)은 피험자의 특성 추정치 외에 집단 소속(G)을 예측 변수로 포함하며, 이는 균일 DIF를 검정하는 데 필수적입니다.\n\\[\nz=\\beta_0+\\beta_1X+\\beta_2G\n\\]\n\n여기서 초점 집단은 G = 1, 참조 집단은 G = 0입니다.\n\n모델 0과 모델 1 간의 의사 R-제곱 차이가 유의미하거나 \\(\\beta_2\\)가 0과 유의미하게 다르면(즉, \\(\\beta_2 \\ne 0\\)) 문항이 균일 DIF를 나타냅니다.\n마지막 모델(모델 2)은 모델 1의 예측 변수에 더해 집단 소속과 피험자의 특성 추정치(GX) 간의 상호작용을 포함하며, 이는 비균일 DIF를 테스트하는 데 필수적입니다.\n\\[\nz=\\beta_0+\\beta_1X+\\beta_2G+\\beta_3GX.\n\\]\n\\(\\beta_2\\)가 유의한지 여부에 관계없이 모델 1과 모델 2 간의 의사 R-제곱 차이가 유의한 경우(또는 \\(\\beta_3\\)가 0과 유의하게 다른 경우) 문항이 비균일 DIF를 나타냅니다.\n균일 및 비균일 DIF에 대한 개별 비교 외에도 균일 및 비균일 DIF를 동시에 고려할 때 모델 0과 모델 2를 비교하기 위한 옴니버스 검정을 수행할 수도 있습니다. 모델 0과 모델 2 간의 유의미한 Rsquared 차이는 조사 대상 문항에 DIF가 있음을 의미하므로 DIF의 유형을 정의하기 위해 후속 분석이 필요합니다.\n로지스틱 회귀분석 접근법을 사용하여 DIF를 탐지하는 방법을 보여드리기 위해 다음 예제에서 difR 패키지의 difLogistic 함수를 사용합니다. MH 방법의 경우, 로지스틱 회귀분석 접근법을 시연하기 위해 VerbAgg를 사용합니다. 먼저, difLogistic 함수에서 사용할 데이터 세트(VerbAgg), 집단 변수를 나타내는 변수(Gender), 초점 집단을 지정하는 값(여성 참가자를 초점 집단으로 설정하려면 focal.name = “F”), 검사 유형(균일 및 비균일 DIF를 동시에 테스트하려면 type = “both”)을 지정합니다. 결과를 logistic_fit으로 저장하고 마지막에 출력합니다.\n\nlogistic_fit <- difLogistic(Data = VerbAgg, group = \"Gender\",\n                            focal.name = \"F\", type = \"both\")\nlogistic_fit\n\n\nDetection of both types of Differential Item Functioning\nusing Logistic regression method, without item purification\nand with LRT DIF statistic\n\nMatching variable: test score \n \nNo set of anchor items was provided \n \nNo p-value adjustment for multiple comparisons \n \nLogistic regression DIF statistic: \n \n            Stat.   P-value   \nS1WantCurse  2.0014  0.3676   \nS1WantScold  3.3541  0.1869   \nS1WantShout  2.4742  0.2902   \nS2WantCurse  4.7296  0.0940 . \nS2WantScold  4.1404  0.1262   \nS2WantShout 11.4111  0.0033 **\nS3WantCurse  1.6061  0.4480   \nS3WantScold  1.6331  0.4419   \nS3WantShout  2.6989  0.2594   \nS4wantCurse  2.4547  0.2931   \nS4WantScold  2.0997  0.3500   \nS4WantShout  3.6877  0.1582   \nS1DoCurse    1.2196  0.5435   \nS1DoScold    4.7304  0.0939 . \nS1DoShout    1.0456  0.5929   \nS2DoCurse    7.6935  0.0213 * \nS2DoScold   10.2622  0.0059 **\nS2DoShout    1.7016  0.4271   \nS3DoCurse    7.2379  0.0268 * \nS3DoScold    5.8680  0.0532 . \nS3DoShout    1.2763  0.5283   \nS4DoCurse    2.9521  0.2285   \nS4DoScold    2.6956  0.2598   \nS4DoShout    1.3524  0.5085   \n\nSignif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  \n\nDetection threshold: 5.9915 (significance level: 0.05)\n\nItems detected as DIF items:\n            \n S2WantShout\n S2DoCurse  \n S2DoScold  \n S3DoCurse  \n\n \nEffect size (Nagelkerke's R^2): \n \nEffect size code: \n 'A': negligible effect \n 'B': moderate effect \n 'C': large effect \n \n            R^2    ZT JG\nS1WantCurse 0.0067 A  A \nS1WantScold 0.0101 A  A \nS1WantShout 0.0074 A  A \nS2WantCurse 0.0177 A  A \nS2WantScold 0.0125 A  A \nS2WantShout 0.0343 A  A \nS3WantCurse 0.0056 A  A \nS3WantScold 0.0050 A  A \nS3WantShout 0.0106 A  A \nS4wantCurse 0.0085 A  A \nS4WantScold 0.0060 A  A \nS4WantShout 0.0133 A  A \nS1DoCurse   0.0039 A  A \nS1DoScold   0.0122 A  A \nS1DoShout   0.0033 A  A \nS2DoCurse   0.0243 A  A \nS2DoScold   0.0277 A  A \nS2DoShout   0.0058 A  A \nS3DoCurse   0.0232 A  A \nS3DoScold   0.0211 A  A \nS3DoShout   0.0078 A  A \nS4DoCurse   0.0092 A  A \nS4DoScold   0.0083 A  A \nS4DoShout   0.0057 A  A \n\nEffect size codes: \n Zumbo & Thomas (ZT): 0 'A' 0.13 'B' 0.26 'C' 1 \n Jodoin & Gierl (JG): 0 'A' 0.035 'B' 0.07 'C' 1 \n\n Output was not captured! \n\n\ndiffMH 함수의 결과와 유사하게, diffLogistic 함수의 결과는 두 섹션으로 구성됩니다. 결과의 상단 부분(위 그림)은 모델 0과 모델 2의 적합도와 해당 p값을 비교하여 얻은 우도비 검정 통계를 보여줍니다. 결과에 따르면 4개의 문항이 유의 수준 \\(\\alpha = .05\\)에서 DIF에 대해 플래그가 지정된 것으로 나타났습니다. 이러한 문항은 결과의 첫 번째 부분 끝에 나열되어 있습니다.\n결과의 두 번째 부분(아래 표시)에는 모델 0과 모델 2 간의 의사 R-제곱 차이를 사용하여 계산된 효과 크기가 표시됩니다. 열 ZT는 무시할 수 있는 DIF의 경우 \\(\\Delta R^2 \\le .13\\), 중간 정도의 DIF의 경우 \\(.13< \\Delta R^2 \\le .13\\), 큰 DIF의 경우 \\(\\Delta R^2 > .26\\)으로 Zumbo와 Thomas(1997)가 제안한 효과 크기 방법을 참조합니다. 열 JG는 무시할 수 있는 DIF의 경우 \\(\\Delta R^2 \\le .035\\), 중간 정도의 DIF의 경우 \\(.035 < \\Delta R^2 \\le .07\\), 큰 DIF의 경우 $\\Delta R^2 > .07$로 Jodoin과 Gierl(2001)이 제안한 다른 효과 크기 방법을 참조합니다. 결과는 두 효과 크기 측정값에 따라 모든 문항에 대해 효과 크기가 “A: 무시할 수 있는 DIF”로 나타났습니다.\n균일 및 비균일 DIF에 대한 옴니버스 테스트 외에도 각 유형의 DIF를 개별적으로 조사할 수도 있습니다. 예를 들어 type = “udif” 및 type = “nudif”를 사용하여 균일 및 비균일 DIF 문항을 개별적으로 검사할 수 있습니다.\n\ndifLogistic(Data = VerbAgg, group = \"Gender\", focal.name = \"F\",\n            type = \"udif\")\n\n\nDetection of uniform Differential Item Functioning\nusing Logistic regression method, without item purification\nand with LRT DIF statistic\n\nMatching variable: test score \n \nNo set of anchor items was provided \n \nNo p-value adjustment for multiple comparisons \n \nLogistic regression DIF statistic: \n \n            Stat.   P-value    \nS1WantCurse  1.9998  0.1573    \nS1WantScold  1.9065  0.1673    \nS1WantShout  2.1606  0.1416    \nS2WantCurse  4.2639  0.0389 *  \nS2WantScold  2.9036  0.0884 .  \nS2WantShout 11.3031  0.0008 ***\nS3WantCurse  0.0955  0.7573    \nS3WantScold  1.6260  0.2023    \nS3WantShout  2.1397  0.1435    \nS4wantCurse  1.9563  0.1619    \nS4WantScold  0.0042  0.9485    \nS4WantShout  3.6491  0.0561 .  \nS1DoCurse    0.4234  0.5153    \nS1DoScold    4.0968  0.0430 *  \nS1DoShout    0.7163  0.3974    \nS2DoCurse    7.6372  0.0057 ** \nS2DoScold    9.1401  0.0025 ** \nS2DoShout    0.0928  0.7607    \nS3DoCurse    7.1433  0.0075 ** \nS3DoScold    4.6496  0.0311 *  \nS3DoShout    0.5258  0.4684    \nS4DoCurse    1.8339  0.1757    \nS4DoScold    2.3918  0.1220    \nS4DoShout    1.0577  0.3037    \n\nSignif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  \n\nDetection threshold: 3.8415 (significance level: 0.05)\n\nItems detected as uniform DIF items:\n            \n S2WantCurse\n S2WantShout\n S1DoScold  \n S2DoCurse  \n S2DoScold  \n S3DoCurse  \n S3DoScold  \n\n \nEffect size (Nagelkerke's R^2): \n \nEffect size code: \n 'A': negligible effect \n 'B': moderate effect \n 'C': large effect \n \n            R^2    ZT JG\nS1WantCurse 0.0067 A  A \nS1WantScold 0.0058 A  A \nS1WantShout 0.0065 A  A \nS2WantCurse 0.0159 A  A \nS2WantScold 0.0088 A  A \nS2WantShout 0.0340 A  A \nS3WantCurse 0.0003 A  A \nS3WantScold 0.0049 A  A \nS3WantShout 0.0084 A  A \nS4wantCurse 0.0068 A  A \nS4WantScold 0.0000 A  A \nS4WantShout 0.0131 A  A \nS1DoCurse   0.0014 A  A \nS1DoScold   0.0105 A  A \nS1DoShout   0.0023 A  A \nS2DoCurse   0.0241 A  A \nS2DoScold   0.0247 A  A \nS2DoShout   0.0003 A  A \nS3DoCurse   0.0229 A  A \nS3DoScold   0.0167 A  A \nS3DoShout   0.0032 A  A \nS4DoCurse   0.0057 A  A \nS4DoScold   0.0073 A  A \nS4DoShout   0.0044 A  A \n\nEffect size codes: \n Zumbo & Thomas (ZT): 0 'A' 0.13 'B' 0.26 'C' 1 \n Jodoin & Gierl (JG): 0 'A' 0.035 'B' 0.07 'C' 1 \n\n Output was not captured! \n\ndifLogistic(Data = VerbAgg, group = \"Gender\", focal.name = \"F\",\n            type = \"nudif\")\n\n\nDetection of nonuniform Differential Item Functioning\nusing Logistic regression method, without item purification\nand with LRT DIF statistic\n\nMatching variable: test score \n \nNo set of anchor items was provided \n \nNo p-value adjustment for multiple comparisons \n \nLogistic regression DIF statistic: \n \n            Stat.  P-value \nS1WantCurse 0.0016 0.9686  \nS1WantScold 1.4476 0.2289  \nS1WantShout 0.3136 0.5755  \nS2WantCurse 0.4658 0.4949  \nS2WantScold 1.2367 0.2661  \nS2WantShout 0.1080 0.7425  \nS3WantCurse 1.5106 0.2190  \nS3WantScold 0.0071 0.9330  \nS3WantShout 0.5592 0.4546  \nS4wantCurse 0.4983 0.4802  \nS4WantScold 2.0955 0.1477  \nS4WantShout 0.0386 0.8442  \nS1DoCurse   0.7962 0.3722  \nS1DoScold   0.6335 0.4261  \nS1DoShout   0.3293 0.5661  \nS2DoCurse   0.0563 0.8124  \nS2DoScold   1.1221 0.2895  \nS2DoShout   1.6088 0.2047  \nS3DoCurse   0.0945 0.7585  \nS3DoScold   1.2184 0.2697  \nS3DoShout   0.7505 0.3863  \nS4DoCurse   1.1182 0.2903  \nS4DoScold   0.3039 0.5815  \nS4DoShout   0.2947 0.5872  \n\nSignif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  \n\nDetection threshold: 3.8415 (significance level: 0.05)\n\nItems detected as DIF items: No DIF item detected \n \nEffect size (Nagelkerke's R^2): \n \nEffect size code: \n 'A': negligible effect \n 'B': moderate effect \n 'C': large effect \n \n            R^2    ZT JG\nS1WantCurse 0.0000 A  A \nS1WantScold 0.0043 A  A \nS1WantShout 0.0009 A  A \nS2WantCurse 0.0017 A  A \nS2WantScold 0.0037 A  A \nS2WantShout 0.0003 A  A \nS3WantCurse 0.0053 A  A \nS3WantScold 0.0000 A  A \nS3WantShout 0.0022 A  A \nS4wantCurse 0.0017 A  A \nS4WantScold 0.0060 A  A \nS4WantShout 0.0001 A  A \nS1DoCurse   0.0026 A  A \nS1DoScold   0.0016 A  A \nS1DoShout   0.0010 A  A \nS2DoCurse   0.0002 A  A \nS2DoScold   0.0030 A  A \nS2DoShout   0.0055 A  A \nS3DoCurse   0.0003 A  A \nS3DoScold   0.0043 A  A \nS3DoShout   0.0046 A  A \nS4DoCurse   0.0035 A  A \nS4DoScold   0.0009 A  A \nS4DoShout   0.0012 A  A \n\nEffect size codes: \n Zumbo & Thomas (ZT): 0 'A' 0.13 'B' 0.26 'C' 1 \n Jodoin & Gierl (JG): 0 'A' 0.035 'B' 0.07 'C' 1 \n\n Output was not captured! \n\n\ndiffLogistic 함수의 다른 옵션으로는 우도비 통계 대신 Wald 검정을 사용하기 위한 criterion = “Wald”, 일치 조건으로 다른 연속형 또는 불연속형 변수를 선택하기 위한 match, 앵커 문항의 반복 정제를 위한 purify = TRUE, 데이터 세트의 앵커 문항 목록을 지정하는 anchor가 있습니다.\ndiffMH 함수에 대해 수행한 것과 마찬가지로, 저장된 diffLogistic 함수의 결과를 사용하여 DIF 문항을 그래픽으로 검사할 수 있습니다(그림 11.3). plot 함수를 사용하여 우도비 통계에 따라 플래그가 지정된 문항을 그래프로 그립니다. DIF로 플래그가 지정된 문항은 임계값 우도비 통계의 가로선 위에 표시됩니다(유의 수준이 \\(\\alpha = .05\\)인 경우 5.9915). 알파 수준은 diffLogistic 함수의 alpha 옵션을 사용하여 수정할 수 있습니다(예: alpha = .01).\n\nplot(logistic_fit)\n\n\n\n\nThe plot was not captured!\n\n\n또한 plot 함수를 사용하면 우도비 통계를 기반으로 플래그가 지정된 문항에 대한 개별 그래프를 만들 수 있습니다. 이 그래프는 참조 집단과 초점 집단에 대해 별도의 ICC를 생성하여 DIF 유형(예: 균일 DIF 대 비균일 DIF)과 DIF의 심각도를 시각적으로 검사할 수 있게 해줍니다. 이 그래프는 X축의 일치 기준(예: match = “score”가 difLogistic 함수에 사용된 경우 전체 검사 점수)과 Y축의 정답 확률(즉, 0보다 1을 받을 확률)을 기준으로 두 개의 ICC를 생성합니다. 이러한 ICC는 DIF 유형이 균일한지 또는 균일하지 않은지, 두 집단(즉, 참조 집단과 초점 집단) 중 어느 집단이 다른 집단보다 우세한지를 나타낼 수 있습니다.\n다음 예에서는 VerbAgg 데이터 세트의 문항 6에 대한 개별 DIF 그래프를 생성합니다. item = 6을 사용하여 문항 6을 선택하고 plot = “itemCurve”를 사용하여 우도비 통계에 기반한 그래프 대신 ICC를 얻습니다. 그림 11.4는 여성 참가자(즉, 초점 집단)가 남성 참가자보다 문항 6(점원이 잘못된 정보를 제공해서 기차를 놓친다면 소리를 지르고 싶다)에 대해 예 또는 아니오를 선택할 가능성이 더 높은 문항 6이 균일한 DIF를 나타낸다는 것을 보여줍니다. VerbAgg 데이터 세트의 다른 플래그가 지정된 문항에 대해서도 유사한 그래프를 만들 수 있습니다.\n\nplot(logistic_fit, item = 6, plot = \"itemCurve\")\n\n\n\n\nThe plot was not captured!\n\n\n\n\n11.3.3 문항반응이론 우도비 검정\n문항 반응 이론 우도비(IRT-LR) 검정(Thissen et al., 1993)은 이분 및 다분으로 채점된 문항 모두에 대해 균일 및 비균일 DIF를 감지하는 가장 효과적인 방법 중 하나로 간주됩니다. IRT-LR 검정은 일련의 우도비 검정과 함께 두 개의 내재된 IRT 모델을 비교하는 것을 포함합니다. 먼저, 모든 문항 모수가 참조 집단과 초점 집단 간에 달라질 수 있는 전체 모델을 추정합니다. 다음으로, DIF가 의심되는 문항의 모수가 참조 집단과 초점 집단 간에 동일하도록 제약된 제약 모델을 추정합니다. 문항이 DIF를 나타내는지 여부를 검정하기 위해 다음 공식을 사용하여 우도비 통계를 계산합니다.\n\\[\nLikelihood ratio statistic = -2lnL_R-(-2lnL_F)\n\\]\n\n여기서 \\(L_R\\)은 제약 모델의 로그 우도이고 \\(L_F\\)는 전체 모델의 로그 우도입니다.\n\n우도비 통계는 제약 모델과 전체 모델 간에 추정된 모수 수의 차이와 동일한 자유도를 갖는 카이제곱 분포를 따릅니다. 통계적으로 유의미한 우도비 통계는 문항에 DIF가 있음을 나타내며, 따라서 후속 검정을 수행하여 DIF 유형을 식별해야 합니다. 예를 들어, 문항의 변별도 모수만 참조 집단과 초점 집단 간에 동일하도록 제약하고 문항의 난이도 모수는 두 집단에 대해 개별적으로 추정합니다. 이 모델과 앞서 설명한 전체 모델을 비교한 결과 유의미한 우도비 통계는 해당 문항이 비균등 DIF를 나타낸다는 것을 시사합니다. 문항의 난이도 모수가 두 집단 간에 동일하도록 제약하여 유사한 검정을 수행하여 문항이 균일 DIF를 나타내는지 확인할 수 있습니다.\n다음 예에서는, mirt 패키지(Chalmers, 2012)의 DIF 함수를 사용하여 균일 및 비균일 DIF를 감지하기 위해 IRT-LR 검정을 수행하는 방법을 보여줍니다. 균일 및 비균일 DIF를 모두 감지하는 방법을 보여주기 위해 VerbAgg 데이터 세트의 문항이 2모수 IRT 모델을 따른다고 가정합니다(단일차원 IRT 모델에 대한 자세한 내용은 제5장 참조). DIF 함수를 사용하여 DIF를 감지하려면 두 단계가 필요합니다:\n1. multiGroup 함수를 사용하여 전체 모델을 추정하고, 여기서 문항 모수가 VerbAgg 데이터 세트의 남성 및 여성 참가자인 참조 집단과 초점 집단에 대해 자유롭게 추정됩니다. multipleGroup 함수는 제5장에서 자세히 설명한 mirt 함수와 매우 유사합니다. 먼저 twopl_mod를 생성하여 VerbAgg 데이터 세트의 24개 문항에 기반한 단일차원 검사 구조를 정의합니다. 다음으로, 이 모델을 model = twopl_mod로 multipleGroup 함수에 전달합니다. mirt 함수와 달리, multipleGroup 함수는 집단 변수를 지정해야 하며, 이 예에서는 Gender(group = VerbAgg$Gender)입니다. 이 다집단 분석의 결과를 twopl_fit으로 저장합니다.\n2. 그런 다음 twopl_fit의 결과를 MGmodel = twopl_fit으로 DIF 함수에 전달합니다. 다음으로, 제약 모델에서 동일하도록 제약해야 하는 모수를 정의합니다. 문항이 DIF를 나타내는지 여부를 결정하기 위해 문항 변별도와 난이도 모수를 모두 which.par = c(“a1”, “d”)로 제약합니다. 마지막으로 DIF 분석을 위한 스키마를 정의합니다. DIF 함수에는 DIF 분석 수행 방법을 결정하는 몇 가지 스키마가 포함되어 있습니다. 예를 들어 scheme = “add”를 사용하면 데이터 세트의 각 문항을 한 번에 하나씩 제약하여 DIF 분석이 수행됩니다. 마찬가지로 scheme = “add_sequential”을 사용하면 DIF에 대해 더 이상 플래그가 지정된 문항이 없을 때까지 문항을 반복하여 순차적으로 DIF 분석이 수행됩니다. 이 예에서는 스키마를 scheme = “add”로 정의합니다. 결과는 results_irtlr로 저장됩니다.\n분석이 완료되면, hemp 패키지의 irtlr_summary 함수를 사용하여 DIF 표시로 플래그가 지정된 문항을 출력합니다. irtlr_summary 함수를 사용하려면 카이제곱 검정의 알파 유의 수준을 정의해야 하며, 기본값은 \\(\\alpha = .05\\)입니다. 위에서 설명한 단계는 다음 R 코드를 통해 시연됩니다.\n\nlibrary(\"mirt\")\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ ggplot2::%+%()    masks psych::%+%()\n✖ ggplot2::alpha()  masks psych::alpha()\n✖ tidyr::expand()   masks Matrix::expand()\n✖ dplyr::filter()   masks stats::filter()\n✖ dplyr::lag()      masks stats::lag()\n✖ ggplot2::margin() masks equate::margin()\n✖ tidyr::pack()     masks Matrix::pack()\n✖ tidyr::unpack()   masks Matrix::unpack()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\ntwopl_mod <- \"F = 1 - 24\"\ntwopl_fit <- multipleGroup(data = VerbAgg[, 2:25],\n                           model = twopl_mod, SE = TRUE,\n                           group = VerbAgg$Gender)\n\n\nIteration: 1, Log-Lik: -4086.452, Max-Change: 0.90657\nIteration: 2, Log-Lik: -3996.045, Max-Change: 0.35379\nIteration: 3, Log-Lik: -3982.004, Max-Change: 0.20731\nIteration: 4, Log-Lik: -3976.584, Max-Change: 0.14613\nIteration: 5, Log-Lik: -3974.171, Max-Change: 0.10218\nIteration: 6, Log-Lik: -3973.011, Max-Change: 0.07126\nIteration: 7, Log-Lik: -3971.890, Max-Change: 0.02063\nIteration: 8, Log-Lik: -3971.825, Max-Change: 0.01621\nIteration: 9, Log-Lik: -3971.785, Max-Change: 0.01305\nIteration: 10, Log-Lik: -3971.723, Max-Change: 0.00792\nIteration: 11, Log-Lik: -3971.717, Max-Change: 0.00449\nIteration: 12, Log-Lik: -3971.713, Max-Change: 0.00418\nIteration: 13, Log-Lik: -3971.701, Max-Change: 0.00454\nIteration: 14, Log-Lik: -3971.700, Max-Change: 0.00159\nIteration: 15, Log-Lik: -3971.700, Max-Change: 0.00160\nIteration: 16, Log-Lik: -3971.699, Max-Change: 0.00145\nIteration: 17, Log-Lik: -3971.699, Max-Change: 0.00132\nIteration: 18, Log-Lik: -3971.699, Max-Change: 0.00053\nIteration: 19, Log-Lik: -3971.699, Max-Change: 0.00052\nIteration: 20, Log-Lik: -3971.699, Max-Change: 0.00050\nIteration: 21, Log-Lik: -3971.699, Max-Change: 0.00048\nIteration: 22, Log-Lik: -3971.698, Max-Change: 0.00071\nIteration: 23, Log-Lik: -3971.698, Max-Change: 0.00060\nIteration: 24, Log-Lik: -3971.698, Max-Change: 0.00071\nIteration: 25, Log-Lik: -3971.698, Max-Change: 0.00039\nIteration: 26, Log-Lik: -3971.698, Max-Change: 0.00037\nIteration: 27, Log-Lik: -3971.698, Max-Change: 0.00036\nIteration: 28, Log-Lik: -3971.698, Max-Change: 0.00048\nIteration: 29, Log-Lik: -3971.698, Max-Change: 0.00045\nIteration: 30, Log-Lik: -3971.698, Max-Change: 0.00049\nIteration: 31, Log-Lik: -3971.698, Max-Change: 0.00032\nIteration: 32, Log-Lik: -3971.698, Max-Change: 0.00035\nIteration: 33, Log-Lik: -3971.698, Max-Change: 0.00034\nIteration: 34, Log-Lik: -3971.698, Max-Change: 0.00037\nIteration: 35, Log-Lik: -3971.698, Max-Change: 0.00035\nIteration: 36, Log-Lik: -3971.698, Max-Change: 0.00038\nIteration: 37, Log-Lik: -3971.698, Max-Change: 0.00029\nIteration: 38, Log-Lik: -3971.698, Max-Change: 0.00031\nIteration: 39, Log-Lik: -3971.698, Max-Change: 0.00031\nIteration: 40, Log-Lik: -3971.698, Max-Change: 0.00029\nIteration: 41, Log-Lik: -3971.698, Max-Change: 0.00029\nIteration: 42, Log-Lik: -3971.698, Max-Change: 0.00030\nIteration: 43, Log-Lik: -3971.698, Max-Change: 0.00025\nIteration: 44, Log-Lik: -3971.698, Max-Change: 0.00026\nIteration: 45, Log-Lik: -3971.698, Max-Change: 0.00026\nIteration: 46, Log-Lik: -3971.698, Max-Change: 0.00023\nIteration: 47, Log-Lik: -3971.698, Max-Change: 0.00023\nIteration: 48, Log-Lik: -3971.698, Max-Change: 0.00024\nIteration: 49, Log-Lik: -3971.698, Max-Change: 0.00020\nIteration: 50, Log-Lik: -3971.698, Max-Change: 0.00021\nIteration: 51, Log-Lik: -3971.698, Max-Change: 0.00021\nIteration: 52, Log-Lik: -3971.698, Max-Change: 0.00018\nIteration: 53, Log-Lik: -3971.698, Max-Change: 0.00019\nIteration: 54, Log-Lik: -3971.698, Max-Change: 0.00019\nIteration: 55, Log-Lik: -3971.698, Max-Change: 0.00016\nIteration: 56, Log-Lik: -3971.698, Max-Change: 0.00017\nIteration: 57, Log-Lik: -3971.698, Max-Change: 0.00017\nIteration: 58, Log-Lik: -3971.698, Max-Change: 0.00015\nIteration: 59, Log-Lik: -3971.698, Max-Change: 0.00015\nIteration: 60, Log-Lik: -3971.698, Max-Change: 0.00015\nIteration: 61, Log-Lik: -3971.698, Max-Change: 0.00013\nIteration: 62, Log-Lik: -3971.698, Max-Change: 0.00013\nIteration: 63, Log-Lik: -3971.698, Max-Change: 0.00014\nIteration: 64, Log-Lik: -3971.698, Max-Change: 0.00012\nIteration: 65, Log-Lik: -3971.698, Max-Change: 0.00012\nIteration: 66, Log-Lik: -3971.698, Max-Change: 0.00012\nIteration: 67, Log-Lik: -3971.698, Max-Change: 0.00010\nIteration: 68, Log-Lik: -3971.698, Max-Change: 0.00011\nIteration: 69, Log-Lik: -3971.698, Max-Change: 0.00011\nIteration: 70, Log-Lik: -3971.698, Max-Change: 0.00009\n\nCalculating information matrix...\n\nresults_irtlr <- DIF(MGmodel = twopl_fit,\n                     which.par = c(\"a1\", \"d\"),\n                     scheme = \"add\")\n\nNOTE: No hyper-parameters were estimated in the DIF model. \n      For effective DIF testing, freeing the focal group hyper-parameters is recommended.\n\n#irtlr_summary(results_irtlr, alpha = 0.05)\nDIFitemslist <- results_irtlr[results_irtlr$p < 0.05,]\nDIFitemslist <- DIFitemslist[,6:8]\nDIFitemslist <- rownames_to_column(DIFitemslist,\n                   var = \"Item\")\nnames(DIFitemslist) <- c(\"Item\",\"chi_square\",\"df\",\"p_value\")\nDIFitemslist\n\n       Item chi_square     df p_value\n1 S1DoScold      4.185  7.326       2\n2 S2DoCurse      0.812 10.699       2\n3 S2DoScold     -1.309 12.820       2\n4 S3DoCurse      1.199 10.312       2\n5 S3DoScold      3.179  8.333       2\n\n\nirtlr_summary 함수에서 반환된 결과는 VerbAgg 데이터 세트의 5개 문항이 성별 관련 DIF를 나타낸다는 것을 보여줍니다. 이러한 문항이 균일하거나 비균일하게 DIF를 나타내는지 확인하기 위해 초점 집단과 참조 집단 간에 문항 난이도 모수만 제약하여 후속 검사를 수행합니다. 또한 첫 번째 분석 결과를 바탕으로 어떤 문항에 대해 DIF를 검사할지 지정합니다. which 함수를 사용하여 플래그가 지정된 문항의 열 번호(예: VerbAgg[,2:25]의 여섯 번째 문항)를 저장하고 이를 DIFitems로 저장합니다.\n\n#DIFitems <- which(colnames(VerbAgg[, 2:25]) %in% \n#                    irtlr_summary(results_irtlr, alpha = .05)$Item)\n\n\nDIFitems <- which(colnames(VerbAgg[, 2:25]) %in% \n                    rownames(results_irtlr[results_irtlr$p < 0.05, ]))\n\nDIFitems\n\n[1] 14 16 17 19 20\n\n\n다음으로, DIF 함수에서 items2test = DIFitems를 사용하여 균일 DIF를 테스트할 문항을 지정합니다. 또한 초점 집단과 기준 집단 간에 난이도 모수가 고정되어 균일 DIF를 검사할 수 있도록 제약된 모수를 which.par = “d”)로 수정합니다.\n\nresults_irtlr <- DIF(MGmodel = twopl_fit, which.par = \"d\",\n                     scheme = \"add\", items2test = DIFitems)\n\nNOTE: No hyper-parameters were estimated in the DIF model. \n      For effective DIF testing, freeing the focal group hyper-parameters is recommended.\n\n#irtlr_summary(results_irtlr, alpha = .05)\nDIFitemslist <- results_irtlr[results_irtlr$p < 0.05,]\nDIFitemslist <- DIFitemslist[,6:8]\nDIFitemslist <- rownames_to_column(DIFitemslist,\n                                   var = \"Item\")\nnames(DIFitemslist) <- c(\"Item\",\"chi_square\",\"df\",\"p_value\")\nDIFitemslist\n\n       Item chi_square     df p_value\n1 S1DoScold     -0.085  5.841       1\n2 S2DoCurse     -3.568  9.324       1\n3 S2DoScold     -5.677 11.433       1\n4 S3DoCurse     -4.136  9.892       1\n5 S3DoScold     -2.571  8.327       1\n\n\n두 번째 분석의 결과에서는 첫 번째 분석의 5개 문항이 모두 균일 DIF를 나타내며, 이는 p값이 DIF 분석에서 설정한 유의 수준(\\(\\alpha = .05\\))보다 작기 때문입니다. IRT-LR 검정 결과 외에도 plot 함수를 사용하여 DIF 문항을 시각적으로 살펴볼 수 있습니다. 예를 들어, 문항 14(S1DoScold)와 문항 16(S2DoCurse)은 IRT-LR 검정에 따라 균일 DIF를 나타내는 것으로 플래그가 지정된 두 문항입니다. twopl_fit의 결과를 사용하여 각 문항에 대한 남성 및 여성 참가자의 ICC를 그릴 수 있습니다.\n\nplot(twopl_fit, type = \"trace\", which.items = c(14, 16), \n     par.settings = simpleTheme(lty = 1:2, lwd = 2),\n     auto.key = list(points = FALSE, lines = TRUE, columns = 2))\n\n\n\n\n그림 11.5는 두 문항 모두에서 남성 참가자가 여성 참가자에 비해 예 또는 아니오를 선택할 가능성이 더 높다는 것을 보여줍니다. 문항이 균일 DIF를 나타내기 때문에 편향의 방향은 잠재 특성 연속체를 따라 동일합니다(즉, 남성 참가자가 여성 참가자보다 계속해서 더 높은 가능성을 가짐).\nDIF 함수에는 다른 설정에서 유용할 수 있는 다른 옵션이 있습니다. 예를 들어, Wald = TRUE는 우도비 검정 대신 Wald 검정의 결과를 반환합니다. 또한 p.adjust을 사용하여 우도비 검정의 p값을 조정할 수 있습니다. 예를 들어, p.adjust = “BH” 및 p.adjust = “bonferroni”는 각각 Benjamini-Hochberg 방법(Benjamini-Hochberg, 1995) 및 Bonferroni 보정에 따라 조정된 p값을 반환합니다. 마지막으로, plotdif = TRUE를 지정하여 DIF 함수에서 직접 문항 그래프를 얻을 수 있습니다.\n요약하면, 이 장에서 논의한 DIF 방법은 균일 및 비균일 DIF를 감지하는 데 가장 널리 사용되는 방법입니다. 예제에서는 VerbAgg 데이터 세트의 이분 문항에 초점을 맞추었지만, 이러한 방법은 다분 문항에도 사용할 수 있습니다. 또한 이러한 DIF 검출 방법은 두 개 이상의 잠재 특성이 측정되는 다차원 검사 구조에도 사용할 수 있습니다(다차원 DIF 분석에 대한 자세한 내용은 Bulut and Suh (2017) 참조)."
  },
  {
    "objectID": "chap11.html#요약",
    "href": "chap11.html#요약",
    "title": "11  측정 불변성과 차별기능문항",
    "section": "11.4 요약",
    "text": "11.4 요약\n이 장의 전반부에서는 척도 수준 편향을 감지하기 위한 측정 불변성을 소개했습니다. 측정 불변성은 측정되는 구조가 개인의 하위 그룹에서 동일한 방식으로 작동하는지 확인하는 데 중요합니다. 불변성을 위반하면 통계 분석이 위태로워질 수 있습니다. 측정 불변성(형태, 약, 강, 엄격 및 부분 측정 불변성)을 검사하는 단계에 대해 설명한 후, lavaan 패키지를 사용하여 각 단계를 검사하는 방법을 시연했습니다(Rosseel, 2012). 이 장의 후반부에서는 DIF를 소개했습니다. 두 가지 유형의 DIF(균일 및 비균일)에 대해 설명하고, 맨텔-헨첼(MH) 방법, 로지스틱 회귀분석, 문항 반응 이론 우도비(IRT-LR) 검정에 대해 설명했습니다. MH 방법과 로지스틱 회귀분석은 difR 패키지(Magis et al., 2010)를, IRT-LR 검정은 mirt 패키지(Chalmers, 2012)를 사용하여 시연했습니다. 여기서 소개한 세 가지 DIF 검출 방법 중 IRT-LR 검사는 문항 유형(이분 대 다분) 및 DIF 유형(균일 대 비균일)에 따라 가장 유연하게 적용할 수 있는 방법입니다. 그러나 IRT-LR 검사에서는 미리 지정된 IRT 모델을 사용해야 한다는 점에 유의해야 합니다(IRT 모델에 대한 자세한 내용은 제5장부터 제7장까지 참조). 이 장에서는 다루지 않았지만 semTools(semTools Contributors, 2016)는 measurementinvariance 함수를 통해 모든 측정 불변성 단계를 자동화할 수 있으며, lordif 패키지(Choi, Gibbons, & Crane, 2016)는 이분 및 다분 문항 모두에 대한 DIF를 검사하기 위한 추가적인 함수를 제공합니다."
  },
  {
    "objectID": "chap12.html#개요",
    "href": "chap12.html#개요",
    "title": "12  측정의 고급 주제",
    "section": "12.1 개요",
    "text": "12.1 개요\n마지막 장에서는 교육 및 심리학 분야의 연구자 및 실무자가 관심을 가질 만한 다른 R 패키지에 대한 간략한 개요를 제공합니다. 이러한 패키지는 본서에 포함하지 않은 고급 심리측정 방법에 중점을 둡니다."
  },
  {
    "objectID": "chap12.html#cran-작업-보기",
    "href": "chap12.html#cran-작업-보기",
    "title": "12  측정의 고급 주제",
    "section": "12.2 CRAN 작업 보기",
    "text": "12.2 CRAN 작업 보기\nCRAN 작업 보기1의 핵심은 관련 R 패키지 모음을 빠르고 쉽게 설치할 수 있는 메타 패키지입니다. 작업 보기는 R 커뮤니티의 구성원이 큐레이션하고 유지 관리합니다. 작업 뷰를 설치하면 해당 특정 작업 뷰에 포함된 모든 패키지가 설치됩니다. 따라서 작업 보기를 사용하면 개별적으로 패키지를 설치할 필요 없이 관련 패키지를 효율적으로 설치하고 업데이트할 수 있지만, R을 업데이트하거나 새 컴퓨터로 이동할 때 원하는 R 패키지를 다시 설치하기 위해 별도의 R 스크립트를 유지 관리해야 할 필요성이 완전히 사라지지는 않습니다. 또한 작업 보기는 특히 좀 더 난해한 방법이 필요한 경우 R 에코시스템의 관련 패키지에 대해 학습할 수 있는 좋은 방법입니다.\n그래픽(제9장에서 언급했듯이), 베이지안 추론, 기계 학습 등 통계 내 다양한 영역에 대한 작업 보기가 존재합니다. 본서의 독자들이 특히 관심을 가질 만한 것은 심리측정(Psychometrics라고 함)과 사회과학(SocialSciences라고 함)을 위한 CRAN 작업 보기입니다. 이러한 작업 보기에는 이 책 전체에서 설명하는 많은 패키지(mirt, lavaan, psych 및 equate 포함)와 다양한 관련 하위 영역의 패키지가 설치되어 있습니다. 예를 들어, 심리측정 작업 보기에는 문항 반응 이론, 대응 분석 및 최적 척도법, 데이터 축소(예: 요인 분석 및 주성분 분석), 구조 방정식 모델링, 고전적 검사 이론, 다차원 척도법 등과 관련된 패키지가 설치되어 있습니다.\n작업 보기를 설치하려면 먼저 ctv 패키지를 설치하고 로드해야 합니다. (Zeileis, 2005).\n\n#install.packages(\"ctv\")\nlibrary(\"ctv\")\n\nctv 패키지에는 사용자에게 필요할 수 있는 두 가지 함수가 있습니다. Psychometrics task view와 같은 작업 보기를 설치하려면 다음과 같이 입력합니다.\n\n#install.views(\"Psychometrics\")\n\n이 작업 보기 내에서 패키지를 업데이트하려면 다음과 같이 입력합니다.\n\n#update.views(\"Psychometrics\")\n\n작업 보기로 작업할 때 두 가지 중요한 주의 사항이 있습니다. 첫째, 어떤 패키지는 한 플랫폼에서만 사용할 수 있고 다른 플랫폼에서는 사용할 수 없는 경우가 있습니다(예: 어떤 패키지는 Windows에서만 사용할 수 있고 Mac이나 Linux에서는 사용할 수 없는 경우가 있습니다). 둘째, 작업 보기를 설치하면 작업 보기의 핵심 패키지와 종속성을 고려한 후 수백 개의 패키지를 설치할 수 있습니다. 따라서 디스크 공간이나 인터넷 대역폭이 문제가 되는 경우 패키지를 개별적으로 설치하고 패키지 설치를 위한 별도의 R 스크립트를 유지하는 것이 더 나을 수 있습니다."
  },
  {
    "objectID": "chap12.html#컴퓨터-적응-검사",
    "href": "chap12.html#컴퓨터-적응-검사",
    "title": "12  측정의 고급 주제",
    "section": "12.3 컴퓨터 적응 검사",
    "text": "12.3 컴퓨터 적응 검사\n컴퓨터 적응 검사(CAT)는 피험자의 응답 패턴(예: 문항이 이분으로 채점되는 경우 정답 또는 오답)에 따라 대규모 문제 은행에서 선택된 고유한 문항 세트를 각 피험자에게 제공하는 고급 검사 관리 시스템입니다. CAT의 기본 원칙은 피험자의 잠재 특성 수준에 따라 너무 쉽거나 어려운 문항을 많이 출제하는 대신 가장 적절한 문항을 출제하는 것입니다. 이러한 방식은 일반적으로 피험자의 잠재 특성 수준에 관계없이 많은 검사 문항으로 구성된 지필 및 컴퓨터 기반 시험에 비해 훨씬 적은 수의 문항으로 매우 정확한 잠재 특성 추정치를 산출하는 검사 시행을 가능하게 합니다.\n일반적인 CAT 시스템은 세 단계로 구성됩니다. 첫째, 피험자는 미리 결정된 잠재 특성 수준(예: \\(\\theta = 0\\))에 적합한 문항으로 검사를 시작하며, 이는 피험자의 초기 잠재 특성 수준으로 간주되기도 합니다. 둘째, 문항에 대한 피험자의 응답에 따라 CAT 시스템은 피험자의 잠재 특성 수준에 대한 업데이트된 추정치를 제공합니다. 셋째, 업데이트된 잠재 특성 수준에 따라 CAT 시스템은 문제 은행에서 가장 적합한 문항을 선택합니다. 이 반복 프로세스는 사전 결정된 검사 종료 기준(예: 최대 검사 문항 수, 잠재 특성에 대한 허용 가능한 표준 오차 수준)이 충족될 때까지 계속됩니다.\n연구자와 실무자는 종종 CAT의 타당성, 적용 가능성 및 계획에 관한 다양한 연구 질문에 답하기 위해 시뮬레이션 연구를 수행합니다. Thompson and Weiss(2011)는 CAT에서 시뮬레이션 연구의 세 가지 유형을 설명합니다.\n1. 이미 피험자 그룹에게 시행된 지필 또는 컴퓨터 기반 검사에 CAT를 사용할 수 있는지 조사하기 위한 사후 시뮬레이션,\n2. 가상의 검사 시나리오에서 다양한 CAT 접근법의 성능을 평가하기 위한 몬테카를로 시뮬레이션,\n3. 각 피험자가 문제 은행의 문항 중 적어도 일부에 답하는 지필 또는 컴퓨터 기반 검사에 대한 CAT의 타당성을 조사하기 위한 하이브리드 시뮬레이션.\nR에는 CAT 관련 시뮬레이션 연구를 수행하는 데 사용할 수 있는 여러 패키지가 있습니다. 연구자와 실무자를 위해 두 가지 패키지, mirtCAT(Chalmers, 2016)과 catR(Magis & Barrada, 2017)을 언급하고자 합니다. 두 패키지 모두 연구자와 실무자에게 고급 문항 선택 및 잠재 특성 추정 알고리즘을 사용하여 다양한 CAT 시나리오를 시뮬레이션할 수 있는 일련의 시뮬레이션 기능을 제공합니다.\ncatR 패키지는 단일차원 문항 반응 이론(IRT) 프레임워크에 따라 CAT에 대한 응답 패턴을 생성하는 루틴으로 구성됩니다. 시뮬레이션에는 이분 및 다분 IRT 모델을 모두 사용할 수 있습니다. 이 패키지는 잠재 특성 추정, 최적의 문항 선택, 시험 종료, 문항 노출 제어, 내용 균형 맞추기를 위한 다양한 고급 알고리즘을 제공합니다. randomCAT은 catR 패키지에서 시뮬레이션 연구를 설계하고 실행하는 주요 함수입니다. catR 패키지의 중요한 특징은 사용자가 온라인 및 오프라인 적응형 시험을 관리하기 위한 오픈 소스 플랫폼인 Concerto(http://concertoplatform.com/{_blank=““})를 사용하여 실제 CAT 관리를 설계하고 구현할 수 있다는 것입니다.\nmirtCAT 패키지를 사용하면 단일차원 및 다차원 IRT 프레임워크에서 CAT 시뮬레이션을 설계할 수 있습니다. catR 패키지와 마찬가지로 이분 및 다분 IRT 모델을 모두 시뮬레이션에 사용할 수 있습니다. 이 패키지를 통해 사용자는 다양한 검사 시나리오에서 적응형 검사와 비적응형 검사를 모두 설계할 수 있습니다. mirtCAT 패키지의 시뮬레이션 연구 설계 및 실행에는 mirtCAT 함수가 사용됩니다. mirtCAT 패키지는 실시간 적응형 또는 비적응형 검사를 관리하기 위한 HTML 인터페이스 생성(shiny 패키지 사용), 사후 및 몬테카를로 시뮬레이션 연구 실행, CAT 애플리케이션의 결과 시각화 등의 추가 기능도 제공합니다."
  },
  {
    "objectID": "chap12.html#인지-진단-모델링",
    "href": "chap12.html#인지-진단-모델링",
    "title": "12  측정의 고급 주제",
    "section": "12.4 인지 진단 모델링",
    "text": "12.4 인지 진단 모델링\n진단 분류 모델링이라고도 하는 인지 진단 모델링(CDM)은 지난 몇 년 동안 가장 인기 있는 심리측정 분야 중 하나였습니다. CDM은 IRT 프레임워크에서 잠재적 특성을 정의하는 데 사용되는 연속 척도가 아닌 불연속 척도(예: 숙달 대 비숙달)로 피험자의 여러 기술 또는 인지요소를 정의합니다. CDM 접근법은 문항에 답하는 데 필요한 각 기술 또는 인지요소에 대한 숙달 상태를 기반으로 피험자의 강점과 약점에 대한 진단 정보를 제공하는 것을 목표로 합니다. 다양한 인지 진단 모델에 대한 자세한 개요와 비교를 원하시는 독자는 Rupp, Templin, Henson(2010)과 de la Torre, Minchen(2014)을 살펴보시기 바랍니다.\n최근에는 CDM 프레임워크가 적응 검사와 같은 다른 심리측정 연구 분야에도 적용되고 있습니다. 인지 진단 컴퓨터 적응 검사(CD-CAT)는 CAT의 효율성과 정확성에 CDM에서 파생된 개별화된 진단 피드백을 결합한 것입니다(Cheng, 2009). 이러한 발전으로 CDM에 대한 관심이 높아지면서 R에서 CDM과 그 응용 프로그램에 대한 관심도 높아졌습니다. R의 CDM 패키지 수는 계속 증가하고 있지만, 두 가지 패키지를 언급하고자 합니다: CDM(George, Robitzsch, Kiefer, Groß, & Ünlü, 2016) 및 GDINA(Ma & de la Torre, 2017). 두 패키지 모두 이분 또는 다분 문항으로 진단 평가를 위한 인지 진단 모델을 추정하기 위한 다양한 도구를 제공합니다. 또한 GDINA 패키지는 사용자가 입력 파일을 업로드하고 다양한 인지 진단 모델에 대해 원하는 추정 옵션을 선택할 수 있는 그래픽 사용자 인터페이스를 제공합니다(자세한 내용은 GDINA의 startGDINA 함수 참조)."
  },
  {
    "objectID": "chap12.html#irt-linking-절차",
    "href": "chap12.html#irt-linking-절차",
    "title": "12  측정의 고급 주제",
    "section": "12.5 IRT Linking 절차",
    "text": "12.5 IRT Linking 절차\n제10장에서는 고전검사이론(CTT)의 맥락에서 다양한 동등화 설계(예: 단일 집단, 동등집단, 비동등집단)와 동등화 방법(예: 일반 선형 및 동백분위)을 설명했습니다. CTT의 동등화 과정은 서로 다른 시험 시행자 또는 피험자 집단의 시험 점수를 공통 척도에 배치하여 피험자 간에 의미 있는 점수 비교가 이루어질 수 있도록 하는 것을 목표로 합니다. CTT와 달리 IRT의 동등화 적용은 서로 다른 시험 관리 또는 피험자 그룹에서 얻은 문항 모수를 연결하여 검사 점수에 대한 공통 척도를 달성합니다. 따라서 IRT의 동등화 과정을 흔히 Linking이라고 합니다. IRT 연결 방법에는 동시 보정, Stocking-Lord 방법(Stocking & Lord, 1983), Haebara 방법(Haebara, 1980), 평균/평균 및 평균/시그마 방법(A. S. Cohen & Kim, 1998) 등이 있습니다. IRT 연결 방법에 대한 자세한 검토는 Lee and Ban(2009)과 Kolen and Brennan(2014)을 참고하시기 바랍니다.\nIRT linking 절차를 구현하기 위한 도구를 제공하는 여러 R 패키지가 있는데, plink(Weeks, 2010), equateIRT(Battauz, 2015), SNSequate(Gonzalez Burgos, 2017) 등이 있습니다. 이 중 plink 패키지는 단일차원 및 다차원 IRT 방법을 사용하여 여러 피험자 집단에 대해 이분 및 다분 문항으로 구성된 혼합 형식 검사를 연결할 수 있기 때문에 가장 포괄적인 패키지입니다. 이 패키지는 평균/시그마, 평균/평균, Haebara, Stocking-Lord linking 방법을 지원합니다. plink 함수는 단일차원 및 다차원 IRT linking 절차를 사용하여 혼합 형식 검사를 연결하기 위한 기본 함수입니다. 이 패키지에는 IRT 진점수 및 관찰 점수 동등화 방법을 위한 추가 함수도 포함되어 있습니다. equate는 단일차원 IRT 프레임워크에서 혼합 형식 검사에 대한 IRT 진점수 및 관찰 점수 동등화 수행을 위한 기본 함수입니다. 독자들은 Journal of Statistical Software(Weeks, 2010)에 실린 plink 논문을 통해 plink를 사용한 linking의 더 많은 예를 살펴볼 것을 권장합니다."
  },
  {
    "objectID": "chap12.html#측정의-베이지안-모델",
    "href": "chap12.html#측정의-베이지안-모델",
    "title": "12  측정의 고급 주제",
    "section": "12.6 측정의 베이지안 모델",
    "text": "12.6 측정의 베이지안 모델\n전통적인 통계 방법은 확률에 대한 빈도주의적 관점을 사용합니다. 즉, 사건이 발생할 확률은 무한히 많은 수의 복제된 연구, 실험, 시험 관리 등에서 해당 사건이 발생하는 상대적인 빈도입니다. 빈도주의적 관점과 달리 베이지안 관점은 확률을 신념의 정도에 따라 정의하며 확률에 대한 주관적인 관점을 나타냅니다.\n개념적으로 베이지안 통계는 베이즈 정리를 통해 이러한 주관적 관점(사전 분포라고 함)과 우도 함수(일반적으로 빈도주의 통계에 적합한 통계 모델)의 곱에 해당하는 확률 분포(사후 분포라고 함)를 도출해냅니다. 어떤 사전 분포를 지정해야 하는지에 대한 문제와 사전 분포가 비정보적일 수 있는지에 대한 논의가 뜨겁게 진행되어 왔습니다. 모든 모델이 주관적이지만, 베이지안 모델링은 이러한 이유로 인해 과거에 지나치게 주관적이라는 조롱을 받아왔습니다. 다행히도 이러한 논쟁은 대부분 가라앉았고 이제는 베이지안 방법의 유용성에 초점을 맞추고 있습니다.\n많은 사후 분포는 분석적으로 도출할 수 없고 계산 부담이 큰 마르코프 체인 몬테카를로 방법(Gelman et al., 2014)을 사용하여 근사치를 구해야 하기 때문에, 이러한 방법은 컴퓨팅 성능이 향상되고 더 복잡한 통계 문제를 해결하려는 욕구가 커지면서 최근에야 응용 분야에서 인기를 얻기 시작했습니다. 많은 통계 모델이 기존의 모델링 프레임워크에는 쉽게 맞출 수 없지만, 베이지안 모델에서는 사전 분포의 사용으로 인해 쉽게 맞출 수 있습니다.\n본서 전체에 걸쳐 빈도주의적 관점을 제시했지만, 빈도주의적 모델에 대한 편견이나 선호를 나타내려는 의도는 없습니다. 대신, 베이지안 모델을 고려하기 전에 빈도주의 모델을 충분히 이해해야 한다고 생각합니다. 그 이유는 많은 베이지안 모델이 기본 사전 분포를 가정하는데, 이는 애플리케이션에 적합할 수도 있고 적합하지 않을 수도 있으며, 이러한 수준의 복잡성을 추가하기 전에 모델을 이해하는 것이 중요하기 때문입니다. 그렇지 않으면 이미 큰 “블랙박스”에 추가 계층을 추가하는 것이 되기 때문입니다. 또한 빈도주의 모델을 적용하는 데 통계 이론에 대한 이해가 필요한지 여부는 논란의 여지가 있지만, 베이지안 모델은 확률 분포를 지정해야 한다는 점을 고려하면 최소한 통계 이론에 대한 기초적인 지식은 필요합니다. 수학적 배경 지식이 풍부한 독자에게는 Gelman 외(2014) 또는 Carlin and Louis(2008)를 추천합니다. 최소한의 통계 이론으로 보다 부드러운 입문이 필요한 독자에게는 Kruschke(2014)가 좋은 출발점이 될 것입니다.\nR에는 베이지안 측정 모델에 적합한 수많은 엔진과 라이브러리가 있습니다. 고급 베이지안 사용자를 위해 rjags(Plummer, 2016), runjags(Denwood, 2016), rstan(Stan Development Team, 2016) 패키지는 JAGS 및 Stan 모델링 플랫폼에 대한 R 인터페이스를 제공합니다. 이러한 라이브러리는 래퍼 함수 역할을 하며 사용자가 이러한 베이지안 프로그래밍 언어와 더 쉽게 상호 작용할 수 있도록 합니다. 이러한 플랫폼 사용의 단점은 사용자가 모델 구문을 작성하는 방법을 알아야 한다는 것입니다. 그러나 사용자가 모델을 작성할 수 있게 되면 이러한 라이브러리를 사용하여 베이지안 프레임워크 내에서 모든 측정 모델을 쉽게 맞출 수 있다는 장점이 있습니다.\n이 핸드북의 많은 독자는 이러한 라이브러리를 어렵게 느낄 수 있습니다. 다행히도 더 사용자 친화적인 다른 베이지안 패키지가 있습니다. 확인적 베이지안 잠재변수 모델을 맞추기 위해 blavaan 패키지(Merkle & Rosseel, 2016)를 사용할 수 있으며, 베이지안 탐색적 요인 모델을 맞추기 위해 BayesFM(Piatek, 2017) 또는 MCMCpack(Martin, Quinn, & Park, 2011) 패키지를 사용할 수 있습니다. 또한 MCMCpack 및 pscl(Jackman, 2015) 패키지를 사용하여 IRT 모델을 맞출 수 있습니다. 마지막으로 edstan 패키지(Furr, 2017)는 Stan 언어에 대한 일부 IRT 모델(예: Rasch, 2PL, 부분 점수 및 등급 척도 모델)을 추정하는 데 편리한 패키지이며, 몇 가지 제한 사항이 있지만 Stan과 인터페이스하는 데 사용할 수 있습니다.\n이러한 패키지 중 다수는 이전 분포를 지정하는 유연성에서 차이가 있습니다. 이러한 사양은 대부분의 분석에 적합할 수 있지만, 사용자가 사전 분포를 변경할 수 있는 민감도 분석은 모수 추정 및 모델 결과에 대한 사전 분포의 영향의 크기를 이해하고 정량화하는 방법으로 강력히 권장합니다."
  },
  {
    "objectID": "chap12.html#위계적-선형-분석hlm",
    "href": "chap12.html#위계적-선형-분석hlm",
    "title": "12  측정의 고급 주제",
    "section": "12.7 위계적 선형 분석(HLM)",
    "text": "12.7 위계적 선형 분석(HLM)\n측정 모델은 아니지만 위계적 선형 모델(HLM)2은 교육 및 사회 과학 분야에서 일반적이고 매우 중요한 통계 모델입니다. 참가자에 대한 데이터를 반복적으로 수집하거나 학교, 학군 등에 내재된 교실 내에 내재된 학생에 대한 데이터를 수집하는 경우 이러한 관찰은 독립적이지 않으며, 참가자 내 또는 교실 내 학생 간의 잔차는 상관관계가 있습니다. HLM을 사용하면 이러한 독립성 부족을 통계적으로 통제할 수 있으며, 이는 표준 오차 및 추정 모수에 영향을 미칩니다. 또한 무선 표본의 교사에게 평가를 실시할 수 있지만, 해당 교사에게만 관심이 있는 것이 아니라(즉, 교사를 고정 효과로 취급) 모든 교사에게 관심이 있는 것(즉, 교사를 무선 효과로 취급)일 수 있습니다. 이 작업은 HLM 내에서 수행할 수 있습니다.3\n제3장에 제시된 일반화 가능도 이론 모델과 제8장에 제시된 설명적 IRT 모델은 실제로는 변형된 HLM에 불과합니다. 그렇기 때문에 두 사례 모두에서 일반적으로 사용되는 단일 HLM용 R 패키지인 lme4(Bates et al., 2015)가 사용되었습니다. lme4 패키지는 선형 혼합 효과(결과 변수가 조건부 정규 분포라고 가정할 때)와 일반화된 선형 혼합 효과(결과 변수가 이항, 푸아송, 감마 또는 기타 분포를 가질 수 있는 경우, 잠재적 분포 목록은 ?family 참조)를 모두 맞출 수 있습니다. lme4의 주요 함수는 선형 혼합 효과 모델을 맞추기 위한 lmer와 일반화된 선형 혼합 효과 모델을 맞추기 위한 glmer입니다. 두 함수 모두 최소 하나의 무선 효과가 필요하며, 그렇지 않으면 일반 선형(예: 다중 회귀) 또는 일반화된 선형 회귀(예: 로지스틱 회귀) 중 하나를 수행해야 합니다. lme4 외에도, 일반적으로 기본 R 설치에 포함되어 있는 nlme 패키지(Pinheiro, Bates, DebRoy, Sarkar, & R Core Team, 2017)는 선형 혼합 효과 모델뿐만 아니라 lme4에서 사용할 수 없는 더 복잡한 오차 구조에도 적합할 수 있습니다.\nlme4를 사용하는 실무자는 자신의 모델에서 p값을 사용할 수 없는 반면, nlme에서는 사용할 수 있다는 사실에 당황할 수 있습니다. 그러나 HLM에서 이를 계산할 수 있는 몇 가지 옵션이 있습니다.4 또한 lmerTest 패키지(Kuznetsova, Bruun Brockhoff, & Haubo Bojesen Christensen, 2016)는 lme4 패키지를 통해 얻은 모수 추정치(특히 lmer 및 glmer 함수 사용)에 대한 p-값을 생성할 수 있습니다. 그럼에도 불구하고, 이것이 NLME 또는 LME4 중 하나를 선택하는 데 영향을 미쳐서는 안 됩니다. 일반적으로 lme4는 활발히 개발되고 있기 때문에 사용하고, lme4로 추정할 수 없는 모델에 맞출 필요가 있을 때만 nlme로 이동합니다.\n마지막으로, R에서 이러한 모델을 맞추는 데 관한 훌륭한 책이 많이 있습니다. 여기에는 nlme의 저자와 lme4의 저자 중 한 명이 쓴 혼합 효과 책이 포함됩니다(Pinheiro & Bates, 2006). 이 책은 R의 전신인 S의 nlme 라이브러리를 위해 작성되었지만, 본문에 설명된 코드와 통계적 방법은 R에서도 동일하며 오늘날에도 여전히 적용 가능합니다. Faraway(2014, 2016)의 일반 회귀 모델링 서적은 HLM을 위한 또 다른 훌륭한 리소스입니다. Faraway(2016)에서 저자는 일반화된 선형 모델링 및 비모수 회귀뿐만 아니라 HLM에 대해서도 설명합니다. 마지막으로, Gelman과 Hill(2007)이 쓴 다목적 회귀 및 데이터 분석 책은 데이터 분석이 필요한 실무자, 시뮬레이션을 실행하는 방법과 이유를 알아야 하는 실무자, R에서 HLM을 실행하려는 실무자에게 훌륭한 리소스입니다. Gelman과 Hill(2007)은 기초부터 시작하여 R을 사용한 베이지안 HLM까지 빠르게 진행하지만 가독성이 높고 연구자 및 실무자를 위한 많은 실질적인 조언으로 가득 차 있습니다."
  },
  {
    "objectID": "chap12.html#프로파일-분석",
    "href": "chap12.html#프로파일-분석",
    "title": "12  측정의 고급 주제",
    "section": "12.8 프로파일 분석",
    "text": "12.8 프로파일 분석\n프로파일 분석은 관찰 점수를 수준 및 패턴 효과로 비직교적으로 분해하기 위해 교육, 심리학 및 의학 분야의 연구자들이 널리 사용하는 기법입니다. R의 profileR 패키지(Bulut & Desjardins, 2017)에는 준거 관련 프로파일 분석(M. L. Davison & Davenport, 2002), 다차원 척도를 통한 프로파일 분석(M. L. Davison, 1994), 조절된 프로파일 분석, 집단별 프로파일 분석, 프로파일 신뢰도(Bulut, 2013; Bulut et al., 2017), 요인 모델을 사용하여 도출한 개인 내 점수 프로파일(M. L. Davison, Kim, & Close, 2009)을 수행할 수 있는 루틴이 포함되어 있습니다. profileR 패키지를 통해 연구자는 특정 효과(예: 수준 또는 패턴)와 관련된 변산성을 정량화하고, 프로파일에 대한 일련의 가설을 검정하고, 프로파일 그래프를 빠르게 생성하고, 추가 분석(예: 회귀)을 위한 정보를 추출할 수 있습니다.\nprofileR 패키지의 주요 기능으로는 준거 관련 프로필 분석을 위한 cpa, 조절된 프로파일 분석을 위한 mpa, 다차원 척도법을 통한 프로파일 분석을 위한 pams, 집단별 프로파일 분석을 위한 pbg, 개인 내 및 개인 간 프로파일 신뢰도를 위한 pr, 프로파일 그래프를 그리기 위한 profileplot 등이 있습니다. profileR 패키지에 대한 자세한 내용은 패키지 매뉴얼을 참조하시기 바랍니다."
  },
  {
    "objectID": "chap12.html#요약",
    "href": "chap12.html#요약",
    "title": "12  측정의 고급 주제",
    "section": "12.9 요약",
    "text": "12.9 요약\n이 장에서는 이 책에서 다루지 않은 교육 및 심리학 분야의 연구자 및 실무자가 관심을 가질 만한 R 패키지를 개괄적으로 소개했습니다. CRAN 작업 보기, CAT에서 시뮬레이션 연구를 수행하기 위한 catR 및 mirtCAT 패키지, 인지 진단 모델 추정을 위한 CDM 및 GDINA 패키지, 단일차원 및 다차원 IRT 모델에서 linking 절차를 위한 plink 패키지, 위계적 선형 및 비선형 모델 추정을 위한 lme4 및 nlme 패키지, 프로파일 분석을 수행하기 위한 profileR 패키지에 대해 설명했습니다. 또한, 베이지안 모델을 추정하고 JAGS 및 Stan과 같은 다른 베이지안 소프트웨어 프로그램과 상호 작용할 수 있는 여러 R 패키지에 대해서도 언급했습니다."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  }
]